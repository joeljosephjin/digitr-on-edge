{
  "version": 3,
  "sources": ["../../../common/lib/backend-impl.ts", "../../../common/lib/backend.ts", "../../../common/lib/version.ts", "../../../common/lib/env-impl.ts", "../../../common/lib/env.ts", "../../../common/lib/tensor-conversion-impl.ts", "../../../common/lib/tensor-factory-impl.ts", "../../../common/lib/tensor-impl-type-mapping.ts", "../../../common/lib/tensor-utils-impl.ts", "../../../common/lib/tensor-impl.ts", "../../../common/lib/tensor.ts", "../../../common/lib/inference-session-impl.ts", "../../../common/lib/inference-session.ts", "../../../common/lib/onnx-value.ts", "../../../common/lib/training-session-impl.ts", "../../../common/lib/training-session.ts", "../../../common/lib/index.ts", "nodejs-ignore:fs", "nodejs-ignore:path", "../../lib/wasm/binding/ort-wasm-simd.jsep.js", "nodejs-ignore:worker_threads", "nodejs-ignore:perf_hooks", "nodejs-ignore:os", "../../lib/wasm/binding/ort-wasm-simd-threaded.jsep.js", "../../lib/wasm/binding/ort-wasm-threaded.worker.js", "../../lib/wasm/wasm-factory.ts", "../../lib/wasm/wasm-utils.ts", "../../lib/wasm/run-options.ts", "../../lib/wasm/session-options.ts", "../../lib/wasm/wasm-common.ts", "../../lib/wasm/jsep/log.ts", "../../lib/wasm/jsep/tensor-view.ts", "../../lib/wasm/jsep/webgpu/types.ts", "../../lib/wasm/jsep/webgpu/gpu-data-manager.ts", "../../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts", "../../lib/wasm/jsep/util.ts", "../../lib/wasm/jsep/webgpu/ops/common.ts", "../../lib/wasm/jsep/webgpu/ops/transpose.ts", "../../lib/wasm/jsep/webgpu/ops/reduce-shared.ts", "../../lib/wasm/jsep/webgpu/ops/reduce.ts", "../../lib/wasm/jsep/webgpu/ops/argminmax.ts", "../../lib/wasm/jsep/webgpu/ops/bias-add.ts", "../../lib/wasm/jsep/webgpu/ops/unary-op.ts", "../../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts", "../../lib/wasm/jsep/webgpu/ops/binary-op.ts", "../../lib/wasm/jsep/webgpu/ops/concat.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts", "../../lib/wasm/jsep/webgpu/ops/fuse-utils.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-grouped.ts", "../../lib/wasm/jsep/webgpu/ops/conv.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-transpose.ts", "../../lib/wasm/jsep/webgpu/ops/einsum.ts", "../../lib/wasm/jsep/webgpu/ops/expand.ts", "../../lib/wasm/jsep/webgpu/ops/gather.ts", "../../lib/wasm/jsep/webgpu/ops/gather-elements.ts", "../../lib/wasm/jsep/webgpu/ops/gemm.ts", "../../lib/wasm/jsep/webgpu/ops/instance-norm.ts", "../../lib/wasm/jsep/webgpu/ops/layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/matmul.ts", "../../lib/wasm/jsep/webgpu/ops/pad.ts", "../../lib/wasm/jsep/webgpu/ops/pool.ts", "../../lib/wasm/jsep/webgpu/ops/range.ts", "../../lib/wasm/jsep/webgpu/ops/resize.ts", "../../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/slice.ts", "../../lib/wasm/jsep/webgpu/ops/softmax.ts", "../../lib/wasm/jsep/webgpu/ops/split.ts", "../../lib/wasm/jsep/webgpu/ops/tile.ts", "../../lib/wasm/jsep/webgpu/ops/where.ts", "../../lib/wasm/jsep/webgpu/op-resolve-rules.ts", "../../lib/wasm/jsep/webgpu/program-manager.ts", "../../lib/wasm/jsep/backend-webgpu.ts", "../../lib/wasm/jsep/init.ts", "../../lib/wasm/wasm-core-impl.ts", "proxy-worker:./proxy-worker/main", "../../lib/wasm/proxy-wrapper.ts", "../../lib/wasm/session-handler-inference.ts", "../../lib/backend-wasm.ts", "../../lib/backend-wasm-inference.ts", "../../lib/index.ts", "../../lib/version.ts"],
  "sourcesContent": ["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession} from './training-session.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a handler instance of a training inference session.\n *\n * @ignore\n */\nexport interface TrainingSessionHandler extends SessionHandler {\n  runTrainStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(): Promise<void>;\n\n  createInferenceSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n\n  createTrainingSessionHandler?\n      (checkpointStateUriOrBuffer: TrainingSession.URIorBuffer, trainModelUriOrBuffer: TrainingSession.URIorBuffer,\n       evalModelUriOrBuffer: TrainingSession.URIorBuffer, optimizerModelUriOrBuffer: TrainingSession.URIorBuffer,\n       options: InferenceSession.SessionOptions): Promise<TrainingSessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl.js';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0-dev.20231103-1439da36fe';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\ntype NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor|NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {SessionHandler, TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\ntype FeedsType = InferenceSession.FeedsType;\ntype FetchesType = InferenceSession.FetchesType;\ntype ReturnType = InferenceSession.ReturnType;\ntype RunOptions = InferenceSession.RunOptions;\n\nconst noBackendErrMsg: string = 'Training backend could not be resolved. ' +\n    'Make sure you\\'re using the correct configuration & WebAssembly files.';\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    const evalModel: string|Uint8Array = trainingOptions.evalModel || '';\n    const optimizerModel: string|Uint8Array = trainingOptions.optimizerModel || '';\n    const options: SessionOptions = sessionOptions || {};\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    if (backend.createTrainingSessionHandler) {\n      const handler = await backend.createTrainingSessionHandler(\n          trainingOptions.checkpointState, trainingOptions.trainModel, evalModel, optimizerModel, options);\n      return new TrainingSession(handler);\n    } else {\n      throw new Error(noBackendErrMsg);\n    }\n  }\n\n  /**\n   * Helper function for runTrainStep and future runStep methods that handles the type-narrowing conversion from\n   * the given parameters to SessionHandler.FetchesType and RunOptions.\n   *\n   * @param feeds the required input\n   * @param arg1 narrowed & converted into the SessionHandler.FetchesType or RunOptions object\n   * @param arg2 optional RunOptions object.\n   * @returns\n   */\n  typeNarrowingForRunStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions):\n      [SessionHandler.FetchesType, RunOptions] {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSession.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    return [fetches, options];\n  }\n\n  /**\n   * Helper method for runTrainStep and any other runStep methods. Takes the ReturnType result from the SessionHandler\n   * and changes it into a map of Tensors.\n   *\n   * @param results\n   * @returns\n   */\n  convertHandlerReturnTypeToMapOfTensors(results: SessionHandler.ReturnType): ReturnType {\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  runTrainStep(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  runTrainStep(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async runTrainStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const [fetches, options] = this.typeNarrowingForRunStep(feeds, arg1, arg2);\n    const results = await this.handler.runTrainStep(feeds, fetches, options);\n    return this.convertHandlerReturnTypeToMapOfTensors(results);\n  }\n\n  async loadParametersBuffer(_array: Uint8Array, _trainableOnly: boolean): Promise<void> {\n    throw new Error('Method not implemented.');\n  }\n\n  async getContiguousParameters(_trainableOnly: boolean): Promise<Uint8Array> {\n    throw new Error('Method not implemented.');\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n  /**\n   * Copies from a buffer containing parameters to the TrainingSession parameters.\n   *\n   * @param buffer - buffer containing parameters\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies from the TrainingSession parameters to a buffer.\n   *\n   * @param trainableOnly - True if trainable parameters only to be copied, false othrwise.\n   * @returns A promise that resolves to a buffer of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './onnx-value.js';\nexport * from './training-session.js';\n", "export const readFile = undefined;", "export const join = undefined;", "\r\nvar ortWasm = (() => {\r\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\r\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\r\n  return (\r\nfunction(moduleArg = {}) {\r\n\r\nvar d=moduleArg,aa,h;d.ready=new Promise((a,b)=>{aa=a;h=b});\"use strict\";\r\nd.jsepInit=(a,b,c,e,g,k,l,t)=>{d.Za=a;d.Oa=b;d.Qa=c;d.Ja=e;d.Pa=g;d.ra=k;d.Ra=l;d.Sa=t;b=(m,p,n)=>(...u)=>{const w=r,f=p?.();u=m(...u);const q=p?.();f!==q&&(m=q,n(f),p=n=null);return r!=w?ba():u};c=m=>async(...p)=>{try{if(d.Da)throw Error(\"Session already started\");const n=d.Da={Ta:p[0],errors:[]},u=await m(...p);if(d.Da!==n)throw Error(\"Session mismatch\");a.flush();const w=n.errors;if(0<w.length){let f=await Promise.all(w);f=f.filter(q=>q);if(0<f.length)throw Error(f.join(\"\\n\"));}return u}finally{d.Da=\r\nnull}};d._OrtRun=c(b(d._OrtRun,()=>d._OrtRun,m=>d._OrtRun=m));d._OrtRunWithBinding=c(b(d._OrtRunWithBinding,()=>d._OrtRunWithBinding,m=>d._OrtRunWithBinding=m));d._OrtBindInput=b(d._OrtBindInput,()=>d._OrtBindInput,m=>d._OrtBindInput=m);d.jsepRegisterBuffer=(m,p,n,u)=>a.registerBuffer(m,p,n,u);d.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};d.jsepGetBuffer=m=>a.getBuffer(m);d.jsepCreateDownloader=(m,p,n)=>a.createDownloader(m,p,n)};\r\nvar ca=Object.assign({},d),x=\"./this.program\",y=(a,b)=>{throw b;},da=\"object\"==typeof window,z=\"function\"==typeof importScripts,ea=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,A=\"\",B,C,D;\r\nif(ea){var fs=require(\"fs\"),fa=require(\"path\");A=z?fa.dirname(A)+\"/\":__dirname+\"/\";B=(a,b)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);return fs.readFileSync(a,b?void 0:\"utf8\")};D=a=>{a=B(a,!0);a.buffer||(a=new Uint8Array(a));return a};C=(a,b,c,e=!0)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);fs.readFile(a,e?void 0:\"utf8\",(g,k)=>{g?c(g):b(e?k.buffer:k)})};!d.thisProgram&&1<process.argv.length&&(x=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);y=(a,b)=>{process.exitCode=\r\na;throw b;};d.inspect=()=>\"[Emscripten Module object]\"}else if(da||z)z?A=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(A=document.currentScript.src),_scriptDir&&(A=_scriptDir),0!==A.indexOf(\"blob:\")?A=A.substr(0,A.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):A=\"\",B=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},z&&(D=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),\r\nC=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)};var ha=d.print||console.log.bind(console),E=d.printErr||console.error.bind(console);Object.assign(d,ca);ca=null;d.thisProgram&&(x=d.thisProgram);d.quit&&(y=d.quit);var F;d.wasmBinary&&(F=d.wasmBinary);var noExitRuntime=d.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&H(\"no native wasm support detected\");\r\nvar I,J,K=!1,L,M,N,O,P,ia,ja;function ka(){var a=I.buffer;d.HEAP8=M=new Int8Array(a);d.HEAP16=new Int16Array(a);d.HEAP32=O=new Int32Array(a);d.HEAPU8=N=new Uint8Array(a);d.HEAPU16=new Uint16Array(a);d.HEAPU32=P=new Uint32Array(a);d.HEAPF32=ia=new Float32Array(a);d.HEAPF64=ja=new Float64Array(a)}var la=[],ma=[],na=[];function oa(){var a=d.preRun.shift();la.unshift(a)}var Q=0,pa=null,R=null;\r\nfunction H(a){if(d.onAbort)d.onAbort(a);a=\"Aborted(\"+a+\")\";E(a);K=!0;L=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");h(a);throw a;}function qa(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var S;S=\"ort-wasm-simd.wasm\";if(!qa(S)){var ra=S;S=d.locateFile?d.locateFile(ra,A):A+ra}function sa(a){if(a==S&&F)return new Uint8Array(F);if(D)return D(a);throw\"both async and sync fetching of the wasm failed\";}\r\nfunction ta(a){if(!F&&(da||z)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>sa(a));if(C)return new Promise((b,c)=>{C(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>sa(a))}function ua(a,b,c){return ta(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{E(\"failed to asynchronously prepare wasm: \"+e);H(e)})}\r\nfunction va(a,b){var c=S;return F||\"function\"!=typeof WebAssembly.instantiateStreaming||qa(c)||c.startsWith(\"file://\")||ea||\"function\"!=typeof fetch?ua(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(g){E(\"wasm streaming compile failed: \"+g);E(\"falling back to ArrayBuffer instantiation\");return ua(c,a,b)}))}\r\nvar T,wa={913792:a=>{d.ra(\"Abs\",a,void 0)},913843:a=>{d.ra(\"Neg\",a,void 0)},913894:a=>{d.ra(\"Floor\",a,void 0)},913947:a=>{d.ra(\"Ceil\",a,void 0)},913999:a=>{d.ra(\"Reciprocal\",a,void 0)},914057:a=>{d.ra(\"Sqrt\",a,void 0)},914109:a=>{d.ra(\"Exp\",a,void 0)},914160:a=>{d.ra(\"Erf\",a,void 0)},914211:a=>{d.ra(\"Sigmoid\",a,void 0)},914266:a=>{d.ra(\"Log\",a,void 0)},914317:a=>{d.ra(\"Sin\",a,void 0)},914368:a=>{d.ra(\"Cos\",a,void 0)},914419:a=>{d.ra(\"Tan\",a,void 0)},914470:a=>{d.ra(\"Asin\",a,void 0)},914522:a=>{d.ra(\"Acos\",\r\na,void 0)},914574:a=>{d.ra(\"Atan\",a,void 0)},914626:a=>{d.ra(\"Sinh\",a,void 0)},914678:a=>{d.ra(\"Cosh\",a,void 0)},914730:a=>{d.ra(\"Asinh\",a,void 0)},914783:a=>{d.ra(\"Acosh\",a,void 0)},914836:a=>{d.ra(\"Atanh\",a,void 0)},914889:a=>{d.ra(\"Tanh\",a,void 0)},914941:a=>{d.ra(\"Not\",a,void 0)},914992:(a,b,c)=>{d.ra(\"ClipV10\",a,{min:b,max:c})},915064:a=>{d.ra(\"Clip\",a,void 0)},915116:(a,b)=>{d.ra(\"Elu\",a,{alpha:b})},915174:a=>{d.ra(\"Relu\",a,void 0)},915226:(a,b)=>{d.ra(\"LeakyRelu\",a,{alpha:b})},915290:(a,b)=>\r\n{d.ra(\"ThresholdedRelu\",a,{alpha:b})},915360:(a,b)=>{d.ra(\"Cast\",a,{to:b})},915418:a=>{d.ra(\"Add\",a,void 0)},915469:a=>{d.ra(\"Sub\",a,void 0)},915520:a=>{d.ra(\"Mul\",a,void 0)},915571:a=>{d.ra(\"Div\",a,void 0)},915622:a=>{d.ra(\"Pow\",a,void 0)},915673:a=>{d.ra(\"Equal\",a,void 0)},915726:a=>{d.ra(\"Greater\",a,void 0)},915781:a=>{d.ra(\"GreaterOrEqual\",a,void 0)},915843:a=>{d.ra(\"Less\",a,void 0)},915895:a=>{d.ra(\"LessOrEqual\",a,void 0)},915954:(a,b,c,e,g)=>{d.ra(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\r\naxes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},916118:(a,b,c,e,g)=>{d.ra(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},916281:(a,b,c,e,g)=>{d.ra(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},916444:(a,b,c,e,g)=>{d.ra(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},916608:(a,b,c,e,g)=>{d.ra(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\r\naxes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},916771:(a,b,c,e,g)=>{d.ra(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},916933:(a,b,c,e,g)=>{d.ra(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},917095:(a,b,c,e,g)=>{d.ra(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},917261:(a,b,c,e,g)=>{d.ra(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\r\naxes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},917430:(a,b,c,e,g)=>{d.ra(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},917599:a=>{d.ra(\"Where\",a,void 0)},917652:(a,b,c)=>{d.ra(\"Transpose\",a,{perm:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[]})},917765:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[g],pads:[k,l],strides:[t],wIsConst:()=>!!M[p>>>0],outputPadding:n?\r\nArray.from(O.subarray(u>>>0,u+n>>>0)):[],outputShape:w?Array.from(O.subarray(f>>>0,f+w>>>0)):[],activation:U(q)})},918179:(a,b,c,e,g,k,l,t,m,p,n,u,w,f)=>{d.ra(\"ConvTranspose\",a,{format:t?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(O.subarray(g>>>0,g+2>>>0)),pads:Array.from(O.subarray(k>>>0,k+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<p?Array.from(O.subarray(n>>>0,n+p>>>0)):[],outputShape:0<\r\nu?Array.from(O.subarray(w>>>0,w+u>>>0)):[],activation:U(f)})},918736:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[g],pads:[k,l],strides:[t],wIsConst:()=>!!M[p>>>0],outputPadding:n?Array.from(O.subarray(u>>>0,u+n>>>0)):[],outputShape:w?Array.from(O.subarray(f>>>0,f+w>>>0)):[],activation:U(q)})},919150:(a,b,c,e,g,k,l,t,m,p,n,u,w,f)=>{d.ra(\"ConvTranspose\",a,{format:t?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>\r\n0,c+2>>>0)),group:e,kernelShape:Array.from(O.subarray(g>>>0,g+2>>>0)),pads:Array.from(O.subarray(k>>>0,k+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<p?Array.from(O.subarray(n>>>0,n+p>>>0)):[],outputShape:0<u?Array.from(O.subarray(w>>>0,w+u>>>0)):[],activation:U(f)})},919707:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},919798:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q,v)=>{d.ra(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,\r\nstorage_order:g,dilations:[k,l],kernel_shape:[t,m],pads:[p,n,u,w],strides:[f,q]})},920082:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},920173:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q,v)=>{d.ra(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:g,dilations:[k,l],kernel_shape:[t,m],pads:[p,n,u,w],strides:[f,q]})},920457:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},920544:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q,v)=>{d.ra(\"MaxPool\",a,{format:v?\r\n\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:g,dilations:[k,l],kernel_shape:[t,m],pads:[p,n,u,w],strides:[f,q]})},920824:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},920911:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q,v)=>{d.ra(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:g,dilations:[k,l],kernel_shape:[t,m],pads:[p,n,u,w],strides:[f,q]})},921191:(a,b,c,e,g)=>{d.ra(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:g})},921295:a=>{d.ra(\"MatMul\",\r\na,void 0)},921349:(a,b,c,e)=>{d.ra(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},921457:(a,b,c,e)=>{d.ra(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},921565:(a,b)=>{d.ra(\"Softmax\",a,{axis:b})},921628:(a,b)=>{d.ra(\"Concat\",a,{axis:b})},921688:(a,b,c,e,g)=>{d.ra(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},921833:a=>{d.ra(\"Expand\",a,void 0)},921887:(a,b)=>{d.ra(\"Gather\",a,{axis:Number(b)})},921958:(a,b)=>{d.ra(\"GatherElements\",a,{axis:Number(b)})},\r\n922037:(a,b,c,e,g,k,l,t,m,p,n)=>{d.ra(\"Resize\",a,{antialias:b,axes:c?Array.from(O.subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:U(g),cubicCoeffA:k,excludeOutside:l,extrapolationValue:t,keepAspectRatioPolicy:U(m),mode:U(p),nearestMode:U(n)})},922388:(a,b,c,e,g,k,l)=>{d.ra(\"Slice\",a,{starts:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[],axes:k?Array.from(O.subarray(l>>>0,l+k>>>0)):[]})},922619:a=>{d.ra(\"Tile\",a,void 0)},922671:(a,b,c)=>{d.ra(\"LayerNormalization\",\r\na,{axis:Number(b),epsilon:Number(c)})},922778:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},922892:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},923006:a=>{d.ra(\"Range\",a,void 0)},923059:(a,b)=>{d.ra(\"Einsum\",a,{equation:U(b)})},923140:(a,b,c,e,g)=>{d.ra(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(O.subarray(g>>>0,g+e>>>0)):[]})},923272:a=>{d.ra(\"Gelu\",a,void 0)},923324:a=>{d.ra(\"BiasAdd\",a,void 0)},923379:a=>{d.ra(\"BiasSplitGelu\",a,void 0)},\r\n923440:(a,b)=>{d.ra(\"SkipLayerNormalization\",a,{epsilon:b})},923521:(a,b,c,e,g,k,l,t,m,p,n,u,w)=>{d.ra(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[g],pads:k?Array.from(O.subarray(l>>>0,l+k>>>0)):[],strides:[t],w_is_const:()=>!!M[p>>>0],activation:U(n),activation_params:u?Array.from(ia.subarray(w>>>0,w+u>>>0)):[]})},923902:(a,b,c,e,g,k,l,t,m,p,n,u,w,f,q,v)=>{d.ra(\"Conv\",a,{format:u?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:g,kernel_shape:[k,l],pads:t?Array.from(O.subarray(m>>>\r\n0,m+t>>>0)):[],strides:[p,n],w_is_const:()=>!!M[w>>>0],activation:U(f),activation_params:q?Array.from(ia.subarray(v>>>0,v+q>>>0)):[]})},924304:a=>{d.Ra(a)},924338:(a,b)=>d.Sa(a,b,d.Da.Ta,d.Da.errors),924450:a=>d.Oa(a),924483:a=>d.Qa(a),924515:(a,b,c)=>{d.Ja(a,b,c,!0)},924554:(a,b,c)=>{d.Ja(a,b,c)}};function xa(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}var ya=a=>{for(;0<a.length;)a.shift()(d)};\r\nfunction za(a){this.Ha=a-24;this.Ma=function(b){P[this.Ha+4>>2>>>0]=b};this.La=function(b){P[this.Ha+8>>2>>>0]=b};this.Ya=function(b,c){this.Ka();this.Ma(b);this.La(c)};this.Ka=function(){P[this.Ha+16>>2>>>0]=0}}\r\nvar Aa=0,Ba=0,Ca=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Da=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Ca)return Ca.decode(a.subarray(b,c));for(e=\"\";b<c;){var g=a[b++];if(g&128){var k=a[b++]&63;if(192==(g&224))e+=String.fromCharCode((g&31)<<6|k);else{var l=a[b++]&63;g=224==(g&240)?(g&15)<<12|k<<6|l:(g&7)<<18|k<<12|l<<6|a[b++]&63;65536>g?e+=String.fromCharCode(g):(g-=65536,e+=String.fromCharCode(55296|g>>10,56320|g&1023))}}else e+=String.fromCharCode(g)}return e},\r\nU=(a,b)=>(a>>>=0)?Da(N,a,b):\"\",Ea=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},Fa=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var g=c;e=c+e-1;for(var k=0;k<a.length;++k){var l=a.charCodeAt(k);if(55296<=l&&57343>=l){var t=a.charCodeAt(++k);l=65536+((l&1023)<<10)|t&1023}if(127>=l){if(c>=e)break;b[c++>>>0]=l}else{if(2047>=l){if(c+1>=e)break;b[c++>>>0]=192|l>>6}else{if(65535>=l){if(c+2>=e)break;b[c++>>>0]=224|l>>12}else{if(c+\r\n3>=e)break;b[c++>>>0]=240|l>>18;b[c++>>>0]=128|l>>12&63}b[c++>>>0]=128|l>>6&63}b[c++>>>0]=128|l&63}}b[c>>>0]=0;return c-g},V=a=>0===a%4&&(0!==a%100||0===a%400),Ga=[0,31,60,91,121,152,182,213,244,274,305,335],Ha=[0,31,59,90,120,151,181,212,243,273,304,334],Ja=a=>{var b=Ea(a)+1,c=Ia(b);c&&Fa(a,N,c,b);return c},Ka=[],La=(a,b)=>{Ka.length=0;var c;for(b>>=2;c=N[a++>>>0];)b+=105!=c&b,Ka.push(105==c?O[b>>>0]:ja[b++>>>1]),++b;return Ka},Na={},Pa=()=>{if(!Oa){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",\r\nPWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:x||\"./this.program\"},b;for(b in Na)void 0===Na[b]?delete a[b]:a[b]=Na[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Oa=c}return Oa},Oa,Qa=[null,[],[]],Ra=[31,29,31,30,31,30,31,31,30,31,30,31],Sa=[31,28,31,30,31,30,31,31,30,31,30,31];function Ta(a){var b=Array(Ea(a)+1);Fa(a,b,0,b.length);return b}\r\nfunction Ua(a,b,c,e){function g(f,q,v){for(f=\"number\"==typeof f?f.toString():f||\"\";f.length<q;)f=v[0]+f;return f}function k(f,q){return g(f,q,\"0\")}function l(f,q){function v(Ma){return 0>Ma?-1:0<Ma?1:0}var G;0===(G=v(f.getFullYear()-q.getFullYear()))&&0===(G=v(f.getMonth()-q.getMonth()))&&(G=v(f.getDate()-q.getDate()));return G}function t(f){switch(f.getDay()){case 0:return new Date(f.getFullYear()-1,11,29);case 1:return f;case 2:return new Date(f.getFullYear(),0,3);case 3:return new Date(f.getFullYear(),\r\n0,2);case 4:return new Date(f.getFullYear(),0,1);case 5:return new Date(f.getFullYear()-1,11,31);case 6:return new Date(f.getFullYear()-1,11,30)}}function m(f){var q=f.Ba;for(f=new Date((new Date(f.Ca+1900,0,1)).getTime());0<q;){var v=f.getMonth(),G=(V(f.getFullYear())?Ra:Sa)[v];if(q>G-f.getDate())q-=G-f.getDate()+1,f.setDate(1),11>v?f.setMonth(v+1):(f.setMonth(0),f.setFullYear(f.getFullYear()+1));else{f.setDate(f.getDate()+q);break}}v=new Date(f.getFullYear()+1,0,4);q=t(new Date(f.getFullYear(),\r\n0,4));v=t(v);return 0>=l(q,f)?0>=l(v,f)?f.getFullYear()+1:f.getFullYear():f.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var p=O[e+40>>2>>>0];e={Wa:O[e>>2>>>0],Va:O[e+4>>2>>>0],Ea:O[e+8>>2>>>0],Ia:O[e+12>>2>>>0],Fa:O[e+16>>2>>>0],Ca:O[e+20>>2>>>0],wa:O[e+24>>2>>>0],Ba:O[e+28>>2>>>0],$a:O[e+32>>2>>>0],Ua:O[e+36>>2>>>0],Xa:p?U(p):\"\"};c=U(c);p={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\r\n\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var n in p)c=c.replace(new RegExp(n,\"g\"),p[n]);var u=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),w=\"January February March April May June July August September October November December\".split(\" \");p={\"%a\":f=>u[f.wa].substring(0,3),\"%A\":f=>u[f.wa],\"%b\":f=>w[f.Fa].substring(0,\r\n3),\"%B\":f=>w[f.Fa],\"%C\":f=>k((f.Ca+1900)/100|0,2),\"%d\":f=>k(f.Ia,2),\"%e\":f=>g(f.Ia,2,\" \"),\"%g\":f=>m(f).toString().substring(2),\"%G\":f=>m(f),\"%H\":f=>k(f.Ea,2),\"%I\":f=>{f=f.Ea;0==f?f=12:12<f&&(f-=12);return k(f,2)},\"%j\":f=>{for(var q=0,v=0;v<=f.Fa-1;q+=(V(f.Ca+1900)?Ra:Sa)[v++]);return k(f.Ia+q,3)},\"%m\":f=>k(f.Fa+1,2),\"%M\":f=>k(f.Va,2),\"%n\":()=>\"\\n\",\"%p\":f=>0<=f.Ea&&12>f.Ea?\"AM\":\"PM\",\"%S\":f=>k(f.Wa,2),\"%t\":()=>\"\\t\",\"%u\":f=>f.wa||7,\"%U\":f=>k(Math.floor((f.Ba+7-f.wa)/7),2),\"%V\":f=>{var q=Math.floor((f.Ba+\r\n7-(f.wa+6)%7)/7);2>=(f.wa+371-f.Ba-2)%7&&q++;if(q)53==q&&(v=(f.wa+371-f.Ba)%7,4==v||3==v&&V(f.Ca)||(q=1));else{q=52;var v=(f.wa+7-f.Ba-1)%7;(4==v||5==v&&V(f.Ca%400-1))&&q++}return k(q,2)},\"%w\":f=>f.wa,\"%W\":f=>k(Math.floor((f.Ba+7-(f.wa+6)%7)/7),2),\"%y\":f=>(f.Ca+1900).toString().substring(2),\"%Y\":f=>f.Ca+1900,\"%z\":f=>{f=f.Ua;var q=0<=f;f=Math.abs(f)/60;return(q?\"+\":\"-\")+String(\"0000\"+(f/60*100+f%60)).slice(-4)},\"%Z\":f=>f.Xa,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(n in p)c.includes(n)&&(c=c.replace(new RegExp(n,\r\n\"g\"),p[n](e)));c=c.replace(/\\0\\0/g,\"%\");n=Ta(c);if(n.length>b)return 0;M.set(n,a>>>0);return n.length-1}function W(a){try{a()}catch(b){H(b)}}function Va(a){var b={},c;for(c in a)(function(e){var g=a[e];b[e]=\"function\"==typeof g?function(){X.push(e);try{return g.apply(null,arguments)}finally{K||(X.pop()===e||H(),r&&1===Y&&0===X.length&&(Y=0,W(Wa),\"undefined\"!=typeof Fibers&&Fibers.ab()))}}:g})(c);return b}var Y=0,r=null,Xa=0,X=[],Ya={},Za={},$a=0,ab=null,bb=[];\r\nfunction ba(){return new Promise((a,b)=>{ab={resolve:a,reject:b}})}function cb(){var a=Ia(65548),b=a+12;P[a>>2>>>0]=b;P[a+4>>2>>>0]=b+65536;b=X[0];var c=Ya[b];void 0===c&&(c=$a++,Ya[b]=c,Za[c]=b);O[a+8>>2>>>0]=c;return a}\r\nfunction db(a){if(!K){if(0===Y){var b=!1,c=!1;a((e=0)=>{if(!K&&(Xa=e,b=!0,c)){Y=2;W(()=>eb(r));\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.resume();e=!1;try{var g=(0,J[Za[O[r+8>>2>>>0]]])()}catch(t){g=t,e=!0}var k=!1;if(!r){var l=ab;l&&(ab=null,(e?l.reject:l.resolve)(g),k=!0)}if(e&&!k)throw g;}});c=!0;b||(Y=1,r=cb(),\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.pause(),W(()=>fb(r)))}else 2===Y?(Y=0,W(gb),hb(r),r=null,bb.forEach(e=>{if(!K)try{if(e(),!noExitRuntime)try{L=L=e=L;if(!noExitRuntime){if(d.onExit)d.onExit(e);\r\nK=!0}y(e,new xa(e))}catch(g){g instanceof xa||\"unwind\"==g||y(1,g)}}catch(g){g instanceof xa||\"unwind\"==g||y(1,g)}})):H(`invalid state: ${Y}`);return Xa}}function ib(a){return db(b=>{a().then(b)})}\r\nvar kb={n:function(a,b,c){return ib(async()=>{await d.Pa(a,b,c)})},a:function(a,b,c){a>>>=0;(new za(a)).Ya(b>>>0,c>>>0);Aa=a;Ba++;throw Aa;},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getUTCSeconds();O[c+4>>2>>>0]=\r\na.getUTCMinutes();O[c+8>>2>>>0]=a.getUTCHours();O[c+12>>2>>>0]=a.getUTCDate();O[c+16>>2>>>0]=a.getUTCMonth();O[c+20>>2>>>0]=a.getUTCFullYear()-1900;O[c+24>>2>>>0]=a.getUTCDay();O[c+28>>2>>>0]=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0},r:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getSeconds();O[c+4>>2>>>0]=a.getMinutes();O[c+8>>2>>>0]=a.getHours();O[c+12>>2>>>0]=a.getDate();O[c+16>>2>>>0]=a.getMonth();O[c+20>>2>>>\r\n0]=a.getFullYear()-1900;O[c+24>>2>>>0]=a.getDay();O[c+28>>2>>>0]=(V(a.getFullYear())?Ga:Ha)[a.getMonth()]+a.getDate()-1|0;O[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();O[c+32>>2>>>0]=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0},s:function(a){a>>>=0;var b=new Date(O[a+20>>2>>>0]+1900,O[a+16>>2>>>0],O[a+12>>2>>>0],O[a+8>>2>>>0],O[a+4>>2>>>0],O[a>>2>>>0],0),c=O[a+32>>2>>>0],e=b.getTimezoneOffset(),\r\ng=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),k=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),l=Math.min(k,g);0>c?O[a+32>>2>>>0]=Number(g!=k&&l==e):0<c!=(l==e)&&(g=Math.max(k,g),b.setTime(b.getTime()+6E4*((0<c?l:g)-e)));O[a+24>>2>>>0]=b.getDay();O[a+28>>2>>>0]=(V(b.getFullYear())?Ga:Ha)[b.getMonth()]+b.getDate()-1|0;O[a>>2>>>0]=b.getSeconds();O[a+4>>2>>>0]=b.getMinutes();O[a+8>>2>>>0]=b.getHours();O[a+12>>2>>>0]=b.getDate();O[a+16>>2>>>0]=b.getMonth();O[a+20>>2>>>0]=b.getYear();a=b.getTime()/\r\n1E3;return jb((T=a,1<=+Math.abs(T)?0<T?+Math.floor(T/4294967296)>>>0:~~+Math.ceil((T-+(~~T>>>0))/4294967296)>>>0:0)),a>>>0},o:function(){return-52},p:function(){},v:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}c>>>=0;var g=(new Date).getFullYear(),k=new Date(g,0,1),l=new Date(g,6,1);g=k.getTimezoneOffset();var t=l.getTimezoneOffset();P[a>>>0>>2>>>0]=60*Math.max(g,t);O[b>>>0>>2>>>0]=Number(g!=t);a=e(k);b=e(l);a=Ja(a);b=Ja(b);t<g?(P[c>>2>>>0]=a,P[c+\r\n4>>2>>>0]=b):(P[c>>2>>>0]=b,P[c+4>>2>>>0]=a)},e:()=>{H(\"\")},b:function(a,b,c){a>>>=0;b=La(b>>>0,c>>>0);return wa[a].apply(null,b)},i:function(a,b,c){a>>>=0;b=La(b>>>0,c>>>0);return wa[a].apply(null,b)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(a,b,c){b>>>=0;return N.copyWithin(a>>>0>>>0,b>>>0,b+(c>>>0)>>>0)},u:function(a){a>>>=0;var b=N.length;if(4294901760<a)return!1;for(var c=1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var g=Math;\r\ne=Math.max(a,e);a:{g=g.min.call(g,4294901760,e+(65536-e%65536)%65536)-I.buffer.byteLength+65535>>>16;try{I.grow(g);ka();var k=1;break a}catch(l){}k=void 0}if(k)return!0}return!1},D:function(a,b){a>>>=0;b>>>=0;var c=0;Pa().forEach(function(e,g){var k=b+c;g=P[a+4*g>>2>>>0]=k;for(k=0;k<e.length;++k)M[g++>>0>>>0]=e.charCodeAt(k);M[g>>0>>>0]=0;c+=e.length+1});return 0},E:function(a,b){a>>>=0;b>>>=0;var c=Pa();P[a>>2>>>0]=c.length;var e=0;c.forEach(function(g){e+=g.length+1});P[b>>2>>>0]=e;return 0},f:()=>\r\n52,k:function(){return 52},t:function(){return 70},j:function(a,b,c,e){b>>>=0;c>>>=0;e>>>=0;for(var g=0,k=0;k<c;k++){var l=P[b>>2>>>0],t=P[b+4>>2>>>0];b+=8;for(var m=0;m<t;m++){var p=N[l+m>>>0],n=Qa[a];0===p||10===p?((1===a?ha:E)(Da(n,0)),n.length=0):n.push(p)}g+=t}P[e>>2>>>0]=g;return 0},F:Ua,d:function(a,b,c,e){return Ua(a>>>0,b>>>0,c>>>0,e>>>0)}};\r\n(function(){function a(c){c=c.exports;c=Va(c);J=c=lb(c);I=J.M;ka();ma.unshift(J.N);Q--;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(0==Q&&(null!==pa&&(clearInterval(pa),pa=null),R)){var e=R;R=null;e()}return c}var b={a:kb};Q++;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(d.instantiateWasm)try{return d.instantiateWasm(b,a)}catch(c){E(\"Module.instantiateWasm callback failed with error: \"+c),h(c)}va(b,function(c){a(c.instance)}).catch(h);return{}})();\r\nd._OrtInit=(a,b)=>(d._OrtInit=J.O)(a,b);d._OrtGetLastError=(a,b)=>(d._OrtGetLastError=J.P)(a,b);d._OrtCreateSessionOptions=(a,b,c,e,g,k,l,t,m,p)=>(d._OrtCreateSessionOptions=J.Q)(a,b,c,e,g,k,l,t,m,p);d._OrtAppendExecutionProvider=(a,b)=>(d._OrtAppendExecutionProvider=J.R)(a,b);d._OrtAddFreeDimensionOverride=(a,b,c)=>(d._OrtAddFreeDimensionOverride=J.S)(a,b,c);d._OrtAddSessionConfigEntry=(a,b,c)=>(d._OrtAddSessionConfigEntry=J.T)(a,b,c);d._OrtReleaseSessionOptions=a=>(d._OrtReleaseSessionOptions=J.U)(a);\r\nd._OrtCreateSession=(a,b,c)=>(d._OrtCreateSession=J.V)(a,b,c);d._OrtReleaseSession=a=>(d._OrtReleaseSession=J.W)(a);d._OrtGetInputOutputCount=(a,b,c)=>(d._OrtGetInputOutputCount=J.X)(a,b,c);d._OrtGetInputName=(a,b)=>(d._OrtGetInputName=J.Y)(a,b);d._OrtGetOutputName=(a,b)=>(d._OrtGetOutputName=J.Z)(a,b);d._OrtFree=a=>(d._OrtFree=J._)(a);d._OrtCreateTensor=(a,b,c,e,g,k)=>(d._OrtCreateTensor=J.$)(a,b,c,e,g,k);d._OrtGetTensorData=(a,b,c,e,g)=>(d._OrtGetTensorData=J.aa)(a,b,c,e,g);\r\nd._OrtReleaseTensor=a=>(d._OrtReleaseTensor=J.ba)(a);d._OrtCreateRunOptions=(a,b,c,e)=>(d._OrtCreateRunOptions=J.ca)(a,b,c,e);d._OrtAddRunConfigEntry=(a,b,c)=>(d._OrtAddRunConfigEntry=J.da)(a,b,c);d._OrtReleaseRunOptions=a=>(d._OrtReleaseRunOptions=J.ea)(a);d._OrtCreateBinding=a=>(d._OrtCreateBinding=J.fa)(a);d._OrtBindInput=(a,b,c)=>(d._OrtBindInput=J.ga)(a,b,c);d._OrtBindOutput=(a,b,c,e)=>(d._OrtBindOutput=J.ha)(a,b,c,e);d._OrtClearBoundOutputs=a=>(d._OrtClearBoundOutputs=J.ia)(a);\r\nd._OrtReleaseBinding=a=>(d._OrtReleaseBinding=J.ja)(a);d._OrtRunWithBinding=(a,b,c,e,g)=>(d._OrtRunWithBinding=J.ka)(a,b,c,e,g);d._OrtRun=(a,b,c,e,g,k,l,t)=>(d._OrtRun=J.la)(a,b,c,e,g,k,l,t);d._OrtEndProfiling=a=>(d._OrtEndProfiling=J.ma)(a);d._JsepOutput=(a,b,c)=>(d._JsepOutput=J.na)(a,b,c);d._JsepGetNodeName=a=>(d._JsepGetNodeName=J.oa)(a);\r\nvar Ia=d._malloc=a=>(Ia=d._malloc=J.pa)(a),hb=d._free=a=>(hb=d._free=J.qa)(a),jb=a=>(jb=J.sa)(a),mb=()=>(mb=J.ta)(),nb=a=>(nb=J.ua)(a),ob=a=>(ob=J.va)(a),fb=a=>(fb=J.xa)(a),Wa=()=>(Wa=J.ya)(),eb=a=>(eb=J.za)(a),gb=()=>(gb=J.Aa)();d.___start_em_js=924587;d.___stop_em_js=924748;function lb(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>g=>e(g)>>>0;a.__errno_location=b(a.__errno_location);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}d.stackAlloc=ob;\r\nd.stackSave=mb;d.stackRestore=nb;d.UTF8ToString=U;d.stringToUTF8=(a,b,c)=>Fa(a,N,b,c);d.lengthBytesUTF8=Ea;var Z;R=function pb(){Z||qb();Z||(R=pb)};\r\nfunction qb(){function a(){if(!Z&&(Z=!0,d.calledRun=!0,!K)){ya(ma);aa(d);if(d.onRuntimeInitialized)d.onRuntimeInitialized();if(d.postRun)for(\"function\"==typeof d.postRun&&(d.postRun=[d.postRun]);d.postRun.length;){var b=d.postRun.shift();na.unshift(b)}ya(na)}}if(!(0<Q)){if(d.preRun)for(\"function\"==typeof d.preRun&&(d.preRun=[d.preRun]);d.preRun.length;)oa();ya(la);0<Q||(d.setStatus?(d.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){d.setStatus(\"\")},1);a()},1)):a())}}\r\nif(d.preInit)for(\"function\"==typeof d.preInit&&(d.preInit=[d.preInit]);0<d.preInit.length;)d.preInit.pop()();qb();\r\n\r\n\r\n  return moduleArg.ready\r\n}\r\n\r\n);\r\n})();\r\nif (typeof exports === 'object' && typeof module === 'object')\r\n  module.exports = ortWasm;\r\nelse if (typeof define === 'function' && define['amd'])\r\n  define([], () => ortWasm);\r\n", "", "", "export const cpus = undefined;", "\r\nvar ortWasmThreaded = (() => {\r\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\r\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\r\n  return (\r\nfunction(moduleArg = {}) {\r\n\r\nfunction d(){l.buffer!=n.buffer&&u();return n}function v(){l.buffer!=n.buffer&&u();return aa}function z(){l.buffer!=n.buffer&&u();return ba}function A(){l.buffer!=n.buffer&&u();return ca}function da(){l.buffer!=n.buffer&&u();return ea}function fa(){l.buffer!=n.buffer&&u();return ha}var B=moduleArg,ia,C;B.ready=new Promise((a,b)=>{ia=a;C=b});\"use strict\";\r\nB.jsepInit=(a,b,c,e,f,h,k,r)=>{B.Qb=a;B.wb=b;B.yb=c;B.jb=e;B.xb=f;B.Ea=h;B.zb=k;B.Ab=r;b=(p,m,q)=>(...w)=>{const y=D,g=m?.();w=p(...w);const t=m?.();g!==t&&(p=t,q(g),m=q=null);return D!=y?ja():w};c=p=>async(...m)=>{try{if(B.bb)throw Error(\"Session already started\");const q=B.bb={Fb:m[0],errors:[]},w=await p(...m);if(B.bb!==q)throw Error(\"Session mismatch\");a.flush();const y=q.errors;if(0<y.length){let g=await Promise.all(y);g=g.filter(t=>t);if(0<g.length)throw Error(g.join(\"\\n\"));}return w}finally{B.bb=\r\nnull}};B._OrtRun=c(b(B._OrtRun,()=>B._OrtRun,p=>B._OrtRun=p));B._OrtRunWithBinding=c(b(B._OrtRunWithBinding,()=>B._OrtRunWithBinding,p=>B._OrtRunWithBinding=p));B._OrtBindInput=b(B._OrtBindInput,()=>B._OrtBindInput,p=>B._OrtBindInput=p);B.jsepRegisterBuffer=(p,m,q,w)=>a.registerBuffer(p,m,q,w);B.jsepUnregisterBuffers=p=>{a.unregisterBuffers(p)};B.jsepGetBuffer=p=>a.getBuffer(p);B.jsepCreateDownloader=(p,m,q)=>a.createDownloader(p,m,q)};\r\nvar ka=Object.assign({},B),la=\"./this.program\",E=(a,b)=>{throw b;},ma=\"object\"==typeof window,F=\"function\"==typeof importScripts,G=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,H=B.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function na(a){return B.locateFile?B.locateFile(a,I):I+a}var oa,J,pa;\r\nif(G){var fs=require(\"fs\"),qa=require(\"path\");I=F?qa.dirname(I)+\"/\":__dirname+\"/\";oa=(b,c)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);return fs.readFileSync(b,c?void 0:\"utf8\")};pa=b=>{b=oa(b,!0);b.buffer||(b=new Uint8Array(b));return b};J=(b,c,e,f=!0)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);fs.readFile(b,f?void 0:\"utf8\",(h,k)=>{h?e(h):c(f?k.buffer:k)})};!B.thisProgram&&1<process.argv.length&&(la=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);E=(b,c)=>{process.exitCode=\r\nb;throw c;};B.inspect=()=>\"[Emscripten Module object]\";let a;try{a=require(\"worker_threads\")}catch(b){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),b;}global.Worker=a.Worker}else if(ma||F)F?I=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(I=document.currentScript.src),(typeof _scriptDir !== \"undefined\" && _scriptDir)&&(I=_scriptDir),0!==I.indexOf(\"blob:\")?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",G||(oa=a=>{var b=\r\nnew XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},F&&(pa=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),J=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)});G&&\"undefined\"==typeof performance&&(global.performance=require(\"perf_hooks\").performance);\r\nvar ra=console.log.bind(console),sa=console.error.bind(console);G&&(ra=(...a)=>fs.writeSync(1,a.join(\" \")+\"\\n\"),sa=(...a)=>fs.writeSync(2,a.join(\" \")+\"\\n\"));var ta=B.print||ra,K=B.printErr||sa;Object.assign(B,ka);ka=null;B.thisProgram&&(la=B.thisProgram);B.quit&&(E=B.quit);var L;B.wasmBinary&&(L=B.wasmBinary);var noExitRuntime=B.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&M(\"no native wasm support detected\");var l,N,ua,P=!1,Q,n,aa,ba,ca,ea,ha;\r\nfunction u(){var a=l.buffer;B.HEAP8=n=new Int8Array(a);B.HEAP16=new Int16Array(a);B.HEAP32=ba=new Int32Array(a);B.HEAPU8=aa=new Uint8Array(a);B.HEAPU16=new Uint16Array(a);B.HEAPU32=ca=new Uint32Array(a);B.HEAPF32=ea=new Float32Array(a);B.HEAPF64=ha=new Float64Array(a)}var va=B.INITIAL_MEMORY||16777216;5242880<=va||M(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+va+\"! (STACK_SIZE=5242880)\");\r\nif(H)l=B.wasmMemory;else if(B.wasmMemory)l=B.wasmMemory;else if(l=new WebAssembly.Memory({initial:va/65536,maximum:65536,shared:!0}),!(l.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),G&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),\r\nError(\"bad memory\");u();va=l.buffer.byteLength;var wa=[],xa=[],ya=[],za=0;function Aa(){return noExitRuntime||0<za}var R=0,Ba=null,S=null;function Ca(){R++;B.monitorRunDependencies&&B.monitorRunDependencies(R)}function Da(){R--;B.monitorRunDependencies&&B.monitorRunDependencies(R);if(0==R&&(null!==Ba&&(clearInterval(Ba),Ba=null),S)){var a=S;S=null;a()}}\r\nfunction M(a){if(B.onAbort)B.onAbort(a);a=\"Aborted(\"+a+\")\";K(a);P=!0;Q=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");C(a);throw a;}function Ea(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var T;T=\"ort-wasm-simd-threaded.wasm\";Ea(T)||(T=na(T));function Fa(a){if(a==T&&L)return new Uint8Array(L);if(pa)return pa(a);throw\"both async and sync fetching of the wasm failed\";}\r\nfunction Ga(a){if(!L&&(ma||F)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Fa(a));if(J)return new Promise((b,c)=>{J(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>Fa(a))}function Ha(a,b,c){return Ga(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{K(\"failed to asynchronously prepare wasm: \"+e);M(e)})}\r\nfunction Ia(a,b){var c=T;return L||\"function\"!=typeof WebAssembly.instantiateStreaming||Ea(c)||c.startsWith(\"file://\")||G||\"function\"!=typeof fetch?Ha(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){K(\"wasm streaming compile failed: \"+f);K(\"falling back to ArrayBuffer instantiation\");return Ha(c,a,b)}))}\r\nvar U,Ja={914988:a=>{B.Ea(\"Abs\",a,void 0)},915039:a=>{B.Ea(\"Neg\",a,void 0)},915090:a=>{B.Ea(\"Floor\",a,void 0)},915143:a=>{B.Ea(\"Ceil\",a,void 0)},915195:a=>{B.Ea(\"Reciprocal\",a,void 0)},915253:a=>{B.Ea(\"Sqrt\",a,void 0)},915305:a=>{B.Ea(\"Exp\",a,void 0)},915356:a=>{B.Ea(\"Erf\",a,void 0)},915407:a=>{B.Ea(\"Sigmoid\",a,void 0)},915462:a=>{B.Ea(\"Log\",a,void 0)},915513:a=>{B.Ea(\"Sin\",a,void 0)},915564:a=>{B.Ea(\"Cos\",a,void 0)},915615:a=>{B.Ea(\"Tan\",a,void 0)},915666:a=>{B.Ea(\"Asin\",a,void 0)},915718:a=>{B.Ea(\"Acos\",\r\na,void 0)},915770:a=>{B.Ea(\"Atan\",a,void 0)},915822:a=>{B.Ea(\"Sinh\",a,void 0)},915874:a=>{B.Ea(\"Cosh\",a,void 0)},915926:a=>{B.Ea(\"Asinh\",a,void 0)},915979:a=>{B.Ea(\"Acosh\",a,void 0)},916032:a=>{B.Ea(\"Atanh\",a,void 0)},916085:a=>{B.Ea(\"Tanh\",a,void 0)},916137:a=>{B.Ea(\"Not\",a,void 0)},916188:(a,b,c)=>{B.Ea(\"ClipV10\",a,{min:b,max:c})},916260:a=>{B.Ea(\"Clip\",a,void 0)},916312:(a,b)=>{B.Ea(\"Elu\",a,{alpha:b})},916370:a=>{B.Ea(\"Relu\",a,void 0)},916422:(a,b)=>{B.Ea(\"LeakyRelu\",a,{alpha:b})},916486:(a,b)=>\r\n{B.Ea(\"ThresholdedRelu\",a,{alpha:b})},916556:(a,b)=>{B.Ea(\"Cast\",a,{to:b})},916614:a=>{B.Ea(\"Add\",a,void 0)},916665:a=>{B.Ea(\"Sub\",a,void 0)},916716:a=>{B.Ea(\"Mul\",a,void 0)},916767:a=>{B.Ea(\"Div\",a,void 0)},916818:a=>{B.Ea(\"Pow\",a,void 0)},916869:a=>{B.Ea(\"Equal\",a,void 0)},916922:a=>{B.Ea(\"Greater\",a,void 0)},916977:a=>{B.Ea(\"GreaterOrEqual\",a,void 0)},917039:a=>{B.Ea(\"Less\",a,void 0)},917091:a=>{B.Ea(\"LessOrEqual\",a,void 0)},917150:(a,b,c,e,f)=>{B.Ea(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\r\naxes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917314:(a,b,c,e,f)=>{B.Ea(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917477:(a,b,c,e,f)=>{B.Ea(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917640:(a,b,c,e,f)=>{B.Ea(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917804:(a,b,c,e,f)=>{B.Ea(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\r\naxes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},917967:(a,b,c,e,f)=>{B.Ea(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},918129:(a,b,c,e,f)=>{B.Ea(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},918291:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},918457:(a,b,c,e,f)=>{B.Ea(\"ReduceSumSquare\",a,{keepDims:!!b,\r\nnoopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},918626:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},918795:a=>{B.Ea(\"Where\",a,void 0)},918848:(a,b,c)=>{B.Ea(\"Transpose\",a,{perm:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[]})},918961:(a,b,c,e,f,h,k,r,p,m,q,w,y,g,t)=>{B.Ea(\"ConvTranspose\",a,{format:p?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[r],wIsConst:()=>\r\n!!d()[m>>>0],outputPadding:q?Array.from(z().subarray(w>>>0,w+q>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(t)})},919375:(a,b,c,e,f,h,k,r,p,m,q,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:r?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[p>>>0],outputPadding:0<m?Array.from(z().subarray(q>>>\r\n0,q+m>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>0,y+w>>>0)):[],activation:V(g)})},919932:(a,b,c,e,f,h,k,r,p,m,q,w,y,g,t)=>{B.Ea(\"ConvTranspose\",a,{format:p?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[r],wIsConst:()=>!!d()[m>>>0],outputPadding:q?Array.from(z().subarray(w>>>0,w+q>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(t)})},920346:(a,b,c,e,f,h,k,r,p,m,q,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:r?\"NHWC\":\"NCHW\",autoPad:b,\r\ndilations:Array.from(z().subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[p>>>0],outputPadding:0<m?Array.from(z().subarray(q>>>0,q+m>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>0,y+w>>>0)):[],activation:V(g)})},920903:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},920994:(a,b,c,e,f,h,k,r,p,m,q,w,y,g,t,x)=>{B.Ea(\"AveragePool\",a,\r\n{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[r,p],pads:[m,q,w,y],strides:[g,t]})},921278:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},921369:(a,b,c,e,f,h,k,r,p,m,q,w,y,g,t,x)=>{B.Ea(\"AveragePool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[r,p],pads:[m,q,w,y],strides:[g,t]})},921653:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},921740:(a,\r\nb,c,e,f,h,k,r,p,m,q,w,y,g,t,x)=>{B.Ea(\"MaxPool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[r,p],pads:[m,q,w,y],strides:[g,t]})},922020:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},922107:(a,b,c,e,f,h,k,r,p,m,q,w,y,g,t,x)=>{B.Ea(\"MaxPool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[r,p],pads:[m,q,w,y],strides:[g,t]})},922387:(a,b,c,e,f)=>{B.Ea(\"Gemm\",\r\na,{alpha:b,beta:c,transA:e,transB:f})},922491:a=>{B.Ea(\"MatMul\",a,void 0)},922545:(a,b,c,e)=>{B.Ea(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},922653:(a,b,c,e)=>{B.Ea(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},922761:(a,b)=>{B.Ea(\"Softmax\",a,{axis:b})},922824:(a,b)=>{B.Ea(\"Concat\",a,{axis:b})},922884:(a,b,c,e,f)=>{B.Ea(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},923029:a=>{B.Ea(\"Expand\",a,void 0)},923083:(a,b)=>{B.Ea(\"Gather\",a,\r\n{axis:Number(b)})},923154:(a,b)=>{B.Ea(\"GatherElements\",a,{axis:Number(b)})},923233:(a,b,c,e,f,h,k,r,p,m,q)=>{B.Ea(\"Resize\",a,{antialias:b,axes:c?Array.from(z().subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:V(f),cubicCoeffA:h,excludeOutside:k,extrapolationValue:r,keepAspectRatioPolicy:V(p),mode:V(m),nearestMode:V(q)})},923584:(a,b,c,e,f,h,k)=>{B.Ea(\"Slice\",a,{starts:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(z().subarray(k>>>\r\n0,k+h>>>0)):[]})},923815:a=>{B.Ea(\"Tile\",a,void 0)},923867:(a,b,c)=>{B.Ea(\"LayerNormalization\",a,{axis:Number(b),epsilon:Number(c)})},923974:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},924088:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},924202:a=>{B.Ea(\"Range\",a,void 0)},924255:(a,b)=>{B.Ea(\"Einsum\",a,{equation:V(b)})},924336:(a,b,c,e,f)=>{B.Ea(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},924468:a=>\r\n{B.Ea(\"Gelu\",a,void 0)},924520:a=>{B.Ea(\"BiasAdd\",a,void 0)},924575:a=>{B.Ea(\"BiasSplitGelu\",a,void 0)},924636:(a,b)=>{B.Ea(\"SkipLayerNormalization\",a,{epsilon:b})},924717:(a,b,c,e,f,h,k,r,p,m,q,w,y)=>{B.Ea(\"Conv\",a,{format:p?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[],strides:[r],w_is_const:()=>!!d()[m>>>0],activation:V(q),activation_params:w?Array.from(da().subarray(y>>>0,y+w>>>0)):[]})},925098:(a,b,c,e,f,h,k,r,p,m,q,w,y,g,t,\r\nx)=>{B.Ea(\"Conv\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,k],pads:r?Array.from(z().subarray(p>>>0,p+r>>>0)):[],strides:[m,q],w_is_const:()=>!!d()[y>>>0],activation:V(g),activation_params:t?Array.from(da().subarray(x>>>0,x+t>>>0)):[]})},925500:a=>{B.zb(a)},925534:(a,b)=>B.Ab(a,b,B.bb.Fb,B.bb.errors),925646:a=>B.wb(a),925679:a=>B.yb(a),925711:(a,b,c)=>{B.jb(a,b,c,!0)},925750:(a,b,c)=>{B.jb(a,b,c)}};\r\nfunction Ka(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}function La(a){a.terminate();a.onmessage=()=>{}}function Ma(a){(a=W.Qa[a])||M();W.Eb(a)}function Na(a){var b=W.tb();if(!b)return 6;W.Ya.push(b);W.Qa[a.Xa]=b;b.Xa=a.Xa;var c={cmd:\"run\",start_routine:a.Gb,arg:a.rb,pthread_ptr:a.Xa};G&&b.unref();b.postMessage(c,a.Mb);return 0}\r\nvar Oa=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Pa=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Oa)return Oa.decode(a.buffer instanceof SharedArrayBuffer?a.slice(b,c):a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var k=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|k:(f&7)<<18|h<<12|k<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>\r\n10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},V=(a,b)=>(a>>>=0)?Pa(v(),a,b):\"\";function Qa(a){if(H)return X(1,1,a);Q=a;if(!Aa()){W.Hb();if(B.onExit)B.onExit(a);P=!0}E(a,new Ka(a))}\r\nvar Sa=a=>{Q=a;if(H)throw Ra(a),\"unwind\";Qa(a)},W={ab:[],Ya:[],mb:[],Qa:{},gb:function(){H?W.vb():W.ub()},ub:function(){wa.unshift(()=>{Ca();W.Bb(()=>Da())})},vb:function(){W.receiveObjectTransfer=W.Db;W.threadInitTLS=W.lb;W.setExitStatus=W.kb;noExitRuntime=!1},kb:function(a){Q=a},Sb:[\"$terminateWorker\"],Hb:function(){for(var a of W.Ya)La(a);for(a of W.ab)La(a);W.ab=[];W.Ya=[];W.Qa=[]},Eb:function(a){var b=a.Xa;delete W.Qa[b];W.ab.push(a);W.Ya.splice(W.Ya.indexOf(a),1);a.Xa=0;Ta(b)},Db:function(){},\r\nlb:function(){W.mb.forEach(a=>a())},Cb:a=>new Promise(b=>{a.onmessage=h=>{h=h.data;var k=h.cmd;if(h.targetThread&&h.targetThread!=Ua()){var r=W.Qa[h.Rb];r?r.postMessage(h,h.transferList):K('Internal error! Worker sent a message \"'+k+'\" to target pthread '+h.targetThread+\", but that thread no longer exists!\")}else if(\"checkMailbox\"===k)Va();else if(\"spawnThread\"===k)Na(h);else if(\"cleanupThread\"===k)Ma(h.thread);else if(\"killThread\"===k)h=h.thread,k=W.Qa[h],delete W.Qa[h],La(k),Ta(h),W.Ya.splice(W.Ya.indexOf(k),\r\n1),k.Xa=0;else if(\"cancelThread\"===k)W.Qa[h.thread].postMessage({cmd:\"cancel\"});else if(\"loaded\"===k)a.loaded=!0,b(a);else if(\"alert\"===k)alert(\"Thread \"+h.threadId+\": \"+h.text);else if(\"setimmediate\"===h.target)a.postMessage(h);else if(\"callHandler\"===k)B[h.handler](...h.args);else k&&K(\"worker sent an unknown command \"+k)};a.onerror=h=>{K(\"worker sent an error! \"+h.filename+\":\"+h.lineno+\": \"+h.message);throw h;};G&&(a.on(\"message\",function(h){a.onmessage({data:h})}),a.on(\"error\",function(h){a.onerror(h)}));\r\nvar c=[],e=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],f;for(f of e)B.hasOwnProperty(f)&&c.push(f);a.postMessage({cmd:\"load\",handlers:c,urlOrBlob:B.mainScriptUrlOrBlob||_scriptDir,wasmMemory:l,wasmModule:ua})}),Bb:function(a){a()},qb:function(){var a=na(\"ort-wasm-simd-threaded.worker.js\");a=new Worker(a);W.ab.push(a)},tb:function(){0==W.ab.length&&(W.qb(),W.Cb(W.ab[0]));return W.ab.pop()}};B.PThread=W;var Wa=a=>{for(;0<a.length;)a.shift()(B)};\r\nB.establishStackSpace=function(){var a=Ua(),b=z()[a+52>>2>>>0];a=z()[a+56>>2>>>0];Xa(b,b-a);Ya(b)};function Ra(a){if(H)return X(2,0,a);Sa(a)}B.invokeEntryPoint=function(a,b){a=Za.apply(null,[a,b]);Aa()?W.kb(a):$a(a)};function ab(a){this.fb=a-24;this.pb=function(b){A()[this.fb+4>>2>>>0]=b};this.ob=function(b){A()[this.fb+8>>2>>>0]=b};this.gb=function(b,c){this.nb();this.pb(b);this.ob(c)};this.nb=function(){A()[this.fb+16>>2>>>0]=0}}var bb=0,cb=0;\r\nfunction db(a,b,c,e){return H?X(3,1,a,b,c,e):eb(a,b,c,e)}function eb(a,b,c,e){a>>>=0;b>>>=0;c>>>=0;e>>>=0;if(\"undefined\"==typeof SharedArrayBuffer)return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var f=[];if(H&&0===f.length)return db(a,b,c,e);a={Gb:c,Xa:a,rb:e,Mb:f};return H?(a.Ob=\"spawnThread\",postMessage(a,f),0):Na(a)}function fb(a,b,c){return H?X(4,1,a,b,c):0}function gb(a,b){if(H)return X(5,1,a,b)}\r\nvar hb=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},ib=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var k=a.charCodeAt(h);if(55296<=k&&57343>=k){var r=a.charCodeAt(++h);k=65536+((k&1023)<<10)|r&1023}if(127>=k){if(c>=e)break;b[c++>>>0]=k}else{if(2047>=k){if(c+1>=e)break;b[c++>>>0]=192|k>>6}else{if(65535>=k){if(c+2>=e)break;b[c++>>>0]=224|k>>12}else{if(c+3>=e)break;b[c++>>>0]=240|k>>\r\n18;b[c++>>>0]=128|k>>12&63}b[c++>>>0]=128|k>>6&63}b[c++>>>0]=128|k&63}}b[c>>>0]=0;return c-f},jb=(a,b,c)=>ib(a,v(),b,c);function kb(a,b){if(H)return X(6,1,a,b)}function lb(a,b,c){if(H)return X(7,1,a,b,c)}function mb(a,b,c){return H?X(8,1,a,b,c):0}function nb(a,b){if(H)return X(9,1,a,b)}function ob(a,b,c){if(H)return X(10,1,a,b,c)}function pb(a,b,c,e){if(H)return X(11,1,a,b,c,e)}function qb(a,b,c,e){if(H)return X(12,1,a,b,c,e)}function rb(a,b,c,e){if(H)return X(13,1,a,b,c,e)}\r\nfunction sb(a){if(H)return X(14,1,a)}function tb(a,b){if(H)return X(15,1,a,b)}function ub(a,b,c){if(H)return X(16,1,a,b,c)}var vb=a=>{if(!P)try{if(a(),!Aa())try{H?$a(Q):Sa(Q)}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}};function wb(a){a>>>=0;\"function\"===typeof Atomics.Nb&&(Atomics.Nb(z(),a>>2,a).value.then(Va),a+=128,Atomics.store(z(),a>>2,1))}B.__emscripten_thread_mailbox_await=wb;function Va(){var a=Ua();a&&(wb(a),vb(()=>xb()))}B.checkMailbox=Va;\r\nvar Y=a=>0===a%4&&(0!==a%100||0===a%400),yb=[0,31,60,91,121,152,182,213,244,274,305,335],zb=[0,31,59,90,120,151,181,212,243,273,304,334];function Ab(a,b,c,e,f,h,k,r){return H?X(17,1,a,b,c,e,f,h,k,r):-52}function Bb(a,b,c,e,f,h,k){if(H)return X(18,1,a,b,c,e,f,h,k)}var Db=a=>{var b=hb(a)+1,c=Cb(b);c&&jb(a,c,b);return c},Eb=[],Fb=(a,b)=>{Eb.length=0;var c;for(b>>=2;c=v()[a++>>>0];)b+=105!=c&b,Eb.push(105==c?z()[b>>>0]:fa()[b++>>>1]),++b;return Eb},Hb=a=>{var b=Gb();a=a();Ya(b);return a};\r\nfunction X(a,b){var c=arguments.length-2,e=arguments;return Hb(()=>{for(var f=Ib(8*c),h=f>>3,k=0;k<c;k++){var r=e[2+k];fa()[h+k>>>0]=r}return Jb(a,c,f,b)})}\r\nvar Kb=[],Lb={},Nb=()=>{if(!Mb){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:la||\"./this.program\"},b;for(b in Lb)void 0===Lb[b]?delete a[b]:a[b]=Lb[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Mb=c}return Mb},Mb;\r\nfunction Ob(a,b){if(H)return X(19,1,a,b);a>>>=0;b>>>=0;var c=0;Nb().forEach(function(e,f){var h=b+c;f=A()[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)d()[f++>>0>>>0]=e.charCodeAt(h);d()[f>>0>>>0]=0;c+=e.length+1});return 0}function Pb(a,b){if(H)return X(20,1,a,b);a>>>=0;b>>>=0;var c=Nb();A()[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});A()[b>>2>>>0]=e;return 0}function Qb(a){return H?X(21,1,a):52}function Rb(a,b,c,e){return H?X(22,1,a,b,c,e):52}\r\nfunction Sb(a,b,c,e,f){return H?X(23,1,a,b,c,e,f):70}var Tb=[null,[],[]];function Vb(a,b,c,e){if(H)return X(24,1,a,b,c,e);b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var k=A()[b>>2>>>0],r=A()[b+4>>2>>>0];b+=8;for(var p=0;p<r;p++){var m=v()[k+p>>>0],q=Tb[a];0===m||10===m?((1===a?ta:K)(Pa(q,0)),q.length=0):q.push(m)}f+=r}A()[e>>2>>>0]=f;return 0}var Wb=[31,29,31,30,31,30,31,31,30,31,30,31],Xb=[31,28,31,30,31,30,31,31,30,31,30,31];function Yb(a){var b=Array(hb(a)+1);ib(a,b,0,b.length);return b}\r\nvar Zb=(a,b)=>{d().set(a,b>>>0)};\r\nfunction $b(a,b,c,e){function f(g,t,x){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<t;)g=x[0]+g;return g}function h(g,t){return f(g,t,\"0\")}function k(g,t){function x(Ub){return 0>Ub?-1:0<Ub?1:0}var O;0===(O=x(g.getFullYear()-t.getFullYear()))&&0===(O=x(g.getMonth()-t.getMonth()))&&(O=x(g.getDate()-t.getDate()));return O}function r(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\r\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function p(g){var t=g.Za;for(g=new Date((new Date(g.$a+1900,0,1)).getTime());0<t;){var x=g.getMonth(),O=(Y(g.getFullYear())?Wb:Xb)[x];if(t>O-g.getDate())t-=O-g.getDate()+1,g.setDate(1),11>x?g.setMonth(x+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+t);break}}x=new Date(g.getFullYear()+1,0,4);t=r(new Date(g.getFullYear(),\r\n0,4));x=r(x);return 0>=k(t,g)?0>=k(x,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var m=z()[e+40>>2>>>0];e={Kb:z()[e>>2>>>0],Jb:z()[e+4>>2>>>0],cb:z()[e+8>>2>>>0],ib:z()[e+12>>2>>>0],eb:z()[e+16>>2>>>0],$a:z()[e+20>>2>>>0],Wa:z()[e+24>>2>>>0],Za:z()[e+28>>2>>>0],Tb:z()[e+32>>2>>>0],Ib:z()[e+36>>2>>>0],Lb:m?V(m):\"\"};c=V(c);m={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\r\n\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var q in m)c=c.replace(new RegExp(q,\"g\"),m[q]);var w=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),y=\"January February March April May June July August September October November December\".split(\" \");m={\"%a\":g=>w[g.Wa].substring(0,3),\"%A\":g=>w[g.Wa],\"%b\":g=>\r\ny[g.eb].substring(0,3),\"%B\":g=>y[g.eb],\"%C\":g=>h((g.$a+1900)/100|0,2),\"%d\":g=>h(g.ib,2),\"%e\":g=>f(g.ib,2,\" \"),\"%g\":g=>p(g).toString().substring(2),\"%G\":g=>p(g),\"%H\":g=>h(g.cb,2),\"%I\":g=>{g=g.cb;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var t=0,x=0;x<=g.eb-1;t+=(Y(g.$a+1900)?Wb:Xb)[x++]);return h(g.ib+t,3)},\"%m\":g=>h(g.eb+1,2),\"%M\":g=>h(g.Jb,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.cb&&12>g.cb?\"AM\":\"PM\",\"%S\":g=>h(g.Kb,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.Wa||7,\"%U\":g=>h(Math.floor((g.Za+7-g.Wa)/7),2),\"%V\":g=>\r\n{var t=Math.floor((g.Za+7-(g.Wa+6)%7)/7);2>=(g.Wa+371-g.Za-2)%7&&t++;if(t)53==t&&(x=(g.Wa+371-g.Za)%7,4==x||3==x&&Y(g.$a)||(t=1));else{t=52;var x=(g.Wa+7-g.Za-1)%7;(4==x||5==x&&Y(g.$a%400-1))&&t++}return h(t,2)},\"%w\":g=>g.Wa,\"%W\":g=>h(Math.floor((g.Za+7-(g.Wa+6)%7)/7),2),\"%y\":g=>(g.$a+1900).toString().substring(2),\"%Y\":g=>g.$a+1900,\"%z\":g=>{g=g.Ib;var t=0<=g;g=Math.abs(g)/60;return(t?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Lb,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(q in m)c.includes(q)&&\r\n(c=c.replace(new RegExp(q,\"g\"),m[q](e)));c=c.replace(/\\0\\0/g,\"%\");q=Yb(c);if(q.length>b)return 0;Zb(q,a);return q.length-1}function ac(a){try{a()}catch(b){M(b)}}function bc(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){cc.push(e);try{return f.apply(null,arguments)}finally{P||(cc.pop()===e||M(),D&&1===Z&&0===cc.length&&(Z=0,za+=1,ac(dc),\"undefined\"!=typeof Fibers&&Fibers.Ub()))}}:f})(c);return b}var Z=0,D=null,ec=0,cc=[],fc={},gc={},hc=0,ic=null,jc=[];\r\nfunction ja(){return new Promise((a,b)=>{ic={resolve:a,reject:b}})}function kc(){var a=Cb(65548),b=a+12;A()[a>>2>>>0]=b;A()[a+4>>2>>>0]=b+65536;b=cc[0];var c=fc[b];void 0===c&&(c=hc++,fc[b]=c,gc[c]=b);b=c;z()[a+8>>2>>>0]=b;return a}function lc(){var a=z()[D+8>>2>>>0];a=N[gc[a]];--za;return a()}\r\nfunction mc(a){if(!P){if(0===Z){var b=!1,c=!1;a((e=0)=>{if(!P&&(ec=e,b=!0,c)){Z=2;ac(()=>nc(D));\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.resume();e=!1;try{var f=lc()}catch(r){f=r,e=!0}var h=!1;if(!D){var k=ic;k&&(ic=null,(e?k.reject:k.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Z=1,D=kc(),\"undefined\"!=typeof Browser&&Browser.hb.sb&&Browser.hb.pause(),ac(()=>oc(D)))}else 2===Z?(Z=0,ac(pc),qc(D),D=null,jc.forEach(e=>vb(e))):M(`invalid state: ${Z}`);return ec}}\r\nfunction rc(a){return mc(b=>{a().then(b)})}W.gb();\r\nvar sc=[null,Qa,Ra,db,fb,gb,kb,lb,mb,nb,ob,pb,qb,rb,sb,tb,ub,Ab,Bb,Ob,Pb,Qb,Rb,Sb,Vb],vc={r:function(a,b,c){return rc(async()=>{await B.xb(a,b,c)})},b:function(a,b,c){a>>>=0;(new ab(a)).gb(b>>>0,c>>>0);bb=a;cb++;throw bb;},O:function(a){tc(a>>>0,!F,1,!ma,131072,!1);W.lb()},l:function(a){a>>>=0;H?postMessage({cmd:\"cleanupThread\",thread:a}):Ma(a)},I:eb,i:fb,U:gb,E:kb,G:lb,V:mb,S:nb,K:ob,R:pb,p:qb,F:rb,C:sb,T:tb,D:ub,q:()=>!0,A:function(a,b){a>>>=0;a==b>>>0?setTimeout(()=>Va()):H?postMessage({targetThread:a,\r\ncmd:\"checkMailbox\"}):(a=W.Qa[a])&&a.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:wb,X:function(a){G&&W.Qa[a>>>0].ref()},u:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getUTCSeconds();z()[c+4>>2>>>0]=a.getUTCMinutes();z()[c+8>>2>>>0]=a.getUTCHours();z()[c+12>>2>>>0]=a.getUTCDate();z()[c+16>>2>>>0]=a.getUTCMonth();z()[c+20>>2>>>0]=a.getUTCFullYear()-1900;z()[c+24>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),\r\n0,1,0,0,0,0))/864E5|0;z()[c+28>>2>>>0]=a},v:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getSeconds();z()[c+4>>2>>>0]=a.getMinutes();z()[c+8>>2>>>0]=a.getHours();z()[c+12>>2>>>0]=a.getDate();z()[c+16>>2>>>0]=a.getMonth();z()[c+20>>2>>>0]=a.getFullYear()-1900;z()[c+24>>2>>>0]=a.getDay();b=(Y(a.getFullYear())?yb:zb)[a.getMonth()]+a.getDate()-1|0;z()[c+28>>2>>>0]=b;z()[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),\r\n6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0;z()[c+32>>2>>>0]=a},w:function(a){a>>>=0;var b=new Date(z()[a+20>>2>>>0]+1900,z()[a+16>>2>>>0],z()[a+12>>2>>>0],z()[a+8>>2>>>0],z()[a+4>>2>>>0],z()[a>>2>>>0],0),c=z()[a+32>>2>>>0],e=b.getTimezoneOffset(),f=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),k=Math.min(h,f);0>c?z()[a+32>>2>>>0]=Number(f!=h&&k==e):\r\n0<c!=(k==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?k:f)-e)));z()[a+24>>2>>>0]=b.getDay();c=(Y(b.getFullYear())?yb:zb)[b.getMonth()]+b.getDate()-1|0;z()[a+28>>2>>>0]=c;z()[a>>2>>>0]=b.getSeconds();z()[a+4>>2>>>0]=b.getMinutes();z()[a+8>>2>>>0]=b.getHours();z()[a+12>>2>>>0]=b.getDate();z()[a+16>>2>>>0]=b.getMonth();z()[a+20>>2>>>0]=b.getYear();a=b.getTime()/1E3;return uc((U=a,1<=+Math.abs(U)?0<U?+Math.floor(U/4294967296)>>>0:~~+Math.ceil((U-+(~~U>>>0))/4294967296)>>>0:0)),a>>>0},s:Ab,t:Bb,\r\nz:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}a>>>=0;b>>>=0;c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),k=new Date(f,6,1);f=h.getTimezoneOffset();var r=k.getTimezoneOffset(),p=Math.max(f,r);A()[a>>2>>>0]=60*p;z()[b>>2>>>0]=Number(f!=r);a=e(h);b=e(k);a=Db(a);b=Db(b);r<f?(A()[c>>2>>>0]=a,A()[c+4>>2>>>0]=b):(A()[c>>2>>>0]=b,A()[c+4>>2>>>0]=a)},d:()=>{M(\"\")},c:function(a,b,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},k:function(a,\r\nb,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},m:function(){},j:function(){return Date.now()},W:()=>{za+=1;throw\"unwind\";},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return G?require(\"os\").cpus().length:navigator.hardwareConcurrency},L:function(a,b,c,e){W.Pb=b>>>0;Kb.length=c;b=e>>>0>>3;for(e=0;e<c;e++)Kb[e]=fa()[b+e>>>0];return(0>a?Ja[-a-1]:sc[a]).apply(null,Kb)},y:function(a){a>>>=0;var b=v().length;if(a<=b||4294901760<a)return!1;for(var c=\r\n1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;e=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-l.buffer.byteLength+65535>>>16;try{l.grow(f);u();var h=1;break a}catch(k){}h=void 0}if(h)return!0}return!1},P:Ob,Q:Pb,H:Sa,h:Qb,o:Rb,x:Sb,n:Vb,a:l||B.wasmMemory,J:$b,e:function(a,b,c,e){return $b(a>>>0,b>>>0,c>>>0,e>>>0)}};\r\n(function(){function a(c,e){c=c.exports;c=bc(c);N=c=wc(c);W.mb.push(N.Da);xa.unshift(N.Y);ua=e;Da();return c}var b={a:vc};Ca();if(B.instantiateWasm)try{return B.instantiateWasm(b,a)}catch(c){K(\"Module.instantiateWasm callback failed with error: \"+c),C(c)}Ia(b,function(c){a(c.instance,c.module)}).catch(C);return{}})();B._OrtInit=(a,b)=>(B._OrtInit=N.Z)(a,b);B._OrtGetLastError=(a,b)=>(B._OrtGetLastError=N._)(a,b);\r\nB._OrtCreateSessionOptions=(a,b,c,e,f,h,k,r,p,m)=>(B._OrtCreateSessionOptions=N.$)(a,b,c,e,f,h,k,r,p,m);B._OrtAppendExecutionProvider=(a,b)=>(B._OrtAppendExecutionProvider=N.aa)(a,b);B._OrtAddFreeDimensionOverride=(a,b,c)=>(B._OrtAddFreeDimensionOverride=N.ba)(a,b,c);B._OrtAddSessionConfigEntry=(a,b,c)=>(B._OrtAddSessionConfigEntry=N.ca)(a,b,c);B._OrtReleaseSessionOptions=a=>(B._OrtReleaseSessionOptions=N.da)(a);B._OrtCreateSession=(a,b,c)=>(B._OrtCreateSession=N.ea)(a,b,c);\r\nB._OrtReleaseSession=a=>(B._OrtReleaseSession=N.fa)(a);B._OrtGetInputOutputCount=(a,b,c)=>(B._OrtGetInputOutputCount=N.ga)(a,b,c);B._OrtGetInputName=(a,b)=>(B._OrtGetInputName=N.ha)(a,b);B._OrtGetOutputName=(a,b)=>(B._OrtGetOutputName=N.ia)(a,b);B._OrtFree=a=>(B._OrtFree=N.ja)(a);B._OrtCreateTensor=(a,b,c,e,f,h)=>(B._OrtCreateTensor=N.ka)(a,b,c,e,f,h);B._OrtGetTensorData=(a,b,c,e,f)=>(B._OrtGetTensorData=N.la)(a,b,c,e,f);B._OrtReleaseTensor=a=>(B._OrtReleaseTensor=N.ma)(a);\r\nB._OrtCreateRunOptions=(a,b,c,e)=>(B._OrtCreateRunOptions=N.na)(a,b,c,e);B._OrtAddRunConfigEntry=(a,b,c)=>(B._OrtAddRunConfigEntry=N.oa)(a,b,c);B._OrtReleaseRunOptions=a=>(B._OrtReleaseRunOptions=N.pa)(a);B._OrtCreateBinding=a=>(B._OrtCreateBinding=N.qa)(a);B._OrtBindInput=(a,b,c)=>(B._OrtBindInput=N.ra)(a,b,c);B._OrtBindOutput=(a,b,c,e)=>(B._OrtBindOutput=N.sa)(a,b,c,e);B._OrtClearBoundOutputs=a=>(B._OrtClearBoundOutputs=N.ta)(a);B._OrtReleaseBinding=a=>(B._OrtReleaseBinding=N.ua)(a);\r\nB._OrtRunWithBinding=(a,b,c,e,f)=>(B._OrtRunWithBinding=N.va)(a,b,c,e,f);B._OrtRun=(a,b,c,e,f,h,k,r)=>(B._OrtRun=N.wa)(a,b,c,e,f,h,k,r);B._OrtEndProfiling=a=>(B._OrtEndProfiling=N.xa)(a);B._JsepOutput=(a,b,c)=>(B._JsepOutput=N.ya)(a,b,c);B._JsepGetNodeName=a=>(B._JsepGetNodeName=N.za)(a);var Ua=B._pthread_self=()=>(Ua=B._pthread_self=N.Aa)(),Cb=B._malloc=a=>(Cb=B._malloc=N.Ba)(a),qc=B._free=a=>(qc=B._free=N.Ca)(a);B.__emscripten_tls_init=()=>(B.__emscripten_tls_init=N.Da)();\r\nvar tc=B.__emscripten_thread_init=(a,b,c,e,f,h)=>(tc=B.__emscripten_thread_init=N.Fa)(a,b,c,e,f,h);B.__emscripten_thread_crashed=()=>(B.__emscripten_thread_crashed=N.Ga)();\r\nvar Jb=(a,b,c,e)=>(Jb=N.Ha)(a,b,c,e),Ta=a=>(Ta=N.Ia)(a),$a=B.__emscripten_thread_exit=a=>($a=B.__emscripten_thread_exit=N.Ja)(a),xb=B.__emscripten_check_mailbox=()=>(xb=B.__emscripten_check_mailbox=N.Ka)(),uc=a=>(uc=N.La)(a),Xa=(a,b)=>(Xa=N.Ma)(a,b),Gb=()=>(Gb=N.Na)(),Ya=a=>(Ya=N.Oa)(a),Ib=a=>(Ib=N.Pa)(a),Za=B.dynCall_ii=(a,b)=>(Za=B.dynCall_ii=N.Ra)(a,b),oc=a=>(oc=N.Sa)(a),dc=()=>(dc=N.Ta)(),nc=a=>(nc=N.Ua)(a),pc=()=>(pc=N.Va)();B.___start_em_js=925783;B.___stop_em_js=925944;\r\nfunction wc(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.pthread_self=b(a.pthread_self);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}B.keepRuntimeAlive=Aa;B.wasmMemory=l;B.stackAlloc=Ib;B.stackSave=Gb;B.stackRestore=Ya;B.UTF8ToString=V;B.stringToUTF8=jb;B.lengthBytesUTF8=hb;B.ExitStatus=Ka;B.PThread=W;var xc;S=function yc(){xc||zc();xc||(S=yc)};\r\nfunction zc(){function a(){if(!xc&&(xc=!0,B.calledRun=!0,!P)){H||Wa(xa);ia(B);if(B.onRuntimeInitialized)B.onRuntimeInitialized();if(!H){if(B.postRun)for(\"function\"==typeof B.postRun&&(B.postRun=[B.postRun]);B.postRun.length;){var b=B.postRun.shift();ya.unshift(b)}Wa(ya)}}}if(!(0<R))if(H)ia(B),H||Wa(xa),startWorker(B);else{if(B.preRun)for(\"function\"==typeof B.preRun&&(B.preRun=[B.preRun]);B.preRun.length;)wa.unshift(B.preRun.shift());Wa(wa);0<R||(B.setStatus?(B.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){B.setStatus(\"\")},\r\n1);a()},1)):a())}}if(B.preInit)for(\"function\"==typeof B.preInit&&(B.preInit=[B.preInit]);0<B.preInit.length;)B.preInit.pop()();zc();\r\n\r\n\r\n  return moduleArg.ready\r\n}\r\n\r\n);\r\n})();\r\nif (typeof exports === 'object' && typeof module === 'object')\r\n  module.exports = ortWasmThreaded;\r\nelse if (typeof define === 'function' && define['amd'])\r\n  define([], () => ortWasmThreaded);\r\n", "\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport * as path from 'node:path';\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from './binding/ort-wasm';\nimport {OrtWasmThreadedModule} from './binding/ort-wasm-threaded';\n\n/* eslint-disable @typescript-eslint/no-require-imports */\nlet ortWasmFactory: EmscriptenModuleFactory<OrtWasmModule>;\n\nif (!BUILD_DEFS.DISABLE_TRAINING) {\n  ortWasmFactory = require('./binding/ort-training-wasm-simd.js');\n} else {\n  ortWasmFactory =\n      BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm.js') : require('./binding/ort-wasm-simd.jsep.js');\n}\n\nconst ortWasmFactoryThreaded: EmscriptenModuleFactory<OrtWasmModule> = !BUILD_DEFS.DISABLE_WASM_THREAD ?\n    (BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm-threaded.js') :\n                                 require('./binding/ort-wasm-simd-threaded.jsep.js')) :\n    ortWasmFactory;\n/* eslint-enable @typescript-eslint/no-require-imports */\n\nlet wasm: OrtWasmModule|undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  try {\n    // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n    if (typeof SharedArrayBuffer === 'undefined') {\n      return false;\n    }\n\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(new Uint8Array([\n      0,   97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1,   28,  0, 65, 0,\n      253, 15, 253, 12,  0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0,  0,  253, 186, 1, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst getWasmFileName = (useSimd: boolean, useThreads: boolean) => {\n  if (useSimd) {\n    if (!BUILD_DEFS.DISABLE_TRAINING) {\n      return 'ort-training-wasm-simd.wasm';\n    }\n    return useThreads ? 'ort-wasm-simd-threaded.wasm' : 'ort-wasm-simd.wasm';\n  } else {\n    return useThreads ? 'ort-wasm-threaded.wasm' : 'ort-wasm.wasm';\n  }\n};\n\nexport const initializeWebAssembly = async(flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initializeWebAssembly()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initializeWebAssembly()\\' failed.');\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  const numThreads = flags.numThreads!;\n  const simd = flags.simd!;\n\n  const useThreads = numThreads > 1 && isMultiThreadSupported();\n  const useSimd = simd && isSimdSupported();\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const wasmFileName = getWasmFileName(useSimd, useThreads);\n  const wasmPathOverride = typeof wasmPaths === 'object' ? wasmPaths[wasmFileName] : undefined;\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(new Promise((resolve) => {\n      setTimeout(() => {\n        isTimeout = true;\n        resolve();\n      }, timeout);\n    }));\n  }\n\n  // promise for module initialization\n  tasks.push(new Promise((resolve, reject) => {\n    const factory = useThreads ? ortWasmFactoryThreaded : ortWasmFactory;\n    const config: Partial<OrtWasmModule> = {\n      locateFile: (fileName: string, scriptDirectory: string) => {\n        if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads && fileName.endsWith('.worker.js') &&\n            typeof Blob !== 'undefined') {\n          return URL.createObjectURL(new Blob(\n              [\n                // This require() function is handled by esbuild plugin to load file content as string.\n                // eslint-disable-next-line @typescript-eslint/no-require-imports\n                require('./binding/ort-wasm-threaded.worker.js')\n              ],\n              {type: 'text/javascript'}));\n        }\n\n        if (fileName.endsWith('.wasm')) {\n          if (wasmPathOverride) {\n            return wasmPathOverride;\n          }\n\n          const prefix = wasmPrefixOverride ?? scriptDirectory;\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            if (wasmFileName === 'ort-wasm-simd.wasm') {\n              return prefix + 'ort-wasm-simd.jsep.wasm';\n            } else if (wasmFileName === 'ort-wasm-simd-threaded.wasm') {\n              return prefix + 'ort-wasm-simd-threaded.jsep.wasm';\n            }\n          }\n\n          return prefix + wasmFileName;\n        }\n\n        return scriptDirectory + fileName;\n      }\n    };\n\n    if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads) {\n      if (typeof Blob === 'undefined') {\n        config.mainScriptUrlOrBlob = path.join(__dirname, 'ort-wasm-threaded.js');\n      } else {\n        const scriptSourceCode = `var ortWasmThreaded=${factory.toString()};`;\n        config.mainScriptUrlOrBlob = new Blob([scriptSourceCode], {type: 'text/javascript'});\n      }\n    }\n\n    factory(config).then(\n        // wasm module initialized successfully\n        module => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        });\n  }));\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    initializing = true;\n\n    (wasm as OrtWasmThreadedModule).PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {getInstance} from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions =\n    (options: Record<string, unknown>, prefix: string, seen: WeakSet<Record<string, unknown>>,\n     handler: ExtraOptionsHandler): void => {\n      if (typeof options == 'object' && options !== null) {\n        if (seen.has(options)) {\n          throw new Error('Circular reference in options');\n        } else {\n          seen.add(options);\n        }\n      }\n\n      Object.entries(options).forEach(([key, value]) => {\n        const name = (prefix) ? prefix + key : key;\n        if (typeof value === 'object') {\n          iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n        } else if (typeof value === 'string' || typeof value === 'number') {\n          handler(name, value.toString());\n        } else if (typeof value === 'boolean') {\n          handler(name, (value) ? '1' : '0');\n        } else {\n          throw new Error(`Can't handle extra config type: ${typeof value}`);\n        }\n      });\n    };\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const paramsOffset = wasm.stackAlloc(8);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + 4);\n    const errorCode = wasm.HEAP32[paramsOffset / 4];\n    const errorMessagePointer = wasm.HEAPU32[paramsOffset / 4 + 1];\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2;  // Default to warning\n    } else if (\n        typeof options.logSeverityLevel !== 'number' || !Number.isInteger(options.logSeverityLevel) ||\n        options.logSeverityLevel < 0 || options.logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0;  // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n        runOptions.logSeverityLevel!, runOptions.logVerbosityLevel!, !!runOptions.terminate!, tagDataOffset);\n    if (runOptionsHandle === 0) {\n      checkLastError('Can\\'t create run options.');\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string|unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential'|'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (options.executionProviders &&\n      options.executionProviders.some(ep => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst setExecutionProviders =\n    (sessionOptionsHandle: number, executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n     allocs: number[]): void => {\n      for (const ep of executionProviders) {\n        let epName = typeof ep === 'string' ? ep : ep.name;\n\n        // check EP name\n        switch (epName) {\n          case 'xnnpack':\n            epName = 'XNNPACK';\n            break;\n          case 'webnn':\n            epName = 'WEBNN';\n            if (typeof ep !== 'string') {\n              const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n              if (webnnOptions?.deviceType) {\n                const keyDataOffset = allocWasmString('deviceType', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.deviceType, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'deviceType' - ${webnnOptions.deviceType}.`);\n                }\n              }\n              if (webnnOptions?.powerPreference) {\n                const keyDataOffset = allocWasmString('powerPreference', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.powerPreference, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'powerPreference' - ${webnnOptions.powerPreference}.`);\n                }\n              }\n            }\n            break;\n          case 'webgpu':\n            epName = 'JS';\n            if (typeof ep !== 'string') {\n              const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n              if (webgpuOptions?.preferredLayout) {\n                if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                  throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n                }\n                const keyDataOffset = allocWasmString('preferredLayout', allocs);\n                const valueDataOffset = allocWasmString(webgpuOptions.preferredLayout, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'preferredLayout' - ${webgpuOptions.preferredLayout}.`);\n                }\n              }\n            }\n            break;\n          case 'wasm':\n          case 'cpu':\n            continue;\n          default:\n            throw new Error(`not supported execution provider: ${epName}`);\n        }\n\n        const epNameDataOffset = allocWasmString(epName, allocs);\n        if (getInstance()._OrtAppendExecutionProvider(sessionOptionsHandle, epNameDataOffset) !== 0) {\n          checkLastError(`Can't append execution provider: ${epName}.`);\n        }\n      }\n    };\n\nexport const setSessionOptions = (options?: InferenceSession.SessionOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n        typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2;  // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0;  // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset = typeof sessionOptions.optimizedModelFilePath === 'string' ?\n        allocWasmString(sessionOptions.optimizedModelFilePath, allocs) :\n        0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n        graphOptimizationLevel, !!sessionOptions.enableCpuMemArena, !!sessionOptions.enableMemPattern, executionMode,\n        !!sessionOptions.enableProfiling, 0, logIdDataOffset, logSeverityLevel, logVerbosityLevel,\n        optimizedModelFilePathOffset);\n    if (sessionOptionsHandle === 0) {\n      checkLastError('Can\\'t create session options.');\n    }\n\n    if (sessionOptions.executionProviders) {\n      setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor element size in bytes by the given data type\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const getTensorElementSize = (dateType: number): number|\n    undefined => [undefined, 4, 1, 1, 2, 2, 4, 8, undefined, 1, 2, 8, 4, 8, undefined, undefined, undefined][dateType];\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (type: Tensor.Type): Float32ArrayConstructor|Uint8ArrayConstructor|\n    Int8ArrayConstructor|Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|\n    Uint8ArrayConstructor|Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor => {\n      switch (type) {\n        case 'float16':\n          return Uint16Array;\n        case 'float32':\n          return Float32Array;\n        case 'uint8':\n          return Uint8Array;\n        case 'int8':\n          return Int8Array;\n        case 'uint16':\n          return Uint16Array;\n        case 'int16':\n          return Int16Array;\n        case 'int32':\n          return Int32Array;\n        case 'bool':\n          return Uint8Array;\n        case 'float64':\n          return Float64Array;\n        case 'uint32':\n          return Uint32Array;\n        case 'int64':\n          return BigInt64Array;\n        case 'uint64':\n          return BigUint64Array;\n        default:\n          throw new Error(`unsupported type: ${type}`);\n      }\n    };\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes => type === 'float32' ||\n    type === 'int32' || type === 'int64' || type === 'bool' || type === 'float16' || type === 'uint32';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation|undefined =>\n    (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer'] as const)[location];\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {logLevelStringToEnum} from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString|MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel|undefined;\nlet debug: boolean|undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\nimport {tensorTypeToTypedArrayConstructor} from '../wasm-common';\n\nexport const createView = (dataBuffer: ArrayBuffer, type: Tensor.Type): Int32Array|Uint32Array|BigInt64Array|\n    BigUint64Array|Uint8Array|Float32Array|Float64Array|Int8Array|Int16Array|Uint16Array =>\n        new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../tensor-view';\n\nimport {ShaderHelper} from './ops/common';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2\n}\nexport type GpuDataId = number;\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\n\nexport interface ProgramUniform {\n  type: 'int32'|'float32'|'uint32';\n  data: number|readonly number[];\n}\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none'|'type'|'rank'|'dims'|'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: {x: number; y?: number; z?: number};\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView|number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: {[key: string]: unknown};\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\n\nimport {GpuData, GpuDataId, GpuDataType} from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData|undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(buffer: GPUBuffer): void;\n\n  /**\n   * destroy all gpu buffers. Call this when the session.release is called.\n   */\n  dispose(): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(size / 16) * 16;\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData =\n    async(backend: WebGpuBackend, gpuBuffer: GPUBuffer, originalSize: number, getTargetBuffer?: () => Uint8Array):\n        Promise<Uint8Array> => {\n          const bufferSize = calcNormalizedBufferSize(originalSize);\n          const gpuReadBuffer = backend.device.createBuffer(\n              // eslint-disable-next-line no-bitwise\n              {size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ});\n          try {\n            const commandEncoder = backend.getCommandEncoder();\n            backend.endComputePass();\n            commandEncoder.copyBufferToBuffer(\n                gpuBuffer /* source buffer */, 0 /* source offset */, gpuReadBuffer /* destination buffer */,\n                0 /* destination offset */, bufferSize /* size */\n            );\n            backend.flush();\n\n            await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n            const arrayBuffer = gpuReadBuffer.getMappedRange();\n            if (getTargetBuffer) {\n              // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n              const targetBuffer = getTargetBuffer();\n              targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n              return targetBuffer;\n            } else {\n              // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n              // ArrayBuffer.\n              return new Uint8Array(arrayBuffer.slice(0, originalSize));\n            }\n          } finally {\n            gpuReadBuffer.destroy();\n          }\n        };\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for uploading ( data is unmapped )\n  private buffersForUploadingPending: GPUBuffer[];\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The external buffers registered users for IO Binding.\n  private externalBuffers: Map<GPUBuffer, GpuDataId>;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersForUploadingPending = [];\n    this.buffersPending = [];\n    this.externalBuffers = new Map();\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (gpuDataCache.originalSize !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        {mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC});\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n\n    this.buffersForUploadingPending.push(gpuBufferForUploading);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n        sourceGpuDataCache.gpuData.buffer, 0, destinationGpuDataCache.gpuData.buffer, 0, size);\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number {\n    let id: number|undefined;\n    if (previousBuffer) {\n      id = this.externalBuffers.get(previousBuffer);\n      if (id === undefined) {\n        throw new Error('previous buffer is not registered');\n      }\n      if (buffer === previousBuffer) {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${\n                id}, buffer is the same, skip.`);\n        return id;\n      }\n      this.externalBuffers.delete(previousBuffer);\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, {gpuData: {id, type: GpuDataType.default, buffer}, originalSize});\n    this.externalBuffers.set(buffer, id);\n    LOG_DEBUG(\n        'verbose',\n        () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`);\n    return id;\n  }\n\n  unregisterExternalBuffer(buffer: GPUBuffer): void {\n    const id = this.externalBuffers.get(buffer);\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      this.externalBuffers.delete(buffer);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcNormalizedBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      let buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        buffers = [];\n        freeBuffers.set(bufferSize, buffers);\n      }\n      if (buffers.length > 0) {\n        gpuBuffer = buffers.pop() as GPUBuffer;\n      } else {\n        // create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n    }\n\n    const gpuData = {id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer};\n    this.storageCache.set(gpuData.id, {gpuData, originalSize: size});\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData|undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(id: GpuDataId): number {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('releasing data does not exist');\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    for (const buffer of this.buffersForUploadingPending) {\n      // upload buffer is only useful in the session creation time. So we don't need to reuse them in session running.\n      buffer.destroy();\n    }\n    this.buffersForUploadingPending = [];\n    for (const buffer of this.buffersPending) {\n      // eslint-disable-next-line no-bitwise\n      if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n        // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n        this.freeBuffers.get(buffer.size)!.push(buffer);\n        // eslint-disable-next-line no-bitwise\n      } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n        // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n        this.freeUniformBuffers.get(buffer.size)!.push(buffer);\n      } else {\n        buffer.destroy();\n      }\n    }\n    this.buffersPending = [];\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n    new GpuDataManagerImpl(...args);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private _cacheKey: string;\n  public get cacheKey(): string {\n    if (!this._cacheKey) {\n      this._cacheKey =\n          Object.getOwnPropertyNames(this).sort().map(name => `${(this as Record<string, unknown>)[name]}`).join(';');\n    }\n    return this._cacheKey;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(attribute: T): T&AttributeWithCacheKey =>\n    new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number]|undefined {\n    return (a[1] !== b[0]) ? undefined : [a[0], b[1]];\n  }\n}\n\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(adims: readonly number[], bdims: readonly number[], isMatMul = false): readonly number[]|undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul =\n          MatMulUtil.calcMatMulShape([adims[arank - 2], adims[arank - 1]], [bdims[brank - 2], bdims[brank - 1]]);\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      cdims[crank - i] = Math.max(aLen, bLen);\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n            // eslint-disable-next-line max-len\n            'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.');\n      }\n      size *= dims[i];\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map(x => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n      isGlobalOperator: boolean, inputDims: readonly number[], kernelShape: number[], strides: number[],\n      dilations: number[], pads: number[]): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n      inputDims: readonly number[], strides: readonly number[], dilations: readonly number[],\n      kernelShape: readonly number[], pads: number[], isChannelLast: boolean, autoPad?: string): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== (inputDims.length - 2)) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== (inputDims.length - 2)) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n          inputDims[dim + (isChannelLast ? 1 : 2)], strides[dim], dilations[dim], kernelShape[dim], pads, dim,\n          dim + inputDims.length - 2, autoPad);\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n      isGlobalOperator: boolean, inputDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n        isGlobalOperator, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n      inputDims: readonly number[], filterDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n      isGlobalOperator: boolean, inputDims: readonly number[], outputDims: number[], strides: readonly number[],\n      dilations: readonly number[], kernelShape: readonly number[], pads: number[], autoPad?: string) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2], strides[dim], dilations[dim], kernelShape[dim], pads, dim, dim + inputDims.length - 2,\n            autoPad));\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n      inSize: number, stride: number, dilation: number, kernel: number, pads: number[], padHeadIndex: number,\n      padTailIndex: number, autoPad?: string): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor(((inSize - dkernel) / stride) + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] =\n                (autoPad === 'SAME_LOWER') ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor(((inSize + padNeeded - kernel) / stride) + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor(((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride) + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n      leftShape: readonly number[], transLeft: boolean, rightShape: readonly number[], transRight: boolean,\n      biasShape?: readonly number[]): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\n\nexport const MIN_CLIP = -3.4028234663852886e+38;\nexport const MAX_CLIP = 3.4028234663852886e+38;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {ShapeUtil} from '../../util';\nimport {ProgramUniform} from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input or an output) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number|string, value: number|string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number|string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number|string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number|string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input or an output.\n   */\n  readonly usage: 'input'|'output';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1|2|3|4): string|[string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (type) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (dims: readonly number[]):\n    ProgramUniform[] => [{type: 'uint32', data: dims}, {type: 'uint32', data: ShapeUtil.computeStrides(dims)}];\n\n/**\n * A helper function to get maximum vector size for specified data length\n * @param size\n */\nexport const getMaxComponents = (size: number) => {\n  // we cannot use vec3 type since it has alignment of 16 bytes\n  if (size % 4 === 0) {\n    return 4;\n  } else if (size % 2 === 0) {\n    return 2;\n  }\n\n  return 1;\n};\n\n/**\n * A helper function that initializes variable as a scalar or vector. e.g. f32(0) or vec4f(0,0,0,0)\n * @param dataType\n * @param components\n * @param value\n */\nexport const fillVector = (dataType = 'f32', components?: number, value = '0') => {\n  if (!components || components === 1) {\n    return `${dataType}(${value})`;\n  }\n\n  return `vec${components}<${dataType}>(${value})`;\n};\n\n/**\n * A helper function that casts value or vector to f32\n * @param dataType\n * @param components\n * @param value\n */\nexport const castToF32 = (dataType: string, components: number, value: string) => {\n  if (dataType === 'f32') {\n    return value;\n  }\n  if (components === 1) {\n    return `f32(${value})`;\n  }\n\n  return `vec${components}f(${value})`;\n};\n\n/**\n * A helper function that returns scalar or sums all components of a vector\n * @param name\n * @param components\n */\nexport const sumVector = (name: string, components: number) => {\n  if (components === 4) {\n    return `(${name}.x + ${name}.y + ${name}.z + ${name}.w)`;\n  } else if (components === 2) {\n    return `(${name}.x + ${name}.y)`;\n  } else if (components === 3) {\n    return `(${name}.x + ${name}.y + ${name}.z)`;\n  }\n\n  return name;\n};\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param isInput - whether the helper is for an input or an output.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper =\n    (name: string, tensorType: number, shapeOrRank: number|readonly number[], isInput: boolean,\n     components: 1|2|3|4): IndicesHelper => {\n      const useUniform = typeof shapeOrRank === 'number';\n      const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n      const rankIdentity = [...new Array(rank).keys()];\n      const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n      const mappedType = getWgslMappedType(tensorType, components);\n      const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n      const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n      const type = {indices: indicesType, value: valueType, storage: storageType, tensor: tensorType};\n\n      const normalizeDim = (dim: number|string): string => typeof dim === 'string' ? dim : `${dim}u`;\n\n      const implementationUsed = {\n        offsetToIndices: false,\n        indicesToOffset: false,\n        broadcastedIndicesToOffset: false,\n        set: false,\n        setByIndices: false,\n        get: false,\n        getByIndices: false,\n      };\n\n      const uniformPrefix = useUniform ? 'uniforms.' : '';\n      const shape = `${uniformPrefix}${name}_shape`;\n      const strides = `${uniformPrefix}${name}_strides`;\n      let o2iSnippet = '';\n      for (let i = 0; i < rank - 1; i++) {\n        o2iSnippet += `\n    let dim${i} = current / ${strides}[${i}];\n    let rest${i} = current % ${strides}[${i}];\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n      }\n      o2iSnippet += `indices[${rank - 1}] = current;`;\n\n      const offsetToIndicesImplementation = rank < 2 ? '' : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n      const offsetToIndices = (varOffset: string) => {\n        implementationUsed.offsetToIndices = true;\n        return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n      };\n\n      const offsets: string[] = [];\n      if (rank >= 2) {\n        for (let i = rank - 1; i >= 0; i--) {\n          offsets.push(`${strides}[${i}] * (indices[${i}])`);\n        }\n      }\n\n      const indicesToOffsetImplementation = rank < 2 ? '' : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n      const indicesToOffset = (varIndices: string) => {\n        implementationUsed.indicesToOffset = true;\n        return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n      };\n\n      const indices = (...init: ReadonlyArray<number|string>) =>\n          rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n      const indicesGet = (varIndices: string, idx: number|string) => {\n        if (rank < 2) {\n          return `${varIndices}`;\n        } else {\n          return `${varIndices}[${idx}]`;\n        }\n      };\n\n      const indicesSet = (varIndices: string, idx: number|string, value: string) => {\n        if (rank < 2) {\n          return `${varIndices}=${value};`;\n        } else {\n          return `${varIndices}[${idx}]=${value};`;\n        }\n      };\n\n      const broadcastedIndicesToOffsetImplementation: {[key: string]: string} = {};\n      const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n        implementationUsed.broadcastedIndicesToOffset = true;\n        const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n        if (implKey in broadcastedIndicesToOffsetImplementation) {\n          return `${implKey}(${varIndices})`;\n        }\n        const offsets = [];\n        for (let i = rank - 1; i >= 0; i--) {\n          const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n          offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n        }\n        broadcastedIndicesToOffsetImplementation[implKey] =\n            `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n        return `${implKey}(${varIndices})`;\n      };\n\n      const setByOffset = (offset: number|string, value: string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]=${value};`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByOffset = (offset: number|string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `i32(${name}[${offset}].x)`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `u32(${name}[${offset}].x)`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n              offset}] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByIndicesImplementation = rank < 2 ? '' : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n      const getImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n      })();\n\n      const get = (...indices: ReadonlyArray<number|string>) => {\n        if (indices.length !== rank) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n\n        const normalizedIndices = indices.map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return getByOffset('0u');\n        } else if (rank === 1) {\n          return getByOffset(normalizedIndices[0]);\n        } else {\n          implementationUsed.get = true;\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}(${normalizedIndices})`;\n        }\n      };\n\n      const getByIndices = (varIndices: string) => {\n        if (rank < 2) {\n          return getByOffset(varIndices);\n        } else {\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}ByIndices(${varIndices})`;\n        }\n      };\n\n      const setByIndicesImplementation = rank < 2 ? '' : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n      const setImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n      })();\n\n      const set = (...indicesAndValue: ReadonlyArray<number|string>) => {\n        if (indicesAndValue.length !== rank + 1) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n        const value = indicesAndValue[rank];\n        if (typeof value !== 'string') {\n          throw new Error('value must be string');\n        }\n\n        const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return setByOffset('0u', value);\n        } else if (rank === 1) {\n          return setByOffset(normalizedIndices[0], value);\n        } else {\n          implementationUsed.set = true;\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}(${normalizedIndices}, ${value})`;\n        }\n      };\n\n      const setByIndices = (varIndices: string, value: string) => {\n        if (rank < 2) {\n          return setByOffset(varIndices, value);\n        } else {\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}ByIndices(${varIndices}, ${value});`;\n        }\n      };\n\n      const impl = () => {\n        const impls = [];\n        if (!useUniform) {\n          impls.push(`const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`);\n          impls.push(`const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`);\n        }\n        if (implementationUsed.offsetToIndices) {\n          impls.push(offsetToIndicesImplementation);\n        }\n        if (implementationUsed.indicesToOffset) {\n          impls.push(indicesToOffsetImplementation);\n        }\n        if (implementationUsed.broadcastedIndicesToOffset) {\n          Object.values(broadcastedIndicesToOffsetImplementation).forEach(impl => impls.push(impl));\n        }\n        if (implementationUsed.set) {\n          impls.push(setImplementation);\n        }\n        if (implementationUsed.setByIndices) {\n          impls.push(setByIndicesImplementation);\n        }\n        if (implementationUsed.get) {\n          impls.push(getImplementation);\n        }\n        if (implementationUsed.getByIndices) {\n          impls.push(getByIndicesImplementation);\n        }\n        return impls.join('\\n');\n      };\n\n      return {\n        impl,\n        type,\n        offsetToIndices,\n        indicesToOffset,\n        broadcastedIndicesToOffset,\n        indices,\n        indicesGet,\n        indicesSet,\n        set,\n        setByOffset,\n        setByIndices,\n        get,\n        getByOffset,\n        getByIndices,\n        // isVec4,\n        usage: isInput ? 'input' : 'output',\n        name,\n        strides,\n        shape,\n        rank\n      };\n    };\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, true, components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, false, components);\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number|[number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   */\n  registerUniform(name: string, type: string): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(private normalizedDispatchGroup: [number, number, number]) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number|string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number|[number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>` :\n                                             `@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch ?\n        'let global_idx = global_id.x;' :\n        `let global_idx = (workgroup_id.z * ${this.normalizedDispatchGroup[0] * this.normalizedDispatchGroup[1]}u +\n          workgroup_id.y * ${this.normalizedDispatchGroup[0]}u + workgroup_id.x) * ${\n            workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_index;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    this.indicesHelpers.push(variable);\n    if (variable.shape.startsWith('uniforms.')) {\n      this.uniforms.push({name: variable.shape.replace('uniforms.', ''), type: variable.type.indices});\n    }\n    if (variable.strides.startsWith('uniforms.')) {\n      this.uniforms.push({name: variable.strides.replace('uniforms.', ''), type: variable.type.indices});\n    }\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map(v => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  registerUniform(name: string, type: string): ShaderHelper {\n    this.uniforms.push({name, type});\n    return this;\n  }\n\n  private indicesHelpers: IndicesHelper[] = [];\n  private uniforms: Array<{name: string; type: string}> = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const {name, type} of this.uniforms) {\n      uniformSnippets.push(`${name}:${type}`);\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return this.uniformDeclaration() + this.indicesHelpers.map(i => i.impl()).join('\\n');\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number]) => new ShaderHelperImpl(dispatchGroup);\n\n/**\n * This function comes from https://github.com/tensorflow/tfjs/blob/master/tfjs-core/src/ops/broadcast_util.ts#L18-L40\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport const getBroadcastDims = (inShape: readonly number[], outShape: readonly number[]): number[] => {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n};\n\n// TODO: remove this limitation once >4D dims are supported by uniform.\nexport const enableShapesUniforms = (rank: number): boolean => rank <= 4;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n    (perm && perm.length !== inputRank) ? [...(new Array(inputRank).keys())].reverse() : perm;\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n    ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nexport const createTransposeProgramInfo = (inputTensor: TensorView, permAttr: number[]): ProgramInfo => {\n  const inputDataType = inputTensor.dataType;\n  const inputRank = inputTensor.dims.length;\n  const perm = getAdjustedPerm(inputRank, permAttr);\n  const useShapesUniforms = enableShapesUniforms(inputRank);\n  const outputShape = getOutputShape(inputTensor.dims, perm);\n  const outShapeOrRank = useShapesUniforms ? outputShape.length : outputShape;\n  const inShapeOrRank = useShapesUniforms ? inputRank : inputTensor.dims;\n  const output = outputVariable('output', inputDataType, outShapeOrRank);\n  const input = inputVariable('a', inputDataType, inShapeOrRank);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n  return {\n    name: 'Transpose',\n    shaderCache: {hint: `${permAttr}`, inputDependencies: useShapesUniforms ? ['rank'] : ['dims']},\n    getRunData: (inputs) => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n        dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        programUniforms: useShapesUniforms ?\n            [\n              {type: 'uint32', data: outputSize},\n              ...createTensorShapeVariables(inputs[0].dims),\n              ...createTensorShapeVariables(outputShape),\n            ] :\n            [\n              {type: 'uint32', data: outputSize},\n            ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createTransposeProgramInfo(context.inputs[0], attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n    createAttributeWithCacheKey({perm: attributes.perm as number[]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {createReduceAttributesFromInputs, ReduceAttributes} from './reduce';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst reduceOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate * candidate',\n  logSumExp: 'bestValue + exp(candidate)',\n  l1: 'bestValue + abs(candidate)',\n  l2: 'bestValue + candidate * candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceSharedOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate',\n  logSumExp: 'bestValue + candidate',\n  l1: 'bestValue + candidate',\n  l2: 'bestValue + candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceInitValues: {[key: string]: string} = {\n  max: '_A[offset]',\n  min: '_A[offset]',\n  mean: '0',\n  sum: '0',\n  prod: '1',\n  sumSquare: '0',\n  logSumExp: '0',\n  l1: '0',\n  l2: '0',\n  logSum: '0'\n};\n\nconst reduceOutputValues: {[key: string]: string} = {\n  max: 'bestValue',\n  min: 'bestValue',\n  sum: 'bestValue',\n  prod: 'bestValue',\n  sumSquare: 'bestValue',\n  logSumExp: 'log(bestValue)',\n  l1: 'bestValue',\n  l2: 'sqrt(bestValue)',\n  logSum: 'log(bestValue)'\n};\n\nconst getInnerMostAxes = (numInnerAxes: number, rank: number): number[] => {\n  const res = [];\n  for (let i = rank - numInnerAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n};\n\nconst computeOutAndReduceShapes = (shape: readonly number[], axes: readonly number[]): [number[], number[]] => {\n  const outputShape = [];\n  const rank = shape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputShape.push(shape[dim]);\n    }\n  }\n  const reduceShape = axes.map(dim => shape[dim]);\n  return [outputShape, reduceShape];\n};\n\nconst expandShapeToKeepDim = (shape: number[], axes: number[]): number[] => {\n  const rank = shape.length + axes.length;\n  const expandShape = [];\n  let shapeIdx = 0;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      expandShape.push(shape[shapeIdx++]);\n    } else {\n      expandShape.push(1);\n    }\n  }\n  return expandShape;\n};\n\nconst areAxesInnerMostDims = (axes: number[], rank: number): boolean => {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n};\n\nconst getAxesPermutation = (axes: number[], rank: number): number[] => {\n  const res = [];\n  if (!areAxesInnerMostDims(axes, rank)) {\n    for (let i = 0; i < rank; ++i) {\n      if (axes.indexOf(i) === -1) {\n        res.push(i);\n      }\n    }\n    axes.forEach(axis => res.push(axis));\n  }\n  return res;\n};\n\nexport const createReduceSharedProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceType: string,\n     outputDataType: DataType, outputShape: number[], reduceShape: number[]): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const reduceSize = ShapeUtil.size(reduceShape);\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n\n      const workgroupSize = 32;\n\n      const sharedMemorySnippet = `\n          var<workgroup> aBestValues : array<${output.type.storage}, ${workgroupSize}>;\n       `;\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.registerUniform('reduceSize', 'u32').declareVariables(input, output)}\n        ${sharedMemorySnippet}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${shaderHelper.mainStart(workgroupSize)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${workgroupSize};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${output.type.storage}(${reduceInitValues[reduceType]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${workgroupSize}) {\n           let candidate = ${output.type.storage}(${input.getByOffset('offset + k')});\n           bestValue = ${reduceOps[reduceType]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${workgroupSize}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${reduceSharedOps[reduceType]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${\n          output.setByOffset(\n              'outputIndex',\n              `${\n                  reduceType === 'mean' ? `bestValue / ${output.type.storage}(uniforms.reduceSize)` :\n                                          `${reduceOutputValues[reduceType]}`}`)};\n         }\n        }`;\n\n      // One work group is responsible for only one element of output.\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: outputSize},\n          programUniforms: [{type: 'uint32', data: reduceSize}]\n        }),\n      };\n    };\n\nconst reduceCommon =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes,\n     reduceType: 'sum'|'sumSquare'|'prod'|'min'|'max'|'mean'|'logSumExp'|'l1'|'l2'|'logSum'): void => {\n      const updatedAttributes: ReduceAttributes =\n          context.inputs.length === 1 ? attributes : createReduceAttributesFromInputs(context.inputs, attributes);\n\n      let updatedAxes = updatedAttributes.axes;\n      if (updatedAxes.length === 0 && !updatedAttributes.noopWithEmptyAxes) {\n        updatedAxes = context.inputs[0].dims.map((s, i) => i);\n      }\n      const normalizeAxes = ShapeUtil.normalizeAxes(updatedAxes, context.inputs[0].dims.length);\n\n      let axes = normalizeAxes;\n      let input = context.inputs[0];\n      const permutedAxes = getAxesPermutation(axes, context.inputs[0].dims.length);\n      if (permutedAxes.length > 0) {\n        input = context.compute(\n            createTransposeProgramInfo(context.inputs[0], permutedAxes), {inputs: [0], outputs: [-1]})[0];\n        axes = getInnerMostAxes(axes.length, input.dims.length);\n      }\n\n      const [outputShape, reduceShape] = computeOutAndReduceShapes(input.dims, axes);\n      let finalOutputShape = outputShape;\n      if (updatedAttributes.keepDims) {\n        finalOutputShape = expandShapeToKeepDim(outputShape, normalizeAxes);\n      }\n\n      context.compute(\n          createReduceSharedProgramInfo(\n              name, {hint: updatedAttributes.cacheKey, inputDependencies: ['type']}, [input], reduceType,\n              context.inputs[0].dataType, finalOutputShape, reduceShape),\n          {inputs: [input]});\n    };\n\nexport const reduceMeanShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMeanShared', attributes, 'mean');\n};\n\nexport const reduceL1Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL1Shared', attributes, 'l1');\n};\n\nexport const reduceL2Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL2Shared', attributes, 'l2');\n};\n\nexport const reduceLogSumExpShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumExpShared', attributes, 'logSumExp');\n};\n\nexport const reduceMaxShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMaxShared', attributes, 'max');\n};\n\nexport const reduceMinShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMinShared', attributes, 'min');\n};\n\nexport const reduceProdShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceProdShared', attributes, 'prod');\n};\n\nexport const reduceSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumShared', attributes, 'sum');\n};\n\nexport const reduceSumSquareShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumSquareShared', attributes, 'sumSquare');\n};\n\nexport const reduceLogSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumShared', attributes, 'logSum');\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\nimport {reduceL1Shared, reduceL2Shared, reduceLogSumExpShared, reduceLogSumShared, reduceMaxShared, reduceMeanShared, reduceMinShared, reduceProdShared, reduceSumShared, reduceSumSquareShared} from './reduce-shared';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp =\n    (input: IndicesHelper, output: IndicesHelper,\n     axes: readonly number[]) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByOffset('inputOffset')};`, ''];\nexport const createReduceProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceOp: ReduceOp,\n     axesInput: number[], outputDataType: DataType, keepDims = false, noopWithEmptyAxes = false): ProgramInfo => {\n      const outputShape: number[] = [];\n      const inputShape = inputs[0].dims;\n\n      const axes = ShapeUtil.normalizeAxes(axesInput, inputs[0].dims.length);\n      const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n      inputShape.forEach((d, i) => {\n        if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n          if (keepDims) {\n            outputShape.push(1);\n          }  // else { // skip this axis}\n        } else {\n          outputShape.push(d);\n        }\n      });\n\n      const idxCopy: string[] = [];  // copy output indexes to input indexes\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n      const ops = reduceOp(input, output, axes);\n      const inputOffsetAssignment = `inputOffset = ${input.indicesToOffset('inputIndices')};`;\n      const initinputOffsetLet = `let ${inputOffsetAssignment};`;\n      const initinputOffsetVar = `var ${inputOffsetAssignment};`;\n      const initinputOffset = (ops[1] === '') ? '' : initinputOffsetVar;\n      let reduceOps = ((ops[1] === '') ? initinputOffsetLet : inputOffsetAssignment) + '\\n' + ops[2];\n\n      for (let k = 0, l = 0; k < inputs[0].dims.length; k++) {\n        // if this axis is reduced\n        if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n          if (keepDims) {\n            l++;\n          }\n          // loop over the d-th axis\n          reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputs[0].dims[k]}; j${k}++) {\n                ${ops[2].includes('lastIndex') ? `let lastIndex = j${k};` : ''}\n                ${input.indicesSet('inputIndices', k, `j${k}`)}\n                ${reduceOps}\n              }`;\n        } else {\n          idxCopy.push(`${input.indicesSet('inputIndices', k, output.indicesGet('outputIndices', l))};`);\n          l++;\n        }\n      }\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          var inputIndices: ${input.type.indices};\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${initinputOffset}\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n      };\n    };\n\nexport const createReduceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ReduceAttributes): ReduceAttributes => {\n      const axes: number[] = [];\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => axes.push(Number(v)));\n      }\n      return createAttributeWithCacheKey(\n          {axes, keepDims: attributes.keepDims, noopWithEmptyAxes: attributes.noopWithEmptyAxes});\n    };\n\nconst runReduceProgram =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes, reduceOp: ReduceOp): void => {\n      const inputs = context.inputs;\n      const updatedAttributes: ReduceAttributes =\n          inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n      context.compute(\n          createReduceProgramInfo(\n              name, {hint: updatedAttributes.cacheKey}, [inputs[0]],\n              updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n              updatedAttributes.axes, inputs[0].dataType, updatedAttributes.keepDims,\n              updatedAttributes.noopWithEmptyAxes),\n          {inputs: [0]});\n    };\n\nconst reduceLogSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nconst reduceL1Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += abs(${input.getByOffset('inputOffset')});`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nconst reduceL2Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += (t * t);`,\n       'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nconst reduceLogSumExpNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += exp(${input.getByOffset('inputOffset')});`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nconst reduceMaxNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('inputIndices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = max(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nconst reduceMeanNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByOffset('inputOffset')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nconst reduceMinNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = min(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nconst reduceProdNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(1);`,\n       '',\n       `value *= ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nconst reduceSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nconst reduceSumSquareNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += t * t;`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nconst useNaiveReduceMethod =\n    (shape: readonly number[], axes: readonly number[], noopWithEmptyAxes: boolean): boolean => {\n      if (axes.length === 0) {\n        return noopWithEmptyAxes ? true : false;\n      }\n\n      let outputSize = 1;\n      let reduceSize = 1;\n      for (let dim = 0; dim < axes.length; dim++) {\n        if (axes.indexOf(dim) === -1) {\n          outputSize *= shape[dim];\n        } else {\n          reduceSize *= shape[dim];\n        }\n      }\n\n      // The condition data is very rough, although considering the count of Execution Unit (EU), the potential\n      // work groups in a EU and the counts of loops in the naive and shared methods, also doing experiments\n      // on some machines.\n      return reduceSize < 32 && outputSize > 1024 ? true : false;\n    };\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMeanNaive(context, attributes);\n  } else {\n    reduceMeanShared(context, attributes);\n  }\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL1Naive(context, attributes);\n  } else {\n    reduceL1Shared(context, attributes);\n  }\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL2Naive(context, attributes);\n  } else {\n    reduceL2Shared(context, attributes);\n  }\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumExpNaive(context, attributes);\n  } else {\n    reduceLogSumExpShared(context, attributes);\n  }\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMaxNaive(context, attributes);\n  } else {\n    reduceMaxShared(context, attributes);\n  }\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMinNaive(context, attributes);\n  } else {\n    reduceMinShared(context, attributes);\n  }\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceProdNaive(context, attributes);\n  } else {\n    reduceProdShared(context, attributes);\n  }\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumNaive(context, attributes);\n  } else {\n    reduceSumShared(context, attributes);\n  }\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumSquareNaive(context, attributes);\n  } else {\n    reduceSumSquareShared(context, attributes);\n  }\n};\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumNaive(context, attributes);\n  } else {\n    reduceLogSumShared(context, attributes);\n  }\n};\n\nexport const parseReduceAttributes = (attributes: Record<string, unknown>): ReduceAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ReduceAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createReduceProgramInfo, ReduceOp} from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nconst createArgMinMaxAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ArgMinMaxAttributes): ArgMinMaxAttributes =>\n        createAttributeWithCacheKey(\n            {axis: attributes.axis, keepDims: attributes.keepDims, selectLastIndex: attributes.selectLastIndex});\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  const updatedAttributes: ArgMinMaxAttributes =\n      context.inputs.length === 1 ? attributes : createArgMinMaxAttributesFromInputs(context.inputs, attributes);\n  context.compute(\n      createReduceProgramInfo(\n          'ArgMin', {hint: updatedAttributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [updatedAttributes.axis],\n          DataType.int64, updatedAttributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  const updatedAttributes: ArgMinMaxAttributes =\n      context.inputs.length === 1 ? attributes : createArgMinMaxAttributesFromInputs(context.inputs, attributes);\n  context.compute(\n      createReduceProgramInfo(\n          'argMax', {hint: updatedAttributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [updatedAttributes.axis],\n          DataType.int64, updatedAttributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {MAX_CLIP, MIN_CLIP, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName|ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader =\n    (shaderHelper: ShaderHelper, datasize: number, inputDataType: number, outputDataType: number,\n     funcCall: ElementwiseFunctionCall, additionalImplementation?: string): string => {\n      const vecSize = Math.ceil(datasize / 4);\n\n      let expression = '';\n      if (typeof funcCall === 'string') {\n        expression = `${funcCall}(a)`;\n      } else {\n        expression = funcCall('a');\n      }\n\n      const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n      const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n\n      return `\n  ${shaderHelper.declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n    };\n\nconst createElementwiseProgramInfo =\n    (input: TensorView, name: string, funcCall: ElementwiseFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType: number = input.dataType): ProgramInfo => ({\n      name,\n      shaderCache: {hint: cacheKey},\n      getShaderSource: shaderHelper => createElementwiseProgramShader(\n          shaderHelper, ShapeUtil.size(input.dims), input.dataType, outputDataType, funcCall, additionalImplementation),\n      getRunData: (inputTensors) => ({\n        outputs: [{dims: input.dims, dataType: outputDataType}],\n        dispatchGroup:\n            {x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */)}\n      })\n    });\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n    createAttributeWithCacheKey(attributes as {to: number});\n\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n      createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to));\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nexport const clipV10 = (context: ComputeContext, attributes: ClipAttributes): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(\n      createElementwiseProgramInfo(\n          context.inputs[0], 'Clip', a => `clamp(${a}, clip_min_, clip_max_)`, `\n    const clip_min_: vec4<${dataType}> = vec4(${dataType}(${attributes.min}));\n    const clip_max_: vec4<${dataType}> = vec4(${dataType}(${attributes.max}));\n`,\n          attributes.cacheKey),\n      {inputs: [0]});\n};\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  const min = (inputs.length >= 2) ? inputs[1].getFloat32Array()[0] : MIN_CLIP;\n  const max = (inputs.length >= 3) ? inputs[2].getFloat32Array()[0] : MAX_CLIP;\n  return createAttributeWithCacheKey({min, max});\n};\n\nexport const clip = (context: ComputeContext): void => {\n  const attributes = generateClipAttributesFromInputs(context.inputs);\n  clipV10(context, attributes);\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n    createAttributeWithCacheKey(attributes as {alpha: number});\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Elu', a => `elu_vf32(${a})`, `\n  const elu_alpha_: f32 = f32(${attributes.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey));\n};\n\nexport const erfImpl = (dataType: string, varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: ${dataType}) -> ${dataType} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Erf', a => `erf_vf32(${a})`, erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Gelu', a => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'LeakyRelu', a => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<f32>(0.0))`,\n      `const leaky_relu_alpha_: f32 = f32(${attributes.alpha});`, attributes.cacheKey));\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', a => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', a => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', a => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Relu', a => `select(vec4<f32>(0.0), ${a}, ${a} > vec4<f32>(0.0))`));\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', a => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', 'tanh'));\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'ThresholdedRelu', a => `select(vec4<f32>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${attributes.alpha});`, attributes.cacheKey));\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {erfImpl} from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl('vec4f')}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall = BuiltinFunctionName|BinaryCustomExpression|{\n  scalar: BinaryCustomExpression;\n  vector: BinaryCustomExpression;\n};\n\nconst createBinaryOpProgramShader =\n    (shaderHelper: ShaderHelper, dimsA: readonly number[], dimsB: readonly number[], dimsOutput: readonly number[],\n     vectorize: boolean, doBroadcast: boolean, funcCall: BinaryFunctionCall, typeA: number, typeB: number,\n     typeOutput: number, additionalImplementation?: string) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      let expressionScalar: BinaryCustomExpression;\n      let expressionVector: BinaryCustomExpression;\n      if (typeof funcCall === 'string') {\n        expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n      } else if (typeof funcCall === 'function') {\n        expressionScalar = expressionVector = funcCall;\n      } else {\n        expressionScalar = funcCall.scalar;\n        expressionVector = funcCall.vector;\n      }\n\n      let broadcastImpl = '';\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', typeA, dimsA, 4);\n      const b = inputVariable('bData', typeB, dimsB, 4);\n      if (doBroadcast) {\n        const calcOffsetImpl = (dims: readonly number[]) => {\n          const strides = ShapeUtil.computeStrides(dims);\n          const offsets: string[] = [];\n          for (let i = dims.length - 1; i >= 0; i--) {\n            const idx = output.indicesGet('outputIndices', i + dimsOutput.length - dims.length);\n            offsets.push(`${strides[i]}u * (${idx} % ${dims[i]}u)`);\n          }\n          return offsets.length > 0 ? offsets.join('+') : '0u';\n        };\n\n        broadcastImpl = `\n          fn calcOffsetA(outputIndices: ${output.type.indices}) -> u32 {\n            return ${calcOffsetImpl(dimsA)};\n          }\n\n          fn calcOffsetB(outputIndices: ${output.type.indices}) -> u32 {\n            return ${calcOffsetImpl(dimsB)};\n          }\n        `;\n      }\n\n      let assignment: string;\n      if (vectorize) {\n        if (doBroadcast) {\n          const isAOneElement = ShapeUtil.size(dimsA) === 1;\n          const isBOneElement = ShapeUtil.size(dimsB) === 1;\n          if (isAOneElement || isBOneElement) {\n            assignment = output.setByOffset(\n                'global_idx',\n                expressionVector(\n                    isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n                    isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx')));\n          } else {\n            assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = calcOffsetA(outputIndices);\n            let offsetB = calcOffsetB(outputIndices);\n            ${\n                output.setByOffset(\n                    'global_idx', expressionVector(a.getByOffset('offsetA / 4u'), b.getByOffset('offsetB / 4u')))}\n          `;\n          }\n        } else {\n          assignment = output.setByOffset(\n              'global_idx', expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')));\n        }\n      } else {\n        if (!doBroadcast) {\n          throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n        }\n\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = calcOffsetA(outputIndices${x});\n            let offsetB${x} = calcOffsetB(outputIndices${x});\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n        ${broadcastImpl}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createBinaryOpProgramInfo =\n    (name: string, cacheKey: string, a: TensorView, b: TensorView, funcCall: BinaryFunctionCall,\n     additionalImplementation?: string, outputDataType: number = a.dataType): ProgramInfo => {\n      const isBroadcast = !ShapeUtil.areEqual(a.dims, b.dims);\n      let outputShape = a.dims;\n      let outputSize = ShapeUtil.size(a.dims);\n\n      let vectorize = false;\n\n      // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n      if (isBroadcast) {\n        const calculatedShape = BroadcastUtil.calcShape(a.dims, b.dims, false);\n        if (!calculatedShape) {\n          throw new Error('Can\\'t perform binary op on the given tensors');\n        }\n        outputShape = calculatedShape;\n        outputSize = ShapeUtil.size(outputShape);\n        const isAOneElement = ShapeUtil.size(a.dims) === 1;\n        const isBOneElement = ShapeUtil.size(b.dims) === 1;\n\n        // check whether vectorize can be enabled\n        let sharedDimension = 1;\n        for (let i = 1; i < outputShape.length; i++) {\n          const dimA = a.dims[a.dims.length - i] ?? 1;\n          const dimB = b.dims[b.dims.length - i] ?? 1;\n          if (dimA === dimB) {\n            sharedDimension *= dimA;\n          } else {\n            break;\n          }\n        }\n        if (sharedDimension % 4 === 0 || isAOneElement || isBOneElement) {\n          vectorize = true;\n        }\n      } else {\n        // element-wise\n        vectorize = true;\n      }\n\n      return {\n        name,\n        shaderCache: {hint: cacheKey},\n        getShaderSource: (shaderHelper) => createBinaryOpProgramShader(\n            shaderHelper, a.dims, b.dims, outputShape, vectorize, isBroadcast, funcCall, a.dataType, b.dataType,\n            outputDataType, additionalImplementation),\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */)}\n        }),\n      };\n    };\n\nconst runBinaryOp =\n    (context: ComputeContext, name: string, funcCall: BinaryFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType?: number): void => {\n      context.compute(createBinaryOpProgramInfo(\n          name, cacheKey ?? '', context.inputs[0], context.inputs[1], funcCall, additionalImplementation,\n          outputDataType));\n    };\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Equal', ({scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n      context, 'Pow', ({scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})`}),\n      `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${\n          roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `);\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Greater', ({scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Less', ({scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'GreaterOrEqual', ({scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'LessOrEqual', ({scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n\n  const inputType = inputs[0].dataType;\n  const inputDimensionality = inputs[0].dims.length;\n\n  for (const input of inputs) {\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputDimensionality) {\n      throw new Error('input tensors should have the same shape');\n    }\n  }\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (inputs: readonly TensorView[], axis: number): ProgramInfo => {\n  const inputShape = inputs[0].dims.slice();\n  if (axis >= inputShape.length || axis < (-1 * inputShape.length)) {\n    throw new Error('axis specified for concat doesn\\'t match input dimensionality');\n  }\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  // ensure all of the non-concatenated axes match each other\n  // calculate the shape of the output tensor while we do that\n  const outputShape = inputShape.slice(0);\n  for (let i = 1; i < inputs.length; i++) {\n    const dataNShape = inputs[i].dims.slice();\n    for (let axisIndex = 0; axisIndex < inputShape.length; axisIndex++) {\n      // add to the placeholder for computing output shape\n      if (axisIndex === adjustedAxis) {\n        outputShape[adjustedAxis] += dataNShape[axisIndex];\n      }\n      // ensure all non-cancatenated axes match each other\n      else if (inputShape[axisIndex] !== dataNShape[axisIndex]) {\n        throw new Error('non concat dimensions must match');\n      }\n    }\n  }\n\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  const dataType = inputs[0].dataType;\n\n  let previousSum = 0;\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputs[i].dims);\n  }\n\n  const output = outputVariable('output', dataType, outputShape);\n\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateInputIndexImpl(sizeInConcatAxis.length)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n  return {\n    name: 'Concat',\n    shaderCache: {hint: `${axis}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createConcatProgramInfo(context.inputs, attributes.axis));\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport declare type Activation = 'linear' | 'relu' | 'prelu' | 'elu' | 'relu6' | 'leakyrelu' | 'sigmoid' | 'gelu';\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const activationFnSnippet =\n    (activation?: Activation, _hasPreluActivationWeights = false, _packed = false, _coordsLength = 3): string => {\n      if (!activation) {\n        return '';\n      }\n      // TODO: add implementations\n      return '';\n    };\n\nexport const biasActivationSnippet = (hasBias: boolean, activation?: Activation): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      // TODO uncomment the following line when activation is supported above.\n      // ${activation ? 'value = activation(value, coords);' : ''}\n      `;\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = `\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {MAX_CLIP, MIN_CLIP} from '../../util';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly activationCacheKey: string;\n}\n\nexport const getActivationSnippet = (attributes: InternalActivationAttributes, isVec4 = false): {\n  activationFunction: string; applyActivation: string;\n} => {\n  switch (attributes.activation) {\n    case 'Relu':\n      return {activationFunction: '', applyActivation: 'value = max(value, 0.0);'};\n    case 'Sigmoid':\n      return {activationFunction: '', applyActivation: 'value = (1.0 / (1.0 + exp(-value)));'};\n    case 'Clip':\n      return {\n        activationFunction: `const clip_min_=f32(${attributes.clipMin!});const clip_max_=f32(${attributes.clipMax!});`,\n        applyActivation: isVec4 ? 'value = clamp(value, vec4(clip_min_), vec4(clip_max_));' :\n                                  'value = clamp(value, clip_min_, clip_max_);'\n      };\n      // TODO: adding other activations that can be fused.\n    default:\n      return {activationFunction: '', applyActivation: ''};\n  }\n};\n\nexport const parseInternalActivationAttributes =\n    (attributes: Record<string, unknown>|undefined): InternalActivationAttributes => {\n      const activation = attributes?.activation as string || '';\n\n      if (activation === 'Clip') {\n        const [clipMin, clipMax] = attributes?.activation_params as [number, number] || [MIN_CLIP, MAX_CLIP];\n        return {activation, clipMax, clipMin, activationCacheKey: `${activation}:${clipMin},${clipMax}`};\n      }\n      return {activation, activationCacheKey: activation};\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {getBroadcastDims, IndicesHelper, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {getActivationSnippet, InternalActivationAttributes} from '../fuse-utils';\n\nimport {typeSnippet} from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32): string => {\n      const tileAOuter = workgroupSize[1] * workPerThread[1];\n      const tileBOuter = workgroupSize[0] * workPerThread[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n      const innerElementSize = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n\n      if (!(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n             (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n            tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4)) {\n        throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${\n            innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${\n            tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${\n            workPerThread[0]} must be 4.`);\n      }\n      return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n          batchDims ? ', batchIndices' : ''});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n    };\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n    transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n     sequentialAccessByThreads = false): string => {\n      const tileAOuter = workPerThread[1] * workgroupSize[1];\n      const tileBOuter = workPerThread[0] * workgroupSize[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n\n      if (!(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 &&\n            tileInner % workgroupSize[1] === 0)) {\n        throw new Error(`tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n            workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n            workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n      }\n      const rowPerThreadA = tileAHight / workgroupSize[1];\n      const colPerThreadA = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n      const matmulSnippet = sequentialAccessByThreads ?\n          `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n              transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n                           `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    ` :\n          `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n      return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${matmulSnippet}\n  }\n`;\n    };\n\nconst matMulReadWriteFnSource =\n    (component: number, hasBias: boolean, applyActivation: string, variables: IndicesHelper[],\n     batchShapes: Array<readonly number[]>, isChannelsLast = false): string => {\n      const batchAShape = batchShapes[0];\n      const batchBShape = batchShapes[1];\n      const batchShape = batchShapes[2];\n      const batchVariable = variables[0];\n      const aVariable = variables[1];\n      const bVariable = variables[2];\n      const outputVariable = variables[3];\n      const broadCastADims = getBroadcastDims(batchAShape, batchShape);\n      const broadCastBDims = getBroadcastDims(batchBShape, batchShape);\n      const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n      const getAIndices = () => {\n        const aRank = aVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var aIndices: ${aVariable.type.indices};`;\n        for (let i = aRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\naIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastADims.forEach(i => {\n          resStr += `\\naIndices[${i}] = 0;`;\n        });\n        resStr += `\\naIndices[${aRank - 2}] = u32(row);\n                   aIndices[${aRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const getBIndices = () => {\n        const bRank = bVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var bIndices: ${bVariable.type.indices};`;\n        for (let i = bRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\nbIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastBDims.forEach(i => {\n          resStr += `\\nbIndices[${i}] = 0;`;\n        });\n        resStr += `\\nbIndices[${bRank - 2}] = u32(row);\n                   bIndices[${bRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${getAIndices()}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${getBIndices()}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias ?\n              `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};` :\n                                                  ''                                    }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n      return source;\n    };\n\nexport const createMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const outerDimsA = aShape.slice(0, -2);\n      const outerDimsB = bShape.slice(0, -2);\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const batchDims = inputVariable('batchDims', inputs[0].dataType, outerDims);\n      const variables = [batchDims];\n      const batchShapes = [outerDimsA, outerDimsB, outerDims];\n      const batchSize = ShapeUtil.size(outerDims);\n\n      const dimAOuter = aShape[aShape.length - 2];\n      const dimInner = aShape[aShape.length - 1];\n      const dimBOuter = bShape[bShape.length - 1];\n      const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n      const {activationFunction, applyActivation} = getActivationSnippet(activationAttributes, isVec4);\n\n      // TODO: fine tune size\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const workgroupSize: [number, number, number] = [8, 8, 1];\n      const dispatch = [\n        Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2])\n      ];\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const components = isVec4 ? 4 : 1;\n      const A = inputVariable('a', inputs[0].dataType, [...outerDimsA, dimAOuter, dimInner / components], components);\n      const B = inputVariable('b', inputs[1].dataType, [...outerDimsB, dimInner, dimBOuter / components], components);\n      const output =\n          outputVariable('result', inputs[0].dataType, [batchSize, dimAOuter, dimBOuter / components], components);\n      variables.push(A);\n      variables.push(B);\n      variables.push(output);\n      const inputVariables = [A, B];\n      const hasBias = inputs.length > 2;\n      const declareFunctions =\n          matMulReadWriteFnSource(components, hasBias, applyActivation, variables, batchShapes, isChannelsLast);\n      if (hasBias) {\n        const biasComponents = isChannelsLast ? components : 1;\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims, biasComponents));\n      }\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const dimAOuter: i32 = ${dimAOuter};\n  const dimBOuter: i32 = ${dimBOuter};\n  const dimInner: i32 = ${dimInner};\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${activationFunction}\n  ${declareFunctions}\n  ${\n          isVec4 ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims) :\n                   makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)}\n                   ${batchDims.impl()}`;\n      return {\n        name: 'MatMul',\n        shaderCache: {hint: activationAttributes.activationCacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource,\n      };\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {tensorTypeToWsglStorageType} from '../common';\nimport {ConvAttributes} from '../conv';\n\nimport {Activation, activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet =\n    (isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean, fitInner: boolean, addBias = false,\n     activation?: Activation, hasPreluActivationWeights = false, innerElementSizeX = 4, innerElementSizeW = 4,\n     innerElementSize = 4, dataType = 'f32'): string => {\n      const getXSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'resData = x[xIndex];';\n          case 3:\n            return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n          case 4:\n            return 'resData = x[xIndex / 4];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[row * wShape[3] + colIn];';\n          case 4:\n            return 'return w[row * wShape[3] / 4 + colIn];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ` :\n                                             `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'xShape[1]' : 'xShape[2]';\n      const xWidth = isChannelsLast ? 'xShape[2]' : 'xShape[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n      const readXSnippet = `\n    let inChannels = wShape[2];\n    let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (filterDims[1] * inChannels);\n    let WCol = ${col} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n      const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimAOuter && col < dimInner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`) :\n                                       (fitInner && fitBOuter ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimInner && col < dimBOuter) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`);\n\n      const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n      const resType = typeSnippet(innerElementSize, dataType);\n      const aType =\n          isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n      const bType =\n          isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n      const userCode = `\n    ${activationFnSnippet(activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasActivationSnippet(addBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n      return userCode;\n    };\n\nexport const createConv2DMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes, outputShape: readonly number[], dimAOuter: number,\n     dimBOuter: number, dimInner: number, hasBias: boolean, sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      // TODO: enable vec4 for NCHW\n      const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = [8, 8, 1];\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : elementsPerThread[0];\n\n      const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n      const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n      const fitAOuter = dimAOuter % tileAOuter === 0;\n      const fitBOuter = dimBOuter % tileBOuter === 0;\n      const fitInner = dimInner % tileInner === 0;\n\n      const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n      const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 && innerElementSize === 4 ? `vec4<${t}>` : t}>;`,\n        `@group(0) @binding(1) var<storage, read> w: array<${isVec4 ? `vec4<${t}>` : t}>;`\n      ];\n      let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? `vec4<${t}>` : t}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n\n      return {\n        name: 'Conv2DMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${declareInputs.join('')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? `vec4<${t}>` : t}>;\n        //@group(0) @binding(${declareInputs.length + 1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[0]}, ${attributes.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${attributes.pads[0]}, ${attributes.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${\n            conv2dCommonSnippet(\n                isChannelsLast, fitAOuter, fitBOuter, fitInner, hasBias,\n                attributes.activation.toLowerCase() as Activation, false, elementsSize[0], elementsSize[1],\n                elementsSize[2], t)}\n            ${\n            isVec4 ?\n                makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner) :\n                makeMatMulPackedSource(\n                    elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner, false, undefined,\n                    sequentialAccessByThreads)}`\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {calculateOutputShape, ConvAttributes} from './conv';\nimport {getActivationSnippet} from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      const processBias = hasBias ? 'value += b[output_channel];' : '';\n      const xShape = inputs[0].dims;\n      const wShape = inputs[1].dims;\n      const outputChannelsPerGroup = wShape[0] / attributes.group;\n\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes);\n\n      const isChannelLast = attributes.format === 'NHWC';\n      const outputShape = calculateOutputShape(\n          xShape, wShape, attributes.dilations, attributes.pads, attributes.strides, isChannelLast);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const output = outputVariable('output', inputs[0].dataType, outputShape);\n      const x = inputVariable('x', inputs[0].dataType, xShape);\n      const w = inputVariable('w', inputs[1].dataType, wShape);\n      const inputVars = [x, w];\n      if (hasBias) {\n        inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const strides: vec2<u32> = vec2(${attributes.strides[0]}u, ${attributes.strides[1]}u);\n  const pads: vec2<u32> = vec2(${attributes.pads[0]}u, ${attributes.pads[1]}u);\n\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  ${activationFunction}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n          isChannelLast ? 2 : 3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${outputChannelsPerGroup}u;\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${wShape[1]}u; wInChannel++) {\n      let input_channel = group_id * ${wShape[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${wShape[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${attributes.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${xShape[isChannelLast ? 1 : 2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${wShape[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${attributes.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${xShape[isChannelLast ? 2 : 3]}u) {\n            continue;\n          }\n\n          let xVal = ${\n          isChannelLast ? x.get('batch', 'xHeight', 'xWidth', 'input_channel') :\n                          x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n          let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'GroupedConv',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        }),\n        getShaderSource,\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DMatMulProgramInfo} from './3rd-party/conv2d_mm_webgpu';\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createGroupedConvProgramInfo} from './conv-grouped';\nimport {InternalActivationAttributes, parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nexport const calculateOutputShape =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[],\n     adjustPads: readonly number[], strides: readonly number[], isChannelLast: boolean): number[] => {\n      const batchSize = inputShape[0];\n      const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n      const spatialRank = inputSpatialShape.length;\n      const outChannels = kernelShape[0];\n      const kernelSpatialShape = kernelShape.slice(2);\n      const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n      const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n      const outputShape =\n          inputSpatialShapeWithPad.map((v, i) => Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]));\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n      return outputShape;\n    };\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC'|'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support conv 1D and 2D');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n      inputs[0].dims, attributes.strides, attributes.dilations, kernelShape, pads, attributes.format === 'NHWC',\n      attributes.autoPad);\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, {kernelShape, pads, cacheKey: attributes.cacheKey});\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return createAttributeWithCacheKey(\n      {autoPad, format, dilations, group, kernelShape, pads, strides, wIsConst, ...activationAttributes});\n};\n\nconst conv2d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  if (attributes.group !== 1) {\n    context.compute(createGroupedConvProgramInfo(inputs, adjustedAttributes));\n    return;\n  }\n\n  const isChannelsLast = attributes.format === 'NHWC';\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outputShape = calculateOutputShape(\n      inputs[0].dims, inputs[1].dims, attributes.dilations, adjustedAttributes.pads, attributes.strides,\n      isChannelsLast);\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize = isChannelsLast && weightHeight === inputHeight && weightWidth === inputWidth &&\n      attributes.pads[0] === 0 && attributes.pads[1] === 0;\n  if (sameSize ||\n      (weightHeight === 1 && weightWidth === 1 && attributes.dilations[0] === 1 && attributes.dilations[1] === 1 &&\n       attributes.strides[0] === 1 && attributes.strides[1] === 1 && attributes.pads[0] === 0 &&\n       attributes.pads[1] === 0)) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    context.compute(\n        createMatmulProgramInfo(matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n        {inputs: matmulInputs});\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n      context.compute(\n          createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n          {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n      createConv2DMatMulProgramInfo(\n          convInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n          sequentialAccessByThreads),\n      {inputs: convInputs});\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createGroupedConvProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : []));\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);  // currently will fail if not conv1D/2D\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else {\n    conv2d(context, context.inputs, attributes);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nimport {Activation, activationFnSnippet, biasActivationSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dTransposeCommonSnippet =\n    (isChannelsLast: boolean, addBias = false, activation?: Activation, hasPreluActivationWeights = false,\n     innerElementSize = 4): string => {\n      const type = typeSnippet(innerElementSize, 'f32');\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return W[getIndexFromCoords4D(coord, wShape)];';\n          case 4:\n            return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ` :\n                                             `\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'outBackprop[1]' : 'outBackprop[2]';\n      const xWidth = isChannelsLast ? 'outBackprop[2]' : 'outBackprop[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n\n      const readASnippet = `\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${xHeight}) || fract(xR) > 0.0) {\n        return ${type}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${xWidth}) || fract(xC) > 0.0) {\n        return ${type}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${col} % inChannels;\n      ${coordASnippet}\n      return x[getIndexFromCoords4D(coord, xShape)/${innerElementSize}];`;\n\n      const sampleA = isChannelsLast ? `\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimInner) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);` :\n                                       `\n      let col = colIn * ${innerElementSize};\n      if (row < dimInner && col < dimBOuter) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);`;\n\n      const sampleW = `\n      let col = colIn * ${innerElementSize};\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${\n          isChannelsLast ? 'row < dimInner && col < dimBOuter' :\n                           'row < dimInner && col < dimAOuter'}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${getWSnippet(innerElementSize)}\n      }\n      return ${type}(0.0);\n      `;\n\n\n      const userCode = `\n  ${activationFnSnippet(activation, hasPreluActivationWeights, innerElementSize === 4, 4)}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleA : sampleW}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleW : sampleA}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${type}) {\n    let col = colIn * ${innerElementSize};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasActivationSnippet(addBias, activation)}\n      result[getIndexFromCoords4D(coords, outShape)/${innerElementSize}] = value;\n    }\n  }`;\n      return userCode;\n    };\n\nexport const createConv2DTransposeMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes, outputShape: readonly number[],\n     dimAOuter: number, dimBOuter: number, dimInner: number, hasBias: boolean,\n     sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      const isVec4 =\n          isChannelsLast ? inChannels % 4 === 0 && outChannels % 4 === 0 : outWidth % 4 === 0 && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = isVec4 ?\n          [8, 8, 1] :\n          [(dispatchX <= 4 || dispatchY <= 4) ? 4 : 16, dispatchX > 4 && dispatchY <= 4 ? 4 : 16, 1];\n      const elementsPerThread =\n          isVec4 ? [4, 4, 1] : [dispatchX <= 4 ? 1 : 4, dispatchX > 4 && dispatchY <= 4 ? 1 : 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv_backprop_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? 4 : 1;\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`,\n        '@group(0) @binding(1) var<storage, read> W: array<f32>;'\n      ];\n      let declareFunctions = '';\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? 'vec4<f32>' : 'f32'} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n      return {\n        name: 'Conv2DTransposeMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        ${declareInputs.join('\\n')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? 'vec4<f32>' : 'f32'}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n            attributes.kernelShape[isChannelsLast ? 2 : 3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${\n            attributes.dilations[0] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n              ${\n            attributes.dilations[1] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${\n            attributes.pads[0] + attributes.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${\n            attributes.pads[1] + attributes.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${\n            conv2dTransposeCommonSnippet(\n                isChannelsLast, hasBias, attributes.activation.toLowerCase() as Activation, false, innerElementSize)}\n        ${\n            isVec4 ? makeMatMulPackedVec4Source(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner) :\n                     makeMatMulPackedSource(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner, false,\n                         undefined, sequentialAccessByThreads)}`\n      };\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nconst createConvTranspose2DOpProgramShaderSource =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     outputShape: readonly number[], hasBias: boolean, is1DimensionDispatch: boolean, isVec4 = false,\n     dataType: string): string => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const rowDim = isChannelsLast ? 1 : 2;\n      const colDim = isChannelsLast ? 2 : 3;\n      const channelDim = isChannelsLast ? 3 : 1;\n      const outputSize = ShapeUtil.size(outputShape);\n      const workPerThread = isVec4 ? 2 : 1;\n      const group = attributes.group;\n      const wShape = inputs[1].dims;\n      const inputChannelsPerGroup = wShape[0] / group;\n      const outputChannelsPerGroup = wShape[1];\n\n      let declareFunctions = `\n  fn setOutputAtIndex(flatIndex : u32, value : ${isVec4 ? `vec4<${dataType}>` : dataType}) {\n    result[flatIndex] = ${isVec4 ? `vec4<${dataType}>` : dataType}(value);\n  }`;\n      if (hasBias) {\n        declareFunctions += `\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${isVec4 ? `vec4<${dataType}>` : dataType} {\n      return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n    }`;\n      }\n      const components = isVec4 ? 4 : 1;\n      const w = inputVariable('W', inputs[1].dataType, inputs[1].dims, components);\n      const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims, components);\n      const inputVariables = [dy, w];\n      if (hasBias) {\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]], components));\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape, components);\n      const codeSnippet4 = `{\n        let batch: u32 = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} / outShape[1];\n        let r = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} % outShape[1];\n        let c = ${is1DimensionDispatch ? 'global_id.y' : 'workgroup_id.y'} * ${workPerThread};\n        let d1: u32 = ${is1DimensionDispatch ? 'global_id.x' : 'workgroup_id.x'} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${dataType}>, ${workPerThread}>;\n        for (var i = 0; i < ${workPerThread}; i++) {\n          dotProd[i] = vec4<${dataType}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${dataType}(dyCorner.x) + ${dataType}(wR)) / ${dataType}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${dataType}(dyCorner.y) + ${dataType}(wC)) / ${dataType}(strides.y);\n            let dyC2 = (${dataType}(dyCorner.y) + 1.0 + ${dataType}(wC)) / ${dataType}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${dataType}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n\n                dotProd[1] = dotProd[1] + vec4<${dataType}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${channelDim}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${workPerThread}; i = i + 1) {\n          let value = dotProd[i] + ${hasBias ? 'bias[c+i]' : '0.0'};\n          ${output.set('batch', 'r', 'c + i', 'd1', 'value')};\n        }\n      }`;\n      const codeSnippet = `\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let batch = ${output.indicesGet('outputIndices', 0)};\n          let d1 = ${output.indicesGet('outputIndices', channelDim)};\n          let r = ${output.indicesGet('outputIndices', rowDim)};\n          let c = ${output.indicesGet('outputIndices', colDim)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${outputChannelsPerGroup};\n          let wOutChannel = d1 - groupId * ${outputChannelsPerGroup};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[${rowDim}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[${colDim}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${inputChannelsPerGroup};\n              for (var d2: u32 = 0; d2 < ${inputChannelsPerGroup}; d2 = d2 + 1) {\n                let xValue = ${\n          isChannelsLast ? dy.get('batch', 'idyR', 'idyC', 'inputChannel') :\n                           dy.get('batch', 'inputChannel', 'idyR', 'idyC')};\n                let wValue = ${w.get('inputChannel', 'wOutChannel', 'u32(wRPerm)', 'u32(wCPerm)')};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${hasBias ? 'bias[d1]' : '0.0'};\n          ${output.setByOffset('global_idx', 'value')};\n        `;\n\n      return `\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  const outShape : vec4<u32> = vec4<u32>(${outputShape.join(',')});\n  const outBackprop : vec4<u32> = vec4<u32>(${inputs[0].dims.join(',')});\n  const strides : vec2<u32> = vec2<u32>(${attributes.strides[0]}, ${attributes.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n          attributes.kernelShape[isChannelsLast ? 2 : 3]});\n  const dilations : vec2<u32> = vec2<u32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${\n          attributes.dilations[0] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n          ${\n          attributes.dilations[1] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${attributes.pads[0] + attributes.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${attributes.pads[1] + attributes.pads[3]})/2);\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)};\n  ${isVec4 ? codeSnippet4 : codeSnippet}}`;\n    };\n\nexport const createConvTranspose2DProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      // const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = attributes.outputShape;\n      const outputSize = ShapeUtil.size(outputShape);\n\n      // const inChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // TODO Enable isVec4 for performance\n      // Disabled due to weight matrix layout issue\n      // const isVec4 = attributes.group === 1 && isChannelsLast && inChannels % 4 === 0 && outChannels % 4 === 0;\n      const dispatch = [\n        Math.ceil(outputSize / 64),\n        1,\n        1,\n      ];\n      LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      return {\n        name: 'ConvTranspose2D',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }]\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => createConvTranspose2DOpProgramShaderSource(\n            shaderHelper, inputs, attributes, outputShape, hasBias, dispatch[1] === 1 && dispatch[2] === 1, false,\n            dataType),\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DTransposeMatMulProgramInfo} from './3rd-party/conv_backprop_mm_webgpu';\nimport {createConvTranspose2DProgramInfo} from './3rd-party/conv_backprop_webgpu';\nimport {ConvAttributes} from './conv';\nimport {parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst computeTotalPad =\n    (inDim: number, stride: number, adj: number, kernel: number, dilation: number, outSize: number) =>\n        (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[], autoPad: string,\n     group: number, pads: number[], strides: readonly number[], isChannelLast: boolean, outputPadding: number[],\n     outputShape: number[]) => {\n      const spatialRank = inputShape.length - 2;\n      const updateOutputShape = outputShape.length === 0;\n      if (outputPadding.length === 0) {\n        for (let i = 0; i < spatialRank; ++i) {\n          outputPadding.push(0);\n        }\n      }\n      const batchSize = inputShape[0];\n      const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n      for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n        const inSize = inputShape[j];\n        const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n        const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n        distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n        if (updateOutputShape) {\n          outputShape.push(\n              strides[i] * (inSize - 1) + outputPadding[i] + (kernelShape[j] - 1) * dilations[i] + 1 - pads[i] -\n              pads[i + spatialRank]);\n        }\n      }\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n    };\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\n\nconst getAdjustedConvTransposeAttributes =\n    <T extends ConvTransposeAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n      const kernelShape = attributes.kernelShape.slice();\n      // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n      if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n        kernelShape.length = 0;\n        for (let i = 2; i < inputs[1].dims.length; ++i) {\n          kernelShape.push(inputs[1].dims[i]);\n        }\n      }\n      const isChannelsLast = attributes.format === 'NHWC';\n      kernelShape.splice(0, 0, inputs[1].dims[0]);\n      kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n      const pads = attributes.pads.slice();\n      const outputShape = attributes.outputShape.slice();\n      const outputPadding = attributes.outputPadding.slice();\n      const inputShape = inputs[0].dims;\n      let dilations = attributes.dilations.slice();\n      if (dilations.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        dilations = new Array(spatialRank).fill(1);\n      }\n      let strides = attributes.strides.slice();\n      if (strides.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        strides = new Array(spatialRank).fill(1);\n      }\n      // If outputShape is not specified in the attributes of this op, infer it from the parameters\n      // Similarly, automatically infer pads if not specified\n      calculateOutputShapeAndPads(\n          inputShape, kernelShape, dilations, attributes.autoPad, attributes.group, pads, strides, isChannelsLast,\n          outputPadding, outputShape);\n\n      // always return a new object so does not modify the original attributes\n      const newAttributes: T = Object.assign({}, attributes);\n      const cacheKey = attributes.cacheKey + [\n        kernelShape.join('n,'), pads.join(','), strides.join(','), outputPadding.join(','), outputShape.join(','),\n        dilations.join(',')\n      ].join('_');\n      Object.assign(newAttributes, {kernelShape, pads, outputPadding, outputShape, dilations, strides, cacheKey});\n      return newAttributes;\n    };\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad =\n      ['NOTSET', 'VALID', 'SAME_UPPER',\n       'SAME_LOWER'][typeof attributes.autoPad == 'undefined' ? 0 : attributes.autoPad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return createAttributeWithCacheKey({\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes\n  });\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (kernelShapeSet && attributes.kernelShape.length !== 0 &&\n      attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\n// for transposing weight tensor from [C, M/group, KH, KW] to [KH, KW, M/group, C]\nconst weightTransposePerm = [2, 3, 1, 0];\n\nconst convTranspose2d =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n      const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, inputs);\n      const isChannelsLast = attributes.format === 'NHWC';\n      const hasBias = inputs.length === 3;\n      if (adjustedAttributes.group !== 1) {\n        context.compute(createConvTranspose2DProgramInfo(inputs, adjustedAttributes));\n        return;\n      }\n      const outputShape = adjustedAttributes.outputShape;\n      const outHeight = outputShape[isChannelsLast ? 1 : 2];\n      const outWidth = outputShape[isChannelsLast ? 2 : 3];\n      const outChannels = outputShape[isChannelsLast ? 3 : 1];\n      const weightHeight = inputs[1].dims[2];\n      const weightWidth = inputs[1].dims[3];\n      const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n\n      const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n      const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n      const dimInner = weightHeight * weightWidth * inputChannels;\n\n      const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n\n      // STEP.1: transpose weight\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposePerm),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n\n      // STEP.2: prepare reshaped inputs\n      const convTransposeInputs = [inputs[0], transposedWeight];\n      if (hasBias) {\n        if (!isChannelsLast && inputs[2].dims.length === 1) {\n          convTransposeInputs.push(inputs[2].reshape([inputs[2].dims[0], 1, 1]));\n        } else {\n          convTransposeInputs.push(inputs[2]);\n        }\n      }\n\n      // STEP.3: compute matmul\n      context.compute(\n          createConv2DTransposeMatMulProgramInfo(\n              convTransposeInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n              sequentialAccessByThreads),\n          {inputs: convTransposeInputs});\n    };\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  const adjustedAttributes =\n      getAdjustedConvTransposeAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createConvTranspose2DProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] :\n                                     [outputShape[0], outputShape[1], outputShape[3]]));\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    convTranspose2d(context, context.inputs, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern =\n    '[a-zA-Z]|\\\\.\\\\.\\\\.';  // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+';   // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$';  // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern;  // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$';               // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number;           // Symbol corresponding to a dimmension of an input\n  inputIndices: number[];  // Number of input variables the symbol corresponds to\n  dimValue: number;        // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>;  // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number;                      // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(inputs: readonly TensorView[], public readonly equation: string) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n                 .filter(([sym, info]) => (info.count === 1 || sym === '...'))\n                 .map(([sym]) => sym)\n                 .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, true, this.outputDims);\n  }  // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = {count: 1, dimValue, inputIndices: [inputIndex]};\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && (!isInput && term !== '')) {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (this.ellipsisDims.length !== ellipsisDims.length ||\n              this.ellipsisDims.toString() !== ellipsisDims.toString()) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + i);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i);\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>;  // All symbols in the equation\n  hasEllipsis: boolean;                   // The equation has ellipsis or not\n  ellipsisDims: number[];                 // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[];                      // Terms on the left-hand side of the equation\n  rhs: EinsumTerm;                        // Term on the right-hand side of the equation\n  outputDims: number[];                   // Output dimensions of the equation\n}  // End of class EinsumEquation\n\nconst createEinsumProgramInfo = (inputs: readonly TensorView[], einsumEquation: EinsumEquation): ProgramInfo => {\n  const dataType = inputs[0].dataType;\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  for (let i = 0; i < inputs.length; ++i) {\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputs[i].dims);\n  }\n  const outputShape = einsumEquation.outputDims;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', dataType, outputShape);\n  const idxCopy: string[] = [];\n  const rhsSymbols = Array.from(einsumEquation.rhs.symbolToIndices.keys());\n  const initProd = 'var prod = 1.0;';\n  const initSum = 'var sum = 0.0;';\n  const updateSum = 'sum += prod;';\n  const reduceOpsSetIndices: string[] = [];\n  const reduceOpsLoopHeaders: string[] = [];\n  const reduceOpsLoopFooters: string[] = [];\n  const reduceOpCompute: string[] = [];\n  const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === rhsSymbols.length;\n  einsumEquation.symbolToInfo.forEach((info, symbol) => {\n    if (rhsSymbols.includes(symbol)) {\n      const outputIndex = rhsSymbols.indexOf(symbol);\n      einsumEquation.lhs.forEach((term, i) => {\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            idxCopy.push(`${\n                inputVars[i].indicesSet(`input${i}Indices`, index, output.indicesGet('outputIndices', outputIndex))}`);\n          });\n        }\n      });\n    } else {\n      einsumEquation.lhs.forEach((term, i) => {\n        const info = einsumEquation.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid symbol error');\n        }\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n          });\n          reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n        }\n      });\n      reduceOpsLoopHeaders.push(`for(var ${symbol}: u32 = 0; ${symbol} < ${\n          einsumEquation.symbolToInfo.get(symbol)?.dimValue}; ${symbol}++) {`);\n      reduceOpsLoopFooters.push('}');\n    }\n  });\n  const reduceOps = isReduceOpsWithoutLoop ?\n      [\n        ...idxCopy,\n        `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`\n      ] :\n      [\n        ...idxCopy,\n        initSum,\n        ...reduceOpsLoopHeaders,\n        ...reduceOpsSetIndices,\n        initProd,\n        ...reduceOpCompute,\n        updateSum,\n        ...reduceOpsLoopFooters,\n      ];\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(...inputVars, output)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        var outputIndices = ${output.offsetToIndices('global_idx')};\n        ${inputVars.map((inputVar, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n        ${reduceOps.join('\\n')};\n        ${output.setByOffset('global_idx', 'sum')};\n      }`;\n  return {\n    name: 'Einsum',\n    shaderCache: {hint: einsumEquation.equation},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  context.compute(createEinsumProgramInfo(context.inputs, einsumEquation));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({equation});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (shape[shapeIndex] !== inputShape[inputShapeIndex] && shape[shapeIndex] !== 1 &&\n        inputShape[inputShapeIndex] !== 1) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n    (inputShape.length > shape.length) ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const inputShape = ${input.indices(...inputShape)};\n  ${shaderHelper.declareVariables(input, output)}\n  ${shaderHelper.mainStart()}\n  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    var inputIndices: ${input.type.indices};\n    for (var i = 0; i < ${inputShape.length}; i++) {\n      if (${input.indicesGet('inputShape', 'i')} == 1) {\n        ${input.indicesSet('inputIndices', 'i', 0)}\n      } else {\n        ${\n      input.indicesSet(\n          'inputIndices', 'i', output.indicesGet('outputIndices', `i + ${outputShape.length - inputShape.length}`))}\n      }\n    }\n    ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n  }`;\n  return {\n    name: 'Expand',\n    shaderCache: {hint: `${outputShape}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    })\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const data = inputVariable('data', inputs[0].dataType, inputs[0].dims);\n  const indices = inputVariable('inputIndices', inputs[1].dataType, inputs[1].dims);\n  const output = outputVariable('output', inputs[0].dataType, outputShape);\n  const calcDataIndices = (): string => {\n    const indicesRank = indicesShape.length;\n    let calcStr = `var indicesIndices  = ${indices.type.indices}(0);`;\n    for (let i = 0; i < indicesRank; i++) {\n      calcStr += `${indicesRank > 1 ? `indicesIndices[${i}]` : 'indicesIndices'} = ${\n          outputShape.length > 1 ? `outputIndices[${axis + i}]` : 'outputIndices'};`;\n    }\n    calcStr += `\n        var idx = ${indices.getByIndices('indicesIndices')};\n        if (idx < 0) {\n          idx = idx + ${axisDimLimit};\n        }\n        var dataIndices = ${data.type.indices}(0);\n      `;\n    for (let i = 0, j = 0; i < inputRank; i++) {\n      if (i === axis) {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = u32(idx);`;\n        j += indicesRank;\n      } else {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = ${\n            outputShape.length > 1 ? `outputIndices[${j}]` : 'outputIndices'};`;\n        j++;\n      }\n    }\n    return calcStr;\n  };\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        ${calcDataIndices()};\n        let value = ${data.getByIndices('dataIndices')};\n        ${output.setByOffset('global_idx', 'value')};\n      }`;\n  return {\n    name: 'Gather',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [\n        {dims: outputShape, dataType: inputs[0].dataType},\n      ],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo =\n    (inputs: readonly TensorView[], attributes: GatherElementsAttributes): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputOutputDataType = inputs[0].dataType;\n      const inputRank = inputShape.length;\n      const inputStrides = ShapeUtil.computeStrides(inputShape);\n      const inputSize = ShapeUtil.size(inputShape);\n\n      const indicesShape = inputs[1].dims;\n      const indicesDataType = inputs[1].dataType;\n      const indicesSize = ShapeUtil.size(indicesShape);\n\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n      const axisDimLimit = inputShape[axis];\n\n      const outputShape = indicesShape.slice(0);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const input = inputVariable('input', inputOutputDataType, inputShape);\n      const indices = inputVariable('indices', indicesDataType, [indicesSize]);\n      const output = outputVariable('output', inputOutputDataType, outputShape);\n\n\n      // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n      // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n      // Input data will be treated as u32 or two u32 for 8-byte tensors\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputStrides = array<u32, ${inputStrides.length}>(${inputStrides.map(i => `${i}u`).join(',')});\n      ${shaderHelper.declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + ${axisDimLimit};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        if (i == ${axis}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${output.indicesGet('outputIndices', 'i')} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${inputSize}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;\n\n      return {\n        name: 'GatherElements',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {GemmUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if ((inputs[0].dataType !== inputs[1].dataType) ||\n      (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst offsetC = (m: number, n: number, dims: readonly number[]): string => {\n  if (dims.length === 0) {\n    return '0u';\n  }\n\n  const broadcastM = (dims.length === 1 && m !== 1) || (dims.length === 2 && dims[0] !== m);\n  const broadcastN = dims[dims.length - 1] !== n;\n\n  let offset = '0u';\n  if (!broadcastM) {\n    offset += `+ m * ${dims[dims.length - 1]}u`;\n  }\n  if (!broadcastN) {\n    offset += '+n';\n  }\n\n  return offset;\n};\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n      aShape, attributes.transA, bShape, attributes.transB, inputs.length === 3 ? inputs[2].dims : undefined);\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error('Can\\'t use gemm on the given tensors');\n  }\n  const outputSize = ShapeUtil.size(outputShape);\n  let line = '';\n  if (attributes.transA && attributes.transB) {\n    line = 'value += a[k * M + m] * b[n * K + k];';\n  } else if (attributes.transA && !attributes.transB) {\n    line = 'value += a[k * M + m] * b[k * N + n];';\n  } else if (!attributes.transA && attributes.transB) {\n    line = 'value += a[m * K + k] * b[n * K + k];';\n  } else if (!attributes.transA && !attributes.transB) {\n    line = 'value += a[m * K + k] * b[k * N + n];';\n  }\n\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n  const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= alpha;';\n  const calculateC = inputs.length === 3 ? `value += beta * c[${offsetC(M, N, inputs[2].dims)}];` : '';\n  const inputStorageBuffersDeclarations = [\n    `@group(0) @binding(0) var<storage, read> a : array<${dataType}>;`,\n    `@group(0) @binding(1) var<storage, read> b : array<${dataType}>;`\n  ];\n  if (inputs.length === 3) {\n    inputStorageBuffersDeclarations.push(`@group(0) @binding(2) var<storage, read> c : array<${dataType}>;`);\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha = ${dataType}(${attributes.alpha});\n  const beta = ${dataType}(${attributes.beta});\n\n  ${inputStorageBuffersDeclarations.join('\\n')}\n  @group(0) @binding(${inputs.length}) var<storage, read_write> output : array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k<${K}u; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${calculateC}\n    output[global_id.x] = value;\n\n  }`;\n  return {\n    name: 'Gemm',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<GemmAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface InstanceNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n  format: 'NHWC'|'NCHW';\n}\n\nconst metadata = {\n  name: 'InstanceNormalization'\n};\n\nconst createInstanceNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n\n      const outputShape = xShape;\n      const axis = 2;\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n      const C = xShape[1];\n      const x = inputVariable('x', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n      const output = outputVariable('output', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const variables = [x, scale, bias, output];\n      const dataType = x.type.value;\n      const workgroupSize = 64;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  const C: u32 = ${C};\n  const normSize: u32 = ${normSize};\n  const epsilon: f32 = ${attributes.epsilon};\n  var<workgroup> meanShared : ${dataType};\n  var<workgroup> squaredNormShared : ${dataType};\n  var<workgroup> workgroupShared : array<${dataType}, ${workgroupSize}>;\n  const workgroupSize = ${workgroupSize}u;\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${dataType} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${x.get('batch', 'channel', 'h')};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${dataType}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${x.get('batch', 'channel', 'h')} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${dataType}(normSize) + epsilon);\n    let channelScale = invStdDev * ${scale.getByOffset('channel')};\n    let channelShift = ${bias.getByOffset('channel')} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${x.get('batch', 'channel', 'h')} * channelScale + channelShift;\n      ${output.set('batch', 'channel', 'h', 'value')};\n    }\n  }`;\n      return {\n        ...metadata,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: normCount}\n        }),\n        getShaderSource,\n      };\n    };\n\nconst computeMean =\n    (context: ComputeContext, input: TensorView, scale: TensorView, bias: TensorView, n: number, h: number, c: number,\n     epsilon: number) => {\n      const components = getMaxComponents(c);\n      const inputHelper = inputVariable('input', input.dataType, input.dims, components);\n      const scaleHelper = inputVariable('scale', scale.dataType, scale.dims, components);\n      const biasHelper = inputVariable('bias', bias.dataType, bias.dims, components);\n\n      const WG = 64;\n      // we will store channel scale and channel shift in [2, components] matrix\n      // or in vec2 when components == 1\n      const outputType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const sumCastType = components === 1 ? 'f32' : `vec${components}f`;\n      const setOutputValue = (var1: string, var2: string) => `${outputType}(${var1}, ${var2})`;\n      const unitsOfWork = n * c / components;\n      const wgSize = Math.ceil(h / WG);\n\n      const getMeanShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${h * c / components};\n\n  ${shaderHelper.declareVariables(inputHelper)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart(WG)}\n    let currentImageNumber = global_idx / ${WG} / C;\n    let currentChannelNumber = (global_idx / ${WG}) % C;\n    let wgId = global_idx % ${WG};\n    let wgOffset = wgId * ${wgSize};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${wgSize}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${sumCastType}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${setOutputValue('sum', 'squaredSum')};\n  }`;\n\n      const meanValues = context.compute(\n          {\n            name: 'InstanceNormComputeMean',\n            shaderCache: {hint: JSON.stringify({components, n, h, c})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, WG, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: n * c / components},\n            }),\n            getShaderSource: getMeanShaderSource,\n          },\n          {inputs: [input], outputs: [-1]})[0];\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${WG * c / components};\n  const epsilon: f32 = ${epsilon};\n\n  @group(0) @binding(0) var<storage, read> input : array<${outputType}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${scaleHelper.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${biasHelper.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(unitsOfWork)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = 0; i < ${WG}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${WG}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${sumCastType}(scale[currentChannelNumber]);\n    let channelShift = ${sumCastType}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${setOutputValue('channelScale', 'channelShift')};\n  }`;\n\n      return context.compute(\n          {\n            name: 'InstanceNormComputeChannelScaleShift',\n            shaderCache: {hint: JSON.stringify({components, n, h, c, epsilon})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: Math.ceil(unitsOfWork / 64 /* workgroup size */)},\n            }),\n            getShaderSource,\n          },\n          {inputs: [meanValues, scale, bias], outputs: [-1]})[0];\n    };\n\nconst createInstanceNormNHWCProgramInfo =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: InstanceNormAttributes) => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const N = xShape[0];\n      const C = xShape[xShape.length - 1];\n      const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n\n      const components = getMaxComponents(C);\n      const outputSize = ShapeUtil.size(outputShape) / components;\n      const inputHelper = inputVariable('input', inputs[0].dataType, inputs[0].dims, components);\n      const outputHelper = outputVariable('output', inputs[0].dataType, outputShape, components);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const scaleType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const scaleCastType = components === 1 ? dataType : `vec${components}<${dataType}>`;\n      // first compute mean\n      const channelScaleShift = computeMean(context, inputs[0], inputs[1], inputs[2], N, H, C, attributes.epsilon);\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${H};\n  const C: u32 = ${C / components};\n\n  @group(0) @binding(0) var<storage, read> input : array<${inputHelper.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${scaleType}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${outputHelper.type.storage}>;\n\n  ${shaderHelper.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${scaleCastType}(scale[0]), ${scaleCastType}(scale[1]));\n  }`;\n      context.compute(\n          {\n            name: 'InstanceNormalization',\n            shaderCache: {hint: `${attributes.cacheKey}`},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n            }),\n            getShaderSource,\n          },\n          {inputs: [inputs[0], channelScaleShift]});\n    };\n\nexport const parseInstanceNormAttributes = (attributes: InstanceNormAttributes): InstanceNormAttributes =>\n    createAttributeWithCacheKey({epsilon: attributes.epsilon, format: attributes.format});\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    createInstanceNormNHWCProgramInfo(context, context.inputs, attributes);\n  } else {\n    context.compute(createInstanceNormProgramInfo(context.inputs, attributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface LayerNormAttributes extends AttributeWithCacheKey {\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n};\n\nconst createLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: LayerNormAttributes, outputCount: number): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const scale = inputs[1];\n      const bias = inputs[2];\n\n      const outputShape = xShape;\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n      const scaleSize = ShapeUtil.size(scale.dims);\n      const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n      if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n        throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n      }\n\n      const meanInvStdDevDim = [];\n      for (let i = 0; i < xShape.length; ++i) {\n        if (i < axis) {\n          meanInvStdDevDim.push(xShape[i]);\n        } else {\n          meanInvStdDevDim.push(1);\n        }\n      }\n\n      const components = getMaxComponents(normSize);\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const variables = [\n        inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n        inputVariable('scale', scale.dataType, scale.dims, components),\n      ];\n      if (bias) {\n        variables.push(inputVariable('bias', bias.dataType, bias.dims, components));\n      }\n      variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n\n      const hasMeanDataOutput = outputCount > 1;\n      const hasInvStdOutput = outputCount > 2;\n\n      if (hasMeanDataOutput) {\n        variables.push(outputVariable('meanDataOutput', DataType.float, meanInvStdDevDim));\n      }\n      if (hasInvStdOutput) {\n        variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const normSize: f32 = ${normSize};\n  const normSizeVectorized: u32 = ${normSize / components};\n  const epsilon: f32 = ${attributes.epsilon};\n\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(normCount)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${fillVector('f32', components)};\n    var meanSquareVector = ${fillVector('f32', components)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${castToF32(dataType, components, 'x[h + offset]')};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${sumVector('meanVector', components)} / normSize;\n    let meanSquare = sqrt(${sumVector('meanSquareVector', components)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${castToF32(dataType, components, 'x[j + offset]')};\n      let f32scale = ${castToF32(dataType, components, 'scale[j]')};\n      output[j + offset] = ${variables[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${bias ? `+ ${castToF32(dataType, components, 'bias[j]')}` : ''}\n      );\n    }\n\n    ${hasMeanDataOutput ? 'meanDataOutput[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'invStdOutput[global_idx] = 1 / meanSquare' : ''};\n  }`;\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (hasMeanDataOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n      if (hasInvStdOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n\n      return {\n        name: 'LayerNormalization',\n        shaderCache: {hint: `${attributes.cacheKey}|${outputCount}|${inputs.length}`},\n        getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}}),\n        getShaderSource,\n      };\n    };\n\nexport const parseLayerNormAttributes = (attributes: LayerNormAttributes): LayerNormAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis, epsilon: attributes.epsilon});\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil} from '../../util';\nimport {ComputeContext} from '../types';\n\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error('Can\\'t use matmul on the given tensors');\n  }\n  context.compute(createMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface PadAttributes extends AttributeWithCacheKey {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Input type must be float.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[], dataType: string, constantValue: number): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${inputDims[i]}) {\n              break;\n            }\n            offset += k * ${inputStrides[i]};\n        `;\n      }\n\n      return `\n          value = ${dataType}(${constantValue});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n    };\n\nconst getPadReflect =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2 * (inputDims[i] - 1)};\n                  k = k % _2n_1;\n                  if(k >= ${inputDims[i]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadEdge =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${inputDims[i]}) {\n                  k = ${inputDims[i] - 1};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadWrap =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0)  {\n                  k += ${inputDims[i]};\n                }\n                if (k >= ${inputDims[i]}) {\n                  k -= ${inputDims[i]};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadSnippet =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], attributes: PadAttributes, dataType: string): string => {\n      switch (attributes.mode) {\n        case 0:\n          return getPadConstant(\n              output, outputDims, inputDims, inputStrides, attributes.pads, dataType, attributes.value);\n        case 1:\n          return getPadReflect(output, outputDims, inputDims, inputStrides, attributes.pads);\n        case 2:\n          return getPadEdge(output, outputDims, inputDims, inputStrides, attributes.pads);\n        case 3:\n          return getPadWrap(output, outputDims, inputDims, inputStrides, attributes.pads);\n        default:\n          throw new Error('Invalid mode');\n      }\n    };\n\nconst generatePadCode =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: PadAttributes, dataType: string):\n        string => {\n          const inputDims = inputs[0].dims;\n          const outputDims = ShapeUtil.padShape(inputDims.slice(), attributes.pads);\n          const outputSize = ShapeUtil.size(outputDims);\n          const inputStrides = ShapeUtil.computeStrides(inputDims);\n\n          const output = outputVariable('output', inputs[0].dataType, outputDims);\n          const input = inputVariable('x', inputs[0].dataType, inputDims);\n\n          const padSnippet = getPadSnippet(output, outputDims, inputDims, inputStrides, attributes, dataType);\n          const padCode = `\n              ${shaderHelper.declareVariables(input, output)}\n              ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(0);\n              ${padSnippet}\n              output[global_idx] = value;\n          }`;\n          return padCode;\n        };\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  return {\n    name: 'Pad',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n    }),\n    getShaderSource: shaderHelper => generatePadCode(shaderHelper, inputs, attributes, 'f32'),\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value = (inputs.length >= 3 && inputs[2].data) ? inputs[2].getFloat32Array()[0] : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => updatePads[Number(i)] = (Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach(v => pads.push(v));\n\n    return createAttributeWithCacheKey({mode: attributes.mode, value, pads});\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parsePadAttributes = (attributes: Record<string, unknown>): PadAttributes => {\n  const mode = attributes.mode as number;\n  const value = attributes.value as number;\n  const pads = attributes.pads as number[];\n  return createAttributeWithCacheKey({mode, value, pads});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('Pool ops supports 1-D or 2-D inputs only for now.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    input: TensorView, attributes: AttributeType, isGlobalOperator: boolean): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst = input.dims.slice();\n  if (isChannelsLast) {\n    inputShapeAsChannelFirst.splice(1, 0, inputShapeAsChannelFirst.pop()!);  // Move channel to the second position.\n  }\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n      isGlobalOperator, inputShapeAsChannelFirst, strides, dilations, kernelShape, pads, attributes.autoPad);\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, {kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey});\n  } else {\n    Object.assign(newAttributes, {kernelShape, strides, pads, cacheKey: attributes.cacheKey});\n  }\n  const outputShapeAsChannelLast = outputShapeAsChannelFirst.slice();\n  outputShapeAsChannelLast.push(outputShapeAsChannelLast.splice(1, 1)[0]);\n  return [newAttributes, isChannelsLast ? outputShapeAsChannelLast : outputShapeAsChannelFirst];\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    shaderHelper: ShaderHelper, x: IndicesHelper, xShape: readonly number[], outputShape: readonly number[],\n    attributes: AttributeType, op1: string, op2: string, start: string): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputDims = xShape;\n  const dataType = x.type.value;\n  const rank = inputDims.length;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', x.type.tensor, outputShape);\n\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    if (pwStart + pwEnd !== 0) {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}] >= ${inputDims[dimIdxW]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    } else {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      const dimH = inputDims[dimIdxH];\n      if (phStart + phEnd !== 0) {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= ${dimH}) {\n                    pad+= ${kw};\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value: ${dataType} = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelSize = ShapeUtil.size(attributes.kernelShape);\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    const stridesRank = kernelStrides.length;\n    const padsRank = attributes.pads.length;\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            const pads = array<u32, ${padsRank}>(${attributes.pads.map(i => `${i}u`).join(',')});\n            const inputDims = array<u32, ${rank}>(${inputDims.map(i => `${i}u`).join(',')});\n            const kernelStrides = array<u32, ${stridesRank}>(${kernelStrides.map(i => `${i}u`).join(',')});\n            const strides = array<u32, ${stridesRank}>(${attributes.strides.map(i => `${i}u`).join(',')});\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              let xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${output.type.value}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${kernelSize}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${rank - stridesRank}u]\n                    + offsets[j - ${rank - stridesRank}u] - pads[j - 2u];\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC'|'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number]\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: AveragePoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const kernelSize = ShapeUtil.size(adjustedAttributes.kernelShape);\n\n      const x = inputVariable('x', input.dataType, input.dims);\n      const dataType = x.type.value;\n\n      const op1 = 'value += x_val;';\n      let op2 = '';\n      if (adjustedAttributes.countIncludePad) {\n        op2 += `value /= ${dataType}(${kernelSize});`;\n      } else {\n        op2 += `value /= ${dataType}(${kernelSize} - pad);`;\n      }\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '0.0'),\n      };\n    };\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n\n  return createAttributeWithCacheKey({countIncludePad, ...attr});\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: [],\n  cacheKey: ''\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: MaxPoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const op1 = `\n      value = max(x_val, value);\n    `;\n      const op2 = '';\n      const x = inputVariable('x', input.dataType, input.dims);\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '-1e5'),\n      };\n    };\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n\n  return createAttributeWithCacheKey({storageOrder, dilations, ...attr});\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {DataType} from '../../../wasm-common';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {outputVariable, ShaderHelper} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error('Range these inputs\\' contents are invalid.');\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n\n  const output = outputVariable('output', dataType, outputShape);\n  const wgslType = output.type.storage;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        output[global_idx] = ${wgslType}(${start}) + ${wgslType}(global_idx) * ${wgslType}(${delta});\n      }`;\n  return {\n    name: 'Range',\n    shaderCache: {hint: [start, limit, delta].map(x => x.toString()).join('_')},\n    getShaderSource,\n    getRunData: () => (\n        {outputs: [{dims: outputShape, dataType}],\n         dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}})\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), {inputs: []});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype CoordinateTransformMode = 'half_pixel'|'asymmetric'|'pytorch_half_pixel'|'tf_half_pixel_for_nn'|'align_corners'|\n    'tf_crop_and_resize'|'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch'|'not_smaller'|'not_larger';\n\ntype Mode = 'nearest'|'linear'|'cubic';\n\ntype NearestMode = 'round_prefer_floor'|'round_prefer_ceil'|'floor'|'ceil'|'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every((value) => value > 0 || (() => {\n                            throw new Error('Resize requires scales input values to be positive');\n                          }));\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for linear mode');\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every((value) => value >= 0 && value < rank || (() => {\n                          throw new Error('Resize requires axes input values to be positive and less than rank');\n                        }));\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => newScales[value] = scales[index]);\n  return newScales;\n};\n\nconst validateInputs =\n    (inputs: readonly TensorView[], attributes: ResizeAttributes, opsetVersion: number, scales: number[],\n     sizes: number[], roi: number[]): void => {\n      const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n          (opsetVersion > 10) ? [1, 2, 3] : [-1, (inputs.length > 1) ? 1 : -1, -1];\n      const rank = inputs[0].dims.length;\n      if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n        inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n\n      } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n        throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n      }\n\n      if (scalesInputIndex > 0 && inputs.length > scalesInputIndex && inputs[scalesInputIndex].dims.length > 0) {\n        inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n        if (scales.length !== 0 &&\n            (scales.length !== rank && (opsetVersion >= 18 && scales.length !== attributes.axes.length))) {\n          throw new Error(\n              'Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n        }\n        validateScales(scales, attributes);\n        if (attributes.axes.length > 0) {\n          updateScales(scales, attributes.axes, rank).forEach((value, index) => scales[index] = value);\n        }\n      }\n      if (sizesInputIndex > 0 && inputs.length > sizesInputIndex) {\n        inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n        if (sizes.length !== rank || (opsetVersion >= 18 && sizes.length === attributes.axes.length)) {\n          throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n        }\n      }\n\n      if (attributes.axes.length > 0) {\n        if (scales.length !== attributes.axes.length) {\n          throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n        }\n        if (sizes.length !== attributes.axes.length) {\n          throw new Error(\n              'Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n        }\n      }\n      if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n        throw new Error('Resize requires only of scales or sizes to be specified');\n      }\n    };\n\nconst getOriginalCoordinateFromResizedCoordinate = (coordinateTransferMode: CoordinateTransformMode): string =>\n    'fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,\\\n    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { ' +\n    (() => {\n      switch (coordinateTransferMode) {\n        case 'asymmetric':\n          return 'return xResized / xScale;';\n        case 'pytorch_half_pixel':\n          return 'if (lengthResized > 1) { \\\n                    return (xResized + 0.5) / xScale - 0.5; \\\n                  } else { \\\n                    return 0.0; \\\n                  }';\n        case 'tf_half_pixel_for_nn':\n          return 'return (xResized + 0.5) / xScale;';\n        case 'align_corners':\n          return 'if (lengthResized == 1) { \\\n                    return 0.0; \\\n                  } else { \\\n                    return xResized * (lengthOriginal - 1) / (lengthResized - 1); \\\n                  }';\n        case 'tf_crop_and_resize':\n          return 'if (lengthResized > 1) { \\\n                    return roiStart * (lengthOriginal - 1) + \\\n                          (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1); \\\n                  } else { \\\n                    return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1); \\\n                  }';\n        case 'half_pixel_symmetric':\n          return [\n            'const outputWidth = xScale * lengthResized;', 'const adjustment = lengthResized / outputWidth;',\n            'const center = lengthOriginal / 2;', 'const offset = center * (1 - adjustment);',\n            'return offset + ((xResized + 0.5) / xScale) - 0.5;'\n          ].join('\\n');\n        case 'half_pixel':\n          return 'return ((xResized + 0.5) / xScale) - 0.5;';\n        default:\n          throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number): string =>\n    'fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {' + (() => {\n      switch (nearestMode) {\n        case 'round_prefer_ceil':\n          return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n        case 'floor':\n          return 'return floor(xOriginal);';\n        case 'ceil':\n          return 'return ceil(xOriginal);';\n        case 'round_prefer_floor':\n          return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n        case 'simple':\n        default:\n          if (opsetVersion < 11) {\n            return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n          }\n          throw new Error(`Nearest mode ${nearestMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape =\n    (inputShape: readonly number[], scales: readonly number[], sizes: readonly number[], axes: readonly number[]):\n        number[] => {\n          let outputShape: number[] = [];\n          if (sizes.length > 0) {\n            if (axes.length > 0) {\n              inputShape.forEach((v) => outputShape.push(v));\n              if (Math.max(...axes) > inputShape.length) {\n                throw new Error('axes is out of bound');\n              }\n              axes.forEach((v, i) => outputShape[v] = sizes[i]);\n            } else {\n              sizes.forEach((v) => outputShape.push(v));\n            }\n          } else {\n            if (scales.length === 0) {\n              throw new Error('Resize requires either scales or sizes.');\n            } else {\n              outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n            }\n          }\n          return outputShape;\n        };\n\nconst adjustOutputShape =\n    (inputShape: readonly number[], outputShape: readonly number[], scales: number[], attributes: ResizeAttributes):\n        number[] => {\n          const scaleInPolicy = (() => {\n            switch (attributes.keepAspectRatioPolicy) {\n              case 'not_larger':\n                return attributes.axes.length > 0 ? Math.min(...attributes.axes.map(i => scales[i]), Number.MAX_VALUE) :\n                                                    Math.min(...scales, Number.MAX_VALUE);\n              case 'not_smaller':\n                return attributes.axes.length > 0 ? Math.max(...attributes.axes.map(i => scales[i]), Number.MIN_VALUE) :\n                                                    Math.max(...scales, Number.MIN_VALUE);\n              default:\n                throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n            }\n          })();\n          scales.fill(1.0, 0, scales.length);\n          const adjustedOutputShape = inputShape.slice();\n          if (attributes.axes.length > 0) {\n            attributes.axes.forEach((v) => scales[v] = scaleInPolicy);\n            attributes.axes.forEach((v) => adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v]));\n          } else {\n            scales.fill(scaleInPolicy, 0, scales.length);\n            adjustedOutputShape.forEach((v, i) => adjustedOutputShape[i] = Math.round(v * scales[i]));\n          }\n          return adjustedOutputShape;\n        };\n\nconst calculateOriginalIndicesFromOutputIndices =\n    (output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[], scales: readonly number[],\n     roi: readonly number[]): string => `\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> array<f32, ${\n        outputShape.length}> {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n      const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n      const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n      var originalIndices: array<f32, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n        }\n      }\n      return originalIndices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], useExtrapolation: boolean): string => `\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n        const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n        const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n        const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n        var inputIndices: ${input.type.indices};\n        for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n          var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n            if (!${useExtrapolation} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${input.indicesSet('inputIndices', 'i', 'inputIndex')}\n        }\n        return inputIndices;\n    }`;\n\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(inputIndices: ${input.type.indices}) -> bool {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var inputIndex = ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst bilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], useExtrapolation: boolean, extrapolationValue: number): string => {\n      const [batchIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 2 ? [-1, 0, 1, -1] : (scales[1] === 1.0 ? [0, 2, 3, 1] : [0, 1, 2, 3]);\n      return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${input.type.indices};\n      inputIndices[${heightIdx}] = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      inputIndices[${widthIdx}] = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      if (${inputShape.length} > 2) {\n        inputIndices[${channelIdx}] = channel;\n        inputIndices[${batchIdx}] = batch;\n      };\n      return input[${input.indicesToOffset('inputIndices')}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${heightIdx}];\n      var col:f32 = originalIndices[${widthIdx}];\n      if (${useExtrapolation} && (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > ${\n          inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${inputShape.length > 2}) {\n        channel = u32(originalIndices[${channelIdx}]);\n        batch = u32(originalIndices[${batchIdx}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n    };\n\nconst bicubicInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], cubicCoeffA: number, useExtrapolation: boolean,\n     extrapolationValue: number, excludeOutside: boolean): string => {\n      const [heightIdx, widthIdx] = inputShape.length === 2 ? [0, 1] : (scales[1] === 1.0) ? [2, 3] : [1, 2];\n\n      const createCubicInterpolationFunction = (idx: number): string => {\n        const direction = idx === heightIdx ? 'row' : 'col';\n        return `\n      fn ${direction}CubicInterpolation(inputIndices: ${input.type.indices}, outputIndices: ${\n            output.type.indices}) -> f32 {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : `outputIndices[${idx}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${scales[idx]},\n        f32(${outputShape[idx]}), f32(${inputShape[idx]}), ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: f32 = originalIdx + f32(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            if (${excludeOutside}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${useExtrapolation}) {\n              return ${extrapolationValue};\n            } else {\n              ${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${input.type.indices} = inputIndices;\n          inputIndicesCopy[${idx}] = u32(${direction});\n          data[i + 1] = ${idx === heightIdx ? `input[${input.indicesToOffset('inputIndicesCopy')}];` : `\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n      };\n\n      return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n          cubicCoeffA}) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n          cubicCoeffA}) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n    var inputIndices: ${input.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `;\n    };\n\nconst createResizeProgramInfo =\n    (inputTensor: TensorView, attributes: ResizeAttributes, opsetVersion: number, scalesInput: readonly number[],\n     sizes: readonly number[], roiInput: readonly number[]): ProgramInfo => {\n      const inputShape = inputTensor.dims;\n      const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n      let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n      let scales = scalesInput.slice();\n      if (scalesInput.length === 0) {\n        scales = inputShape.map((value, index) => value === 0 ? 1.0 : outputShape[index] / value);\n        if (attributes.keepAspectRatioPolicy !== 'stretch') {\n          outputShape = adjustOutputShape(inputShape, outputShape, scales, attributes);\n        }\n      }\n      const output = outputVariable('output', inputTensor.dataType, outputShape);\n      const input = inputVariable('input', inputTensor.dataType, inputShape);\n      const outputSize = ShapeUtil.size(outputShape);\n      const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n      const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion)};\n              ${\n                calculateInputIndicesFromOutputIndices(\n                    input, output, inputShape, outputShape, scales, roi, useExtrapolation)};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales, roi)};\n              ${\n                bilinearInterpolation(\n                    input, output, inputShape, outputShape, scales, useExtrapolation, attributes.extrapolationValue)};\n              `;\n          case 'cubic':\n            return `\n            ${\n                bicubicInterpolation(\n                    input, output, inputShape, outputShape, scales, roi, attributes.cubicCoeffA, useExtrapolation,\n                    attributes.extrapolationValue, attributes.excludeOutside)};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        if (${noScale}) {\n          output[global_idx] = input[global_idx];\n        } else {\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          var inputIndices: ${input.type.indices};\n          ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                  if (checkInputIndices(inputIndices)) {\n                    output[global_idx] = input[${input.indicesToOffset('inputIndices')}];\n                  } else {\n                    output[global_idx] = ${attributes.extrapolationValue};\n                  }`;\n          case 'linear':\n            return 'output[global_idx] = bilinearInterpolation(outputIndices);';\n          case 'cubic':\n            return 'output[global_idx] = bicubicInterpolation(outputIndices);';\n          default:\n            throw Error(`Unsupported resize mode: ${attributes.mode}`);\n        }\n      })()};\n        }\n      }`;\n\n      return {\n        name: 'Resize',\n        shaderCache: {\n          hint: `${attributes.cacheKey}|${opsetVersion}|${scales.length > 0 ? scales : ''}|${\n              sizes.length > 0 ? sizes : ''}`\n        },\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputTensor.dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        })\n      };\n    };\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(\n      createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {inputs: [0]});\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n      attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = attributes.excludeOutside as number !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode\n  });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface SkipLayerNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: SkipLayerNormAttributes, outputCount: number, isTraining: boolean):\n        ProgramInfo => {\n          const inputShape = inputs[0].dims;\n          const inputSize = ShapeUtil.size(inputShape);\n          const outputShape = inputShape;\n          const outputSize = inputSize;\n          const hiddenSize = inputShape.slice(-1)[0];\n          const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n          const hasBetaInput = inputs.length > 3;\n          const hasBiasInput = inputs.length > 4;\n          const hasMeanOutput = isTraining && outputCount > 1;\n          const hasInvStdDevOutput = isTraining && outputCount > 2;\n          const hasInputSkipBiasSumOutput = outputCount > 3;\n\n          const components = getMaxComponents(hiddenSize);\n          const variables = [\n            inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n            inputVariable('skip', inputs[1].dataType, inputs[1].dims, components),\n            inputVariable('gamma', inputs[2].dataType, inputs[2].dims, components),\n          ];\n          if (hasBetaInput) {\n            variables.push(inputVariable('beta', inputs[3].dataType, inputs[3].dims, components));\n          }\n          if (hasBiasInput) {\n            variables.push(inputVariable('bias', inputs[4].dataType, inputs[4].dims, components));\n          }\n          variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n          if (hasMeanOutput) {\n            variables.push(outputVariable('meanOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInvStdDevOutput) {\n            variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInputSkipBiasSumOutput) {\n            variables.push(outputVariable('inputSkipBiasSum', inputs[0].dataType, outputShape, components));\n          }\n          const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n          const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const hiddenSize: f32 = ${hiddenSize};\n      const hiddenSizeVectorized: u32 = ${hiddenSize / components};\n      const epsilon: f32 = ${attributes.epsilon};\n\n      ${shaderHelper.declareVariables(...variables)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize / hiddenSize)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${fillVector('f32', components)};\n        var squareSum = ${fillVector('f32', components)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${hasBiasInput ? 'bias[i]' : '0.0'};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${hasInputSkipBiasSumOutput ? 'inputSkipBiasSum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          let f32Value = ${castToF32(dataType, components, 'value')};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${sumVector('sum', components)} / hiddenSize;\n        let variance = sqrt(${sumVector('squareSum', components)} / hiddenSize - mean * mean + epsilon);\n        ${hasMeanOutput ? 'meanOutput[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'invStdOutput[global_idx] = 1.0 / variance;' : ''}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${dataType}(mean)) / ${dataType}(variance) * gamma[i]\n           + ${hasBetaInput ? 'beta[i]' : '0.0'};\n        }\n      }`;\n          const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n          if (outputCount > 1) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 2) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 3) {\n            outputs.push({dims: inputShape, dataType: inputs[0].dataType});\n          }\n\n          return {\n            name: 'SkipLayerNormalization',\n            shaderCache: {hint: attributes.cacheKey},\n            getShaderSource,\n            getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(outputSize / hiddenSize / 64)}}),\n          };\n        };\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(\n      createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {outputs});\n};\n\nexport const parseSkipLayerNormAttributes = (attributes: Record<string, unknown>): SkipLayerNormAttributes => {\n  const epsilon = attributes.epsilon as number;\n  return createAttributeWithCacheKey({epsilon});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach(v => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach(v => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SliceAttributes): SliceAttributes => {\n      if (inputs.length > 1) {\n        const starts: number[] = readInput(inputs, 1);\n        const ends: number[] = readInput(inputs, 2);\n        let axes: number[] = readInput(inputs, 3);\n        if (axes.length === 0) {\n          axes = [...Array(inputs[0].dims.length).keys()];\n        }\n        return createAttributeWithCacheKey({starts, ends, axes});\n      } else {\n        return attributes;\n      }\n    };\n\nconst fixStartEndValues =\n    (value: number, index: number, inputShape: readonly number[], axes: readonly number[], steps: readonly number[]):\n        number => {\n          let newValue = value;\n          if (value < 0) {\n            newValue += inputShape[axes[index]];\n          }\n          if (steps[index] < 0) {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n          } else {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n          }\n        };\n\nconst calculateInputIndicesImpl =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[]):\n        string => `fn calculateInputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n          var inputIndices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n            var inputIndex = outputIndex * steps[i] + starts[i] + carry;\n            carry = inputIndex / inputShape[i];\n            inputIndex = inputIndex % inputShape[i];\n            if (signs[i] < 0) {\n              inputIndex = inputShape[i] - inputIndex - 1u + starts[i];\n            }\n            ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'} = inputIndex;\n          }\n          return inputIndices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes = (attributes.axes.length > 0) ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length) :\n                                              [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach((step) => step !== 0 || (() => {\n                            throw new Error('step cannot be 0');\n                          }));\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map(step => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n\n  const outputTensorInfo: TensorInfo = {dims: outputShape, dataType: inputs[0].dataType};\n\n  const output = outputVariable('output', inputs[0].dataType, outputShape);\n  const input = inputVariable('input', inputs[0].dataType, inputShape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(input, output)}\n        const signs = array<i32, ${signs.length}>(${signs.map(i => `${i}i`).join(',')});\n        const starts = array<u32, ${starts.length}>(${starts.map(i => `${i}u`).join(',')});\n        const ends = array<u32, ${ends.length}>(${ends.map(i => `${i}u`).join(',')});\n        const steps = array<u32, ${steps.length}>(${steps.map(i => `${i}u`).join(',')});\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n\n        ${calculateInputIndicesImpl(input, output, inputShape, outputShape)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: {hint: `${attributes.cacheKey}|${inputs[4]?.dims ?? ''}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({starts, ends, axes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {getMaxComponents, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (input: TensorView, attributes: SoftmaxAttributes): ProgramInfo => {\n  const dataType = tensorTypeToWsglStorageType(input.dataType);\n  const shape = input.dims;\n  const outputSize = ShapeUtil.size(shape);\n  const WG = 64;\n  let axis = attributes.axis;\n  if (axis < 0) {\n    axis = shape.length + axis;\n  }\n  if (axis < shape.length - 1) {\n    throw new Error('softmax only supports last axis for now.');\n  }\n\n  const cols = shape[axis];\n  const rows = outputSize / cols;\n  const components = getMaxComponents(cols);\n  const packedCols = cols / components;\n  const valueType = components === 1 ? dataType : `vec${components}<${dataType}>`;\n\n  const maxVector = (name: string, components: number) => {\n    if (components === 4) {\n      return `max(max(${name}.x, ${name}.y), max(${name}.z, ${name}.w))`;\n    } else if (components === 2) {\n      return `max(${name}.x, ${name}.y)`;\n    } else if (components === 3) {\n      return `max(max(${name}.x, ${name}.y), ${name}.z)`;\n    }\n\n    return name;\n  };\n\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl =\n      dataType === 'f32' ? `var threadMax = ${valueType}(-3.402823e+38f);` : `var threadMax = ${valueType}(-65504.0h);`;\n  const getShaderSource = (_shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${valueType};\n      var<workgroup> rowSumShared : ${valueType};\n      var<workgroup> threadShared : array<${valueType}, ${WG}>;\n\n      @group(0) @binding(0) var<storage, read> x : array<${valueType}>;\n      @group(0) @binding(1) var<storage, read_write> result : array<${valueType}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${valueType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${valueType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n\n      @compute @workgroup_size(${WG}, 1, 1)\n      fn main(@builtin(local_invocation_id) local_id : vec3<u32>, @builtin(global_invocation_id) global_id : vec3u) {\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = ${packedCols};\n        let row_stride : i32 = ${packedCols};\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${valueType}(${maxVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${valueType}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${valueType}(${sumVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  return {\n    name: 'Softmax',\n    getRunData: () => ({outputs: [{dims: shape, dataType: input.dataType}], dispatchGroup: {x: rows}}),\n    getShaderSource,\n  };\n};\n\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createSoftmaxProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SplitAttributes): SplitAttributes => {\n      const splitSizes: number[] = [];\n      let numOutputs: number = attributes.numOutputs;\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => splitSizes.push(Number(v)));\n        numOutputs = splitSizes.length;\n      }\n      return createAttributeWithCacheKey({numOutputs, axis: attributes.axis, splitSizes});\n    };\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (outputNumber == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (outputNumber == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(outputNumber: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nconst createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const rank = inputShape.length;\n  const axis = attributes.axis;\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape);\n  const sizeInConcatAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInConcatAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[attributes.axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShapes[i]);\n    outputsTensorInfo.push({dims: outputShapes[i], dataType: inputs[0].dataType});\n  }\n  const indicesAxis = rank < 2 ? 'indices' : `indices[${adjustedAxis}]`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(input, ...outputs)}\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateOutputIndexImpl(sizeInConcatAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(inputSize)}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    let outputNumber = calculateOutputIndex(${indicesAxis});\n    if (outputNumber != 0) {\n        ${indicesAxis} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: {hint: attributes.cacheKey},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n      context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = attributes.numOutputs as number < 0 ? splitSizes.length : attributes.numOutputs as number;\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({axis, numOutputs, splitSizes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n    Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.int32 &&\n      inputs[0].dataType !== DataType.uint32) {\n    throw new Error('Tile only support float, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      var inputIndices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let inputDimValue = ${output.indicesGet('outputIndices', 'i')}  % ${input.indicesGet('inputShape', 'i')};\n\n        ${input.indicesSet('inputIndices', 'i', 'inputDimValue')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: {hint: `${repeats}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst createWhereOpProgramShader =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], dimsOutput: readonly number[], isBroadcast: boolean,\n     typeOutput: number) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', inputs[1].dataType, inputs[1].dims, 4);\n      const b = inputVariable('bData', inputs[2].dataType, inputs[2].dims, 4);\n      const c = inputVariable('cData', inputs[0].dataType, inputs[0].dims, 4);\n\n      let assignment: string;\n      const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n      if (!isBroadcast) {\n        assignment = output.setByOffset(\n            'global_idx',\n            expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')));\n      } else {\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          // eslint-disable-next-line no-bitwise\n          const expressionC = `bool(cData[indexC${x}] & ${0xff000000 >>> ((3 - x) * 8)}u)`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetC${x} = ${c.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let indexC${x} = offsetC${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error('Can\\'t perform where op on the given tensors');\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  return {\n    name: 'Where',\n    getShaderSource: (shaderHelper) =>\n        createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: outputDataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */)}\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {argMax, argMin, parseArgMinMaxAttributes} from './ops/argminmax';\nimport {biasAdd} from './ops/bias-add';\nimport {biasSplitGelu} from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport {concat, parseConcatAttributes} from './ops/concat';\nimport {conv, parseConvAttributes} from './ops/conv';\nimport {convTranspose, parseConvTransposeAttributes} from './ops/conv-transpose';\nimport {einsum, parseEinsumAttributes} from './ops/einsum';\nimport {expand} from './ops/expand';\nimport {gather, parseGatherAttributes} from './ops/gather';\nimport {gatherElements, parseGatherElementsAttributes} from './ops/gather-elements';\nimport {gemm, parseGemmAttributes} from './ops/gemm';\nimport {instanceNorm, parseInstanceNormAttributes} from './ops/instance-norm';\nimport {layerNorm, parseLayerNormAttributes} from './ops/layer-norm';\nimport {matMul} from './ops/matmul';\nimport {pad, parsePadAttributes} from './ops/pad';\nimport * as pool from './ops/pool';\nimport {range} from './ops/range';\nimport {parseReduceAttributes, reduceL1, reduceL2, reduceLogSum, reduceLogSumExp, reduceMax, reduceMean, reduceMin, reduceProd, reduceSum, reduceSumSquare} from './ops/reduce';\nimport {parseResizeAttributes, resize} from './ops/resize';\nimport {parseSkipLayerNormAttributes, skipLayerNorm} from './ops/skip-layer-norm';\nimport {parseSliceAttributes, slice} from './ops/slice';\nimport {parseSoftmaxAttributes, softmax} from './ops/softmax';\nimport {parseSplitAttributes, split} from './ops/split';\nimport {tile} from './ops/tile';\nimport {parseTransposeAttributes, transpose} from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport {where} from './ops/where';\nimport {ComputeContext} from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction]|[RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['ClipV10', [unaryOps.clipV10]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['Floor', [unaryOps.floor]],\n  ['FusedConv', [conv, parseConvAttributes]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['InstanceNormalization', [instanceNorm, parseInstanceNormAttributes]],\n  ['LayerNormalization', [layerNorm, parseLayerNormAttributes]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad, parsePadAttributes]],\n  ['Pow', [binaryOps.pow]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin, parseReduceAttributes]],\n  ['ReduceMean', [reduceMean, parseReduceAttributes]],\n  ['ReduceMax', [reduceMax, parseReduceAttributes]],\n  ['ReduceSum', [reduceSum, parseReduceAttributes]],\n  ['ReduceProd', [reduceProd, parseReduceAttributes]],\n  ['ReduceL1', [reduceL1, parseReduceAttributes]],\n  ['ReduceL2', [reduceL2, parseReduceAttributes]],\n  ['ReduceLogSum', [reduceLogSum, parseReduceAttributes]],\n  ['ReduceLogSumExp', [reduceLogSumExp, parseReduceAttributes]],\n  ['ReduceSumSquare', [reduceSumSquare, parseReduceAttributes]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm, parseSkipLayerNormAttributes]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorDataTypeEnumToString} from '../../wasm-common';\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\nimport {TensorView} from '../tensor-view';\n\nimport {createShaderHelper} from './ops/common';\nimport {Artifact, GpuData, ProgramInfo} from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>;  // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact|undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(buildArtifact: Artifact, inputTensorViews: readonly TensorView[], outputTensorViews: readonly TensorView[],\n      inputs: GpuData[], outputs: GpuData[], dispatchGroup: [number, number, number],\n      uniformBufferBinding: GPUBindingResource|undefined): void {\n    const device = this.backend.device;\n\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({binding: entries.length, resource: {buffer: input.buffer}});\n    }\n    for (const output of outputs) {\n      entries.push({binding: entries.length, resource: {buffer: output.buffer}});\n    }\n    if (uniformBufferBinding) {\n      entries.push({binding: entries.length, resource: uniformBufferBinding});\n    }\n    const bindGroup = device.createBindGroup(\n        {layout: buildArtifact.computePipeline.getBindGroupLayout(0), entries, label: buildArtifact.programInfo.name});\n    computePassEncoder.setBindGroup(0, bindGroup);\n\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n\n    this.backend.pendingDispatchNumber++;\n\n    if (this.backend.isQueryEnabled()) {\n      if (typeof this.backend.queryData === 'undefined') {\n        this.backend.queryData = this.backend.gpuDataManager.create(\n            // eslint-disable-next-line no-bitwise\n            this.backend.querySetCount * 8, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n      }\n      const syncData = this.backend.gpuDataManager.create(\n          // eslint-disable-next-line no-bitwise\n          this.backend.querySetCount * 8, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n      this.backend.endComputePass();\n      this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet, 0, 2, this.backend.queryData.buffer, 0);\n      this.backend.getCommandEncoder().copyBufferToBuffer(\n          this.backend.queryData.buffer, 0, syncData.buffer, 0, this.backend.querySetCount * 8);\n      this.backend.flush();\n\n      const kernelId = this.backend.currentKernelId!;\n      const kernelInfo = this.backend.kernels.get(kernelId)!;\n      const kernelName = `[${kernelInfo[0]}] ${kernelInfo[1]}`;\n\n      syncData.buffer.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(syncData.buffer.getMappedRange());\n        const startTimeU64 = mappedData[0];\n        const endTimeU64 = mappedData[1];\n\n        syncData.buffer.unmap();\n\n        if (typeof this.backend.queryTimeBase === 'undefined') {\n          this.backend.queryTimeBase = startTimeU64;\n        }\n\n        const startTime = Number(startTimeU64 - this.backend.queryTimeBase);\n        const endTime = Number(endTimeU64 - this.backend.queryTimeBase);\n\n        if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n          throw new RangeError('incorrect timestamp range');\n        }\n\n        this.backend.gpuDataManager.release(syncData.id);\n        let inputShapes = '';\n        inputTensorViews.forEach((value, i) => {\n          inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        let outputShapes = '';\n        outputTensorViews.forEach((value, i) => {\n          outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        // eslint-disable-next-line no-console\n        console.log(`[profiling] kernel \"${kernelId}|${kernelName}\" ${inputShapes}${outputShapes}execution time: ${\n            endTime - startTime} ns`);\n      });\n    }\n\n    if (this.backend.pendingDispatchNumber >= 16) {\n      this.backend.flush();\n    }\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    const device = this.backend.device;\n    const extensions: string[] = [];\n    if (device.features.has('shader-f16')) {\n      extensions.push('enable f16;');\n    }\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${extensions.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({code, label: programInfo.name});\n    LOG_DEBUG('verbose', () => `[WebGPU] shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline(\n        {compute: {module: shaderModule, entryPoint: 'main'}, layout: 'auto', label: programInfo.name});\n\n    return {programInfo, computePipeline};\n  }\n\n  normalizeDispatchGroupSize(dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup']):\n      [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.y || 1);\n    const z = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.z || 1);\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, Tensor} from 'onnxruntime-common';\n\nimport {configureLogger, LOG_DEBUG} from './log';\nimport {createView, TensorView} from './tensor-view';\nimport {createGpuDataManager, downloadGpuData, GpuDataManager} from './webgpu/gpu-data-manager';\nimport {RunFunction, WEBGPU_OP_RESOLVE_RULES} from './webgpu/op-resolve-rules';\nimport {ProgramManager} from './webgpu/program-manager';\nimport {ComputeContext, GpuData, ProgramInfo, ProgramInputTensorInfoDependency} from './webgpu/types';\n\nconst getProgramInputTensorInfoDependencyKey =\n    (inputTensors: readonly TensorView[], inputDependencies: readonly ProgramInputTensorInfoDependency[]): string => {\n      if (inputDependencies.length !== inputTensors.length) {\n        throw new Error(`inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n            inputTensors.length}.`);\n      }\n\n      const inputInfos: string[] = [];\n      for (let i = 0; i < inputTensors.length; ++i) {\n        const type = inputTensors[i].dataType;\n        switch (inputDependencies[i]) {\n          case 'none': {\n            inputInfos.push('');\n            break;\n          }\n          case 'type': {\n            inputInfos.push(`${type}`);\n            break;\n          }\n          case 'rank': {\n            const rank = inputTensors[i].dims.length;\n            inputInfos.push(`${type};${rank}`);\n            break;\n          }\n          case 'dims': {\n            const dims = inputTensors[i].dims.join(',');\n            inputInfos.push(`${type};${dims}`);\n            break;\n          }\n          default:\n            throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n        }\n      }\n\n      return inputInfos.join('|');\n    };\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey = (programInfo: ProgramInfo, inputTensors: readonly TensorView[]): string => {\n  // final key format:\n  // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n  let key = programInfo.name;\n  if (programInfo.shaderCache?.hint) {\n    key += '[' + programInfo.shaderCache.hint + ']';\n  }\n  key += `:${\n      getProgramInputTensorInfoDependencyKey(\n          inputTensors,\n          programInfo.shaderCache?.inputDependencies ??\n              new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'))}`;\n  return key;\n};\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number|null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, {[key: string]: unknown}>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): {[key: string]: unknown} {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  /**\n   * a KernelID -> kernel info mapping. value is\n   * [ op_type, name, run function, [optional] preprocess_attribute_once function ]\n   */\n  kernels: Map<number, [string, string, RunFunction, [((attribute: unknown) => unknown) | undefined, unknown]]>;\n\n  private commandEncoder: GPUCommandEncoder|null = null;\n  private computePassEncoder: GPUComputePassEncoder|null = null;\n  pendingDispatchNumber = 0;\n\n  queryData?: GpuData;\n  querySet?: GPUQuerySet;\n  querySetCount = 2;\n  queryTimeBase?: bigint;\n\n  env: Env;\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env): Promise<void> {\n    if (!navigator.gpu) {\n      // WebGPU is not available.\n      throw new Error('WebGpuBackend: WebGPU is not available.');\n    }\n\n    const adapter = await navigator.gpu.requestAdapter();\n    if (!adapter) {\n      throw new Error('WebGpuBackend: Failed to get GPU adapter.');\n    }\n\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('shader-f16')) {\n      requiredFeatures.push('shader-f16');\n    }\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = ev => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    Object.defineProperty(this.env.webgpu, 'device', {value: this.device});\n  }\n\n  dispose(): void {\n    if (typeof this.querySet !== 'undefined') {\n      this.querySet.destroy();\n    }\n    this.gpuDataManager.dispose();\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      const computePassDescriptor: GPUComputePassDescriptor = {};\n      if (this.isQueryEnabled()) {\n        if (typeof this.querySet === 'undefined') {\n          this.querySet = this.device.createQuerySet({\n            type: 'timestamp',\n            count: this.querySetCount,\n          });\n        }\n        computePassDescriptor.timestampWrites = {\n          querySet: this.querySet,\n          beginningOfPassWriteIndex: 0,\n          endOfPassWriteIndex: 1,\n        };\n      }\n\n      this.computePassEncoder = this.getCommandEncoder().beginComputePass(computePassDescriptor);\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (this.commandEncoder) {\n      this.endComputePass();\n      this.device.queue.submit([this.getCommandEncoder().finish()]);\n      this.gpuDataManager.refreshPendingBuffers();\n      this.commandEncoder = null;\n      this.pendingDispatchNumber = 0;\n    }\n  }\n\n  isQueryEnabled(): boolean {\n    if (this.device.features.has('timestamp-query') && this.env.webgpu.profilingMode === 'default') {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(program: ProgramInfo, inputTensorViews: readonly TensorView[], outputIndices: readonly number[],\n      createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n      createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView): TensorView[] {\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const gpuData = this.gpuDataManager.get(inputTensorViews[i].data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${inputTensorViews[i].data}`);\n      }\n      inputDatas[i] = gpuData;\n    }\n\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews);\n    let artifact = this.programManager.getArtifact(key);\n\n    const {outputs, dispatchGroup, programUniforms} = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (!Number.isInteger(validatedOutputIndices[i]) || validatedOutputIndices[i] < -3 ||\n          validatedOutputIndices[i] >= outputs.length) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView = (isTemporary || isPersistent) ?\n          createIntermediateOutput(outputs[i].dataType, outputs[i].dims) :\n          createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputTensorViews.push(tensorView);\n      outputDatas.push(gpuData);\n    }\n\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource|undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      let preLength = 0;\n      const offsets: number[] = [];\n      let maxAlignmentOfField = 1;\n      programUniforms.forEach(v => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        // https://www.w3.org/TR/WGSL/#alignof\n        let baseAlignment: number;\n        switch (data.length) {\n          case 1:\n            baseAlignment = 4;\n            break;\n          case 2:\n            baseAlignment = 8;\n            break;\n          case 3:\n            baseAlignment = 16;\n            break;\n          case 4:\n            baseAlignment = 16;\n            break;\n          case 5:\n            baseAlignment = 16;\n            break;\n          case 6:\n            baseAlignment = 16;\n            break;\n          default:\n            throw new Error(`unsupported data length: ${data.length}`);\n        }\n\n        if (preLength === 5 || preLength === 6) {\n          baseAlignment = 16;\n        }\n        if (baseAlignment > maxAlignmentOfField) {\n          maxAlignmentOfField = baseAlignment;\n        }\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        preLength = data.length;\n        offsets.push(currentOffset);\n        currentOffset += data.length * 4;\n      });\n\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === 'int32') {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === 'uint32') {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        }\n      });\n\n      const uniformBufferData =\n          // eslint-disable-next-line no-bitwise\n          this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = {offset: 0, size: currentOffset, buffer: uniformBufferData.buffer};\n    }\n\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n    }\n\n    LOG_DEBUG(\n        'info',\n        () => `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n            normalizedDispatchGroup[1]}x${normalizedDispatchGroup[2]}`);\n    this.programManager.run(\n        artifact, inputTensorViews, outputTensorViews, inputDatas, outputDatas, normalizedDispatchGroup,\n        uniformBufferBinding);\n\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(opType: string, kernelId: number, attribute: unknown, nodeName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(opType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${opType}`);\n    }\n\n    this.kernels.set(kernelId, [opType, nodeName, op[0], [op[1], attribute]]);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string|null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const [opType, nodeName, kernelEntry, attributes] = kernel;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${opType}] ${nodeName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${opType}] ${nodeName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0;  // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${opType}] ${nodeName}\" failed. ${e}`));\n      return 1;  // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(this.device.popErrorScope().then(\n            err => err ? `GPU validation error for kernel \"[${opType}] ${nodeName}\": ${err.message}` : null));\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer?.[1]);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach(bufferInfo => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[1]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(gpuBuffer: GPUBuffer, size: number, type: Tensor.GpuBufferDataTypes):\n      () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from '../binding/ort-wasm';\nimport {DataType, getTensorElementSize} from '../wasm-common';\n\nimport {WebGpuBackend} from './backend-webgpu';\nimport {LOG_DEBUG} from './log';\nimport {TensorView} from './tensor-view';\nimport {ShapeUtil} from './util';\nimport {ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo} from './webgpu/types';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n      private module: OrtWasmModule, public readonly dataType: number, public readonly data: number,\n      public readonly dims: readonly number[]) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Float32Array() :\n                                new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new BigInt64Array() :\n                                new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): {[key: string]: unknown} {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(private module: OrtWasmModule, private backend: WebGpuBackend, contextDataOffset: number) {\n    const heapU32 = module.HEAPU32;\n\n    // extract context data\n    let dataIndex = (contextDataOffset >> 2);\n    this.opKernelContext = heapU32[dataIndex++];\n    const inputCount = heapU32[dataIndex++];\n    this.outputCount = heapU32[dataIndex++];\n    this.customDataOffset = heapU32[dataIndex++];\n    this.customDataSize = heapU32[dataIndex++];\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = heapU32[dataIndex++];\n      const data = heapU32[dataIndex++];\n      const dim = heapU32[dataIndex++];\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(heapU32[dataIndex++]);\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n        inputsOutputsMapping?.inputs?.map(i => typeof i === 'number' ? this.inputs[i] : i) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n        new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const elementSize = getTensorElementSize(dataType);\n      if (!elementSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const bufferSize = elementSize * ShapeUtil.size(dims);\n      return new TensorViewImpl(this.module, dataType, this.backend.gpuDataManager.create(bufferSize).id, dims);\n    };\n    return this.backend.run(program, mappedInputs, outputIndices, createKernelOutput, createTemporaryOutput);\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const data = this.module.stackAlloc((1 + dims.length) * 4 /* sizeof(size_t) */);\n      let offset = data >> 2;\n      this.module.HEAPU32[offset++] = dims.length;\n      for (let i = 0; i < dims.length; i++) {\n        this.module.HEAPU32[offset++] = dims[i];\n      }\n      return this.module._JsepOutput(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n          `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`);\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\nexport const init = async(module: OrtWasmModule, env: Env): Promise<void> => {\n  const init = module.jsepInit;\n  if (init && navigator.gpu) {\n    if (!env.wasm.simd) {\n      throw new Error(\n          'Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP');\n    }\n    const backend = new WebGpuBackend();\n    await backend.initialize(env);\n\n    init(\n        // backend\n        backend,\n\n        // jsepAlloc()\n        (size: number) => backend.alloc(size),\n\n        // jsepFree()\n        (ptr: number) => backend.free(ptr),\n\n        // jsepCopy(src, dst, size, isSourceGpu)\n        (src: number, dst: number, size: number, isSourceGpu = false) => {\n          if (isSourceGpu) {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyGpuToGpu: src=${src}, dst=${dst}, size=${size}`);\n            backend.memcpy(src, dst);\n          } else {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${src}, gpuDataId=${dst}, size=${size}`);\n            const data = module.HEAPU8.subarray(src, src + size);\n            backend.upload(dst, data);\n          }\n        },\n\n        // jsepCopyAsync(src, dst, size)\n        async(gpuDataId: number, dataOffset: number, size: number):\n            Promise<void> => {\n              LOG_DEBUG(\n                  'verbose',\n                  () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`);\n\n              await backend.download(gpuDataId, () => module.HEAPU8.subarray(dataOffset, dataOffset + size));\n            },\n\n        // jsepCreateKernel\n        (name: string, kernel: number, attribute: unknown) => backend.createKernel(\n            name, kernel, attribute,\n            env.debug || env.webgpu.profilingMode === 'default' ? module.UTF8ToString(module._JsepGetNodeName(kernel)) :\n                                                                  `${kernel}`),\n\n        // jsepReleaseKernel\n        (kernel: number) => backend.releaseKernel(kernel),\n\n        // jsepRun\n        (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string|null>>) => {\n          LOG_DEBUG(\n              'verbose',\n              () => `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${\n                  contextDataOffset}`);\n          const context = new ComputeContextImpl(module, backend, contextDataOffset);\n          return backend.computeKernel(kernel, context, errors);\n        });\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, InferenceSession, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport {setRunOptions} from './run-options';\nimport {setSessionOptions} from './session-options';\nimport {dataLocationStringToEnum, getTensorElementSize, isGpuBufferSupportedType, logLevelStringToEnum, tensorDataTypeEnumToString, tensorDataTypeStringToEnum, tensorTypeToTypedArrayConstructor} from './wasm-common';\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError} from './wasm-utils';\n\nlet ortEnvInitialized = false;\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const dataOffset = wasm.stackAlloc(8);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + 4);\n    if (errorCode !== 0) {\n      checkLastError('Can\\'t get session input/output count.');\n    }\n    return [wasm.HEAP32[dataOffset / 4], wasm.HEAP32[dataOffset / 4 + 1]];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * initialize ORT environment.\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError('Can\\'t initialize onnxruntime.');\n  }\n};\n\n/**\n * intialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async(env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n\n  if (!BUILD_DEFS.DISABLE_WEBGPU) {\n    // init JSEP if available\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n    await initJsep(getInstance(), env);\n  }\n\n  ortEnvInitialized = true;\n};\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu'|'cpu-pinned'|'gpu-buffer';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number, inputNamesUTF8Encoded: number[], outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState|null\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\nexport const isOrtEnvInitialized = (): boolean => ortEnvInitialized;\n\n/**\n * allocate the memory and memcpy the model bytes, preparing for creating an instance of InferenceSession.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const createSessionAllocate = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session using the prepared buffer containing the model data.\n * @param modelData a 2-elements tuple containing the pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSessionFinalize =\n    (modelData: SerializableModeldata, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const wasm = getInstance();\n\n      let sessionHandle = 0;\n      let sessionOptionsHandle = 0;\n      let ioBindingHandle = 0;\n      let allocs: number[] = [];\n      const inputNamesUTF8Encoded = [];\n      const outputNamesUTF8Encoded = [];\n\n      try {\n        [sessionOptionsHandle, allocs] = setSessionOptions(options);\n\n        sessionHandle = wasm._OrtCreateSession(modelData[0], modelData[1], sessionOptionsHandle);\n        if (sessionHandle === 0) {\n          checkLastError('Can\\'t create a session.');\n        }\n\n        const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n        const inputNames = [];\n        const outputNames = [];\n        const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n        for (let i = 0; i < inputCount; i++) {\n          const name = wasm._OrtGetInputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an input name.');\n          }\n          inputNamesUTF8Encoded.push(name);\n          inputNames.push(wasm.UTF8ToString(name));\n        }\n        for (let i = 0; i < outputCount; i++) {\n          const name = wasm._OrtGetOutputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an output name.');\n          }\n          outputNamesUTF8Encoded.push(name);\n          const nameString = wasm.UTF8ToString(name);\n          outputNames.push(nameString);\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            const location = typeof options?.preferredOutputLocation === 'string' ?\n                options.preferredOutputLocation :\n                options?.preferredOutputLocation?.[nameString] ?? 'cpu';\n            if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer') {\n              throw new Error(`Not supported preferred output location: ${location}.`);\n            }\n            outputPreferredLocations.push(location);\n          }\n        }\n\n        // use IO binding only when at least one output is preffered to be on GPU.\n        let bindingState: IOBindingState|null = null;\n        if (!BUILD_DEFS.DISABLE_WEBGPU && outputPreferredLocations.some(l => l === 'gpu-buffer')) {\n          ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n          if (ioBindingHandle === 0) {\n            checkLastError('Can\\'t create IO binding.');\n          }\n\n          bindingState = {\n            handle: ioBindingHandle,\n            outputPreferredLocations,\n            outputPreferredLocationsEncoded: outputPreferredLocations.map(l => dataLocationStringToEnum(l)),\n          };\n        }\n\n        activeSessions.set(sessionHandle, [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, bindingState]);\n        return [sessionHandle, inputNames, outputNames];\n      } catch (e) {\n        inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n        outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n\n        if (ioBindingHandle !== 0) {\n          wasm._OrtReleaseBinding(ioBindingHandle);\n        }\n\n        if (sessionHandle !== 0) {\n          wasm._OrtReleaseSession(sessionHandle);\n        }\n        throw e;\n      } finally {\n        wasm._free(modelData[0]);\n        if (sessionOptionsHandle !== 0) {\n          wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n        }\n        allocs.forEach(alloc => wasm._free(alloc));\n      }\n    };\n\n\n/**\n * create an instance of InferenceSession.\n * @returns the metadata of InferenceSession. 0-value handle for failure.\n */\nexport const createSession =\n    (model: Uint8Array, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const modelData: SerializableModeldata = createSessionAllocate(model);\n      return createSessionFinalize(modelData, options);\n    };\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  if (ioBindingState) {\n    wasm._OrtReleaseBinding(ioBindingState.handle);\n  }\n\n  wasm.jsepUnregisterBuffers?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  wasm._OrtReleaseSession(sessionHandle);\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor =\n    (tensor: TensorMetadata|null, tensorHandles: number[], allocs: number[], sessionId: number, index: number):\n        void => {\n          if (!tensor) {\n            tensorHandles.push(0);\n            return;\n          }\n\n          const wasm = getInstance();\n\n          const dataType = tensor[0];\n          const dims = tensor[1];\n          const location = tensor[3];\n\n          let rawData: number;\n          let dataByteLength: number;\n\n          if (dataType === 'string' && location === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n\n          if (location === 'gpu-buffer') {\n            const gpuBuffer = tensor[2].gpuBuffer as GPUBuffer;\n            const elementSizeInBytes = getTensorElementSize(tensorDataTypeStringToEnum(dataType))!;\n            dataByteLength = dims.reduce((a, b) => a * b, 1) * elementSizeInBytes;\n            rawData = wasm.jsepRegisterBuffer(sessionId, index, gpuBuffer, dataByteLength);\n          } else {\n            const data = tensor[2];\n\n            if (Array.isArray(data)) {\n              // string tensor\n              dataByteLength = 4 * data.length;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              let dataIndex = rawData / 4;\n              for (let i = 0; i < data.length; i++) {\n                if (typeof data[i] !== 'string') {\n                  throw new TypeError(`tensor data at index ${i} is not a string`);\n                }\n                wasm.HEAPU32[dataIndex++] = allocWasmString(data[i], allocs);\n              }\n            } else {\n              dataByteLength = data.byteLength;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n            }\n          }\n\n          const stack = wasm.stackSave();\n          const dimsOffset = wasm.stackAlloc(4 * dims.length);\n          try {\n            let dimIndex = dimsOffset / 4;\n            dims.forEach(d => wasm.HEAP32[dimIndex++] = d);\n            const tensor = wasm._OrtCreateTensor(\n                tensorDataTypeStringToEnum(dataType), rawData, dataByteLength, dimsOffset, dims.length,\n                dataLocationStringToEnum(location));\n            if (tensor === 0) {\n              checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n            }\n            tensorHandles.push(tensor);\n          } finally {\n            wasm.stackRestore(stack);\n          }\n        };\n\n/**\n * perform inference run\n */\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputTensors: TensorMetadata[], outputIndices: number[],\n    outputTensors: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * 4);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * 4);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * 4);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * 4);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      prepareInputOutputTensor(inputTensors[i], inputTensorHandles, inputOutputAllocs, sessionId, inputIndices[i]);\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      prepareInputOutputTensor(\n          outputTensors[i], outputTensorHandles, inputOutputAllocs, sessionId, inputCount + outputIndices[i]);\n    }\n\n    let inputValuesIndex = inputValuesOffset / 4;\n    let inputNamesIndex = inputNamesOffset / 4;\n    let outputValuesIndex = outputValuesOffset / 4;\n    let outputNamesIndex = outputNamesOffset / 4;\n    for (let i = 0; i < inputCount; i++) {\n      wasm.HEAPU32[inputValuesIndex++] = inputTensorHandles[i];\n      wasm.HEAPU32[inputNamesIndex++] = inputNamesUTF8Encoded[inputIndices[i]];\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.HEAPU32[outputValuesIndex++] = outputTensorHandles[i];\n      wasm.HEAPU32[outputNamesIndex++] = outputNamesUTF8Encoded[outputIndices[i]];\n    }\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      const {handle, outputPreferredLocations, outputPreferredLocationsEncoded} = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(`input count from feeds (${\n            inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`);\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3];  // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode =\n              wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], 0, outputPreferredLocationsEncoded[index]);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n    }\n\n    let errorCode: number;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n          sessionHandle, ioBindingState.handle, outputCount, outputValuesOffset, runOptionsHandle);\n    } else {\n      errorCode = await wasm._OrtRun(\n          sessionHandle, inputNamesOffset, inputValuesOffset, inputCount, outputNamesOffset, outputCount,\n          outputValuesOffset, runOptionsHandle);\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = wasm.HEAPU32[outputValuesOffset / 4 + i];\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * 4);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type|undefined, dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n            tensor, tensorDataOffset, tensorDataOffset + 4, tensorDataOffset + 8, tensorDataOffset + 12);\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        let tensorDataIndex = tensorDataOffset / 4;\n        const dataType = wasm.HEAPU32[tensorDataIndex++];\n        dataOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsLength = wasm.HEAPU32[tensorDataIndex++];\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(wasm.HEAPU32[dimsOffset / 4 + i]);\n        }\n        wasm._OrtFree(dimsOffset);\n\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          let dataIndex = dataOffset / 4;\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.HEAPU32[dataIndex++];\n            const maxBytesToRead = i === size - 1 ? undefined : wasm.HEAPU32[dataIndex] - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const gpuBuffer = wasm.jsepGetBuffer(dataOffset);\n            const elementSize = getTensorElementSize(dataType);\n            if (elementSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type, dims, {\n                gpuBuffer,\n                download: wasm.jsepCreateDownloader(gpuBuffer, size * elementSize, type),\n                dispose: () => {\n                  wasm._OrtReleaseTensor(tensor);\n                }\n              },\n              'gpu-buffer'\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength)\n                .set(wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength));\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState) {\n      wasm._OrtClearBoundOutputs(ioBindingState.handle);\n    }\n\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    inputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach(p => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach(p => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError('Can\\'t get an profile file name.');\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n", "/*!\n * ONNX Runtime Web v1.17.0-dev.20231103-1439da36fe\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\n\"use strict\";(()=>{var on=Object.defineProperty;var Su=Object.getOwnPropertyDescriptor;var Cu=Object.getOwnPropertyNames;var Au=Object.prototype.hasOwnProperty;var H=(e,t)=>()=>(e&&(t=e(e=0)),t);var Jt=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),Ir=(e,t)=>{for(var r in t)on(e,r,{get:t[r],enumerable:!0})},Iu=(e,t,r,o)=>{if(t&&typeof t==\"object\"||typeof t==\"function\")for(let n of Cu(t))!Au.call(e,n)&&n!==r&&on(e,n,{get:()=>t[n],enumerable:!(o=Su(t,n))||o.enumerable});return e};var Mt=e=>Iu(on({},\"__esModule\",{value:!0}),e);var an={};Ir(an,{readFile:()=>Eu});var Eu,sn=H(()=>{Eu=void 0});var un={};Ir(un,{join:()=>Tu});var Tu,ln=H(()=>{Tu=void 0});var uo=Jt((so,dn)=>{\"use strict\";var io=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){var r=t,o,n;r.ready=new Promise((l,p)=>{o=l,n=p}),r.jsepInit=(l,p,h,C,T,U,G,ue)=>{r.Za=l,r.Oa=p,r.Qa=h,r.Ja=C,r.Pa=T,r.ra=U,r.Ra=G,r.Sa=ue,p=(Y,Q,J)=>(...ce)=>{let me=He,E=Q?.();ce=Y(...ce);let te=Q?.();return E!==te&&(Y=te,J(E),Q=J=null),He!=me?gr():ce},h=Y=>async(...Q)=>{try{if(r.Da)throw Error(\"Session already started\");let J=r.Da={Ta:Q[0],errors:[]},ce=await Y(...Q);if(r.Da!==J)throw Error(\"Session mismatch\");l.flush();let me=J.errors;if(0<me.length){let E=await Promise.all(me);if(E=E.filter(te=>te),0<E.length)throw Error(E.join(`\n`))}return ce}finally{r.Da=null}},r._OrtRun=h(p(r._OrtRun,()=>r._OrtRun,Y=>r._OrtRun=Y)),r._OrtRunWithBinding=h(p(r._OrtRunWithBinding,()=>r._OrtRunWithBinding,Y=>r._OrtRunWithBinding=Y)),r._OrtBindInput=p(r._OrtBindInput,()=>r._OrtBindInput,Y=>r._OrtBindInput=Y),r.jsepRegisterBuffer=(Y,Q,J,ce)=>l.registerBuffer(Y,Q,J,ce),r.jsepUnregisterBuffers=Y=>{l.unregisterBuffers(Y)},r.jsepGetBuffer=Y=>l.getBuffer(Y),r.jsepCreateDownloader=(Y,Q,J)=>l.createDownloader(Y,Q,J)};var s=Object.assign({},r),u=\"./this.program\",d=(l,p)=>{throw p},a=typeof window==\"object\",m=typeof importScripts==\"function\",g=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",x=\"\",b,w,v;if(g){var y=(sn(),Mt(an)),S=(ln(),Mt(un));x=m?S.dirname(x)+\"/\":__dirname+\"/\",b=(l,p)=>(l=l.startsWith(\"file://\")?new URL(l):S.normalize(l),y.readFileSync(l,p?void 0:\"utf8\")),v=l=>(l=b(l,!0),l.buffer||(l=new Uint8Array(l)),l),w=(l,p,h,C=!0)=>{l=l.startsWith(\"file://\")?new URL(l):S.normalize(l),y.readFile(l,C?void 0:\"utf8\",(T,U)=>{T?h(T):p(C?U.buffer:U)})},!r.thisProgram&&1<process.argv.length&&(u=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),d=(l,p)=>{throw process.exitCode=l,p},r.inspect=()=>\"[Emscripten Module object]\"}else(a||m)&&(m?x=self.location.href:typeof document<\"u\"&&document.currentScript&&(x=document.currentScript.src),e&&(x=e),x.indexOf(\"blob:\")!==0?x=x.substr(0,x.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):x=\"\",b=l=>{var p=new XMLHttpRequest;return p.open(\"GET\",l,!1),p.send(null),p.responseText},m&&(v=l=>{var p=new XMLHttpRequest;return p.open(\"GET\",l,!1),p.responseType=\"arraybuffer\",p.send(null),new Uint8Array(p.response)}),w=(l,p,h)=>{var C=new XMLHttpRequest;C.open(\"GET\",l,!0),C.responseType=\"arraybuffer\",C.onload=()=>{C.status==200||C.status==0&&C.response?p(C.response):h()},C.onerror=h,C.send(null)});var A=r.print||console.log.bind(console),R=r.printErr||console.error.bind(console);Object.assign(r,s),s=null,r.thisProgram&&(u=r.thisProgram),r.quit&&(d=r.quit);var W;r.wasmBinary&&(W=r.wasmBinary);var M=r.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&Le(\"no native wasm support detected\");var D,_,z=!1,F,q,le,B,K,xe,ae;function we(){var l=D.buffer;r.HEAP8=q=new Int8Array(l),r.HEAP16=new Int16Array(l),r.HEAP32=B=new Int32Array(l),r.HEAPU8=le=new Uint8Array(l),r.HEAPU16=new Uint16Array(l),r.HEAPU32=K=new Uint32Array(l),r.HEAPF32=xe=new Float32Array(l),r.HEAPF64=ae=new Float64Array(l)}var j=[],Se=[],Oe=[];function Ie(){var l=r.preRun.shift();j.unshift(l)}var Ce=0,dt=null,Ne=null;function Le(l){throw r.onAbort&&r.onAbort(l),l=\"Aborted(\"+l+\")\",R(l),z=!0,F=1,l=new WebAssembly.RuntimeError(l+\". Build with -sASSERTIONS for more info.\"),n(l),l}function N(l){return l.startsWith(\"data:application/octet-stream;base64,\")}var de;if(de=\"ort-wasm-simd.wasm\",!N(de)){var pe=de;de=r.locateFile?r.locateFile(pe,x):x+pe}function ze(l){if(l==de&&W)return new Uint8Array(W);if(v)return v(l);throw\"both async and sync fetching of the wasm failed\"}function Ue(l){if(!W&&(a||m)){if(typeof fetch==\"function\"&&!l.startsWith(\"file://\"))return fetch(l,{credentials:\"same-origin\"}).then(p=>{if(!p.ok)throw\"failed to load wasm binary file at '\"+l+\"'\";return p.arrayBuffer()}).catch(()=>ze(l));if(w)return new Promise((p,h)=>{w(l,C=>p(new Uint8Array(C)),h)})}return Promise.resolve().then(()=>ze(l))}function Te(l,p,h){return Ue(l).then(C=>WebAssembly.instantiate(C,p)).then(C=>C).then(h,C=>{R(\"failed to asynchronously prepare wasm: \"+C),Le(C)})}function ke(l,p){var h=de;return W||typeof WebAssembly.instantiateStreaming!=\"function\"||N(h)||h.startsWith(\"file://\")||g||typeof fetch!=\"function\"?Te(h,l,p):fetch(h,{credentials:\"same-origin\"}).then(C=>WebAssembly.instantiateStreaming(C,l).then(p,function(T){return R(\"wasm streaming compile failed: \"+T),R(\"falling back to ArrayBuffer instantiation\"),Te(h,l,p)}))}var Ge,Xe={913792:l=>{r.ra(\"Abs\",l,void 0)},913843:l=>{r.ra(\"Neg\",l,void 0)},913894:l=>{r.ra(\"Floor\",l,void 0)},913947:l=>{r.ra(\"Ceil\",l,void 0)},913999:l=>{r.ra(\"Reciprocal\",l,void 0)},914057:l=>{r.ra(\"Sqrt\",l,void 0)},914109:l=>{r.ra(\"Exp\",l,void 0)},914160:l=>{r.ra(\"Erf\",l,void 0)},914211:l=>{r.ra(\"Sigmoid\",l,void 0)},914266:l=>{r.ra(\"Log\",l,void 0)},914317:l=>{r.ra(\"Sin\",l,void 0)},914368:l=>{r.ra(\"Cos\",l,void 0)},914419:l=>{r.ra(\"Tan\",l,void 0)},914470:l=>{r.ra(\"Asin\",l,void 0)},914522:l=>{r.ra(\"Acos\",l,void 0)},914574:l=>{r.ra(\"Atan\",l,void 0)},914626:l=>{r.ra(\"Sinh\",l,void 0)},914678:l=>{r.ra(\"Cosh\",l,void 0)},914730:l=>{r.ra(\"Asinh\",l,void 0)},914783:l=>{r.ra(\"Acosh\",l,void 0)},914836:l=>{r.ra(\"Atanh\",l,void 0)},914889:l=>{r.ra(\"Tanh\",l,void 0)},914941:l=>{r.ra(\"Not\",l,void 0)},914992:(l,p,h)=>{r.ra(\"ClipV10\",l,{min:p,max:h})},915064:l=>{r.ra(\"Clip\",l,void 0)},915116:(l,p)=>{r.ra(\"Elu\",l,{alpha:p})},915174:l=>{r.ra(\"Relu\",l,void 0)},915226:(l,p)=>{r.ra(\"LeakyRelu\",l,{alpha:p})},915290:(l,p)=>{r.ra(\"ThresholdedRelu\",l,{alpha:p})},915360:(l,p)=>{r.ra(\"Cast\",l,{to:p})},915418:l=>{r.ra(\"Add\",l,void 0)},915469:l=>{r.ra(\"Sub\",l,void 0)},915520:l=>{r.ra(\"Mul\",l,void 0)},915571:l=>{r.ra(\"Div\",l,void 0)},915622:l=>{r.ra(\"Pow\",l,void 0)},915673:l=>{r.ra(\"Equal\",l,void 0)},915726:l=>{r.ra(\"Greater\",l,void 0)},915781:l=>{r.ra(\"GreaterOrEqual\",l,void 0)},915843:l=>{r.ra(\"Less\",l,void 0)},915895:l=>{r.ra(\"LessOrEqual\",l,void 0)},915954:(l,p,h,C,T)=>{r.ra(\"ReduceMean\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},916118:(l,p,h,C,T)=>{r.ra(\"ReduceMax\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},916281:(l,p,h,C,T)=>{r.ra(\"ReduceMin\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},916444:(l,p,h,C,T)=>{r.ra(\"ReduceProd\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},916608:(l,p,h,C,T)=>{r.ra(\"ReduceSum\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},916771:(l,p,h,C,T)=>{r.ra(\"ReduceL1\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},916933:(l,p,h,C,T)=>{r.ra(\"ReduceL2\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},917095:(l,p,h,C,T)=>{r.ra(\"ReduceLogSum\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},917261:(l,p,h,C,T)=>{r.ra(\"ReduceSumSquare\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},917430:(l,p,h,C,T)=>{r.ra(\"ReduceLogSumExp\",l,{keepDims:!!p,noopWithEmptyAxes:!!h,axes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},917599:l=>{r.ra(\"Where\",l,void 0)},917652:(l,p,h)=>{r.ra(\"Transpose\",l,{perm:p?Array.from(B.subarray(h>>>0,h+p>>>0)):[]})},917765:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te)=>{r.ra(\"ConvTranspose\",l,{format:Y?\"NHWC\":\"NCHW\",autoPad:p,dilations:[h],group:C,kernel_shape:[T],pads:[U,G],strides:[ue],wIsConst:()=>!!q[Q>>>0],outputPadding:J?Array.from(B.subarray(ce>>>0,ce+J>>>0)):[],outputShape:me?Array.from(B.subarray(E>>>0,E+me>>>0)):[],activation:_e(te)})},918179:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E)=>{r.ra(\"ConvTranspose\",l,{format:ue?\"NHWC\":\"NCHW\",autoPad:p,dilations:Array.from(B.subarray(h>>>0,h+2>>>0)),group:C,kernelShape:Array.from(B.subarray(T>>>0,T+2>>>0)),pads:Array.from(B.subarray(U>>>0,U+4>>>0)),strides:Array.from(B.subarray(G>>>0,G+2>>>0)),wIsConst:()=>!!q[Y>>>0],outputPadding:0<Q?Array.from(B.subarray(J>>>0,J+Q>>>0)):[],outputShape:0<ce?Array.from(B.subarray(me>>>0,me+ce>>>0)):[],activation:_e(E)})},918736:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te)=>{r.ra(\"ConvTranspose\",l,{format:Y?\"NHWC\":\"NCHW\",autoPad:p,dilations:[h],group:C,kernel_shape:[T],pads:[U,G],strides:[ue],wIsConst:()=>!!q[Q>>>0],outputPadding:J?Array.from(B.subarray(ce>>>0,ce+J>>>0)):[],outputShape:me?Array.from(B.subarray(E>>>0,E+me>>>0)):[],activation:_e(te)})},919150:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E)=>{r.ra(\"ConvTranspose\",l,{format:ue?\"NHWC\":\"NCHW\",autoPad:p,dilations:Array.from(B.subarray(h>>>0,h+2>>>0)),group:C,kernelShape:Array.from(B.subarray(T>>>0,T+2>>>0)),pads:Array.from(B.subarray(U>>>0,U+4>>>0)),strides:Array.from(B.subarray(G>>>0,G+2>>>0)),wIsConst:()=>!!q[Y>>>0],outputPadding:0<Q?Array.from(B.subarray(J>>>0,J+Q>>>0)):[],outputShape:0<ce?Array.from(B.subarray(me>>>0,me+ce>>>0)):[],activation:_e(E)})},919707:(l,p)=>{r.ra(\"GlobalAveragePool\",l,{format:p?\"NHWC\":\"NCHW\"})},919798:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te,fe)=>{r.ra(\"AveragePool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:C,storage_order:T,dilations:[U,G],kernel_shape:[ue,Y],pads:[Q,J,ce,me],strides:[E,te]})},920082:(l,p)=>{r.ra(\"GlobalAveragePool\",l,{format:p?\"NHWC\":\"NCHW\"})},920173:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te,fe)=>{r.ra(\"AveragePool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:C,storage_order:T,dilations:[U,G],kernel_shape:[ue,Y],pads:[Q,J,ce,me],strides:[E,te]})},920457:(l,p)=>{r.ra(\"GlobalMaxPool\",l,{format:p?\"NHWC\":\"NCHW\"})},920544:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te,fe)=>{r.ra(\"MaxPool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:C,storage_order:T,dilations:[U,G],kernel_shape:[ue,Y],pads:[Q,J,ce,me],strides:[E,te]})},920824:(l,p)=>{r.ra(\"GlobalMaxPool\",l,{format:p?\"NHWC\":\"NCHW\"})},920911:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te,fe)=>{r.ra(\"MaxPool\",l,{format:fe?\"NHWC\":\"NCHW\",auto_pad:p,ceil_mode:h,count_include_pad:C,storage_order:T,dilations:[U,G],kernel_shape:[ue,Y],pads:[Q,J,ce,me],strides:[E,te]})},921191:(l,p,h,C,T)=>{r.ra(\"Gemm\",l,{alpha:p,beta:h,transA:C,transB:T})},921295:l=>{r.ra(\"MatMul\",l,void 0)},921349:(l,p,h,C)=>{r.ra(\"ArgMax\",l,{keepDims:!!p,selectLastIndex:!!h,axis:C})},921457:(l,p,h,C)=>{r.ra(\"ArgMin\",l,{keepDims:!!p,selectLastIndex:!!h,axis:C})},921565:(l,p)=>{r.ra(\"Softmax\",l,{axis:p})},921628:(l,p)=>{r.ra(\"Concat\",l,{axis:p})},921688:(l,p,h,C,T)=>{r.ra(\"Split\",l,{axis:p,numOutputs:h,splitSizes:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},921833:l=>{r.ra(\"Expand\",l,void 0)},921887:(l,p)=>{r.ra(\"Gather\",l,{axis:Number(p)})},921958:(l,p)=>{r.ra(\"GatherElements\",l,{axis:Number(p)})},922037:(l,p,h,C,T,U,G,ue,Y,Q,J)=>{r.ra(\"Resize\",l,{antialias:p,axes:h?Array.from(B.subarray(C>>>0,C+h>>>0)):[],coordinateTransformMode:_e(T),cubicCoeffA:U,excludeOutside:G,extrapolationValue:ue,keepAspectRatioPolicy:_e(Y),mode:_e(Q),nearestMode:_e(J)})},922388:(l,p,h,C,T,U,G)=>{r.ra(\"Slice\",l,{starts:p?Array.from(B.subarray(h>>>0,h+p>>>0)):[],ends:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[],axes:U?Array.from(B.subarray(G>>>0,G+U>>>0)):[]})},922619:l=>{r.ra(\"Tile\",l,void 0)},922671:(l,p,h)=>{r.ra(\"LayerNormalization\",l,{axis:Number(p),epsilon:Number(h)})},922778:(l,p,h)=>{r.ra(\"InstanceNormalization\",l,{epsilon:p,format:h?\"NHWC\":\"NCHW\"})},922892:(l,p,h)=>{r.ra(\"InstanceNormalization\",l,{epsilon:p,format:h?\"NHWC\":\"NCHW\"})},923006:l=>{r.ra(\"Range\",l,void 0)},923059:(l,p)=>{r.ra(\"Einsum\",l,{equation:_e(p)})},923140:(l,p,h,C,T)=>{r.ra(\"Pad\",l,{mode:p,value:h,pads:C?Array.from(B.subarray(T>>>0,T+C>>>0)):[]})},923272:l=>{r.ra(\"Gelu\",l,void 0)},923324:l=>{r.ra(\"BiasAdd\",l,void 0)},923379:l=>{r.ra(\"BiasSplitGelu\",l,void 0)},923440:(l,p)=>{r.ra(\"SkipLayerNormalization\",l,{epsilon:p})},923521:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me)=>{r.ra(\"Conv\",l,{format:Y?\"NHWC\":\"NCHW\",auto_pad:p,dilations:[h],group:C,kernel_shape:[T],pads:U?Array.from(B.subarray(G>>>0,G+U>>>0)):[],strides:[ue],w_is_const:()=>!!q[Q>>>0],activation:_e(J),activation_params:ce?Array.from(xe.subarray(me>>>0,me+ce>>>0)):[]})},923902:(l,p,h,C,T,U,G,ue,Y,Q,J,ce,me,E,te,fe)=>{r.ra(\"Conv\",l,{format:ce?\"NHWC\":\"NCHW\",auto_pad:p,dilations:[h,C],group:T,kernel_shape:[U,G],pads:ue?Array.from(B.subarray(Y>>>0,Y+ue>>>0)):[],strides:[Q,J],w_is_const:()=>!!q[me>>>0],activation:_e(E),activation_params:te?Array.from(xe.subarray(fe>>>0,fe+te>>>0)):[]})},924304:l=>{r.Ra(l)},924338:(l,p)=>r.Sa(l,p,r.Da.Ta,r.Da.errors),924450:l=>r.Oa(l),924483:l=>r.Qa(l),924515:(l,p,h)=>{r.Ja(l,p,h,!0)},924554:(l,p,h)=>{r.Ja(l,p,h)}};function Fe(l){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${l})`,this.status=l}var yt=l=>{for(;0<l.length;)l.shift()(r)};function bt(l){this.Ha=l-24,this.Ma=function(p){K[this.Ha+4>>2>>>0]=p},this.La=function(p){K[this.Ha+8>>2>>>0]=p},this.Ya=function(p,h){this.Ka(),this.Ma(p),this.La(h)},this.Ka=function(){K[this.Ha+16>>2>>>0]=0}}var Bt=0,lr=0,Ke=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,kt=(l,p,h)=>{p>>>=0;var C=p+h;for(h=p;l[h]&&!(h>=C);)++h;if(16<h-p&&l.buffer&&Ke)return Ke.decode(l.subarray(p,h));for(C=\"\";p<h;){var T=l[p++];if(T&128){var U=l[p++]&63;if((T&224)==192)C+=String.fromCharCode((T&31)<<6|U);else{var G=l[p++]&63;T=(T&240)==224?(T&15)<<12|U<<6|G:(T&7)<<18|U<<12|G<<6|l[p++]&63,65536>T?C+=String.fromCharCode(T):(T-=65536,C+=String.fromCharCode(55296|T>>10,56320|T&1023))}}else C+=String.fromCharCode(T)}return C},_e=(l,p)=>(l>>>=0)?kt(le,l,p):\"\",It=l=>{for(var p=0,h=0;h<l.length;++h){var C=l.charCodeAt(h);127>=C?p++:2047>=C?p+=2:55296<=C&&57343>=C?(p+=4,++h):p+=3}return p},Dt=(l,p,h,C)=>{if(h>>>=0,!(0<C))return 0;var T=h;C=h+C-1;for(var U=0;U<l.length;++U){var G=l.charCodeAt(U);if(55296<=G&&57343>=G){var ue=l.charCodeAt(++U);G=65536+((G&1023)<<10)|ue&1023}if(127>=G){if(h>=C)break;p[h++>>>0]=G}else{if(2047>=G){if(h+1>=C)break;p[h++>>>0]=192|G>>6}else{if(65535>=G){if(h+2>=C)break;p[h++>>>0]=224|G>>12}else{if(h+3>=C)break;p[h++>>>0]=240|G>>18,p[h++>>>0]=128|G>>12&63}p[h++>>>0]=128|G>>6&63}p[h++>>>0]=128|G&63}}return p[h>>>0]=0,h-T},at=l=>l%4===0&&(l%100!==0||l%400===0),dr=[0,31,60,91,121,152,182,213,244,274,305,335],it=[0,31,59,90,120,151,181,212,243,273,304,334],Et=l=>{var p=It(l)+1,h=Rt(p);return h&&Dt(l,le,h,p),h},ct=[],Tt=(l,p)=>{ct.length=0;var h;for(p>>=2;h=le[l++>>>0];)p+=h!=105&p,ct.push(h==105?B[p>>>0]:ae[p++>>>1]),++p;return ct},Ot={},Wt=()=>{if(!_t){var l={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:u||\"./this.program\"},p;for(p in Ot)Ot[p]===void 0?delete l[p]:l[p]=Ot[p];var h=[];for(p in l)h.push(`${p}=${l[p]}`);_t=h}return _t},_t,cr=[null,[],[]],Ve=[31,29,31,30,31,30,31,31,30,31,30,31],zt=[31,28,31,30,31,30,31,31,30,31,30,31];function Vt(l){var p=Array(It(l)+1);return Dt(l,p,0,p.length),p}function ne(l,p,h,C){function T(E,te,fe){for(E=typeof E==\"number\"?E.toString():E||\"\";E.length<te;)E=fe[0]+E;return E}function U(E,te){return T(E,te,\"0\")}function G(E,te){function fe(Xt){return 0>Xt?-1:0<Xt?1:0}var ut;return(ut=fe(E.getFullYear()-te.getFullYear()))===0&&(ut=fe(E.getMonth()-te.getMonth()))===0&&(ut=fe(E.getDate()-te.getDate())),ut}function ue(E){switch(E.getDay()){case 0:return new Date(E.getFullYear()-1,11,29);case 1:return E;case 2:return new Date(E.getFullYear(),0,3);case 3:return new Date(E.getFullYear(),0,2);case 4:return new Date(E.getFullYear(),0,1);case 5:return new Date(E.getFullYear()-1,11,31);case 6:return new Date(E.getFullYear()-1,11,30)}}function Y(E){var te=E.Ba;for(E=new Date(new Date(E.Ca+1900,0,1).getTime());0<te;){var fe=E.getMonth(),ut=(at(E.getFullYear())?Ve:zt)[fe];if(te>ut-E.getDate())te-=ut-E.getDate()+1,E.setDate(1),11>fe?E.setMonth(fe+1):(E.setMonth(0),E.setFullYear(E.getFullYear()+1));else{E.setDate(E.getDate()+te);break}}return fe=new Date(E.getFullYear()+1,0,4),te=ue(new Date(E.getFullYear(),0,4)),fe=ue(fe),0>=G(te,E)?0>=G(fe,E)?E.getFullYear()+1:E.getFullYear():E.getFullYear()-1}l>>>=0,p>>>=0,h>>>=0,C>>>=0;var Q=B[C+40>>2>>>0];C={Wa:B[C>>2>>>0],Va:B[C+4>>2>>>0],Ea:B[C+8>>2>>>0],Ia:B[C+12>>2>>>0],Fa:B[C+16>>2>>>0],Ca:B[C+20>>2>>>0],wa:B[C+24>>2>>>0],Ba:B[C+28>>2>>>0],$a:B[C+32>>2>>>0],Ua:B[C+36>>2>>>0],Xa:Q?_e(Q):\"\"},h=_e(h),Q={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var J in Q)h=h.replace(new RegExp(J,\"g\"),Q[J]);var ce=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),me=\"January February March April May June July August September October November December\".split(\" \");Q={\"%a\":E=>ce[E.wa].substring(0,3),\"%A\":E=>ce[E.wa],\"%b\":E=>me[E.Fa].substring(0,3),\"%B\":E=>me[E.Fa],\"%C\":E=>U((E.Ca+1900)/100|0,2),\"%d\":E=>U(E.Ia,2),\"%e\":E=>T(E.Ia,2,\" \"),\"%g\":E=>Y(E).toString().substring(2),\"%G\":E=>Y(E),\"%H\":E=>U(E.Ea,2),\"%I\":E=>(E=E.Ea,E==0?E=12:12<E&&(E-=12),U(E,2)),\"%j\":E=>{for(var te=0,fe=0;fe<=E.Fa-1;te+=(at(E.Ca+1900)?Ve:zt)[fe++]);return U(E.Ia+te,3)},\"%m\":E=>U(E.Fa+1,2),\"%M\":E=>U(E.Va,2),\"%n\":()=>`\n`,\"%p\":E=>0<=E.Ea&&12>E.Ea?\"AM\":\"PM\",\"%S\":E=>U(E.Wa,2),\"%t\":()=>\"\t\",\"%u\":E=>E.wa||7,\"%U\":E=>U(Math.floor((E.Ba+7-E.wa)/7),2),\"%V\":E=>{var te=Math.floor((E.Ba+7-(E.wa+6)%7)/7);if(2>=(E.wa+371-E.Ba-2)%7&&te++,te)te==53&&(fe=(E.wa+371-E.Ba)%7,fe==4||fe==3&&at(E.Ca)||(te=1));else{te=52;var fe=(E.wa+7-E.Ba-1)%7;(fe==4||fe==5&&at(E.Ca%400-1))&&te++}return U(te,2)},\"%w\":E=>E.wa,\"%W\":E=>U(Math.floor((E.Ba+7-(E.wa+6)%7)/7),2),\"%y\":E=>(E.Ca+1900).toString().substring(2),\"%Y\":E=>E.Ca+1900,\"%z\":E=>{E=E.Ua;var te=0<=E;return E=Math.abs(E)/60,(te?\"+\":\"-\")+(\"0000\"+(E/60*100+E%60)).slice(-4)},\"%Z\":E=>E.Xa,\"%%\":()=>\"%\"},h=h.replace(/%%/g,\"\\0\\0\");for(J in Q)h.includes(J)&&(h=h.replace(new RegExp(J,\"g\"),Q[J](C)));return h=h.replace(/\\0\\0/g,\"%\"),J=Vt(h),J.length>p?0:(q.set(J,l>>>0),J.length-1)}function st(l){try{l()}catch(p){Le(p)}}function pr(l){var p={},h;for(h in l)(function(C){var T=l[C];p[C]=typeof T==\"function\"?function(){wt.push(C);try{return T.apply(null,arguments)}finally{z||(wt.pop()===C||Le(),He&&Je===1&&wt.length===0&&(Je=0,st(qt),typeof Fibers<\"u\"&&Fibers.ab()))}}:T})(h);return p}var Je=0,He=null,fr=0,wt=[],Gt={},Nt={},mr=0,vt=null,hr=[];function gr(){return new Promise((l,p)=>{vt={resolve:l,reject:p}})}function yr(){var l=Rt(65548),p=l+12;K[l>>2>>>0]=p,K[l+4>>2>>>0]=p+65536,p=wt[0];var h=Gt[p];return h===void 0&&(h=mr++,Gt[p]=h,Nt[h]=p),B[l+8>>2>>>0]=h,l}function br(l){if(!z){if(Je===0){var p=!1,h=!1;l((C=0)=>{if(!z&&(fr=C,p=!0,h)){Je=2,st(()=>Pt(He)),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.resume(),C=!1;try{var T=(0,_[Nt[B[He+8>>2>>>0]]])()}catch(ue){T=ue,C=!0}var U=!1;if(!He){var G=vt;G&&(vt=null,(C?G.reject:G.resolve)(T),U=!0)}if(C&&!U)throw T}}),h=!0,p||(Je=1,He=yr(),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.pause(),st(()=>Kt(He)))}else Je===2?(Je=0,st($t),Ut(He),He=null,hr.forEach(C=>{if(!z)try{if(C(),!M)try{F=F=C=F,M||(r.onExit&&r.onExit(C),z=!0),d(C,new Fe(C))}catch(T){T instanceof Fe||T==\"unwind\"||d(1,T)}}catch(T){T instanceof Fe||T==\"unwind\"||d(1,T)}})):Le(`invalid state: ${Je}`);return fr}}function wr(l){return br(p=>{l().then(p)})}var vr={n:function(l,p,h){return wr(async()=>{await r.Pa(l,p,h)})},a:function(l,p,h){throw l>>>=0,new bt(l).Ya(p>>>0,h>>>0),Bt=l,lr++,Bt},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(l,p,h){l=p+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*p:NaN,h>>>=0,l=new Date(1e3*l),B[h>>2>>>0]=l.getUTCSeconds(),B[h+4>>2>>>0]=l.getUTCMinutes(),B[h+8>>2>>>0]=l.getUTCHours(),B[h+12>>2>>>0]=l.getUTCDate(),B[h+16>>2>>>0]=l.getUTCMonth(),B[h+20>>2>>>0]=l.getUTCFullYear()-1900,B[h+24>>2>>>0]=l.getUTCDay(),B[h+28>>2>>>0]=(l.getTime()-Date.UTC(l.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},r:function(l,p,h){l=p+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*p:NaN,h>>>=0,l=new Date(1e3*l),B[h>>2>>>0]=l.getSeconds(),B[h+4>>2>>>0]=l.getMinutes(),B[h+8>>2>>>0]=l.getHours(),B[h+12>>2>>>0]=l.getDate(),B[h+16>>2>>>0]=l.getMonth(),B[h+20>>2>>>0]=l.getFullYear()-1900,B[h+24>>2>>>0]=l.getDay(),B[h+28>>2>>>0]=(at(l.getFullYear())?dr:it)[l.getMonth()]+l.getDate()-1|0,B[h+36>>2>>>0]=-(60*l.getTimezoneOffset()),p=new Date(l.getFullYear(),6,1).getTimezoneOffset();var C=new Date(l.getFullYear(),0,1).getTimezoneOffset();B[h+32>>2>>>0]=(p!=C&&l.getTimezoneOffset()==Math.min(C,p))|0},s:function(l){l>>>=0;var p=new Date(B[l+20>>2>>>0]+1900,B[l+16>>2>>>0],B[l+12>>2>>>0],B[l+8>>2>>>0],B[l+4>>2>>>0],B[l>>2>>>0],0),h=B[l+32>>2>>>0],C=p.getTimezoneOffset(),T=new Date(p.getFullYear(),6,1).getTimezoneOffset(),U=new Date(p.getFullYear(),0,1).getTimezoneOffset(),G=Math.min(U,T);return 0>h?B[l+32>>2>>>0]=+(T!=U&&G==C):0<h!=(G==C)&&(T=Math.max(U,T),p.setTime(p.getTime()+6e4*((0<h?G:T)-C))),B[l+24>>2>>>0]=p.getDay(),B[l+28>>2>>>0]=(at(p.getFullYear())?dr:it)[p.getMonth()]+p.getDate()-1|0,B[l>>2>>>0]=p.getSeconds(),B[l+4>>2>>>0]=p.getMinutes(),B[l+8>>2>>>0]=p.getHours(),B[l+12>>2>>>0]=p.getDate(),B[l+16>>2>>>0]=p.getMonth(),B[l+20>>2>>>0]=p.getYear(),l=p.getTime()/1e3,Lt((Ge=l,1<=+Math.abs(Ge)?0<Ge?+Math.floor(Ge/4294967296)>>>0:~~+Math.ceil((Ge-+(~~Ge>>>0))/4294967296)>>>0:0)),l>>>0},o:function(){return-52},p:function(){},v:function(l,p,h){function C(Y){return(Y=Y.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?Y[1]:\"GMT\"}h>>>=0;var T=new Date().getFullYear(),U=new Date(T,0,1),G=new Date(T,6,1);T=U.getTimezoneOffset();var ue=G.getTimezoneOffset();K[l>>>0>>2>>>0]=60*Math.max(T,ue),B[p>>>0>>2>>>0]=+(T!=ue),l=C(U),p=C(G),l=Et(l),p=Et(p),ue<T?(K[h>>2>>>0]=l,K[h+4>>2>>>0]=p):(K[h>>2>>>0]=p,K[h+4>>2>>>0]=l)},e:()=>{Le(\"\")},b:function(l,p,h){return l>>>=0,p=Tt(p>>>0,h>>>0),Xe[l].apply(null,p)},i:function(l,p,h){return l>>>=0,p=Tt(p>>>0,h>>>0),Xe[l].apply(null,p)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(l,p,h){return p>>>=0,le.copyWithin(l>>>0>>>0,p>>>0,p+(h>>>0)>>>0)},u:function(l){l>>>=0;var p=le.length;if(4294901760<l)return!1;for(var h=1;4>=h;h*=2){var C=p*(1+.2/h);C=Math.min(C,l+100663296);var T=Math;C=Math.max(l,C);e:{T=T.min.call(T,4294901760,C+(65536-C%65536)%65536)-D.buffer.byteLength+65535>>>16;try{D.grow(T),we();var U=1;break e}catch{}U=void 0}if(U)return!0}return!1},D:function(l,p){l>>>=0,p>>>=0;var h=0;return Wt().forEach(function(C,T){var U=p+h;for(T=K[l+4*T>>2>>>0]=U,U=0;U<C.length;++U)q[T++>>0>>>0]=C.charCodeAt(U);q[T>>0>>>0]=0,h+=C.length+1}),0},E:function(l,p){l>>>=0,p>>>=0;var h=Wt();K[l>>2>>>0]=h.length;var C=0;return h.forEach(function(T){C+=T.length+1}),K[p>>2>>>0]=C,0},f:()=>52,k:function(){return 52},t:function(){return 70},j:function(l,p,h,C){p>>>=0,h>>>=0,C>>>=0;for(var T=0,U=0;U<h;U++){var G=K[p>>2>>>0],ue=K[p+4>>2>>>0];p+=8;for(var Y=0;Y<ue;Y++){var Q=le[G+Y>>>0],J=cr[l];Q===0||Q===10?((l===1?A:R)(kt(J,0)),J.length=0):J.push(Q)}T+=ue}return K[C>>2>>>0]=T,0},F:ne,d:function(l,p,h,C){return ne(l>>>0,p>>>0,h>>>0,C>>>0)}};(function(){function l(h){if(h=h.exports,h=pr(h),_=h=pt(h),D=_.M,we(),Se.unshift(_.N),Ce--,r.monitorRunDependencies&&r.monitorRunDependencies(Ce),Ce==0&&(dt!==null&&(clearInterval(dt),dt=null),Ne)){var C=Ne;Ne=null,C()}return h}var p={a:vr};if(Ce++,r.monitorRunDependencies&&r.monitorRunDependencies(Ce),r.instantiateWasm)try{return r.instantiateWasm(p,l)}catch(h){R(\"Module.instantiateWasm callback failed with error: \"+h),n(h)}return ke(p,function(h){l(h.instance)}).catch(n),{}})(),r._OrtInit=(l,p)=>(r._OrtInit=_.O)(l,p),r._OrtGetLastError=(l,p)=>(r._OrtGetLastError=_.P)(l,p),r._OrtCreateSessionOptions=(l,p,h,C,T,U,G,ue,Y,Q)=>(r._OrtCreateSessionOptions=_.Q)(l,p,h,C,T,U,G,ue,Y,Q),r._OrtAppendExecutionProvider=(l,p)=>(r._OrtAppendExecutionProvider=_.R)(l,p),r._OrtAddFreeDimensionOverride=(l,p,h)=>(r._OrtAddFreeDimensionOverride=_.S)(l,p,h),r._OrtAddSessionConfigEntry=(l,p,h)=>(r._OrtAddSessionConfigEntry=_.T)(l,p,h),r._OrtReleaseSessionOptions=l=>(r._OrtReleaseSessionOptions=_.U)(l),r._OrtCreateSession=(l,p,h)=>(r._OrtCreateSession=_.V)(l,p,h),r._OrtReleaseSession=l=>(r._OrtReleaseSession=_.W)(l),r._OrtGetInputOutputCount=(l,p,h)=>(r._OrtGetInputOutputCount=_.X)(l,p,h),r._OrtGetInputName=(l,p)=>(r._OrtGetInputName=_.Y)(l,p),r._OrtGetOutputName=(l,p)=>(r._OrtGetOutputName=_.Z)(l,p),r._OrtFree=l=>(r._OrtFree=_._)(l),r._OrtCreateTensor=(l,p,h,C,T,U)=>(r._OrtCreateTensor=_.$)(l,p,h,C,T,U),r._OrtGetTensorData=(l,p,h,C,T)=>(r._OrtGetTensorData=_.aa)(l,p,h,C,T),r._OrtReleaseTensor=l=>(r._OrtReleaseTensor=_.ba)(l),r._OrtCreateRunOptions=(l,p,h,C)=>(r._OrtCreateRunOptions=_.ca)(l,p,h,C),r._OrtAddRunConfigEntry=(l,p,h)=>(r._OrtAddRunConfigEntry=_.da)(l,p,h),r._OrtReleaseRunOptions=l=>(r._OrtReleaseRunOptions=_.ea)(l),r._OrtCreateBinding=l=>(r._OrtCreateBinding=_.fa)(l),r._OrtBindInput=(l,p,h)=>(r._OrtBindInput=_.ga)(l,p,h),r._OrtBindOutput=(l,p,h,C)=>(r._OrtBindOutput=_.ha)(l,p,h,C),r._OrtClearBoundOutputs=l=>(r._OrtClearBoundOutputs=_.ia)(l),r._OrtReleaseBinding=l=>(r._OrtReleaseBinding=_.ja)(l),r._OrtRunWithBinding=(l,p,h,C,T)=>(r._OrtRunWithBinding=_.ka)(l,p,h,C,T),r._OrtRun=(l,p,h,C,T,U,G,ue)=>(r._OrtRun=_.la)(l,p,h,C,T,U,G,ue),r._OrtEndProfiling=l=>(r._OrtEndProfiling=_.ma)(l),r._JsepOutput=(l,p,h)=>(r._JsepOutput=_.na)(l,p,h),r._JsepGetNodeName=l=>(r._JsepGetNodeName=_.oa)(l);var Rt=r._malloc=l=>(Rt=r._malloc=_.pa)(l),Ut=r._free=l=>(Ut=r._free=_.qa)(l),Lt=l=>(Lt=_.sa)(l),Ft=()=>(Ft=_.ta)(),Ht=l=>(Ht=_.ua)(l),jt=l=>(jt=_.va)(l),Kt=l=>(Kt=_.xa)(l),qt=()=>(qt=_.ya)(),Pt=l=>(Pt=_.za)(l),$t=()=>($t=_.Aa)();r.___start_em_js=924587,r.___stop_em_js=924748;function pt(l){l=Object.assign({},l);var p=C=>()=>C()>>>0,h=C=>T=>C(T)>>>0;return l.__errno_location=p(l.__errno_location),l.malloc=h(l.malloc),l.stackSave=p(l.stackSave),l.stackAlloc=h(l.stackAlloc),l}r.stackAlloc=jt,r.stackSave=Ft,r.stackRestore=Ht,r.UTF8ToString=_e,r.stringToUTF8=(l,p,h)=>Dt(l,le,p,h),r.lengthBytesUTF8=It;var xt;Ne=function l(){xt||Yt(),xt||(Ne=l)};function Yt(){function l(){if(!xt&&(xt=!0,r.calledRun=!0,!z)){if(yt(Se),o(r),r.onRuntimeInitialized&&r.onRuntimeInitialized(),r.postRun)for(typeof r.postRun==\"function\"&&(r.postRun=[r.postRun]);r.postRun.length;){var p=r.postRun.shift();Oe.unshift(p)}yt(Oe)}}if(!(0<Ce)){if(r.preRun)for(typeof r.preRun==\"function\"&&(r.preRun=[r.preRun]);r.preRun.length;)Ie();yt(j),0<Ce||(r.setStatus?(r.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){r.setStatus(\"\")},1),l()},1)):l())}}if(r.preInit)for(typeof r.preInit==\"function\"&&(r.preInit=[r.preInit]);0<r.preInit.length;)r.preInit.pop()();return Yt(),t.ready}})();typeof so==\"object\"&&typeof dn==\"object\"?dn.exports=io:typeof define==\"function\"&&define.amd&&define([],()=>io)});var lo=Jt(()=>{});var co=Jt(()=>{});var po={};Ir(po,{cpus:()=>Ou});var Ou,fo=H(()=>{Ou=void 0});var go=Jt((ho,cn)=>{\"use strict\";var mo=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){function r(){return we.buffer!=Ce.buffer&&pe(),Ce}function o(){return we.buffer!=Ce.buffer&&pe(),dt}function n(){return we.buffer!=Ce.buffer&&pe(),Ne}function s(){return we.buffer!=Ce.buffer&&pe(),Le}function u(){return we.buffer!=Ce.buffer&&pe(),N}function d(){return we.buffer!=Ce.buffer&&pe(),de}var a=t,m,g;a.ready=new Promise((i,c)=>{m=i,g=c}),a.jsepInit=(i,c,f,$,I,P,V,oe)=>{a.Qb=i,a.wb=c,a.yb=f,a.jb=$,a.xb=I,a.Ea=P,a.zb=V,a.Ab=oe,c=(ee,Z,re)=>(...he)=>{let be=Ze,O=Z?.();he=ee(...he);let se=Z?.();return O!==se&&(ee=se,re(O),Z=re=null),Ze!=be?hu():he},f=ee=>async(...Z)=>{try{if(a.bb)throw Error(\"Session already started\");let re=a.bb={Fb:Z[0],errors:[]},he=await ee(...Z);if(a.bb!==re)throw Error(\"Session mismatch\");i.flush();let be=re.errors;if(0<be.length){let O=await Promise.all(be);if(O=O.filter(se=>se),0<O.length)throw Error(O.join(`\n`))}return he}finally{a.bb=null}},a._OrtRun=f(c(a._OrtRun,()=>a._OrtRun,ee=>a._OrtRun=ee)),a._OrtRunWithBinding=f(c(a._OrtRunWithBinding,()=>a._OrtRunWithBinding,ee=>a._OrtRunWithBinding=ee)),a._OrtBindInput=c(a._OrtBindInput,()=>a._OrtBindInput,ee=>a._OrtBindInput=ee),a.jsepRegisterBuffer=(ee,Z,re,he)=>i.registerBuffer(ee,Z,re,he),a.jsepUnregisterBuffers=ee=>{i.unregisterBuffers(ee)},a.jsepGetBuffer=ee=>i.getBuffer(ee),a.jsepCreateDownloader=(ee,Z,re)=>i.createDownloader(ee,Z,re)};var x=Object.assign({},a),b=\"./this.program\",w=(i,c)=>{throw c},v=typeof window==\"object\",y=typeof importScripts==\"function\",S=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",A=a.ENVIRONMENT_IS_PTHREAD||!1,R=\"\";function W(i){return a.locateFile?a.locateFile(i,R):R+i}var M,D,_;if(S){var z=(sn(),Mt(an)),F=(ln(),Mt(un));R=y?F.dirname(R)+\"/\":__dirname+\"/\",M=(c,f)=>(c=c.startsWith(\"file://\")?new URL(c):F.normalize(c),z.readFileSync(c,f?void 0:\"utf8\")),_=c=>(c=M(c,!0),c.buffer||(c=new Uint8Array(c)),c),D=(c,f,$,I=!0)=>{c=c.startsWith(\"file://\")?new URL(c):F.normalize(c),z.readFile(c,I?void 0:\"utf8\",(P,V)=>{P?$(P):f(I?V.buffer:V)})},!a.thisProgram&&1<process.argv.length&&(b=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),w=(c,f)=>{throw process.exitCode=c,f},a.inspect=()=>\"[Emscripten Module object]\";let i;try{i=lo()}catch(c){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),c}global.Worker=i.Worker}else(v||y)&&(y?R=self.location.href:typeof document<\"u\"&&document.currentScript&&(R=document.currentScript.src),typeof e<\"u\"&&e&&(R=e),R.indexOf(\"blob:\")!==0?R=R.substr(0,R.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):R=\"\",S||(M=i=>{var c=new XMLHttpRequest;return c.open(\"GET\",i,!1),c.send(null),c.responseText},y&&(_=i=>{var c=new XMLHttpRequest;return c.open(\"GET\",i,!1),c.responseType=\"arraybuffer\",c.send(null),new Uint8Array(c.response)}),D=(i,c,f)=>{var $=new XMLHttpRequest;$.open(\"GET\",i,!0),$.responseType=\"arraybuffer\",$.onload=()=>{$.status==200||$.status==0&&$.response?c($.response):f()},$.onerror=f,$.send(null)}));S&&typeof performance>\"u\"&&(global.performance=co().performance);var q=console.log.bind(console),le=console.error.bind(console);S&&(q=(...i)=>z.writeSync(1,i.join(\" \")+`\n`),le=(...i)=>z.writeSync(2,i.join(\" \")+`\n`));var B=a.print||q,K=a.printErr||le;Object.assign(a,x),x=null,a.thisProgram&&(b=a.thisProgram),a.quit&&(w=a.quit);var xe;a.wasmBinary&&(xe=a.wasmBinary);var ae=a.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&Ke(\"no native wasm support detected\");var we,j,Se,Oe=!1,Ie,Ce,dt,Ne,Le,N,de;function pe(){var i=we.buffer;a.HEAP8=Ce=new Int8Array(i),a.HEAP16=new Int16Array(i),a.HEAP32=Ne=new Int32Array(i),a.HEAPU8=dt=new Uint8Array(i),a.HEAPU16=new Uint16Array(i),a.HEAPU32=Le=new Uint32Array(i),a.HEAPF32=N=new Float32Array(i),a.HEAPF64=de=new Float64Array(i)}var ze=a.INITIAL_MEMORY||16777216;if(5242880<=ze||Ke(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+ze+\"! (STACK_SIZE=5242880)\"),A)we=a.wasmMemory;else if(a.wasmMemory)we=a.wasmMemory;else if(we=new WebAssembly.Memory({initial:ze/65536,maximum:65536,shared:!0}),!(we.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),S&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");pe(),ze=we.buffer.byteLength;var Ue=[],Te=[],ke=[],Ge=0;function Xe(){return ae||0<Ge}var Fe=0,yt=null,bt=null;function Bt(){Fe++,a.monitorRunDependencies&&a.monitorRunDependencies(Fe)}function lr(){if(Fe--,a.monitorRunDependencies&&a.monitorRunDependencies(Fe),Fe==0&&(yt!==null&&(clearInterval(yt),yt=null),bt)){var i=bt;bt=null,i()}}function Ke(i){throw a.onAbort&&a.onAbort(i),i=\"Aborted(\"+i+\")\",K(i),Oe=!0,Ie=1,i=new WebAssembly.RuntimeError(i+\". Build with -sASSERTIONS for more info.\"),g(i),i}function kt(i){return i.startsWith(\"data:application/octet-stream;base64,\")}var _e;_e=\"ort-wasm-simd-threaded.wasm\",kt(_e)||(_e=W(_e));function It(i){if(i==_e&&xe)return new Uint8Array(xe);if(_)return _(i);throw\"both async and sync fetching of the wasm failed\"}function Dt(i){if(!xe&&(v||y)){if(typeof fetch==\"function\"&&!i.startsWith(\"file://\"))return fetch(i,{credentials:\"same-origin\"}).then(c=>{if(!c.ok)throw\"failed to load wasm binary file at '\"+i+\"'\";return c.arrayBuffer()}).catch(()=>It(i));if(D)return new Promise((c,f)=>{D(i,$=>c(new Uint8Array($)),f)})}return Promise.resolve().then(()=>It(i))}function at(i,c,f){return Dt(i).then($=>WebAssembly.instantiate($,c)).then($=>$).then(f,$=>{K(\"failed to asynchronously prepare wasm: \"+$),Ke($)})}function dr(i,c){var f=_e;return xe||typeof WebAssembly.instantiateStreaming!=\"function\"||kt(f)||f.startsWith(\"file://\")||S||typeof fetch!=\"function\"?at(f,i,c):fetch(f,{credentials:\"same-origin\"}).then($=>WebAssembly.instantiateStreaming($,i).then(c,function(I){return K(\"wasm streaming compile failed: \"+I),K(\"falling back to ArrayBuffer instantiation\"),at(f,i,c)}))}var it,Et={914988:i=>{a.Ea(\"Abs\",i,void 0)},915039:i=>{a.Ea(\"Neg\",i,void 0)},915090:i=>{a.Ea(\"Floor\",i,void 0)},915143:i=>{a.Ea(\"Ceil\",i,void 0)},915195:i=>{a.Ea(\"Reciprocal\",i,void 0)},915253:i=>{a.Ea(\"Sqrt\",i,void 0)},915305:i=>{a.Ea(\"Exp\",i,void 0)},915356:i=>{a.Ea(\"Erf\",i,void 0)},915407:i=>{a.Ea(\"Sigmoid\",i,void 0)},915462:i=>{a.Ea(\"Log\",i,void 0)},915513:i=>{a.Ea(\"Sin\",i,void 0)},915564:i=>{a.Ea(\"Cos\",i,void 0)},915615:i=>{a.Ea(\"Tan\",i,void 0)},915666:i=>{a.Ea(\"Asin\",i,void 0)},915718:i=>{a.Ea(\"Acos\",i,void 0)},915770:i=>{a.Ea(\"Atan\",i,void 0)},915822:i=>{a.Ea(\"Sinh\",i,void 0)},915874:i=>{a.Ea(\"Cosh\",i,void 0)},915926:i=>{a.Ea(\"Asinh\",i,void 0)},915979:i=>{a.Ea(\"Acosh\",i,void 0)},916032:i=>{a.Ea(\"Atanh\",i,void 0)},916085:i=>{a.Ea(\"Tanh\",i,void 0)},916137:i=>{a.Ea(\"Not\",i,void 0)},916188:(i,c,f)=>{a.Ea(\"ClipV10\",i,{min:c,max:f})},916260:i=>{a.Ea(\"Clip\",i,void 0)},916312:(i,c)=>{a.Ea(\"Elu\",i,{alpha:c})},916370:i=>{a.Ea(\"Relu\",i,void 0)},916422:(i,c)=>{a.Ea(\"LeakyRelu\",i,{alpha:c})},916486:(i,c)=>{a.Ea(\"ThresholdedRelu\",i,{alpha:c})},916556:(i,c)=>{a.Ea(\"Cast\",i,{to:c})},916614:i=>{a.Ea(\"Add\",i,void 0)},916665:i=>{a.Ea(\"Sub\",i,void 0)},916716:i=>{a.Ea(\"Mul\",i,void 0)},916767:i=>{a.Ea(\"Div\",i,void 0)},916818:i=>{a.Ea(\"Pow\",i,void 0)},916869:i=>{a.Ea(\"Equal\",i,void 0)},916922:i=>{a.Ea(\"Greater\",i,void 0)},916977:i=>{a.Ea(\"GreaterOrEqual\",i,void 0)},917039:i=>{a.Ea(\"Less\",i,void 0)},917091:i=>{a.Ea(\"LessOrEqual\",i,void 0)},917150:(i,c,f,$,I)=>{a.Ea(\"ReduceMean\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},917314:(i,c,f,$,I)=>{a.Ea(\"ReduceMax\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},917477:(i,c,f,$,I)=>{a.Ea(\"ReduceMin\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},917640:(i,c,f,$,I)=>{a.Ea(\"ReduceProd\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},917804:(i,c,f,$,I)=>{a.Ea(\"ReduceSum\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},917967:(i,c,f,$,I)=>{a.Ea(\"ReduceL1\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},918129:(i,c,f,$,I)=>{a.Ea(\"ReduceL2\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},918291:(i,c,f,$,I)=>{a.Ea(\"ReduceLogSum\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},918457:(i,c,f,$,I)=>{a.Ea(\"ReduceSumSquare\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},918626:(i,c,f,$,I)=>{a.Ea(\"ReduceLogSumExp\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},918795:i=>{a.Ea(\"Where\",i,void 0)},918848:(i,c,f)=>{a.Ea(\"Transpose\",i,{perm:c?Array.from(n().subarray(f>>>0,f+c>>>0)):[]})},918961:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se)=>{a.Ea(\"ConvTranspose\",i,{format:ee?\"NHWC\":\"NCHW\",autoPad:c,dilations:[f],group:$,kernel_shape:[I],pads:[P,V],strides:[oe],wIsConst:()=>!!r()[Z>>>0],outputPadding:re?Array.from(n().subarray(he>>>0,he+re>>>0)):[],outputShape:be?Array.from(n().subarray(O>>>0,O+be>>>0)):[],activation:Ve(se)})},919375:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O)=>{a.Ea(\"ConvTranspose\",i,{format:oe?\"NHWC\":\"NCHW\",autoPad:c,dilations:Array.from(n().subarray(f>>>0,f+2>>>0)),group:$,kernelShape:Array.from(n().subarray(I>>>0,I+2>>>0)),pads:Array.from(n().subarray(P>>>0,P+4>>>0)),strides:Array.from(n().subarray(V>>>0,V+2>>>0)),wIsConst:()=>!!r()[ee>>>0],outputPadding:0<Z?Array.from(n().subarray(re>>>0,re+Z>>>0)):[],outputShape:0<he?Array.from(n().subarray(be>>>0,be+he>>>0)):[],activation:Ve(O)})},919932:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se)=>{a.Ea(\"ConvTranspose\",i,{format:ee?\"NHWC\":\"NCHW\",autoPad:c,dilations:[f],group:$,kernel_shape:[I],pads:[P,V],strides:[oe],wIsConst:()=>!!r()[Z>>>0],outputPadding:re?Array.from(n().subarray(he>>>0,he+re>>>0)):[],outputShape:be?Array.from(n().subarray(O>>>0,O+be>>>0)):[],activation:Ve(se)})},920346:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O)=>{a.Ea(\"ConvTranspose\",i,{format:oe?\"NHWC\":\"NCHW\",autoPad:c,dilations:Array.from(n().subarray(f>>>0,f+2>>>0)),group:$,kernelShape:Array.from(n().subarray(I>>>0,I+2>>>0)),pads:Array.from(n().subarray(P>>>0,P+4>>>0)),strides:Array.from(n().subarray(V>>>0,V+2>>>0)),wIsConst:()=>!!r()[ee>>>0],outputPadding:0<Z?Array.from(n().subarray(re>>>0,re+Z>>>0)):[],outputShape:0<he?Array.from(n().subarray(be>>>0,be+he>>>0)):[],activation:Ve(O)})},920903:(i,c)=>{a.Ea(\"GlobalAveragePool\",i,{format:c?\"NHWC\":\"NCHW\"})},920994:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se,ye)=>{a.Ea(\"AveragePool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:I,dilations:[P,V],kernel_shape:[oe,ee],pads:[Z,re,he,be],strides:[O,se]})},921278:(i,c)=>{a.Ea(\"GlobalAveragePool\",i,{format:c?\"NHWC\":\"NCHW\"})},921369:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se,ye)=>{a.Ea(\"AveragePool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:I,dilations:[P,V],kernel_shape:[oe,ee],pads:[Z,re,he,be],strides:[O,se]})},921653:(i,c)=>{a.Ea(\"GlobalMaxPool\",i,{format:c?\"NHWC\":\"NCHW\"})},921740:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se,ye)=>{a.Ea(\"MaxPool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:I,dilations:[P,V],kernel_shape:[oe,ee],pads:[Z,re,he,be],strides:[O,se]})},922020:(i,c)=>{a.Ea(\"GlobalMaxPool\",i,{format:c?\"NHWC\":\"NCHW\"})},922107:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se,ye)=>{a.Ea(\"MaxPool\",i,{format:ye?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:I,dilations:[P,V],kernel_shape:[oe,ee],pads:[Z,re,he,be],strides:[O,se]})},922387:(i,c,f,$,I)=>{a.Ea(\"Gemm\",i,{alpha:c,beta:f,transA:$,transB:I})},922491:i=>{a.Ea(\"MatMul\",i,void 0)},922545:(i,c,f,$)=>{a.Ea(\"ArgMax\",i,{keepDims:!!c,selectLastIndex:!!f,axis:$})},922653:(i,c,f,$)=>{a.Ea(\"ArgMin\",i,{keepDims:!!c,selectLastIndex:!!f,axis:$})},922761:(i,c)=>{a.Ea(\"Softmax\",i,{axis:c})},922824:(i,c)=>{a.Ea(\"Concat\",i,{axis:c})},922884:(i,c,f,$,I)=>{a.Ea(\"Split\",i,{axis:c,numOutputs:f,splitSizes:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},923029:i=>{a.Ea(\"Expand\",i,void 0)},923083:(i,c)=>{a.Ea(\"Gather\",i,{axis:Number(c)})},923154:(i,c)=>{a.Ea(\"GatherElements\",i,{axis:Number(c)})},923233:(i,c,f,$,I,P,V,oe,ee,Z,re)=>{a.Ea(\"Resize\",i,{antialias:c,axes:f?Array.from(n().subarray($>>>0,$+f>>>0)):[],coordinateTransformMode:Ve(I),cubicCoeffA:P,excludeOutside:V,extrapolationValue:oe,keepAspectRatioPolicy:Ve(ee),mode:Ve(Z),nearestMode:Ve(re)})},923584:(i,c,f,$,I,P,V)=>{a.Ea(\"Slice\",i,{starts:c?Array.from(n().subarray(f>>>0,f+c>>>0)):[],ends:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[],axes:P?Array.from(n().subarray(V>>>0,V+P>>>0)):[]})},923815:i=>{a.Ea(\"Tile\",i,void 0)},923867:(i,c,f)=>{a.Ea(\"LayerNormalization\",i,{axis:Number(c),epsilon:Number(f)})},923974:(i,c,f)=>{a.Ea(\"InstanceNormalization\",i,{epsilon:c,format:f?\"NHWC\":\"NCHW\"})},924088:(i,c,f)=>{a.Ea(\"InstanceNormalization\",i,{epsilon:c,format:f?\"NHWC\":\"NCHW\"})},924202:i=>{a.Ea(\"Range\",i,void 0)},924255:(i,c)=>{a.Ea(\"Einsum\",i,{equation:Ve(c)})},924336:(i,c,f,$,I)=>{a.Ea(\"Pad\",i,{mode:c,value:f,pads:$?Array.from(n().subarray(I>>>0,I+$>>>0)):[]})},924468:i=>{a.Ea(\"Gelu\",i,void 0)},924520:i=>{a.Ea(\"BiasAdd\",i,void 0)},924575:i=>{a.Ea(\"BiasSplitGelu\",i,void 0)},924636:(i,c)=>{a.Ea(\"SkipLayerNormalization\",i,{epsilon:c})},924717:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be)=>{a.Ea(\"Conv\",i,{format:ee?\"NHWC\":\"NCHW\",auto_pad:c,dilations:[f],group:$,kernel_shape:[I],pads:P?Array.from(n().subarray(V>>>0,V+P>>>0)):[],strides:[oe],w_is_const:()=>!!r()[Z>>>0],activation:Ve(re),activation_params:he?Array.from(u().subarray(be>>>0,be+he>>>0)):[]})},925098:(i,c,f,$,I,P,V,oe,ee,Z,re,he,be,O,se,ye)=>{a.Ea(\"Conv\",i,{format:he?\"NHWC\":\"NCHW\",auto_pad:c,dilations:[f,$],group:I,kernel_shape:[P,V],pads:oe?Array.from(n().subarray(ee>>>0,ee+oe>>>0)):[],strides:[Z,re],w_is_const:()=>!!r()[be>>>0],activation:Ve(O),activation_params:se?Array.from(u().subarray(ye>>>0,ye+se>>>0)):[]})},925500:i=>{a.zb(i)},925534:(i,c)=>a.Ab(i,c,a.bb.Fb,a.bb.errors),925646:i=>a.wb(i),925679:i=>a.yb(i),925711:(i,c,f)=>{a.jb(i,c,f,!0)},925750:(i,c,f)=>{a.jb(i,c,f)}};function ct(i){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${i})`,this.status=i}function Tt(i){i.terminate(),i.onmessage=()=>{}}function Ot(i){(i=ne.Qa[i])||Ke(),ne.Eb(i)}function Wt(i){var c=ne.tb();if(!c)return 6;ne.Ya.push(c),ne.Qa[i.Xa]=c,c.Xa=i.Xa;var f={cmd:\"run\",start_routine:i.Gb,arg:i.rb,pthread_ptr:i.Xa};return S&&c.unref(),c.postMessage(f,i.Mb),0}var _t=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,cr=(i,c,f)=>{c>>>=0;var $=c+f;for(f=c;i[f]&&!(f>=$);)++f;if(16<f-c&&i.buffer&&_t)return _t.decode(i.buffer instanceof SharedArrayBuffer?i.slice(c,f):i.subarray(c,f));for($=\"\";c<f;){var I=i[c++];if(I&128){var P=i[c++]&63;if((I&224)==192)$+=String.fromCharCode((I&31)<<6|P);else{var V=i[c++]&63;I=(I&240)==224?(I&15)<<12|P<<6|V:(I&7)<<18|P<<12|V<<6|i[c++]&63,65536>I?$+=String.fromCharCode(I):(I-=65536,$+=String.fromCharCode(55296|I>>10,56320|I&1023))}}else $+=String.fromCharCode(I)}return $},Ve=(i,c)=>(i>>>=0)?cr(o(),i,c):\"\";function zt(i){if(A)return G(1,1,i);Ie=i,Xe()||(ne.Hb(),a.onExit&&a.onExit(i),Oe=!0),w(i,new ct(i))}var Vt=i=>{if(Ie=i,A)throw pr(i),\"unwind\";zt(i)},ne={ab:[],Ya:[],mb:[],Qa:{},gb:function(){A?ne.vb():ne.ub()},ub:function(){Ue.unshift(()=>{Bt(),ne.Bb(()=>lr())})},vb:function(){ne.receiveObjectTransfer=ne.Db,ne.threadInitTLS=ne.lb,ne.setExitStatus=ne.kb,ae=!1},kb:function(i){Ie=i},Sb:[\"$terminateWorker\"],Hb:function(){for(var i of ne.Ya)Tt(i);for(i of ne.ab)Tt(i);ne.ab=[],ne.Ya=[],ne.Qa=[]},Eb:function(i){var c=i.Xa;delete ne.Qa[c],ne.ab.push(i),ne.Ya.splice(ne.Ya.indexOf(i),1),i.Xa=0,en(c)},Db:function(){},lb:function(){ne.mb.forEach(i=>i())},Cb:i=>new Promise(c=>{i.onmessage=P=>{P=P.data;var V=P.cmd;if(P.targetThread&&P.targetThread!=Sr()){var oe=ne.Qa[P.Rb];oe?oe.postMessage(P,P.transferList):K('Internal error! Worker sent a message \"'+V+'\" to target pthread '+P.targetThread+\", but that thread no longer exists!\")}else V===\"checkMailbox\"?$t():V===\"spawnThread\"?Wt(P):V===\"cleanupThread\"?Ot(P.thread):V===\"killThread\"?(P=P.thread,V=ne.Qa[P],delete ne.Qa[P],Tt(V),en(P),ne.Ya.splice(ne.Ya.indexOf(V),1),V.Xa=0):V===\"cancelThread\"?ne.Qa[P.thread].postMessage({cmd:\"cancel\"}):V===\"loaded\"?(i.loaded=!0,c(i)):V===\"alert\"?alert(\"Thread \"+P.threadId+\": \"+P.text):P.target===\"setimmediate\"?i.postMessage(P):V===\"callHandler\"?a[P.handler](...P.args):V&&K(\"worker sent an unknown command \"+V)},i.onerror=P=>{throw K(\"worker sent an error! \"+P.filename+\":\"+P.lineno+\": \"+P.message),P},S&&(i.on(\"message\",function(P){i.onmessage({data:P})}),i.on(\"error\",function(P){i.onerror(P)}));var f=[],$=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],I;for(I of $)a.hasOwnProperty(I)&&f.push(I);i.postMessage({cmd:\"load\",handlers:f,urlOrBlob:a.mainScriptUrlOrBlob||e,wasmMemory:we,wasmModule:Se})}),Bb:function(i){i()},qb:function(){var i=W(\"ort-wasm-simd-threaded.worker.js\");i=new Worker(i),ne.ab.push(i)},tb:function(){return ne.ab.length==0&&(ne.qb(),ne.Cb(ne.ab[0])),ne.ab.pop()}};a.PThread=ne;var st=i=>{for(;0<i.length;)i.shift()(a)};a.establishStackSpace=function(){var i=Sr(),c=n()[i+52>>2>>>0];i=n()[i+56>>2>>>0],Zn(c,c-i),Cr(c)};function pr(i){if(A)return G(2,0,i);Vt(i)}a.invokeEntryPoint=function(i,c){i=Qn.apply(null,[i,c]),Xe()?ne.kb(i):tn(i)};function Je(i){this.fb=i-24,this.pb=function(c){s()[this.fb+4>>2>>>0]=c},this.ob=function(c){s()[this.fb+8>>2>>>0]=c},this.gb=function(c,f){this.nb(),this.pb(c),this.ob(f)},this.nb=function(){s()[this.fb+16>>2>>>0]=0}}var He=0,fr=0;function wt(i,c,f,$){return A?G(3,1,i,c,f,$):Gt(i,c,f,$)}function Gt(i,c,f,$){if(i>>>=0,c>>>=0,f>>>=0,$>>>=0,typeof SharedArrayBuffer>\"u\")return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var I=[];return A&&I.length===0?wt(i,c,f,$):(i={Gb:f,Xa:i,rb:$,Mb:I},A?(i.Ob=\"spawnThread\",postMessage(i,I),0):Wt(i))}function Nt(i,c,f){return A?G(4,1,i,c,f):0}function mr(i,c){if(A)return G(5,1,i,c)}var vt=i=>{for(var c=0,f=0;f<i.length;++f){var $=i.charCodeAt(f);127>=$?c++:2047>=$?c+=2:55296<=$&&57343>=$?(c+=4,++f):c+=3}return c},hr=(i,c,f,$)=>{if(f>>>=0,!(0<$))return 0;var I=f;$=f+$-1;for(var P=0;P<i.length;++P){var V=i.charCodeAt(P);if(55296<=V&&57343>=V){var oe=i.charCodeAt(++P);V=65536+((V&1023)<<10)|oe&1023}if(127>=V){if(f>=$)break;c[f++>>>0]=V}else{if(2047>=V){if(f+1>=$)break;c[f++>>>0]=192|V>>6}else{if(65535>=V){if(f+2>=$)break;c[f++>>>0]=224|V>>12}else{if(f+3>=$)break;c[f++>>>0]=240|V>>18,c[f++>>>0]=128|V>>12&63}c[f++>>>0]=128|V>>6&63}c[f++>>>0]=128|V&63}}return c[f>>>0]=0,f-I},gr=(i,c,f)=>hr(i,o(),c,f);function yr(i,c){if(A)return G(6,1,i,c)}function br(i,c,f){if(A)return G(7,1,i,c,f)}function wr(i,c,f){return A?G(8,1,i,c,f):0}function vr(i,c){if(A)return G(9,1,i,c)}function Rt(i,c,f){if(A)return G(10,1,i,c,f)}function Ut(i,c,f,$){if(A)return G(11,1,i,c,f,$)}function Lt(i,c,f,$){if(A)return G(12,1,i,c,f,$)}function Ft(i,c,f,$){if(A)return G(13,1,i,c,f,$)}function Ht(i){if(A)return G(14,1,i)}function jt(i,c){if(A)return G(15,1,i,c)}function Kt(i,c,f){if(A)return G(16,1,i,c,f)}var qt=i=>{if(!Oe)try{if(i(),!Xe())try{A?tn(Ie):Vt(Ie)}catch(c){c instanceof ct||c==\"unwind\"||w(1,c)}}catch(c){c instanceof ct||c==\"unwind\"||w(1,c)}};function Pt(i){i>>>=0,typeof Atomics.Nb==\"function\"&&(Atomics.Nb(n(),i>>2,i).value.then($t),i+=128,Atomics.store(n(),i>>2,1))}a.__emscripten_thread_mailbox_await=Pt;function $t(){var i=Sr();i&&(Pt(i),qt(()=>Xn()))}a.checkMailbox=$t;var pt=i=>i%4===0&&(i%100!==0||i%400===0),xt=[0,31,60,91,121,152,182,213,244,274,305,335],Yt=[0,31,59,90,120,151,181,212,243,273,304,334];function l(i,c,f,$,I,P,V,oe){return A?G(17,1,i,c,f,$,I,P,V,oe):-52}function p(i,c,f,$,I,P,V){if(A)return G(18,1,i,c,f,$,I,P,V)}var h=i=>{var c=vt(i)+1,f=Qr(c);return f&&gr(i,f,c),f},C=[],T=(i,c)=>{C.length=0;var f;for(c>>=2;f=o()[i++>>>0];)c+=f!=105&c,C.push(f==105?n()[c>>>0]:d()[c++>>>1]),++c;return C},U=i=>{var c=rn();return i=i(),Cr(c),i};function G(i,c){var f=arguments.length-2,$=arguments;return U(()=>{for(var I=nn(8*f),P=I>>3,V=0;V<f;V++){var oe=$[2+V];d()[P+V>>>0]=oe}return Yn(i,f,I,c)})}var ue=[],Y={},Q=()=>{if(!J){var i={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:b||\"./this.program\"},c;for(c in Y)Y[c]===void 0?delete i[c]:i[c]=Y[c];var f=[];for(c in i)f.push(`${c}=${i[c]}`);J=f}return J},J;function ce(i,c){if(A)return G(19,1,i,c);i>>>=0,c>>>=0;var f=0;return Q().forEach(function($,I){var P=c+f;for(I=s()[i+4*I>>2>>>0]=P,P=0;P<$.length;++P)r()[I++>>0>>>0]=$.charCodeAt(P);r()[I>>0>>>0]=0,f+=$.length+1}),0}function me(i,c){if(A)return G(20,1,i,c);i>>>=0,c>>>=0;var f=Q();s()[i>>2>>>0]=f.length;var $=0;return f.forEach(function(I){$+=I.length+1}),s()[c>>2>>>0]=$,0}function E(i){return A?G(21,1,i):52}function te(i,c,f,$){return A?G(22,1,i,c,f,$):52}function fe(i,c,f,$,I){return A?G(23,1,i,c,f,$,I):70}var ut=[null,[],[]];function Xt(i,c,f,$){if(A)return G(24,1,i,c,f,$);c>>>=0,f>>>=0,$>>>=0;for(var I=0,P=0;P<f;P++){var V=s()[c>>2>>>0],oe=s()[c+4>>2>>>0];c+=8;for(var ee=0;ee<oe;ee++){var Z=o()[V+ee>>>0],re=ut[i];Z===0||Z===10?((i===1?B:K)(cr(re,0)),re.length=0):re.push(Z)}I+=oe}return s()[$>>2>>>0]=I,0}var Nn=[31,29,31,30,31,30,31,31,30,31,30,31],Un=[31,28,31,30,31,30,31,31,30,31,30,31];function du(i){var c=Array(vt(i)+1);return hr(i,c,0,c.length),c}var cu=(i,c)=>{r().set(i,c>>>0)};function Ln(i,c,f,$){function I(O,se,ye){for(O=typeof O==\"number\"?O.toString():O||\"\";O.length<se;)O=ye[0]+O;return O}function P(O,se){return I(O,se,\"0\")}function V(O,se){function ye(ao){return 0>ao?-1:0<ao?1:0}var St;return(St=ye(O.getFullYear()-se.getFullYear()))===0&&(St=ye(O.getMonth()-se.getMonth()))===0&&(St=ye(O.getDate()-se.getDate())),St}function oe(O){switch(O.getDay()){case 0:return new Date(O.getFullYear()-1,11,29);case 1:return O;case 2:return new Date(O.getFullYear(),0,3);case 3:return new Date(O.getFullYear(),0,2);case 4:return new Date(O.getFullYear(),0,1);case 5:return new Date(O.getFullYear()-1,11,31);case 6:return new Date(O.getFullYear()-1,11,30)}}function ee(O){var se=O.Za;for(O=new Date(new Date(O.$a+1900,0,1).getTime());0<se;){var ye=O.getMonth(),St=(pt(O.getFullYear())?Nn:Un)[ye];if(se>St-O.getDate())se-=St-O.getDate()+1,O.setDate(1),11>ye?O.setMonth(ye+1):(O.setMonth(0),O.setFullYear(O.getFullYear()+1));else{O.setDate(O.getDate()+se);break}}return ye=new Date(O.getFullYear()+1,0,4),se=oe(new Date(O.getFullYear(),0,4)),ye=oe(ye),0>=V(se,O)?0>=V(ye,O)?O.getFullYear()+1:O.getFullYear():O.getFullYear()-1}i>>>=0,c>>>=0,f>>>=0,$>>>=0;var Z=n()[$+40>>2>>>0];$={Kb:n()[$>>2>>>0],Jb:n()[$+4>>2>>>0],cb:n()[$+8>>2>>>0],ib:n()[$+12>>2>>>0],eb:n()[$+16>>2>>>0],$a:n()[$+20>>2>>>0],Wa:n()[$+24>>2>>>0],Za:n()[$+28>>2>>>0],Tb:n()[$+32>>2>>>0],Ib:n()[$+36>>2>>>0],Lb:Z?Ve(Z):\"\"},f=Ve(f),Z={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var re in Z)f=f.replace(new RegExp(re,\"g\"),Z[re]);var he=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),be=\"January February March April May June July August September October November December\".split(\" \");Z={\"%a\":O=>he[O.Wa].substring(0,3),\"%A\":O=>he[O.Wa],\"%b\":O=>be[O.eb].substring(0,3),\"%B\":O=>be[O.eb],\"%C\":O=>P((O.$a+1900)/100|0,2),\"%d\":O=>P(O.ib,2),\"%e\":O=>I(O.ib,2,\" \"),\"%g\":O=>ee(O).toString().substring(2),\"%G\":O=>ee(O),\"%H\":O=>P(O.cb,2),\"%I\":O=>(O=O.cb,O==0?O=12:12<O&&(O-=12),P(O,2)),\"%j\":O=>{for(var se=0,ye=0;ye<=O.eb-1;se+=(pt(O.$a+1900)?Nn:Un)[ye++]);return P(O.ib+se,3)},\"%m\":O=>P(O.eb+1,2),\"%M\":O=>P(O.Jb,2),\"%n\":()=>`\n`,\"%p\":O=>0<=O.cb&&12>O.cb?\"AM\":\"PM\",\"%S\":O=>P(O.Kb,2),\"%t\":()=>\"\t\",\"%u\":O=>O.Wa||7,\"%U\":O=>P(Math.floor((O.Za+7-O.Wa)/7),2),\"%V\":O=>{var se=Math.floor((O.Za+7-(O.Wa+6)%7)/7);if(2>=(O.Wa+371-O.Za-2)%7&&se++,se)se==53&&(ye=(O.Wa+371-O.Za)%7,ye==4||ye==3&&pt(O.$a)||(se=1));else{se=52;var ye=(O.Wa+7-O.Za-1)%7;(ye==4||ye==5&&pt(O.$a%400-1))&&se++}return P(se,2)},\"%w\":O=>O.Wa,\"%W\":O=>P(Math.floor((O.Za+7-(O.Wa+6)%7)/7),2),\"%y\":O=>(O.$a+1900).toString().substring(2),\"%Y\":O=>O.$a+1900,\"%z\":O=>{O=O.Ib;var se=0<=O;return O=Math.abs(O)/60,(se?\"+\":\"-\")+(\"0000\"+(O/60*100+O%60)).slice(-4)},\"%Z\":O=>O.Lb,\"%%\":()=>\"%\"},f=f.replace(/%%/g,\"\\0\\0\");for(re in Z)f.includes(re)&&(f=f.replace(new RegExp(re,\"g\"),Z[re]($)));return f=f.replace(/\\0\\0/g,\"%\"),re=du(f),re.length>c?0:(cu(re,i),re.length-1)}function $r(i){try{i()}catch(c){Ke(c)}}function pu(i){var c={},f;for(f in i)(function($){var I=i[$];c[$]=typeof I==\"function\"?function(){xr.push($);try{return I.apply(null,arguments)}finally{Oe||(xr.pop()===$||Ke(),Ze&&ft===1&&xr.length===0&&(ft=0,Ge+=1,$r(to),typeof Fibers<\"u\"&&Fibers.Ub()))}}:I})(f);return c}var ft=0,Ze=null,Fn=0,xr=[],Hn={},jn={},fu=0,Zr=null,mu=[];function hu(){return new Promise((i,c)=>{Zr={resolve:i,reject:c}})}function gu(){var i=Qr(65548),c=i+12;s()[i>>2>>>0]=c,s()[i+4>>2>>>0]=c+65536,c=xr[0];var f=Hn[c];return f===void 0&&(f=fu++,Hn[c]=f,jn[f]=c),c=f,n()[i+8>>2>>>0]=c,i}function yu(){var i=n()[Ze+8>>2>>>0];return i=j[jn[i]],--Ge,i()}function bu(i){if(!Oe){if(ft===0){var c=!1,f=!1;i(($=0)=>{if(!Oe&&(Fn=$,c=!0,f)){ft=2,$r(()=>ro(Ze)),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.resume(),$=!1;try{var I=yu()}catch(oe){I=oe,$=!0}var P=!1;if(!Ze){var V=Zr;V&&(Zr=null,($?V.reject:V.resolve)(I),P=!0)}if($&&!P)throw I}}),f=!0,c||(ft=1,Ze=gu(),typeof Browser<\"u\"&&Browser.hb.sb&&Browser.hb.pause(),$r(()=>eo(Ze)))}else ft===2?(ft=0,$r(no),Kn(Ze),Ze=null,mu.forEach($=>qt($))):Ke(`invalid state: ${ft}`);return Fn}}function wu(i){return bu(c=>{i().then(c)})}ne.gb();var vu=[null,zt,pr,wt,Nt,mr,yr,br,wr,vr,Rt,Ut,Lt,Ft,Ht,jt,Kt,l,p,ce,me,E,te,fe,Xt],$u={r:function(i,c,f){return wu(async()=>{await a.xb(i,c,f)})},b:function(i,c,f){throw i>>>=0,new Je(i).gb(c>>>0,f>>>0),He=i,fr++,He},O:function(i){qn(i>>>0,!y,1,!v,131072,!1),ne.lb()},l:function(i){i>>>=0,A?postMessage({cmd:\"cleanupThread\",thread:i}):Ot(i)},I:Gt,i:Nt,U:mr,E:yr,G:br,V:wr,S:vr,K:Rt,R:Ut,p:Lt,F:Ft,C:Ht,T:jt,D:Kt,q:()=>!0,A:function(i,c){i>>>=0,i==c>>>0?setTimeout(()=>$t()):A?postMessage({targetThread:i,cmd:\"checkMailbox\"}):(i=ne.Qa[i])&&i.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:Pt,X:function(i){S&&ne.Qa[i>>>0].ref()},u:function(i,c,f){i=c+2097152>>>0<4194305-!!i?(i>>>0)+4294967296*c:NaN,f>>>=0,i=new Date(1e3*i),n()[f>>2>>>0]=i.getUTCSeconds(),n()[f+4>>2>>>0]=i.getUTCMinutes(),n()[f+8>>2>>>0]=i.getUTCHours(),n()[f+12>>2>>>0]=i.getUTCDate(),n()[f+16>>2>>>0]=i.getUTCMonth(),n()[f+20>>2>>>0]=i.getUTCFullYear()-1900,n()[f+24>>2>>>0]=i.getUTCDay(),i=(i.getTime()-Date.UTC(i.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,n()[f+28>>2>>>0]=i},v:function(i,c,f){i=c+2097152>>>0<4194305-!!i?(i>>>0)+4294967296*c:NaN,f>>>=0,i=new Date(1e3*i),n()[f>>2>>>0]=i.getSeconds(),n()[f+4>>2>>>0]=i.getMinutes(),n()[f+8>>2>>>0]=i.getHours(),n()[f+12>>2>>>0]=i.getDate(),n()[f+16>>2>>>0]=i.getMonth(),n()[f+20>>2>>>0]=i.getFullYear()-1900,n()[f+24>>2>>>0]=i.getDay(),c=(pt(i.getFullYear())?xt:Yt)[i.getMonth()]+i.getDate()-1|0,n()[f+28>>2>>>0]=c,n()[f+36>>2>>>0]=-(60*i.getTimezoneOffset()),c=new Date(i.getFullYear(),6,1).getTimezoneOffset();var $=new Date(i.getFullYear(),0,1).getTimezoneOffset();i=(c!=$&&i.getTimezoneOffset()==Math.min($,c))|0,n()[f+32>>2>>>0]=i},w:function(i){i>>>=0;var c=new Date(n()[i+20>>2>>>0]+1900,n()[i+16>>2>>>0],n()[i+12>>2>>>0],n()[i+8>>2>>>0],n()[i+4>>2>>>0],n()[i>>2>>>0],0),f=n()[i+32>>2>>>0],$=c.getTimezoneOffset(),I=new Date(c.getFullYear(),6,1).getTimezoneOffset(),P=new Date(c.getFullYear(),0,1).getTimezoneOffset(),V=Math.min(P,I);return 0>f?n()[i+32>>2>>>0]=+(I!=P&&V==$):0<f!=(V==$)&&(I=Math.max(P,I),c.setTime(c.getTime()+6e4*((0<f?V:I)-$))),n()[i+24>>2>>>0]=c.getDay(),f=(pt(c.getFullYear())?xt:Yt)[c.getMonth()]+c.getDate()-1|0,n()[i+28>>2>>>0]=f,n()[i>>2>>>0]=c.getSeconds(),n()[i+4>>2>>>0]=c.getMinutes(),n()[i+8>>2>>>0]=c.getHours(),n()[i+12>>2>>>0]=c.getDate(),n()[i+16>>2>>>0]=c.getMonth(),n()[i+20>>2>>>0]=c.getYear(),i=c.getTime()/1e3,Jn((it=i,1<=+Math.abs(it)?0<it?+Math.floor(it/4294967296)>>>0:~~+Math.ceil((it-+(~~it>>>0))/4294967296)>>>0:0)),i>>>0},s:l,t:p,z:function(i,c,f){function $(Z){return(Z=Z.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?Z[1]:\"GMT\"}i>>>=0,c>>>=0,f>>>=0;var I=new Date().getFullYear(),P=new Date(I,0,1),V=new Date(I,6,1);I=P.getTimezoneOffset();var oe=V.getTimezoneOffset(),ee=Math.max(I,oe);s()[i>>2>>>0]=60*ee,n()[c>>2>>>0]=+(I!=oe),i=$(P),c=$(V),i=h(i),c=h(c),oe<I?(s()[f>>2>>>0]=i,s()[f+4>>2>>>0]=c):(s()[f>>2>>>0]=c,s()[f+4>>2>>>0]=i)},d:()=>{Ke(\"\")},c:function(i,c,f){return i>>>=0,c=T(c>>>0,f>>>0),Et[i].apply(null,c)},k:function(i,c,f){return i>>>=0,c=T(c>>>0,f>>>0),Et[i].apply(null,c)},m:function(){},j:function(){return Date.now()},W:()=>{throw Ge+=1,\"unwind\"},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return S?(fo(),Mt(po)).cpus().length:navigator.hardwareConcurrency},L:function(i,c,f,$){for(ne.Pb=c>>>0,ue.length=f,c=$>>>0>>3,$=0;$<f;$++)ue[$]=d()[c+$>>>0];return(0>i?Et[-i-1]:vu[i]).apply(null,ue)},y:function(i){i>>>=0;var c=o().length;if(i<=c||4294901760<i)return!1;for(var f=1;4>=f;f*=2){var $=c*(1+.2/f);$=Math.min($,i+100663296);var I=Math;$=Math.max(i,$);e:{I=I.min.call(I,4294901760,$+(65536-$%65536)%65536)-we.buffer.byteLength+65535>>>16;try{we.grow(I),pe();var P=1;break e}catch{}P=void 0}if(P)return!0}return!1},P:ce,Q:me,H:Vt,h:E,o:te,x:fe,n:Xt,a:we||a.wasmMemory,J:Ln,e:function(i,c,f,$){return Ln(i>>>0,c>>>0,f>>>0,$>>>0)}};(function(){function i(f,$){return f=f.exports,f=pu(f),j=f=xu(f),ne.mb.push(j.Da),Te.unshift(j.Y),Se=$,lr(),f}var c={a:$u};if(Bt(),a.instantiateWasm)try{return a.instantiateWasm(c,i)}catch(f){K(\"Module.instantiateWasm callback failed with error: \"+f),g(f)}return dr(c,function(f){i(f.instance,f.module)}).catch(g),{}})(),a._OrtInit=(i,c)=>(a._OrtInit=j.Z)(i,c),a._OrtGetLastError=(i,c)=>(a._OrtGetLastError=j._)(i,c),a._OrtCreateSessionOptions=(i,c,f,$,I,P,V,oe,ee,Z)=>(a._OrtCreateSessionOptions=j.$)(i,c,f,$,I,P,V,oe,ee,Z),a._OrtAppendExecutionProvider=(i,c)=>(a._OrtAppendExecutionProvider=j.aa)(i,c),a._OrtAddFreeDimensionOverride=(i,c,f)=>(a._OrtAddFreeDimensionOverride=j.ba)(i,c,f),a._OrtAddSessionConfigEntry=(i,c,f)=>(a._OrtAddSessionConfigEntry=j.ca)(i,c,f),a._OrtReleaseSessionOptions=i=>(a._OrtReleaseSessionOptions=j.da)(i),a._OrtCreateSession=(i,c,f)=>(a._OrtCreateSession=j.ea)(i,c,f),a._OrtReleaseSession=i=>(a._OrtReleaseSession=j.fa)(i),a._OrtGetInputOutputCount=(i,c,f)=>(a._OrtGetInputOutputCount=j.ga)(i,c,f),a._OrtGetInputName=(i,c)=>(a._OrtGetInputName=j.ha)(i,c),a._OrtGetOutputName=(i,c)=>(a._OrtGetOutputName=j.ia)(i,c),a._OrtFree=i=>(a._OrtFree=j.ja)(i),a._OrtCreateTensor=(i,c,f,$,I,P)=>(a._OrtCreateTensor=j.ka)(i,c,f,$,I,P),a._OrtGetTensorData=(i,c,f,$,I)=>(a._OrtGetTensorData=j.la)(i,c,f,$,I),a._OrtReleaseTensor=i=>(a._OrtReleaseTensor=j.ma)(i),a._OrtCreateRunOptions=(i,c,f,$)=>(a._OrtCreateRunOptions=j.na)(i,c,f,$),a._OrtAddRunConfigEntry=(i,c,f)=>(a._OrtAddRunConfigEntry=j.oa)(i,c,f),a._OrtReleaseRunOptions=i=>(a._OrtReleaseRunOptions=j.pa)(i),a._OrtCreateBinding=i=>(a._OrtCreateBinding=j.qa)(i),a._OrtBindInput=(i,c,f)=>(a._OrtBindInput=j.ra)(i,c,f),a._OrtBindOutput=(i,c,f,$)=>(a._OrtBindOutput=j.sa)(i,c,f,$),a._OrtClearBoundOutputs=i=>(a._OrtClearBoundOutputs=j.ta)(i),a._OrtReleaseBinding=i=>(a._OrtReleaseBinding=j.ua)(i),a._OrtRunWithBinding=(i,c,f,$,I)=>(a._OrtRunWithBinding=j.va)(i,c,f,$,I),a._OrtRun=(i,c,f,$,I,P,V,oe)=>(a._OrtRun=j.wa)(i,c,f,$,I,P,V,oe),a._OrtEndProfiling=i=>(a._OrtEndProfiling=j.xa)(i),a._JsepOutput=(i,c,f)=>(a._JsepOutput=j.ya)(i,c,f),a._JsepGetNodeName=i=>(a._JsepGetNodeName=j.za)(i);var Sr=a._pthread_self=()=>(Sr=a._pthread_self=j.Aa)(),Qr=a._malloc=i=>(Qr=a._malloc=j.Ba)(i),Kn=a._free=i=>(Kn=a._free=j.Ca)(i);a.__emscripten_tls_init=()=>(a.__emscripten_tls_init=j.Da)();var qn=a.__emscripten_thread_init=(i,c,f,$,I,P)=>(qn=a.__emscripten_thread_init=j.Fa)(i,c,f,$,I,P);a.__emscripten_thread_crashed=()=>(a.__emscripten_thread_crashed=j.Ga)();var Yn=(i,c,f,$)=>(Yn=j.Ha)(i,c,f,$),en=i=>(en=j.Ia)(i),tn=a.__emscripten_thread_exit=i=>(tn=a.__emscripten_thread_exit=j.Ja)(i),Xn=a.__emscripten_check_mailbox=()=>(Xn=a.__emscripten_check_mailbox=j.Ka)(),Jn=i=>(Jn=j.La)(i),Zn=(i,c)=>(Zn=j.Ma)(i,c),rn=()=>(rn=j.Na)(),Cr=i=>(Cr=j.Oa)(i),nn=i=>(nn=j.Pa)(i),Qn=a.dynCall_ii=(i,c)=>(Qn=a.dynCall_ii=j.Ra)(i,c),eo=i=>(eo=j.Sa)(i),to=()=>(to=j.Ta)(),ro=i=>(ro=j.Ua)(i),no=()=>(no=j.Va)();a.___start_em_js=925783,a.___stop_em_js=925944;function xu(i){i=Object.assign({},i);var c=$=>()=>$()>>>0,f=$=>I=>$(I)>>>0;return i.__errno_location=c(i.__errno_location),i.pthread_self=c(i.pthread_self),i.malloc=f(i.malloc),i.stackSave=c(i.stackSave),i.stackAlloc=f(i.stackAlloc),i}a.keepRuntimeAlive=Xe,a.wasmMemory=we,a.stackAlloc=nn,a.stackSave=rn,a.stackRestore=Cr,a.UTF8ToString=Ve,a.stringToUTF8=gr,a.lengthBytesUTF8=vt,a.ExitStatus=ct,a.PThread=ne;var Ar;bt=function i(){Ar||oo(),Ar||(bt=i)};function oo(){function i(){if(!Ar&&(Ar=!0,a.calledRun=!0,!Oe)&&(A||st(Te),m(a),a.onRuntimeInitialized&&a.onRuntimeInitialized(),!A)){if(a.postRun)for(typeof a.postRun==\"function\"&&(a.postRun=[a.postRun]);a.postRun.length;){var c=a.postRun.shift();ke.unshift(c)}st(ke)}}if(!(0<Fe))if(A)m(a),A||st(Te),startWorker(a);else{if(a.preRun)for(typeof a.preRun==\"function\"&&(a.preRun=[a.preRun]);a.preRun.length;)Ue.unshift(a.preRun.shift());st(Ue),0<Fe||(a.setStatus?(a.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){a.setStatus(\"\")},1),i()},1)):i())}}if(a.preInit)for(typeof a.preInit==\"function\"&&(a.preInit=[a.preInit]);0<a.preInit.length;)a.preInit.pop()();return oo(),t.ready}})();typeof ho==\"object\"&&typeof cn==\"object\"?cn.exports=mo:typeof define==\"function\"&&define.amd&&define([],()=>mo)});var yo=Jt((mc,_u)=>{_u.exports='\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\\n'});var mn,Qt,er,Tr,tr,So,hn,De=H(()=>{\"use strict\";mn=e=>{switch(e){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float16\":return 10;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${e}`)}},Qt=e=>{switch(e){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 10:return\"float16\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${e}`)}},er=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],Tr=e=>{switch(e){case\"float16\":return Uint16Array;case\"float32\":return Float32Array;case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"bool\":return Uint8Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},tr=e=>{switch(e){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},So=e=>e===\"float32\"||e===\"int32\"||e===\"int64\"||e===\"bool\"||e===\"float16\"||e===\"uint32\",hn=e=>{switch(e){case\"none\":return 0;case\"cpu\":return 1;case\"cpu-pinned\":return 2;case\"texture\":return 3;case\"gpu-buffer\":return 4;default:throw new Error(`unsupported data location: ${e}`)}}});var Vu,Gu,Co,Ao,Io,Nu,Ee,mt=H(()=>{\"use strict\";De();Vu=[\"V\",\"I\",\"W\",\"E\",\"F\"],Gu=(e,t)=>{console.log(`[${Vu[e]},${new Date().toISOString()}]${t}`)},Io=(e,t)=>{Co=e,Ao=t},Nu=(e,t)=>{let r=tr(e),o=tr(Co);r>=o&&Gu(r,typeof t==\"function\"?t():t)},Ee=(...e)=>{Ao&&Nu(...e)}});var Eo,To=H(()=>{\"use strict\";De();Eo=(e,t)=>new(Tr(t))(e)});var Oo=H(()=>{\"use strict\"});var Or,Uu,_o,yn,gn,Ro,Po=H(()=>{\"use strict\";mt();Oo();Or=e=>Math.ceil(e/16)*16,Uu=1,_o=()=>Uu++,yn=async(e,t,r,o)=>{let n=Or(r),s=e.device.createBuffer({size:n,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let u=e.getCommandEncoder();e.endComputePass(),u.copyBufferToBuffer(t,0,s,0,n),e.flush(),await s.mapAsync(GPUMapMode.READ);let d=s.getMappedRange();if(o){let a=o();return a.set(new Uint8Array(d,0,r)),a}else return new Uint8Array(d.slice(0,r))}finally{s.destroy()}},gn=class{constructor(t){this.backend=t;this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map}upload(t,r){let o=r.buffer,n=r.byteOffset,s=r.byteLength,u=Or(s),d=this.storageCache.get(t);if(!d)throw new Error(\"gpu data for uploading does not exist\");if(d.originalSize!==s)throw new Error(`inconsistent data size. gpu data size=${d.originalSize}, data size=${s}`);let a=this.backend.device.createBuffer({mappedAtCreation:!0,size:u,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),m=a.getMappedRange();new Uint8Array(m).set(new Uint8Array(o,n,s)),a.unmap();let g=this.backend.getCommandEncoder();this.backend.endComputePass(),g.copyBufferToBuffer(a,0,d.gpuData.buffer,0,u),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.upload(id=${t})`),this.buffersForUploadingPending.push(a)}memcpy(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"source gpu data for memcpy does not exist\");let n=this.storageCache.get(r);if(!n)throw new Error(\"destination gpu data for memcpy does not exist\");if(o.originalSize!==n.originalSize)throw new Error(\"inconsistent source and destination gpu data size\");let s=Or(o.originalSize),u=this.backend.getCommandEncoder();this.backend.endComputePass(),u.copyBufferToBuffer(o.gpuData.buffer,0,n.gpuData.buffer,0,s)}registerExternalBuffer(t,r,o){let n;if(o){if(n=this.externalBuffers.get(o),n===void 0)throw new Error(\"previous buffer is not registered\");if(t===o)return Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${n}, buffer is the same, skip.`),n;this.externalBuffers.delete(o)}else n=_o();return this.storageCache.set(n,{gpuData:{id:n,type:0,buffer:t},originalSize:r}),this.externalBuffers.set(t,n),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${n}, registered.`),n}unregisterExternalBuffer(t){let r=this.externalBuffers.get(t);r!==void 0&&(this.storageCache.delete(r),this.externalBuffers.delete(t),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${r}`))}create(t,r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let o=Or(t),n,s=(r&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,u=(r&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(s||u){let a=s?this.freeBuffers:this.freeUniformBuffers,m=a.get(o);m||(m=[],a.set(o,m)),m.length>0?n=m.pop():n=this.backend.device.createBuffer({size:o,usage:r})}else n=this.backend.device.createBuffer({size:o,usage:r});let d={id:_o(),type:0,buffer:n};return this.storageCache.set(d.id,{gpuData:d,originalSize:t}),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.create(size=${t}) => id=${d.id}`),d}get(t){return this.storageCache.get(t)?.gpuData}release(t){let r=this.storageCache.get(t);if(!r)throw new Error(\"releasing data does not exist\");return Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.release(id=${t}), gpuDataId=${r.gpuData.id}`),this.storageCache.delete(t),this.buffersPending.push(r.gpuData.buffer),r.originalSize}async download(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"data does not exist\");await yn(this.backend,o.gpuData.buffer,o.originalSize,r)}refreshPendingBuffers(){for(let t of this.buffersForUploadingPending)t.destroy();this.buffersForUploadingPending=[];for(let t of this.buffersPending)(t.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(t.size).push(t):(t.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(t.size).push(t):t.destroy();this.buffersPending=[]}dispose(){this.freeBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.freeUniformBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.storageCache.forEach(t=>{t.gpuData.buffer.destroy()}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map}},Ro=(...e)=>new gn(...e)});var bn,ie,Pe=H(()=>{\"use strict\";bn=class{constructor(t){Object.assign(this,t)}get cacheKey(){return this._cacheKey||(this._cacheKey=Object.getOwnPropertyNames(this).sort().map(t=>`${this[t]}`).join(\";\")),this._cacheKey}},ie=e=>new bn(e)});var wn,Qe,k,Ct,_r,Rr,Pr,ge=H(()=>{\"use strict\";wn=class{static calcMatMulShape(t,r){return t[1]!==r[0]?void 0:[t[0],r[1]]}},Qe=class{static calcShape(t,r,o=!1){let n=t.length,s=r.length;if(n===0)return r;if(s===0)return t;let u=Math.max(t.length,r.length),d=new Array(u);if(o){if(n<2||s<2)return;let a=wn.calcMatMulShape([t[n-2],t[n-1]],[r[s-2],r[s-1]]);if(a===void 0)return;[d[u-2],d[u-1]]=a}for(let a=o?3:1;a<=u;a++){let m=n-a<0?1:t[n-a],g=s-a<0?1:r[s-a];if(m!==g&&m>1&&g>1)return;d[u-a]=Math.max(m,g)}return d}static isValidBroadcast(t,r){let o=t.length,n=r.length;if(o>n)return!1;for(let s=1;s<=o;s++)if(t[o-s]!==1&&t[o-s]!==r[n-s])return!1;return!0}},k=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static sizeFromDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,r,t.length)}static sizeToDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,r)}static getSizeFromDimensionRange(t,r,o){let n=1;for(let s=r;s<o;s++){if(t[s]<0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains negative values in them.\");n*=t[s]}return n}static computeStrides(t){let r=t.length;if(r===0)return[];if(r===1)return[1];let o=new Array(r);o[r-1]=1,o[r-2]=t[r-1];for(let n=r-3;n>=0;--n)o[n]=o[n+1]*t[n+1];return o}static normalizeAxis(t,r){if(t<-r&&t>=r)throw new Error(\"unsupported axis for this operation.\");return t<0?t+r:t}static normalizeAxes(t,r){return t.map(o=>this.normalizeAxis(o,r??t.length))}static sortBasedOnPerm(t,r){return r?r.map(o=>t[o]):t.slice().reverse()}static padShape(t,r){let o=t.length;return t.map((n,s)=>n+r[s]+r[s+o])}static areEqual(t,r){return t.length!==r.length?!1:t.every((o,n)=>o===r[n])}},Ct=class e{static adjustPoolAttributes(t,r,o,n,s,u){if(!t&&o.length!==r.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(t)for(let d=0;d<r.length-2;d++)d>=o.length?o.push(r[d+2]):o[d]=r[d+2];for(let d=0;d<o.length;d++)if(d<n.length){if(n[d]<0)throw new Error(\"strides should be greater than or equal to 1\")}else n.push(1);for(let d=0;d<o.length;d++)if(d<s.length){if(s[d]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else s.push(1);for(let d=0;d<o.length*2;d++)if(d<u.length){if(u[d]<0)throw new Error(\"pad should be greater than or equal to 1\")}else u.push(0);for(let d=0;d<o.length;d++){if(o[d]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(u[d]>=o[d]||u[d+o.length]>=o[d])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(t,r,o,n,s,u,d){if(d){if(s.length!==2*(t.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(r.length!==t.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(n.length!==t.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let a=0;a<t.length-2;a++)e.adjustPadAndReturnShape(t[a+(u?1:2)],r[a],o[a],n[a],s,a,a+t.length-2,d)}}static computePoolOutputShape(t,r,o,n,s,u,d){if(r.length<=0)throw new Error(\"input shape must be of size greater than 0\");let a=[r[0],r[1]];return e.computeShapeHelper(t,r,a,o,n,s,u,d),a}static computeConvOutputShape(t,r,o,n,s,u,d){if(t.length<=0||r.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");let a=[t[0],r[0]];return e.computeShapeHelper(!1,t,a,o,n,s,u,d),a}static computeShapeHelper(t,r,o,n,s,u,d,a){if(t)for(let m=0;m<r.length-2;m++)o.push(1);else for(let m=0;m<r.length-2;m++)o.push(e.adjustPadAndReturnShape(r[m+2],n[m],s[m],u[m],d,m,m+r.length-2,a))}static adjustPadAndReturnShape(t,r,o,n,s,u,d,a){let m=o*(n-1)+1;if(a&&a!==\"NOTSET\")switch(a){case\"VALID\":return s[u]=0,s[d]=0,Math.floor((t-m)/r+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(o!==1)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{let x=((t+r-1)/r-1)*r+n-t;return s[u]=Math.floor(a===\"SAME_LOWER\"?(x+1)/2:x/2),s[d]=x-s[u],Math.floor((t+x-n)/r+1)}default:throw new Error(\"Unsupported AutoPad type\")}else return Math.floor((t+s[u]+s[d]-m)/r+1)}},_r=class{static getShapeOfGemmResult(t,r,o,n,s){if(t.length!==2||o.length!==2)throw new Error(\"shape need to be of size 2\");let u,d,a;r?(u=t[1],d=t[0]):(u=t[0],d=t[1]);let m=-1;if(n?(a=o[0],m=1):(a=o[1],m=0),o[m]!==d)throw new Error(\"dimension mismatch\");if(u<=0||a<=0||d<=0)throw new Error(\"invalid shape specified\");if(s&&!Qe.isValidBroadcast(s,[u,a]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[u,a,d]}},Rr=-34028234663852886e22,Pr=34028234663852886e22});var Lu,Mo,Me,$n,lt,qe,At,ht,Bo,L,X,vn,ko,xn,Do,ve=H(()=>{\"use strict\";De();ge();Lu=64,Mo=(e,t)=>{if(t===3)throw new Error(\"vec3 has same alignment as vec4, use vec4 instead\");switch(e){case 10:return t>1?`vec${t}<f16>`:\"f16\";case 1:return t>1?`vec${t}<f32>`:\"f32\";case 6:return t>1?`vec${t}<i32>`:\"i32\";case 12:return t>1?`vec${t}<u32>`:\"u32\";case 7:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"i32\"];case 13:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"u32\"];case 9:if(t!==4)throw new Error(\"bool must be vec4\");return[\"u32\",\"vec4<bool>\"];default:throw new Error(`Unknown data type: ${e}`)}},Me=(e,t=1)=>{let r=Mo(e,t);return typeof r==\"string\"?r:r[0]},$n=e=>[{type:\"uint32\",data:e},{type:\"uint32\",data:k.computeStrides(e)}],lt=e=>e%4===0?4:e%2===0?2:1,qe=(e=\"f32\",t,r=\"0\")=>!t||t===1?`${e}(${r})`:`vec${t}<${e}>(${r})`,At=(e,t,r)=>e===\"f32\"?r:t===1?`f32(${r})`:`vec${t}f(${r})`,ht=(e,t)=>t===4?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:t===2?`(${e}.x + ${e}.y)`:t===3?`(${e}.x + ${e}.y + ${e}.z)`:e,Bo=(e,t,r,o,n)=>{let s=typeof r==\"number\",u=s?r:r.length,d=[...new Array(u).keys()],a=u<2?\"u32\":u<=4?`vec${u}<u32>`:`array<u32, ${u}>`,m=Mo(t,n),g=typeof m==\"string\"?m:m[1],x=typeof m==\"string\"?m:m[0],b={indices:a,value:g,storage:x,tensor:t},w=N=>typeof N==\"string\"?N:`${N}u`,v={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},y=s?\"uniforms.\":\"\",S=`${y}${e}_shape`,A=`${y}${e}_strides`,R=\"\";for(let N=0;N<u-1;N++)R+=`\n    let dim${N} = current / ${A}[${N}];\n    let rest${N} = current % ${A}[${N}];\n    indices[${N}] = dim${N};\n    current = rest${N};\n    `;R+=`indices[${u-1}] = current;`;let W=u<2?\"\":`\n  fn o2i_${e}(offset: u32) -> ${b.indices} {\n    var indices: ${b.indices};\n    var current = offset;\n    ${R}\n    return indices;\n  }`,M=N=>(v.offsetToIndices=!0,u<2?N:`o2i_${e}(${N})`),D=[];if(u>=2)for(let N=u-1;N>=0;N--)D.push(`${A}[${N}] * (indices[${N}])`);let _=u<2?\"\":`\n  fn i2o_${e}(indices: ${b.indices}) -> u32 {\n    return ${D.join(\"+\")};\n  }`,z=N=>(v.indicesToOffset=!0,u<2?N:`i2o_${e}(${N})`),F=(...N)=>u===0?\"0u\":`${b.indices}(${N.map(w).join(\",\")})`,q=(N,de)=>u<2?`${N}`:`${N}[${de}]`,le=(N,de,pe)=>u<2?`${N}=${pe};`:`${N}[${de}]=${pe};`,B={},K=(N,de)=>{v.broadcastedIndicesToOffset=!0;let pe=`${de.name}broadcastedIndicesTo${e}Offset`;if(pe in B)return`${pe}(${N})`;let ze=[];for(let Ue=u-1;Ue>=0;Ue--){let Te=de.indicesGet(\"outputIndices\",Ue+de.rank-u);ze.push(`${q(A,Ue)} * (${Te} % ${q(S,Ue)})`)}return B[pe]=`fn ${pe}(outputIndices: ${de.type.indices}) -> u32 {\n             return ${ze.length>0?ze.join(\"+\"):\"0u\"};\n           }`,`${pe}(${N})`},xe=(N,de)=>(()=>{if(b.storage===b.value)return`${e}[${N}]=${de};`;if(b.storage===\"vec2<u32>\"&&b.value===\"i32\")return`${e}[${N}]=vec2<u32>(u32(${de}), select(0u, 0xFFFFFFFFu, ${de} < 0));`;if(b.storage===\"vec2<u32>\"&&b.value===\"u32\")return`${e}[${N}]=vec2<u32>(u32(${de}), 0u);`;if(b.storage===\"u32\"&&b.value===\"vec4<bool>\")return`${e}[${N}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${de}));`;throw new Error(`not supported combination of storage type ${b.storage} and value type ${b.value} yet`)})(),ae=N=>(()=>{if(b.storage===b.value)return`${e}[${N}]`;if(b.storage===\"vec2<u32>\"&&b.value===\"i32\")return`i32(${e}[${N}].x)`;if(b.storage===\"vec2<u32>\"&&b.value===\"u32\")return`u32(${e}[${N}].x)`;if(b.storage===\"u32\"&&b.value===\"vec4<bool>\")return`vec4<bool>(bool(${e}[${N}] & 0xFFu), bool(${e}[${N}] & 0xFF00u), bool(${e}[${N}] & 0xFF0000u), bool(${e}[${N}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${b.storage} and value type ${b.value} yet`)})(),we=u<2?\"\":`\n  fn get_${e}ByIndices(indices: ${b.indices}) -> ${g} {\n    return ${ae(`i2o_${e}(indices)`)};\n  }`,j=u<2?\"\":(()=>{let N=d.map(pe=>`d${pe}: u32`).join(\", \"),de=d.map(pe=>`d${pe}`).join(\", \");return`\n  fn get_${e}(${N}) -> ${g} {\n    return get_${e}ByIndices(${F(de)});\n  }`})(),Se=(...N)=>{if(N.length!==u)throw new Error(`indices length must be ${u}`);let de=N.map(w).join(\",\");return u===0?ae(\"0u\"):u===1?ae(de[0]):(v.get=!0,v.getByIndices=!0,v.indicesToOffset=!0,`get_${e}(${de})`)},Oe=N=>u<2?ae(N):(v.getByIndices=!0,v.indicesToOffset=!0,`get_${e}ByIndices(${N})`),Ie=u<2?\"\":`\n  fn set_${e}ByIndices(indices: ${b.indices}, value: ${g}) {\n    ${xe(`i2o_${e}(indices)`,\"value\")}\n  }`,Ce=u<2?\"\":(()=>{let N=d.map(pe=>`d${pe}: u32`).join(\", \"),de=d.map(pe=>`d${pe}`).join(\", \");return`\n  fn set_${e}(${N}, value: ${g}) {\n    set_${e}ByIndices(${F(de)}, value);\n  }`})();return{impl:()=>{let N=[];return s||(N.push(`const ${S} = ${b.indices}(${r.join(\",\")});`),N.push(`const ${A} = ${b.indices}(${k.computeStrides(r).join(\",\")});`)),v.offsetToIndices&&N.push(W),v.indicesToOffset&&N.push(_),v.broadcastedIndicesToOffset&&Object.values(B).forEach(de=>N.push(de)),v.set&&N.push(Ce),v.setByIndices&&N.push(Ie),v.get&&N.push(j),v.getByIndices&&N.push(we),N.join(`\n`)},type:b,offsetToIndices:M,indicesToOffset:z,broadcastedIndicesToOffset:K,indices:F,indicesGet:q,indicesSet:le,set:(...N)=>{if(N.length!==u+1)throw new Error(`indices length must be ${u}`);let de=N[u];if(typeof de!=\"string\")throw new Error(\"value must be string\");let pe=N.slice(0,u).map(w).join(\",\");return u===0?xe(\"0u\",de):u===1?xe(pe[0],de):(v.set=!0,v.setByIndices=!0,v.indicesToOffset=!0,`set_${e}(${pe}, ${de})`)},setByOffset:xe,setByIndices:(N,de)=>u<2?xe(N,de):(v.setByIndices=!0,v.indicesToOffset=!0,`set_${e}ByIndices(${N}, ${de});`),get:Se,getByOffset:ae,getByIndices:Oe,usage:o?\"input\":\"output\",name:e,strides:A,shape:S,rank:u}},L=(e,t,r,o=1)=>Bo(e,t,r,!0,o),X=(e,t,r,o=1)=>Bo(e,t,r,!1,o),vn=class{constructor(t){this.normalizedDispatchGroup=t;this.indicesHelpers=[];this.uniforms=[];this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(t){return`if (global_idx >= ${typeof t==\"number\"?`${t}u`:t}) { return; }`}mainStart(t=Lu){let r=typeof t==\"number\"?t:t[0],o=typeof t==\"number\"?1:t[1],n=typeof t==\"number\"?1:t[2],s=this.normalizedDispatchGroup[1]===1&&this.normalizedDispatchGroup[2]===1,u=s?`@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>`:`@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>`,d=s?\"let global_idx = global_id.x;\":`let global_idx = (workgroup_id.z * ${this.normalizedDispatchGroup[0]*this.normalizedDispatchGroup[1]}u +\n          workgroup_id.y * ${this.normalizedDispatchGroup[0]}u + workgroup_id.x) * ${r*o*n}u + local_index;`;return`@compute @workgroup_size(${r}, ${o}, ${n})\n  fn main(${u}) {\n    ${d}\n  `}declareVariable(t,r){this.indicesHelpers.push(t),t.shape.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.shape.replace(\"uniforms.\",\"\"),type:t.type.indices}),t.strides.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.strides.replace(\"uniforms.\",\"\"),type:t.type.indices});let o=t.usage===\"input\"?\"read\":\"read_write\",n=t.type.storage;return`@group(0) @binding(${r}) var<storage, ${o}> ${t.name}: array<${n}>;`}declareVariables(...t){return t.map(r=>this.declareVariable(r,this.variableIndex++)).join(`\n`)}registerUniform(t,r){return this.uniforms.push({name:t,type:r}),this}uniformDeclaration(){if(this.uniforms.length===0)return\"\";let t=[];for(let{name:r,type:o}of this.uniforms)t.push(`${r}:${o}`);return`\n      struct Uniforms { ${t.join(\", \")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.indicesHelpers.map(t=>t.impl()).join(`\n`)}},ko=e=>new vn(e),xn=(e,t)=>{let r=e.length,o=[];for(let n=0;n<r;n++){let s=r-1-n,u=e[s]||1;(t[t.length-1-n]||1)>1&&u===1&&o.unshift(s)}return o},Do=e=>e<=4});var Fu,Wo,Hu,ju,gt,zo,Vo,rr=H(()=>{\"use strict\";ge();Pe();ve();Fu=e=>{if(!e||e.length!==1)throw new Error(\"Transpose requires 1 input.\")},Wo=(e,t)=>t&&t.length!==e?[...new Array(e).keys()].reverse():t,Hu=(e,t)=>k.sortBasedOnPerm(e,Wo(e.length,t)),ju=(e,t,r,o)=>{let n=[];n.push(`fn perm(i: ${o.type.indices}) -> ${r.type.indices} {\n    var a: ${r.type.indices};`);for(let s=0;s<t;++s)n.push(r.indicesSet(\"a\",e[s],`i[${s}]`));return n.push(\"return a;}\"),n.join(`\n`)},gt=(e,t)=>{let r=e.dataType,o=e.dims.length,n=Wo(o,t),s=Do(o),u=Hu(e.dims,n),d=s?u.length:u,a=s?o:e.dims,m=X(\"output\",r,d),g=L(\"a\",r,a),x=b=>`\n  ${b.registerUniform(\"output_size\",\"u32\").declareVariables(g,m)}\n\n  ${ju(n,o,g,m)}\n\n  ${b.mainStart()}\n    ${b.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let indices = ${m.offsetToIndices(\"global_idx\")};\n    let aIndices = perm(indices);\n\n    ${m.setByOffset(\"global_idx\",g.getByIndices(\"aIndices\"))}\n  }`;return{name:\"Transpose\",shaderCache:{hint:`${t}`,inputDependencies:s?[\"rank\"]:[\"dims\"]},getRunData:b=>{let w=k.size(u);return{outputs:[{dims:u,dataType:b[0].dataType}],dispatchGroup:{x:Math.ceil(w/64)},programUniforms:s?[{type:\"uint32\",data:w},...$n(b[0].dims),...$n(u)]:[{type:\"uint32\",data:w}]}},getShaderSource:x}},zo=(e,t)=>{Fu(e.inputs),e.compute(gt(e.inputs[0],t.perm))},Vo=e=>ie({perm:e.perm})});var Ku,qu,Yu,Xu,Ju,Zu,Qu,el,tl,rl,et,Go,No,Uo,Lo,Fo,Ho,jo,Ko,qo,Yo,Xo=H(()=>{\"use strict\";ge();ve();Mr();rr();Ku={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate * candidate\",logSumExp:\"bestValue + exp(candidate)\",l1:\"bestValue + abs(candidate)\",l2:\"bestValue + candidate * candidate\",logSum:\"bestValue + candidate\"},qu={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate\",logSumExp:\"bestValue + candidate\",l1:\"bestValue + candidate\",l2:\"bestValue + candidate\",logSum:\"bestValue + candidate\"},Yu={max:\"_A[offset]\",min:\"_A[offset]\",mean:\"0\",sum:\"0\",prod:\"1\",sumSquare:\"0\",logSumExp:\"0\",l1:\"0\",l2:\"0\",logSum:\"0\"},Xu={max:\"bestValue\",min:\"bestValue\",sum:\"bestValue\",prod:\"bestValue\",sumSquare:\"bestValue\",logSumExp:\"log(bestValue)\",l1:\"bestValue\",l2:\"sqrt(bestValue)\",logSum:\"log(bestValue)\"},Ju=(e,t)=>{let r=[];for(let o=t-e;o<t;++o)r.push(o);return r},Zu=(e,t)=>{let r=[],o=e.length;for(let s=0;s<o;s++)t.indexOf(s)===-1&&r.push(e[s]);let n=t.map(s=>e[s]);return[r,n]},Qu=(e,t)=>{let r=e.length+t.length,o=[],n=0;for(let s=0;s<r;s++)t.indexOf(s)===-1?o.push(e[n++]):o.push(1);return o},el=(e,t)=>{for(let r=0;r<e.length;++r)if(e[e.length-r-1]!==t-1-r)return!1;return!0},tl=(e,t)=>{let r=[];if(!el(e,t)){for(let o=0;o<t;++o)e.indexOf(o)===-1&&r.push(o);e.forEach(o=>r.push(o))}return r},rl=(e,t,r,o,n,s,u)=>{let d=r[0].dims,a=k.size(s),m=k.size(u),g=L(\"_A\",r[0].dataType,d),x=X(\"output\",n,s),b=32,w=`\n          var<workgroup> aBestValues : array<${x.type.storage}, ${b}>;\n       `;return{name:e,shaderCache:t,getShaderSource:y=>`\n        ${y.registerUniform(\"reduceSize\",\"u32\").declareVariables(g,x)}\n        ${w}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${y.mainStart(b)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${b};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${x.type.storage}(${Yu[o]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${b}) {\n           let candidate = ${x.type.storage}(${g.getByOffset(\"offset + k\")});\n           bestValue = ${Ku[o]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${b}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${qu[o]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${x.setByOffset(\"outputIndex\",`${o===\"mean\"?`bestValue / ${x.type.storage}(uniforms.reduceSize)`:`${Xu[o]}`}`)};\n         }\n        }`,getRunData:()=>({outputs:[{dims:s,dataType:n}],dispatchGroup:{x:a},programUniforms:[{type:\"uint32\",data:m}]})}},et=(e,t,r,o)=>{let n=e.inputs.length===1?r:Sn(e.inputs,r),s=n.axes;s.length===0&&!n.noopWithEmptyAxes&&(s=e.inputs[0].dims.map((w,v)=>v));let u=k.normalizeAxes(s,e.inputs[0].dims.length),d=u,a=e.inputs[0],m=tl(d,e.inputs[0].dims.length);m.length>0&&(a=e.compute(gt(e.inputs[0],m),{inputs:[0],outputs:[-1]})[0],d=Ju(d.length,a.dims.length));let[g,x]=Zu(a.dims,d),b=g;n.keepDims&&(b=Qu(g,u)),e.compute(rl(t,{hint:n.cacheKey,inputDependencies:[\"type\"]},[a],o,e.inputs[0].dataType,b,x),{inputs:[a]})},Go=(e,t)=>{et(e,\"ReduceMeanShared\",t,\"mean\")},No=(e,t)=>{et(e,\"ReduceL1Shared\",t,\"l1\")},Uo=(e,t)=>{et(e,\"ReduceL2Shared\",t,\"l2\")},Lo=(e,t)=>{et(e,\"ReduceLogSumExpShared\",t,\"logSumExp\")},Fo=(e,t)=>{et(e,\"ReduceMaxShared\",t,\"max\")},Ho=(e,t)=>{et(e,\"ReduceMinShared\",t,\"min\")},jo=(e,t)=>{et(e,\"ReduceProdShared\",t,\"prod\")},Ko=(e,t)=>{et(e,\"ReduceSumShared\",t,\"sum\")},qo=(e,t)=>{et(e,\"ReduceSumSquareShared\",t,\"sumSquare\")},Yo=(e,t)=>{et(e,\"ReduceLogSumShared\",t,\"logSum\")}});var tt,nl,Br,Sn,rt,ol,al,il,sl,ul,ll,dl,cl,pl,fl,nt,Jo,Zo,Qo,ea,ta,ra,na,oa,aa,ia,Ye,Mr=H(()=>{\"use strict\";ge();Pe();ve();Xo();tt=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"Reduce op requires 1 or 2 inputs.\");if(e.length===2&&e[1].dims.length!==1)throw new Error(\"Invalid axes input dims.\")},nl=e=>[\"\",\"\",`var value = ${e.getByOffset(\"inputOffset\")};`,\"\"],Br=(e,t,r,o,n,s,u=!1,d=!1)=>{let a=[],m=r[0].dims,g=k.normalizeAxes(n,r[0].dims.length),x=!d&&g.length===0;m.forEach((z,F)=>{x||g.indexOf(F)>=0?u&&a.push(1):a.push(z)});let b=[],w=L(\"_A\",r[0].dataType,m),v=X(\"output\",s,a),y=o(w,v,g),S=`inputOffset = ${w.indicesToOffset(\"inputIndices\")};`,A=`let ${S};`,R=`var ${S};`,W=y[1]===\"\"?\"\":R,M=(y[1]===\"\"?A:S)+`\n`+y[2];for(let z=0,F=0;z<r[0].dims.length;z++)x||g.indexOf(z)>=0?(u&&F++,M=`for(var j${z}: u32 = 0; j${z} < ${r[0].dims[z]}; j${z}++) {\n                ${y[2].includes(\"lastIndex\")?`let lastIndex = j${z};`:\"\"}\n                ${w.indicesSet(\"inputIndices\",z,`j${z}`)}\n                ${M}\n              }`):(b.push(`${w.indicesSet(\"inputIndices\",z,v.indicesGet(\"outputIndices\",F))};`),F++);let D=k.size(a);return{name:e,shaderCache:t,getShaderSource:z=>`\n        ${z.declareVariables(w,v)}\n\n        ${z.mainStart()}\n          ${z.guardAgainstOutOfBoundsWorkgroupSizes(D)}\n          var inputIndices: ${w.type.indices};\n          let outputIndices = ${v.offsetToIndices(\"global_idx\")};\n\n          ${b.join(`\n`)}\n          ${y[0]}       // init ops for reduce max/min\n          ${W}\n          ${y[1]}\n          ${M}\n          ${y[3]}\n          ${y.length===4?v.setByOffset(\"global_idx\",\"value\"):y.slice(4).join(`\n`)}\n        }`,getRunData:()=>({outputs:[{dims:a,dataType:s}],dispatchGroup:{x:Math.ceil(D/64)}})}},Sn=(e,t)=>{let r=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(o=>r.push(Number(o))),ie({axes:r,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},rt=(e,t,r,o)=>{let n=e.inputs,s=n.length===1?r:Sn(n,r);e.compute(Br(t,{hint:s.cacheKey},[n[0]],s.noopWithEmptyAxes&&s.axes.length===0?nl:o,s.axes,n[0].dataType,s.keepDims,s.noopWithEmptyAxes),{inputs:[0]})},ol=(e,t)=>{tt(e.inputs),rt(e,\"ReduceLogSum\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += ${o.getByOffset(\"inputOffset\")};`,\"value = log(value);\"])},al=(e,t)=>{tt(e.inputs),rt(e,\"ReduceL1\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += abs(${o.getByOffset(\"inputOffset\")});`,\"\"])},il=(e,t)=>{tt(e.inputs),rt(e,\"ReduceL2\",t,(o,n)=>[`var t = ${n.type.value}(0); var value = ${n.type.value}(0);`,\"\",`t = ${o.getByOffset(\"inputOffset\")}; value += (t * t);`,\"value = sqrt(value);\"])},sl=(e,t)=>{tt(e.inputs),rt(e,\"ReduceLogSumExp\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += exp(${o.getByOffset(\"inputOffset\")});`,\"value = log(value);\"])},ul=(e,t)=>{tt(e.inputs),rt(e,\"ReduceMax\",t,(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(o.indicesSet(\"inputIndices\",d,0));return[`${u.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};`,`value = max(value, ${o.getByOffset(\"inputOffset\")});`,\"\"]})},ll=(e,t)=>{tt(e.inputs),rt(e,\"ReduceMean\",t,(o,n,s)=>{let u=1;for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&(u*=e.inputs[0].dims[d]);return[\"var sum = f32(0);\",\"\",`sum += f32(${o.getByOffset(\"inputOffset\")});`,`let value = ${n.type.value}(sum / ${u});`]})},dl=(e,t)=>{tt(e.inputs),rt(e,\"ReduceMin\",t,(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`inputIndices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};`,`value = min(value, ${o.getByOffset(\"inputOffset\")});`,\"\"]})},cl=(e,t)=>{tt(e.inputs),rt(e,\"ReduceProd\",t,(o,n)=>[`var value = ${n.type.storage}(1);`,\"\",`value *= ${o.getByOffset(\"inputOffset\")};`,\"\"])},pl=(e,t)=>{tt(e.inputs),rt(e,\"ReduceSum\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += ${o.getByOffset(\"inputOffset\")};`,\"\"])},fl=(e,t)=>{tt(e.inputs),rt(e,\"ReduceSumSquare\",t,(o,n)=>[`var t = ${n.type.value}(0); var value = ${n.type.value}(0);`,\"\",`t = ${o.getByOffset(\"inputOffset\")}; value += t * t;`,\"\"])},nt=(e,t,r)=>{if(t.length===0)return!!r;let o=1,n=1;for(let s=0;s<t.length;s++)t.indexOf(s)===-1?o*=e[s]:n*=e[s];return n<32&&o>1024},Jo=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?ll(e,t):Go(e,t)},Zo=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?al(e,t):No(e,t)},Qo=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?il(e,t):Uo(e,t)},ea=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?sl(e,t):Lo(e,t)},ta=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?ul(e,t):Fo(e,t)},ra=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?dl(e,t):Ho(e,t)},na=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?cl(e,t):jo(e,t)},oa=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?pl(e,t):Ko(e,t)},aa=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?fl(e,t):qo(e,t)},ia=(e,t)=>{nt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?ol(e,t):Yo(e,t)},Ye=e=>ie(e)});var sa,ua,la,da,Cn,ca=H(()=>{\"use strict\";De();Pe();Mr();sa=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"ArgMinMaxOp op requires 1 or 2 inputs.\");if(e[0].dataType!==1)throw new Error(\"Invalid input type.\")},ua=(e,t)=>ie({axis:t.axis,keepDims:t.keepDims,selectLastIndex:t.selectLastIndex}),la=(e,t)=>{sa(e.inputs);let r=(n,s,u)=>{let d=[];for(let a=0;a<n.rank;a++)(u.indexOf(a)>=0||u.length===0)&&d.push(`inputIndices[${a}] = 0;`);return[`${d.join(`\n`)}`,`var value = ${n.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${n.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\"<=\":\"<\"} value) {\n         value = ${n.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",s.setByOffset(\"global_idx\",\"bestIndex\")]},o=e.inputs.length===1?t:ua(e.inputs,t);e.compute(Br(\"ArgMin\",{hint:o.cacheKey},[e.inputs[0]],r,[o.axis],7,o.keepDims),{inputs:[0]})},da=(e,t)=>{sa(e.inputs);let r=(n,s,u)=>{let d=[];for(let a=0;a<n.rank;a++)(u.indexOf(a)>=0||u.length===0)&&d.push(`inputIndices[${a}] = 0;`);return[`${d.join(`\n`)}`,`var value = ${n.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${n.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\">=\":\">\"} value) {\n         value = ${n.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",s.setByOffset(\"global_idx\",\"bestIndex\")]},o=e.inputs.length===1?t:ua(e.inputs,t);e.compute(Br(\"argMax\",{hint:o.cacheKey},[e.inputs[0]],r,[o.axis],7,o.keepDims),{inputs:[0]})},Cn=e=>ie(e)});var ml,hl,pa,fa=H(()=>{\"use strict\";ge();ve();ml=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![320,640,1280].includes(e[0].dims[2]))throw new Error(\"number of channels should be 320, 640 or 1280\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},hl=e=>{let t=e[0].dims,r=e[0].dims[2],o=k.size(t)/4,n=e[0].dataType,s=L(\"input\",n,t,4),u=L(\"bias\",n,[r],4),d=L(\"residual\",n,t,4),a=X(\"output\",n,t,4);return{name:\"BiasAdd\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)}}),getShaderSource:g=>`\n  const channels = ${r}u / 4;\n  ${g.declareVariables(s,u,d,a)}\n\n  ${g.mainStart()}\n    ${g.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n    let value = ${s.getByOffset(\"global_idx\")}\n      + ${u.getByOffset(\"global_idx % channels\")} + ${d.getByOffset(\"global_idx\")};\n    ${a.setByOffset(\"global_idx\",\"value\")}\n  }`}},pa=e=>{ml(e.inputs),e.compute(hl(e.inputs))}});var gl,$e,ma,ha,ga,ya,ba,wa,va,$a,xa,An,yl,Sa,Ca,Aa,Ia,kr,Ea,Dr,Ta,Oa,_a,Ra,Pa,Ma,Ba,ka,Da,Wa,za,Va,Ga,Na,Ua,La,Fa,In=H(()=>{\"use strict\";De();ge();Pe();ve();gl=(e,t,r,o,n,s)=>{let u=Math.ceil(t/4),d=\"\";typeof n==\"string\"?d=`${n}(a)`:d=n(\"a\");let a=L(\"inputData\",r,[u],4),m=X(\"outputData\",o,[u],4);return`\n  ${e.declareVariables(a,m)}\n\n  ${s??\"\"}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n\n    let a = ${a.getByOffset(\"global_idx\")};\n    ${m.setByOffset(\"global_idx\",d)}\n  }`},$e=(e,t,r,o,n,s=e.dataType)=>({name:t,shaderCache:{hint:n},getShaderSource:u=>gl(u,k.size(e.dims),e.dataType,s,r,o),getRunData:u=>({outputs:[{dims:e.dims,dataType:s}],dispatchGroup:{x:Math.ceil(k.size(u[0].dims)/64/4)}})}),ma=e=>{e.compute($e(e.inputs[0],\"Abs\",\"abs\"))},ha=e=>{e.compute($e(e.inputs[0],\"Acos\",\"acos\"))},ga=e=>{e.compute($e(e.inputs[0],\"Acosh\",\"acosh\"))},ya=e=>{e.compute($e(e.inputs[0],\"Asin\",\"asin\"))},ba=e=>{e.compute($e(e.inputs[0],\"Asinh\",\"asinh\"))},wa=e=>{e.compute($e(e.inputs[0],\"Atan\",\"atan\"))},va=e=>{e.compute($e(e.inputs[0],\"Atanh\",\"atanh\"))},$a=e=>ie(e),xa=(e,t)=>{let r;switch(t.to){case 10:r=\"vec4<f16>\";break;case 1:r=\"vec4<f32>\";break;case 12:r=\"vec4<u32>\";break;case 6:r=\"vec4<i32>\";break;case 9:r=\"vec4<bool>\";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute($e(e.inputs[0],\"Cast\",r,void 0,t.cacheKey,t.to))},An=(e,t)=>{let r=Me(e.inputs[0].dataType);e.compute($e(e.inputs[0],\"Clip\",o=>`clamp(${o}, clip_min_, clip_max_)`,`\n    const clip_min_: vec4<${r}> = vec4(${r}(${t.min}));\n    const clip_max_: vec4<${r}> = vec4(${r}(${t.max}));\n`,t.cacheKey),{inputs:[0]})},yl=e=>{let t=e.length>=2?e[1].getFloat32Array()[0]:Rr,r=e.length>=3?e[2].getFloat32Array()[0]:Pr;return ie({min:t,max:r})},Sa=e=>{let t=yl(e.inputs);An(e,t)},Ca=e=>{e.compute($e(e.inputs[0],\"Ceil\",\"ceil\"))},Aa=e=>{e.compute($e(e.inputs[0],\"Cos\",\"cos\"))},Ia=e=>{e.compute($e(e.inputs[0],\"Cosh\",\"cosh\"))},kr=e=>ie(e),Ea=(e,t)=>{e.compute($e(e.inputs[0],\"Elu\",r=>`elu_vf32(${r})`,`\n  const elu_alpha_: f32 = f32(${t.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},Dr=(e,t=\"f32\")=>`\nconst r0: ${t} = 0.3275911;\nconst r1: ${t} = 0.254829592;\nconst r2: ${t} = -0.284496736;\nconst r3: ${t} = 1.421413741;\nconst r4: ${t} = -1.453152027;\nconst r5: ${t} = 1.061405429;\n\nfn erf_vf32(v: ${e}) -> ${e} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,Ta=e=>{let t=Me(e.inputs[0].dataType);e.compute($e(e.inputs[0],\"Erf\",r=>`erf_vf32(${r})`,Dr(`vec4<${t}>`,t)))},Oa=e=>{e.compute($e(e.inputs[0],\"Exp\",\"exp\"))},_a=e=>{e.compute($e(e.inputs[0],\"Floor\",\"floor\"))},Ra=e=>{let t=Me(e.inputs[0].dataType);e.compute($e(e.inputs[0],\"Gelu\",r=>`0.5 * ${r} * (1.0 + erf_vf32(${r} * 0.7071067811865475))`,Dr(`vec4<${t}>`,t)))},Pa=(e,t)=>{e.compute($e(e.inputs[0],\"LeakyRelu\",r=>`select(leaky_relu_alpha_ * ${r}, ${r}, ${r} >= vec4<f32>(0.0))`,`const leaky_relu_alpha_: f32 = f32(${t.alpha});`,t.cacheKey))},Ma=e=>{e.compute($e(e.inputs[0],\"Not\",t=>`!${t}`))},Ba=e=>{e.compute($e(e.inputs[0],\"Neg\",t=>`-${t}`))},ka=e=>{e.compute($e(e.inputs[0],\"Reciprocal\",t=>`1.0/${t}`))},Da=e=>{e.compute($e(e.inputs[0],\"Relu\",t=>`select(vec4<f32>(0.0), ${t}, ${t} > vec4<f32>(0.0))`))},Wa=e=>{e.compute($e(e.inputs[0],\"Sigmoid\",t=>`(1.0 / (1.0 + exp(-${t})))`))},za=e=>{e.compute($e(e.inputs[0],\"Sin\",\"sin\"))},Va=e=>{e.compute($e(e.inputs[0],\"Sinh\",\"sinh\"))},Ga=e=>{e.compute($e(e.inputs[0],\"Sqrt\",\"sqrt\"))},Na=e=>{e.compute($e(e.inputs[0],\"Tan\",\"tan\"))},Ua=e=>{e.compute($e(e.inputs[0],\"Tanh\",\"tanh\"))},La=(e,t)=>(e.compute($e(e.inputs[0],\"ThresholdedRelu\",r=>`select(vec4<f32>(0.0), ${r}, ${r} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${t.alpha});`,t.cacheKey)),0),Fa=e=>{e.compute($e(e.inputs[0],\"Log\",\"log\"))}});var wl,vl,Ha,ja=H(()=>{\"use strict\";ge();ve();In();wl=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error(\"hidden state should be 2560, 5120 or 10240\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},vl=e=>{let t=e[0].dims.slice();t[2]=t[2]/2;let r=L(\"input\",e[0].dataType,e[0].dims,4),o=L(\"bias\",e[0].dataType,[e[0].dims[2]],4),n=X(\"output\",e[0].dataType,t,4),s=k.size(t)/4;return{name:\"BiasSplitGelu\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:d=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${d.declareVariables(r,o,n)}\n\n  ${Dr(\"vec4f\")}\n\n  ${d.mainStart()}\n    ${d.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${n.setByOffset(\"global_idx\",\"valueLeft * geluRight\")}\n  }`}},Ha=e=>{wl(e.inputs),e.compute(vl(e.inputs))}});var $l,xl,ot,Ka,qa,Ya,Xa,Ja,Za,Qa,ei,ti,ri,ni=H(()=>{\"use strict\";De();ge();ve();$l=(e,t,r,o,n,s,u,d,a,m,g)=>{let x=k.size(o),b=Math.ceil(x/4),w,v;typeof u==\"string\"?w=v=(M,D)=>`${u}((${M}),(${D}))`:typeof u==\"function\"?w=v=u:(w=u.scalar,v=u.vector);let y=\"\",S=X(\"outputData\",m,o,4),A=L(\"aData\",d,t,4),R=L(\"bData\",a,r,4);if(s){let M=D=>{let _=k.computeStrides(D),z=[];for(let F=D.length-1;F>=0;F--){let q=S.indicesGet(\"outputIndices\",F+o.length-D.length);z.push(`${_[F]}u * (${q} % ${D[F]}u)`)}return z.length>0?z.join(\"+\"):\"0u\"};y=`\n          fn calcOffsetA(outputIndices: ${S.type.indices}) -> u32 {\n            return ${M(t)};\n          }\n\n          fn calcOffsetB(outputIndices: ${S.type.indices}) -> u32 {\n            return ${M(r)};\n          }\n        `}let W;if(n)if(s){let M=k.size(t)===1,D=k.size(r)===1;M||D?W=S.setByOffset(\"global_idx\",v(M?`${A.type.value}(${A.getByOffset(\"0\")}.x)`:A.getByOffset(\"global_idx\"),D?`${R.type.value}(${R.getByOffset(\"0\")}.x)`:R.getByOffset(\"global_idx\"))):W=`\n            let outputIndices = ${S.offsetToIndices(\"global_idx * 4u\")};\n            let offsetA = calcOffsetA(outputIndices);\n            let offsetB = calcOffsetB(outputIndices);\n            ${S.setByOffset(\"global_idx\",v(A.getByOffset(\"offsetA / 4u\"),R.getByOffset(\"offsetB / 4u\")))}\n          `}else W=S.setByOffset(\"global_idx\",v(A.getByOffset(\"global_idx\"),R.getByOffset(\"global_idx\")));else{if(!s)throw new Error(\"no necessary to use scalar implementation for element-wise binary op implementation.\");let M=(D,_,z=\"\")=>{let F=`aData[indexA${_}][componentA${_}]`,q=`bData[indexB${_}][componentB${_}]`;return`\n            let outputIndices${_} = ${S.offsetToIndices(`global_idx * 4u + ${_}u`)};\n            let offsetA${_} = calcOffsetA(outputIndices${_});\n            let offsetB${_} = calcOffsetB(outputIndices${_});\n            let indexA${_} = offsetA${_} / 4u;\n            let indexB${_} = offsetB${_} / 4u;\n            let componentA${_} = offsetA${_} % 4u;\n            let componentB${_} = offsetB${_} % 4u;\n            ${D}[${_}] = ${z}(${w(F,q)});\n          `};m===9?W=`\n            var data = vec4<u32>(0);\n            ${M(\"data\",0,\"u32\")}\n            ${M(\"data\",1,\"u32\")}\n            ${M(\"data\",2,\"u32\")}\n            ${M(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:W=`\n            ${M(\"outputData[global_idx]\",0)}\n            ${M(\"outputData[global_idx]\",1)}\n            ${M(\"outputData[global_idx]\",2)}\n            ${M(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(A,R,S)}\n\n        ${g??\"\"}\n        ${y}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n        ${W}\n      }`},xl=(e,t,r,o,n,s,u=r.dataType)=>{let d=!k.areEqual(r.dims,o.dims),a=r.dims,m=k.size(r.dims),g=!1;if(d){let x=Qe.calcShape(r.dims,o.dims,!1);if(!x)throw new Error(\"Can't perform binary op on the given tensors\");a=x,m=k.size(a);let b=k.size(r.dims)===1,w=k.size(o.dims)===1,v=1;for(let y=1;y<a.length;y++){let S=r.dims[r.dims.length-y]??1,A=o.dims[o.dims.length-y]??1;if(S===A)v*=S;else break}(v%4===0||b||w)&&(g=!0)}else g=!0;return{name:e,shaderCache:{hint:t},getShaderSource:x=>$l(x,r.dims,o.dims,a,g,d,n,r.dataType,o.dataType,u,s),getRunData:()=>({outputs:[{dims:a,dataType:u}],dispatchGroup:{x:Math.ceil(m/64/4)}})}},ot=(e,t,r,o,n,s)=>{e.compute(xl(t,n??\"\",e.inputs[0],e.inputs[1],r,o,s))},Ka=e=>{ot(e,\"Add\",(t,r)=>`${t}+${r}`)},qa=e=>{ot(e,\"Div\",(t,r)=>`${t}/${r}`)},Ya=e=>{ot(e,\"Equal\",{scalar:(t,r)=>`u32(${t}==${r})`,vector:(t,r)=>`vec4<u32>(${t}==${r})`},void 0,void 0,9)},Xa=e=>{ot(e,\"Mul\",(t,r)=>`${t}*${r}`)},Ja=e=>{let t=L(\"input\",e.inputs[0].dataType,e.inputs[0].dims).type.value;ot(e,\"Pow\",{scalar:(o,n)=>`pow_custom(${o},${n})`,vector:(o,n)=>`pow_vector_custom(${o},${n})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${t===\"i32\"?\"round\":\"\"}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},Za=e=>{ot(e,\"Sub\",(t,r)=>`${t}-${r}`)},Qa=e=>{ot(e,\"Greater\",{scalar:(t,r)=>`u32(${t}>${r})`,vector:(t,r)=>`vec4<u32>(${t}>${r})`},void 0,void 0,9)},ei=e=>{ot(e,\"Less\",{scalar:(t,r)=>`u32(${t}<${r})`,vector:(t,r)=>`vec4<u32>(${t}<${r})`},void 0,void 0,9)},ti=e=>{ot(e,\"GreaterOrEqual\",{scalar:(t,r)=>`u32(${t}>=${r})`,vector:(t,r)=>`vec4<u32>(${t}>=${r})`},void 0,void 0,9)},ri=e=>{ot(e,\"LessOrEqual\",{scalar:(t,r)=>`u32(${t}<=${r})`,vector:(t,r)=>`vec4<u32>(${t}<=${r})`},void 0,void 0,9)}});var Cl,Al,Il,El,oi,ai,ii=H(()=>{\"use strict\";ge();Pe();ve();Cl=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\");let t=e[0].dataType,r=e[0].dims.length;for(let o of e){if(o.dataType!==t)throw new Error(\"input tensors should be one type\");if(o.dims.length!==r)throw new Error(\"input tensors should have the same shape\")}},Al=e=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,Il=(e,t)=>{let r=e.length,o=[];for(let n=0;n<r;++n){let s=t.setByOffset(\"global_idx\",e[n].getByIndices(\"indices\"));r===1?o.push(s):n===0?o.push(`if (inputIndex == ${n}u) { ${s} }`):n===r-1?o.push(`else { ${s} }`):o.push(`else if (inputIndex == ${n}) { ${s} }`)}return o.join(`\n`)},El=(e,t)=>{let r=e[0].dims.slice();if(t>=r.length||t<-1*r.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");let o=t<0?r.length+t:t,n=r.slice(0);for(let w=1;w<e.length;w++){let v=e[w].dims.slice();for(let y=0;y<r.length;y++)if(y===o)n[o]+=v[y];else if(r[y]!==v[y])throw new Error(\"non concat dimensions must match\")}let s=k.size(n),u=new Array(e.length),d=new Array(e.length),a=e[0].dataType,m=0;for(let w=0;w<e.length;++w)m+=e[w].dims[o],u[w]=m,d[w]=L(`input${w}`,a,e[w].dims);let g=X(\"output\",a,n),x=g.indicesGet(\"indices\",o),b=w=>`\n  ${w.declareVariables(...d,g)}\n\n  const sizeInConcatAxis = array<u32, ${u.length}>(${u.map(v=>`${v}u`).join(\",\")});\n  ${Al(u.length)}\n\n  ${w.mainStart()}\n    ${w.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n\n    var indices = ${g.offsetToIndices(\"global_idx\")};\n\n    let inputIndex = calculateInputIndex(${x});\n    if (inputIndex != 0u) {\n      ${x} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${Il(d,g)}\n  }`;return{name:\"Concat\",shaderCache:{hint:`${t}`},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:b}},oi=(e,t)=>{Cl(e.inputs),e.compute(El(e.inputs,t.axis))},ai=e=>ie({axis:e.axis})});var We,Wr,zr,Vr=H(()=>{\"use strict\";We=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},Wr=(e,t=!1,r=!1,o=3)=>\"\",zr=(e,t)=>`\n      ${e?\"value = value + getBiasByOutputCoords(coords);\":\"\"}\n      // TODO uncomment the following line when activation is supported above.\n      // ${t?\"value = activation(value, coords);\":\"\"}\n      `});var Gr,En=H(()=>{\"use strict\";Gr=`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`});var Nr,Ur,nr=H(()=>{\"use strict\";ge();Nr=(e,t=!1)=>{switch(e.activation){case\"Relu\":return{activationFunction:\"\",applyActivation:\"value = max(value, 0.0);\"};case\"Sigmoid\":return{activationFunction:\"\",applyActivation:\"value = (1.0 / (1.0 + exp(-value)));\"};case\"Clip\":return{activationFunction:`const clip_min_=f32(${e.clipMin});const clip_max_=f32(${e.clipMax});`,applyActivation:t?\"value = clamp(value, vec4(clip_min_), vec4(clip_max_));\":\"value = clamp(value, clip_min_, clip_max_);\"};default:return{activationFunction:\"\",applyActivation:\"\"}}},Ur=e=>{let t=e?.activation||\"\";if(t===\"Clip\"){let[r,o]=e?.activation_params||[Rr,Pr];return{activation:t,clipMax:o,clipMin:r,activationCacheKey:`${t}:${r},${o}`}}return{activation:t,activationCacheKey:t}}});var Tl,Ol,or,si,_l,ar,Rl,Lr,ir=H(()=>{\"use strict\";ge();ve();nr();Vr();Tl=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `,Ol=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${t===3?\"\":\"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];\"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached3[i] + acc[i];\"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached.w + acc[i];\"}\n        }`,or=(e,t,r=\"f32\",o,n=!1,s=32,u=!1,d=32)=>{let a=t[1]*e[1],m=t[0]*e[0],g=n?a:s,x=n?s:a,b=g/t[0],w=s/t[1];if(!((n&&b===4&&e[1]===4||!n&&(b===3||b===4))&&g%t[0]===0&&s%t[1]===0&&e[0]===4))throw new Error(`If transposeA ${n} is true, innerElementSize ${b} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${b} must be 3 or 4.\n  tileAWidth ${g} must be divisible by workgroupSize[0]${t[0]}. tileInner ${s} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${b}<${r}>, ${g/b}>, ${x}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${r}>, ${m/e[0]}>, ${s}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${b};\nconst tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${u?\"0\":\"i32(globalId.z)\"};\n  ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n  let globalRowStart = i32(workgroupId.y) * ${a};\n\n  let numTiles = ${u?`${Math.ceil(d/s)}`:\"(dimInner - 1) / tileInner + 1\"};\n  var kStart = ${u?`i32(globalId.z) * ${d}`:\"0\"};\n\n  var acc: array<vec4<${r}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${w};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${Tl(n,o)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${w}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${o?\", batchIndices\":\"\"});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${b===3?\"\":\"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];\"}\n\n          ${Ol(n,b)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},si=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?\", batchIndices\":\"\"});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?\", batchIndices\":\"\"});\n            `,_l=e=>e?\"let ACached = mm_Asub[k][tileRow + innerRow];\":\"let ACached = mm_Asub[tileRow + innerRow][k];\",ar=(e,t,r=\"f32\",o,n=!1,s=32,u=!1,d=32,a=!1)=>{let m=e[1]*t[1],g=e[0]*t[0],x=n?m:s,b=n?s:m;if(!(b%t[1]===0&&x%t[0]===0&&s%t[1]===0))throw new Error(`tileAHight ${b} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${x} must be divisible by workgroupSize[0]${t[0]}, tileInner ${s} must be divisible by workgroupSize[1]${t[1]}`);let w=b/t[1],v=x/t[0],y=s/t[1],S=a?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${m};\n    let globalColStart = i32(workgroupId.x) * ${g};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${b}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${x}; inputCol = inputCol + ${t[0]}) {\n          ${si(n,o)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${s}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${g}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${o?\", batchIndices\":\"\"});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${r}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${n?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${m};\n\nlet tileRowA = i32(localId.y) * ${w};\nlet tileColA = i32(localId.x) * ${v};\nlet tileRowB = i32(localId.y) * ${y};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${w}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${v}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${si(n,o)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${y}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${o?\", batchIndices\":\"\"});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${r}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${_l(n)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${r}, ${x}>, ${b}>;\n  var<workgroup> mm_Bsub : array<array<${r}, ${g}>, ${s}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${u?\"0\":\"i32(globalId.z)\"};\n    ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n    let numTiles = ${u?`${Math.ceil(d/s)}`:\"(dimInner - 1) / tileInner + 1\"};\n    var kStart = ${u?`i32(globalId.z) * ${d}`:\"0\"};\n\n    var acc : array<array<${r}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${S}\n  }\n`},Rl=(e,t,r,o,n,s=!1)=>{let u=n[0],d=n[1],a=n[2],m=o[0],g=o[1],x=o[2],b=o[3],w=xn(u,a),v=xn(d,a),y=Me(o[0].type.tensor),S=()=>{let W=g.rank,M=m.rank,D=`var aIndices: ${g.type.indices};`;for(let _=W-2-1,z=M-1;_>=0;_--,z--)D+=`\naIndices[${_}] = ${M>1?`batchIndices[${z}]`:\"batchIndices\"};`;return w.forEach(_=>{D+=`\naIndices[${_}] = 0;`}),D+=`\naIndices[${W-2}] = u32(row);\n                   aIndices[${W-1}] = u32(colIn);`,D},A=()=>{let W=x.rank,M=m.rank,D=`var bIndices: ${x.type.indices};`;for(let _=W-2-1,z=M-1;_>=0;_--,z--)D+=`\nbIndices[${_}] = ${M>1?`batchIndices[${z}]`:\"batchIndices\"};`;return v.forEach(_=>{D+=`\nbIndices[${_}] = 0;`}),D+=`\nbIndices[${W-2}] = u32(row);\n                   bIndices[${W-1}] = u32(colIn);`,D};return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${m.type.indices}) -> ${We(e,y)} {\n      var value = ${We(e,y)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${S()}\n        value = ${g.getByIndices(\"aIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${m.type.indices}) -> ${We(e,y)} {\n      var value = ${We(e,y)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${A()}\n        value = ${x.getByIndices(\"bIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${We(e,y)}) {\n      let col = colIn * ${e};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${s?\"bias[colIn]\":`${We(e,y)}(bias[row])`};`:\"\"}\n        ${r}\n        ${b.setByIndices(\"vec3<u32>(coords)\",\"value\")}\n      }\n    }\n    `},Lr=(e,t,r,o,n=!1)=>{let s=e[0].dims,u=e[1].dims,d=s.slice(0,-2),a=u.slice(0,-2),m=o?o.slice(0,-2):r.slice(0,-2),g=L(\"batchDims\",e[0].dataType,m),x=[g],b=[d,a,m],w=k.size(m),v=s[s.length-2],y=s[s.length-1],S=u[u.length-1],A=y%4===0&&S%4===0,{activationFunction:R,applyActivation:W}=Nr(t,A),M=v<=8?[4,1,1]:[4,4,1],D=[8,8,1],_=[Math.ceil(S/D[0]/M[0]),Math.ceil(v/D[1]/M[1]),Math.ceil(w/D[2]/M[2])],z=Me(e[0].dataType),F=A?4:1,q=L(\"a\",e[0].dataType,[...d,v,y/F],F),le=L(\"b\",e[1].dataType,[...a,y,S/F],F),B=X(\"result\",e[0].dataType,[w,v,S/F],F);x.push(q),x.push(le),x.push(B);let K=[q,le],xe=e.length>2,ae=Rl(F,xe,W,x,b,n);if(xe){let j=n?F:1;K.push(L(\"bias\",e[2].dataType,e[2].dims,j))}let we=j=>`\n  const dimAOuter: i32 = ${v};\n  const dimBOuter: i32 = ${S};\n  const dimInner: i32 = ${y};\n  ${j.declareVariables(...K,B)}\n  ${R}\n  ${ae}\n  ${A?or(M,D,z,g):ar(M,D,z,g)}\n                   ${g.impl()}`;return{name:\"MatMul\",shaderCache:{hint:t.activationCacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:_[0],y:_[1],z:_[2]}}),getShaderSource:we}}});var Pl,ui,li=H(()=>{\"use strict\";mt();ge();ve();Vr();En();ir();Pl=(e,t,r,o,n=!1,s,u=!1,d=4,a=4,m=4,g=\"f32\")=>{let x=le=>{switch(le){case 1:return\"resData = x[xIndex];\";case 3:return`resData = vec3<${g}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return\"resData = x[xIndex / 4];\";default:throw new Error(`innerElementSize ${le} is not supported.`)}},b=le=>{switch(le){case 1:return\"return w[row * wShape[3] + colIn];\";case 4:return\"return w[row * wShape[3] / 4 + colIn];\";default:throw new Error(`innerElementSize ${le} is not supported.`)}},w=e?`\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `:`\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `,v=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,y=e?\"xShape[1]\":\"xShape[2]\",S=e?\"xShape[2]\":\"xShape[3]\",A=e?\"row\":\"col\",R=e?\"col\":\"row\",W=`\n    let inChannels = wShape[2];\n    let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n    let outRow = ${A} / outWidth;\n    let outCol = ${A} % outWidth;\n\n    let WRow = ${R} / (filterDims[1] * inChannels);\n    let WCol = ${R} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${R} % inChannels;\n    var resData = ${We(d,g)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${y} && xCol >= 0 && xCol < ${S}) {\n      ${w}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${x(d)}\n    }\n    return resData;`,M=e?t&&o?`\n    let col = colIn * ${d};\n    ${W}`:`\n    let col = colIn * ${d};\n    if (row < dimAOuter && col < dimInner) {\n      ${W}\n    }\n    return ${We(d,g)}(0.0);`:o&&r?`\n    let col = colIn * ${d};\n    ${W}`:`\n    let col = colIn * ${d};\n    if (row < dimInner && col < dimBOuter) {\n      ${W}\n    }\n    return ${We(d,g)}(0.0);`,D=`${b(a)}`,_=We(m,g),z=e?We(d,g):We(a,g),F=e?We(a,g):We(d,g);return`\n    ${Wr(s,u,m===4,4)}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${z} {\n      ${e?M:D}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${F} {\n      ${e?D:M}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${_}) {\n      let col = colIn * ${m};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${v}\n      ${zr(n,s)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},ui=(e,t,r,o,n,s,u,d)=>{let a=t.format===\"NHWC\",m=a?e[0].dims[3]:e[0].dims[1],g=r[0],x=a?r[2]:r[3],b=a?r[1]:r[2],w=a?r[3]:r[1],v=a&&(m%4===0||m%3===0)&&w%4===0,y=a?w:x*b,S=a?x*b:w,A=[8,8,1],R=o<=8?[4,1,1]:[4,4,1],W=[Math.ceil(y/A[0]/R[0]),Math.ceil(S/A[1]/R[1]),Math.ceil(g/A[2]/R[2])];Ee(\"verbose\",()=>`[conv2d_mm_webgpu] dispatch = ${W}`);let M=v?a&&m%4!==0?3:4:R[0],D=A[1]*R[1],_=A[0]*R[0],z=Math.max(A[0]*M,A[1]),F=o%D===0,q=n%_===0,le=s%z===0,B=v?[M,4,4]:[1,1,1],K=Me(e[0].dataType),xe=[`@group(0) @binding(0) var<storage, read> x: array<${v&&M===4?`vec4<${K}>`:K}>;`,`@group(0) @binding(1) var<storage, read> w: array<${v?`vec4<${K}>`:K}>;`],ae=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${v?`vec4<${K}>`:K}) {\n        result[flatIndex] = ${v?`vec4<${K}>`:K}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${v?`vec4<${K}>`:K}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${v?\"/ 4\":\"\"}, value);\n      }`;return u&&(xe.push(`@group(0) @binding(2) var<storage, read> bias: array<${v?`vec4<${K}>`:K}>;`),ae+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${v?`vec4<${K}>`:K} {\n          return bias[coords.${a?\"w\":\"y\"}${v?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:W[0],y:W[1],z:W[2]}}),getShaderSource:()=>`\n        ${Gr}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${xe.join(\"\")}\n        @group(0) @binding(${xe.length}) var<storage, read_write> result: array<${v?`vec4<${K}>`:K}>;\n        //@group(0) @binding(${xe.length+1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${k.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[0]}, ${t.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${t.pads[0]}, ${t.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${n};\n        const dimInner : i32 = ${s};\n        ${ae}\n        ${Pl(a,F,q,le,u,t.activation.toLowerCase(),!1,B[0],B[1],B[2],K)}\n            ${v?or(R,A,K,void 0,!a,z):ar(R,A,K,void 0,!a,z,!1,void 0,d)}`}}});var Tn,di=H(()=>{\"use strict\";ge();ve();_n();nr();Tn=(e,t,r)=>{let o=e.length>2,n=o?\"value += b[output_channel];\":\"\",s=e[0].dims,u=e[1].dims,d=u[0]/t.group,{activationFunction:a,applyActivation:m}=Nr(t),g=t.format===\"NHWC\",x=On(s,u,t.dilations,t.pads,t.strides,g),b=k.size(x),w=X(\"output\",e[0].dataType,x),v=L(\"x\",e[0].dataType,s),y=L(\"w\",e[1].dataType,u),S=[v,y];o&&S.push(L(\"b\",e[2].dataType,e[2].dims));let A=R=>`\n  const strides: vec2<u32> = vec2(${t.strides[0]}u, ${t.strides[1]}u);\n  const pads: vec2<u32> = vec2(${t.pads[0]}u, ${t.pads[1]}u);\n\n  ${R.declareVariables(...S,w)}\n\n  ${a}\n\n  ${R.mainStart()}\n    ${R.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n\n    let outputIndices = ${w.offsetToIndices(\"global_idx\")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${g?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${g?1:2}], outputIndices[${g?2:3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${d}u;\n\n    var value: ${w.type.value} = ${w.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${u[1]}u; wInChannel++) {\n      let input_channel = group_id * ${u[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${u[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${t.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${s[g?1:2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${u[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${t.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${s[g?2:3]}u) {\n            continue;\n          }\n\n          let xVal = ${g?v.get(\"batch\",\"xHeight\",\"xWidth\",\"input_channel\"):v.get(\"batch\",\"input_channel\",\"xHeight\",\"xWidth\")};\n          let wVal = ${y.get(\"output_channel\",\"wInChannel\",\"wHeight\",\"wWidth\")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${n}\n    ${m}\n    ${w.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"GroupedConv\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r?r(x):x,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(b/64)}}),getShaderSource:A}}});var On,ci,Ml,pi,Rn,Bl,kl,Pn,_n=H(()=>{\"use strict\";ge();Pe();li();ir();di();nr();rr();On=(e,t,r,o,n,s)=>{let u=e[0],d=e.slice(s?1:2,s?3:4),a=d.length,m=t[0],x=t.slice(2).map((v,y)=>v+(v-1)*(r[y]-1)),w=d.map((v,y)=>v+o[y]+o[y+a]).map((v,y)=>Math.floor((v-x[y]+n[y])/n[y]));return w.splice(0,0,u),w.splice(s?3:1,0,m),w},ci=[2,3,1,0],Ml=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support conv 1D and 2D\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[1]*t.group;if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(e.length===3&&(e[2].dims.length!==1||e[1].dims[0]!==e[2].dims[0]))throw new Error(\"invalid bias\");let n=e[0].dims.length-2;if(t.dilations.length!==n)throw new Error(`dilations should be ${n}D`);if(t.strides.length!==n)throw new Error(`strides should be ${n}D`);if(t.pads.length!==n*2)throw new Error(`pads should be ${n*2}D`);if(t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\")},pi=(e,t)=>{let r=e.kernelShape.slice();for(let s=2;s<t[1].dims.length;++s)r[s-2]===0&&(r[s-2]=t[1].dims[s]);let o=e.pads.slice();Ct.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,r,o,e.format===\"NHWC\",e.autoPad);let n=Object.assign({},e);return Object.assign(n,{kernelShape:r,pads:o,cacheKey:e.cacheKey}),n},Rn=e=>{let t=Ur(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],n=e.dilations,s=e.group,u=e.kernel_shape,d=e.pads,a=e.strides,m=e.w_is_const();return ie({autoPad:o,format:r,dilations:n,group:s,kernelShape:u,pads:d,strides:a,wIsConst:m,...t})},Bl=(e,t,r)=>{let o=pi(r,t);if(r.group!==1){e.compute(Tn(t,o));return}let n=r.format===\"NHWC\",s=t.length===3,u=t[0].dims[n?1:2],d=t[0].dims[n?2:3],a=t[0].dims[n?3:1],m=t[1].dims[2],g=t[1].dims[3],x=On(t[0].dims,t[1].dims,r.dilations,o.pads,r.strides,n),b=x[n?1:2],w=x[n?2:3],v=x[n?3:1],y=n&&m===u&&g===d&&r.pads[0]===0&&r.pads[1]===0;if(y||m===1&&g===1&&r.dilations[0]===1&&r.dilations[1]===1&&r.strides[0]===1&&r.strides[1]===1&&r.pads[0]===0&&r.pads[1]===0){let _=x[0],z,F,q,le=[];if(n){let B=e.kernelCustomData.wT??e.compute(gt(t[1],ci),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];if(r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=B),y){let K=u*d*a;z=t[0].reshape([1,_,K]),F=B.reshape([1,K,v]),q=[1,_,v]}else z=t[0].reshape([_,u*d,a]),F=B.reshape([1,a,v]),q=[_,b*w,v];le.push(z),le.push(F)}else z=t[0].reshape([_,a,u*d]),F=t[1].reshape([1,v,a]),q=[_,v,b*w],le.push(F),le.push(z);s&&le.push(t[2]),e.compute(Lr(le,o,x,q,n),{inputs:le});return}let S=!0,A=e.kernelCustomData.wT??e.compute(gt(t[1],ci),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=A);let R=[t[0],A];s&&R.push(t[2]);let W=n?b*w:v,M=n?v:b*w,D=m*g*a;e.compute(ui(R,o,x,W,M,D,s,S),{inputs:R})},kl=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];e.inputs.length===3&&o.push(e.inputs[2]);let n=[0,t.pads[0],0,t.pads[1]],s=[1].concat(t.strides),u=[1].concat(t.dilations),d=[1].concat(t.kernelShape),a=pi({...t,pads:n,strides:s,dilations:u,kernelShape:d},o);e.compute(Tn(o,a,m=>r?[m[0],m[2],m[3]]:[]))},Pn=(e,t)=>{Ml(e.inputs,t),e.inputs[0].dims.length===3?kl(e,t):Bl(e,e.inputs,t)}});var Dl,fi,mi=H(()=>{\"use strict\";mt();ge();Vr();En();ir();Dl=(e,t=!1,r,o=!1,n=4)=>{let s=We(n,\"f32\"),u=A=>{switch(A){case 1:return\"return W[getIndexFromCoords4D(coord, wShape)];\";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${A} is not supported.`)}},d=e?`\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      `:`\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `,a=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,m=e?\"outBackprop[1]\":\"outBackprop[2]\",g=e?\"outBackprop[2]\":\"outBackprop[3]\",x=e?\"row\":\"col\",b=e?\"col\":\"row\",w=`\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      let outRow = ${x} / outWidth;\n      let outCol = ${x} % outWidth;\n\n      let WRow = ${b} / (filterDims[1] * inChannels);\n      let WCol = ${b} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${m}) || fract(xR) > 0.0) {\n        return ${s}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${g}) || fract(xC) > 0.0) {\n        return ${s}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${b} % inChannels;\n      ${d}\n      return x[getIndexFromCoords4D(coord, xShape)/${n}];`,v=e?`\n      let col = colIn * ${n};\n      if (row < dimAOuter && col < dimInner) {\n        ${w}\n      }\n      return ${s}(0.0);`:`\n      let col = colIn * ${n};\n      if (row < dimInner && col < dimBOuter) {\n        ${w}\n      }\n      return ${s}(0.0);`,y=`\n      let col = colIn * ${n};\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${e?\"row < dimInner && col < dimBOuter\":\"row < dimInner && col < dimAOuter\"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${u(n)}\n      }\n      return ${s}(0.0);\n      `;return`\n  ${Wr(r,o,n===4,4)}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${s} {\n    ${e?v:y}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${s} {\n    ${e?y:v}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${s}) {\n    let col = colIn * ${n};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${a}\n      ${zr(t,r)}\n      result[getIndexFromCoords4D(coords, outShape)/${n}] = value;\n    }\n  }`},fi=(e,t,r,o,n,s,u,d)=>{let a=t.format===\"NHWC\",m=a?e[0].dims[3]:e[0].dims[1],g=r[0],x=a?r[2]:r[3],b=a?r[1]:r[2],w=a?r[3]:r[1],v=a?m%4===0&&w%4===0:x%4===0&&w%4===0,y=a?w:x*b,S=a?x*b:w,A=v?[8,8,1]:[y<=4||S<=4?4:16,y>4&&S<=4?4:16,1],R=v?[4,4,1]:[y<=4?1:4,y>4&&S<=4?1:4,1],W=[Math.ceil(y/A[0]/R[0]),Math.ceil(S/A[1]/R[1]),Math.ceil(g/A[2]/R[2])];Ee(\"verbose\",()=>`[conv_backprop_mm_webgpu] dispatch = ${W}`);let M=v?4:1,D=Math.max(A[0]*M,A[1]),_=[`@group(0) @binding(0) var<storage, read> x: array<${v?\"vec4<f32>\":\"f32\"}>;`,\"@group(0) @binding(1) var<storage, read> W: array<f32>;\"],z=\"\";return u&&(_.push(`@group(0) @binding(2) var<storage, read> bias: array<${v?\"vec4<f32>\":\"f32\"}>;`),z+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${v?\"vec4<f32>\":\"f32\"} {\n          return bias[coords.${a?\"w\":\"y\"}${v?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DTransposeMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:W[0],y:W[1],z:W[2]}}),getShaderSource:()=>`\n        ${Gr}\n        ${_.join(`\n`)}\n        @group(0) @binding(${_.length}) var<storage, read_write> result: array<${v?\"vec4<f32>\":\"f32\"}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${k.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[a?1:2]}, ${t.kernelShape[a?2:3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${t.dilations[0]<=1?0:(t.kernelShape[a?1:2]-1)*(t.dilations[0]-1)},\n              ${t.dilations[1]<=1?0:(t.kernelShape[a?2:3]-1)*(t.dilations[1]-1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${t.pads[0]+t.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${t.pads[1]+t.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${n};\n        const dimInner : i32 = ${s};\n        ${z}\n        ${Dl(a,u,t.activation.toLowerCase(),!1,M)}\n        ${v?or(R,A,\"f32\",void 0,!a,D):ar(R,A,\"f32\",void 0,!a,D,!1,void 0,d)}`}}});var Wl,Mn,hi=H(()=>{\"use strict\";mt();ge();ve();Wl=(e,t,r,o,n,s,u=!1,d)=>{let a=r.format===\"NHWC\",m=a?1:2,g=a?2:3,x=a?3:1,b=k.size(o),w=u?2:1,v=r.group,y=t[1].dims,S=y[0]/v,A=y[1],R=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${u?`vec4<${d}>`:d}) {\n    result[flatIndex] = ${u?`vec4<${d}>`:d}(value);\n  }`;n&&(R+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${u?`vec4<${d}>`:d} {\n      return bias[coords.${a?\"w\":\"y\"}${u?\"/ 4\":\"\"}];\n    }`);let W=u?4:1,M=L(\"W\",t[1].dataType,t[1].dims,W),D=L(\"Dy\",t[0].dataType,t[0].dims,W),_=[D,M];n&&_.push(L(\"bias\",t[2].dataType,[o[x]],W));let z=X(\"result\",t[0].dataType,o,W),F=`{\n        let batch: u32 = ${s?\"global_id.z\":\"workgroup_id.z\"} / outShape[1];\n        let r = ${s?\"global_id.z\":\"workgroup_id.z\"} % outShape[1];\n        let c = ${s?\"global_id.y\":\"workgroup_id.y\"} * ${w};\n        let d1: u32 = ${s?\"global_id.x\":\"workgroup_id.x\"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${d}>, ${w}>;\n        for (var i = 0; i < ${w}; i++) {\n          dotProd[i] = vec4<${d}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${d}(dyCorner.x) + ${d}(wR)) / ${d}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${d}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${d}(dyCorner.y) + ${d}(wC)) / ${d}(strides.y);\n            let dyC2 = (${d}(dyCorner.y) + 1.0 + ${d}(wC)) / ${d}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${d}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${d}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${D.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${D.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n\n                dotProd[1] = dotProd[1] + vec4<${d}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${x}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${D.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${M.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${D.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${w}; i = i + 1) {\n          let value = dotProd[i] + ${n?\"bias[c+i]\":\"0.0\"};\n          ${z.set(\"batch\",\"r\",\"c + i\",\"d1\",\"value\")};\n        }\n      }`,q=`\n          let outputIndices = ${z.offsetToIndices(\"global_idx\")};\n          let batch = ${z.indicesGet(\"outputIndices\",0)};\n          let d1 = ${z.indicesGet(\"outputIndices\",x)};\n          let r = ${z.indicesGet(\"outputIndices\",m)};\n          let c = ${z.indicesGet(\"outputIndices\",g)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${A};\n          let wOutChannel = d1 - groupId * ${A};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${d}(dyRCorner) + ${d}(wR)) / ${d}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${d}(outBackprop[${m}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${d}(dyCCorner) + ${d}(wC)) / ${d}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${d}(outBackprop[${g}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${S};\n              for (var d2: u32 = 0; d2 < ${S}; d2 = d2 + 1) {\n                let xValue = ${a?D.get(\"batch\",\"idyR\",\"idyC\",\"inputChannel\"):D.get(\"batch\",\"inputChannel\",\"idyR\",\"idyC\")};\n                let wValue = ${M.get(\"inputChannel\",\"wOutChannel\",\"u32(wRPerm)\",\"u32(wCPerm)\")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${n?\"bias[d1]\":\"0.0\"};\n          ${z.setByOffset(\"global_idx\",\"value\")};\n        `;return`\n  ${e.declareVariables(..._,z)}\n  ${R}\n  const outShape : vec4<u32> = vec4<u32>(${o.join(\",\")});\n  const outBackprop : vec4<u32> = vec4<u32>(${t[0].dims.join(\",\")});\n  const strides : vec2<u32> = vec2<u32>(${r.strides[0]}, ${r.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${r.kernelShape[a?1:2]}, ${r.kernelShape[a?2:3]});\n  const dilations : vec2<u32> = vec2<u32>(${r.dilations[0]}, ${r.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${r.dilations[0]<=1?0:(r.kernelShape[a?1:2]-1)*(r.dilations[0]-1)},\n          ${r.dilations[1]<=1?0:(r.kernelShape[a?2:3]-1)*(r.dilations[1]-1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${r.pads[0]+r.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${r.pads[1]+r.pads[3]})/2);\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)};\n  ${u?F:q}}`},Mn=(e,t,r)=>{let o=e.length>2,n=t.outputShape,s=k.size(n),u=[Math.ceil(s/64),1,1];Ee(\"verbose\",()=>`[conv2d_backprop_webgpu] dispatch = ${u}`);let d=Me(e[0].dataType);return{name:\"ConvTranspose2D\",shaderCache:{hint:t.cacheKey},getRunData:()=>({dispatchGroup:{x:u[0],y:u[1],z:u[2]},outputs:[{dims:r?r(n):n,dataType:e[0].dataType}]}),getShaderSource:a=>Wl(a,e,t,n,o,u[1]===1&&u[2]===1,!1,d)}}});var zl,Vl,Gl,gi,yi,Nl,Ul,Ll,Fl,bi,wi=H(()=>{\"use strict\";Pe();mi();hi();nr();rr();zl=(e,t,r,o,n,s)=>(e-1)*t+r+(o-1)*n+1-s,Vl=(e,t,r,o,n)=>{let s=Math.floor(e/2);t===\"SAME_UPPER\"?(r[o]=s,r[n]=e-s):t===\"SAME_LOWER\"&&(r[o]=e-s,r[n]=s)},Gl=(e,t,r,o,n,s,u,d,a,m)=>{let g=e.length-2,x=m.length===0;if(a.length===0)for(let v=0;v<g;++v)a.push(0);let b=e[0],w=t[d?3:1]*n;for(let v=0,y=e.length-g-(d?1:0);v<g;++v,++y){let S=e[y],A=x?S*u[v]:m[v],R=zl(S,u[v],s[v],t[y],r[v],A);Vl(R,o,s,v,v+g),x&&m.push(u[v]*(S-1)+a[v]+(t[y]-1)*r[v]+1-s[v]-s[v+g])}m.splice(0,0,b),m.splice(d?3:1,0,w)},gi=(e,t)=>{let r=e.kernelShape.slice();if(e.kernelShape.length===0||e.kernelShape.reduce((b,w)=>b*w,1)===0){r.length=0;for(let b=2;b<t[1].dims.length;++b)r.push(t[1].dims[b])}let o=e.format===\"NHWC\";r.splice(0,0,t[1].dims[0]),r.splice(o?3:1,0,t[1].dims[1]);let n=e.pads.slice(),s=e.outputShape.slice(),u=e.outputPadding.slice(),d=t[0].dims,a=e.dilations.slice();if(a.reduce((b,w)=>b+w,0)===0){let b=t[0].dims.length-2;a=new Array(b).fill(1)}let m=e.strides.slice();if(m.reduce((b,w)=>b+w,0)===0){let b=t[0].dims.length-2;m=new Array(b).fill(1)}Gl(d,r,a,e.autoPad,e.group,n,m,o,u,s);let g=Object.assign({},e),x=e.cacheKey+[r.join(\"n,\"),n.join(\",\"),m.join(\",\"),u.join(\",\"),s.join(\",\"),a.join(\",\")].join(\"_\");return Object.assign(g,{kernelShape:r,pads:n,outputPadding:u,outputShape:s,dilations:a,strides:m,cacheKey:x}),g},yi=e=>{let t=Ur(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][typeof e.autoPad>\"u\"?0:e.autoPad],n=e.dilations,s=e.group,u=e.kernelShape,d=e.pads,a=e.strides,m=e.wIsConst(),g=e.outputPadding,x=e.outputShape;return ie({autoPad:o,format:r,dilations:n,group:s,kernelShape:u,outputPadding:g,outputShape:x,pads:d,strides:a,wIsConst:m,...t})},Nl=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support 2-dimensional conv\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[0];if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");let n=e[1].dims[1]*t.group;if(e.length===3&&(e[2].dims.length!==1||e[2].dims[0]!==n))throw new Error(\"invalid bias\");let s=e[0].dims.length-2;if(t.dilations.reduce((g,x)=>g+x,0)>0&&t.dilations.length!==s)throw new Error(`dilations should be ${s}D`);if(t.strides.reduce((g,x)=>g+x,0)>0&&t.strides.length!==s)throw new Error(`strides should be ${s}D`);if(t.pads.reduce((g,x)=>g+x,0)>0&&t.pads.length!==s*2)throw new Error(`pads should be ${s*2}D`);if(t.outputPadding.length!==s&&t.outputPadding.length!==0)throw new Error(`output_padding should be ${s}D`);if(t.kernelShape.reduce((g,x)=>g+x,0)>0&&t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(t.outputShape.length!==0&&t.outputShape.length!==e[0].dims.length-2)throw new Error(\"invalid output shape\")},Ul=[2,3,1,0],Ll=(e,t,r)=>{let o=gi(r,t),n=r.format===\"NHWC\",s=t.length===3;if(o.group!==1){e.compute(Mn(t,o));return}let u=o.outputShape,d=u[n?1:2],a=u[n?2:3],m=u[n?3:1],g=t[1].dims[2],x=t[1].dims[3],b=t[0].dims[n?3:1],w=n?d*a:m,v=n?m:d*a,y=g*x*b,S=!0,A=e.kernelCustomData.wT??e.compute(gt(t[1],Ul),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=A);let R=[t[0],A];s&&(!n&&t[2].dims.length===1?R.push(t[2].reshape([t[2].dims[0],1,1])):R.push(t[2])),e.compute(fi(R,o,u,w,v,y,s,S),{inputs:R})},Fl=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];o.length===3&&o.push(e.inputs[2]);let n=t.kernelShape;(n.length===0||n[0]===0)&&(n=[e.inputs[1].dims[2]]);let s=t.dilations;(s.length===0||s[0]===0)&&(s=[1]);let u=t.strides;(u.length===0||u[0]===0)&&(u=[1]);let d=t.pads;d.length===0&&(d=[0,0]),d=[0,d[0],0,d[1]],u=[1].concat(u),s=[1].concat(s),n=[1].concat(n);let a=gi({...t,pads:d,strides:u,dilations:s,kernelShape:n},o);e.compute(Mn(o,a,m=>r?[m[0],m[2],m[3]]:[m[0],m[1],m[3]]))},bi=(e,t)=>{Nl(e.inputs,t),e.inputs[0].dims.length===3?Fl(e,t):Ll(e,e.inputs,t)}});var Bn,Fr,vi,Hl,jl,kn,Dn,Kl,$i,xi,Si=H(()=>{\"use strict\";ge();Pe();ve();Bn=\"[a-zA-Z]|\\\\.\\\\.\\\\.\",Fr=\"(\"+Bn+\")+\",vi=\"^\"+Fr+\"$\",Hl=\"(\"+Fr+\",)*\"+Fr,jl=\"^\"+Hl+\"$\",kn=class{constructor(t=-1){this.symbolToIndices=new Map,this.inputIndex=t}addSymbol(t,r){let o=this.symbolToIndices.get(t);o===void 0?o=[r]:o.push(r),this.symbolToIndices.set(t,o)}},Dn=class{constructor(t,r){this.equation=r;this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[o,n]=r.includes(\"->\")?r.split(\"->\",2):[r,\"\"];if(!o.match(RegExp(jl)))throw new Error(\"Invalid LHS term\");if(o.split(\",\").forEach((d,a)=>{let m=t[a].dims.slice();if(!d.match(RegExp(vi)))throw new Error(\"Invalid LHS term\");let g=this.processTerm(d,!0,m,a);this.lhs.push(g)}),n===\"\")n+=[...this.symbolToInfo.entries()].filter(([d,a])=>a.count===1||d===\"...\").map(([d])=>d).join(\"\");else if(!n.match(RegExp(Fr)))throw new Error(\"Invalid RHS\");n.match(RegExp(Bn,\"g\"))?.forEach(d=>{if(d===\"...\")this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let a=this.symbolToInfo.get(d);if(a===void 0)throw new Error(\"Invalid RHS symbol\");this.outputDims.push(a.dimValue)}}),this.rhs=this.processTerm(n,!0,this.outputDims)}addSymbol(t,r,o){let n=this.symbolToInfo.get(t);if(n!==void 0){if(n.dimValue!==r&&n.count!==1)throw new Error(\"Dimension mismatch\");n.count++,n.inputIndices.push(o)}else n={count:1,dimValue:r,inputIndices:[o]};this.symbolToInfo.set(t,n)}processTerm(t,r,o,n=-1){let s=o.length,u=!1,d=[],a=0;if(!t.match(RegExp(vi))&&!r&&t!==\"\")throw new Error(\"Invalid LHS term\");let m=t.match(RegExp(Bn,\"g\")),g=new kn(n);return m?.forEach((x,b)=>{if(x===\"...\"){if(u)throw new Error(\"Only one ellipsis is allowed per input term\");u=!0;let w=s-m.length+1;if(w<0)throw new Error(\"Ellipsis out of bounds\");if(d=o.slice(a,a+w),this.hasEllipsis){if(this.ellipsisDims.length!==d.length||this.ellipsisDims.toString()!==d.toString())throw new Error(\"Ellipsis dimensions mismatch\")}else if(r)this.hasEllipsis=!0,this.ellipsisDims=d;else throw new Error(\"Ellipsis must be specified in the LHS\");for(let v=0;v<d.length;v++){let y=String.fromCharCode(\"0\".charCodeAt(0)+b);g.addSymbol(y,b+v),this.addSymbol(y,o[a++],n)}}else g.addSymbol(x,b),this.addSymbol(x,o[a++],n)}),g}},Kl=(e,t)=>{let r=e[0].dataType,o=new Array(e.length);for(let W=0;W<e.length;++W)o[W]=L(`input${W}`,r,e[W].dims);let n=t.outputDims,s=k.size(n),u=X(\"output\",r,n),d=[],a=Array.from(t.rhs.symbolToIndices.keys()),m=\"var prod = 1.0;\",g=\"var sum = 0.0;\",x=\"sum += prod;\",b=[],w=[],v=[],y=[],S=t.symbolToInfo.size===a.length;t.symbolToInfo.forEach((W,M)=>{if(a.includes(M)){let D=a.indexOf(M);t.lhs.forEach((_,z)=>{if(W.inputIndices.includes(z)){let F=_.symbolToIndices.get(M);if(F===void 0)throw new Error(\"Invalid symbol error\");F.forEach(q=>{d.push(`${o[z].indicesSet(`input${z}Indices`,q,u.indicesGet(\"outputIndices\",D))}`)})}})}else t.lhs.forEach((D,_)=>{let z=t.symbolToInfo.get(M);if(z===void 0)throw new Error(\"Invalid symbol error\");if(z.inputIndices.includes(_)){let F=D.symbolToIndices.get(M);if(F===void 0)throw new Error(\"Invalid symbol error\");F.forEach(q=>{b.push(`${o[_].indicesSet(`input${_}Indices`,q,`${M}`)}`)}),y.push(`prod *= ${o[_].getByIndices(`input${_}Indices`)};`)}}),w.push(`for(var ${M}: u32 = 0; ${M} < ${t.symbolToInfo.get(M)?.dimValue}; ${M}++) {`),v.push(\"}\")});let A=S?[...d,`let sum = ${o.map((W,M)=>W.getByIndices(`input${M}Indices`)).join(\" * \")};`]:[...d,g,...w,...b,m,...y,x,...v],R=W=>`\n      ${W.declareVariables(...o,u)}\n\n      ${W.mainStart()}\n        ${W.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n        var outputIndices = ${u.offsetToIndices(\"global_idx\")};\n        ${o.map((M,D)=>`var input${D}Indices: ${o[D].type.indices};`).join(`\n`)}\n        ${A.join(`\n`)};\n        ${u.setByOffset(\"global_idx\",\"sum\")};\n      }`;return{name:\"Einsum\",shaderCache:{hint:t.equation},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:R}},$i=(e,t)=>{let r=new Dn(e.inputs,t.equation);e.compute(Kl(e.inputs,r))},xi=e=>{let t=e.equation.replace(/\\s+/g,\"\");return ie({equation:t})}});var ql,Ci,Yl,Xl,Ai,Ii=H(()=>{\"use strict\";ge();ve();ql=e=>{if(!e||e.length!==2)throw new Error(\"Expand requires 2 input.\");let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=r.length<t.length?0:r.length-t.length,n=t.length<r.length?0:t.length-r.length;for(;o<r.length&&n<t.length;++o,++n)if(r[o]!==t[n]&&r[o]!==1&&t[n]!==1)throw new Error(\"Expand requires shape to be broadcastable to input\")},Ci=(e,t)=>{let r=e.length-t.length,o=[];for(let n=0;n<r;++n)o.push(e[n]);for(let n=0;n<t.length;++n)o.push(t[n]===1?e[n+r]:t[n]);return o},Yl=(e,t)=>e.length>t.length?Ci(e,t):Ci(t,e),Xl=e=>{let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=Yl(t,r),n=k.size(o),s=e[0].dataType,u=L(\"input\",s,t),d=X(\"output\",s,o),a=m=>`\n  const inputShape = ${u.indices(...t)};\n  ${m.declareVariables(u,d)}\n  ${m.mainStart()}\n  ${m.guardAgainstOutOfBoundsWorkgroupSizes(n)}\n    let outputIndices = ${d.offsetToIndices(\"global_idx\")};\n    var inputIndices: ${u.type.indices};\n    for (var i = 0; i < ${t.length}; i++) {\n      if (${u.indicesGet(\"inputShape\",\"i\")} == 1) {\n        ${u.indicesSet(\"inputIndices\",\"i\",0)}\n      } else {\n        ${u.indicesSet(\"inputIndices\",\"i\",d.indicesGet(\"outputIndices\",`i + ${o.length-t.length}`))}\n      }\n    }\n    ${d.setByOffset(\"global_idx\",u.getByIndices(\"inputIndices\"))}\n  }`;return{name:\"Expand\",shaderCache:{hint:`${o}`},getShaderSource:a,getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(n/64)}})}},Ai=e=>{ql(e.inputs),e.compute(Xl(e.inputs),{inputs:[0]})}});var Jl,Zl,Ei,Ti,Oi=H(()=>{\"use strict\";ge();Pe();ve();Jl=e=>{if(!e||e.length!==2)throw new Error(\"Gather requires 2 inputs.\")},Zl=(e,t)=>{let r=e[0].dims,o=e[1].dims,n=r.length,s=k.normalizeAxis(t.axis,n),u=r.slice(0);u.splice(s,1,...o);let d=r[s],a=k.size(u),m=L(\"data\",e[0].dataType,e[0].dims),g=L(\"inputIndices\",e[1].dataType,e[1].dims),x=X(\"output\",e[0].dataType,u),b=()=>{let v=o.length,y=`var indicesIndices  = ${g.type.indices}(0);`;for(let S=0;S<v;S++)y+=`${v>1?`indicesIndices[${S}]`:\"indicesIndices\"} = ${u.length>1?`outputIndices[${s+S}]`:\"outputIndices\"};`;y+=`\n        var idx = ${g.getByIndices(\"indicesIndices\")};\n        if (idx < 0) {\n          idx = idx + ${d};\n        }\n        var dataIndices = ${m.type.indices}(0);\n      `;for(let S=0,A=0;S<n;S++)S===s?(y+=`${n>1?`dataIndices[${S}]`:\"dataIndices\"} = u32(idx);`,A+=v):(y+=`${n>1?`dataIndices[${S}]`:\"dataIndices\"} = ${u.length>1?`outputIndices[${A}]`:\"outputIndices\"};`,A++);return y},w=v=>`\n      ${v.declareVariables(m,g,x)}\n      ${v.mainStart()}\n        ${v.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n        let outputIndices = ${x.offsetToIndices(\"global_idx\")};\n        ${b()};\n        let value = ${m.getByIndices(\"dataIndices\")};\n        ${x.setByOffset(\"global_idx\",\"value\")};\n      }`;return{name:\"Gather\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:u,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:w}},Ei=e=>ie({axis:e.axis}),Ti=(e,t)=>{let r=e.inputs;Jl(r),e.compute(Zl(e.inputs,t))}});var Ql,ed,_i,Ri,Pi=H(()=>{\"use strict\";ge();Pe();ve();Ql=e=>{if(!e||e.length!==2)throw new Error(\"GatherElements requires 2 inputs.\");if(e[0].dims.length<1)throw new Error(\"GatherElements requires that the data input be rank >= 1.\");if(e[0].dims.length!==e[1].dims.length)throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`)},ed=(e,t)=>{let r=e[0].dims,o=e[0].dataType,n=r.length,s=k.computeStrides(r),u=k.size(r),d=e[1].dims,a=e[1].dataType,m=k.size(d),g=k.normalizeAxis(t.axis,n),x=r[g],b=d.slice(0),w=k.size(b),v=L(\"input\",o,r),y=L(\"indices\",a,[m]),S=X(\"output\",o,b),A=R=>`\n      const inputStrides = array<u32, ${s.length}>(${s.map(W=>`${W}u`).join(\",\")});\n      ${R.declareVariables(v,y,S)}\n      ${R.mainStart()}\n      ${R.guardAgainstOutOfBoundsWorkgroupSizes(w)}\n\n      let outputIndices = ${S.offsetToIndices(\"global_idx\")};\n\n      var idx = ${y.getByOffset(\"global_idx\")};\n      if (idx < 0) {\n        idx = idx + ${x};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${r.length}; i++) {\n        if (i == ${g}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${S.indicesGet(\"outputIndices\",\"i\")} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${u}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;return{name:\"GatherElements\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:b,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(w/64)}}),getShaderSource:A}},_i=e=>ie({axis:e.axis}),Ri=(e,t)=>{let r=e.inputs;Ql(r),e.compute(ed(e.inputs,t))}});var td,rd,nd,Mi,Bi,ki=H(()=>{\"use strict\";ge();Pe();ve();td=e=>{if(!e)throw new Error(\"Input is missing\");if(e.length<2||e.length>3)throw new Error(\"Invaid input number.\");if(e.length===3&&e[2].dims.length>2)throw new Error(\"Invalid input shape of C\");if(e[0].dataType!==e[1].dataType||e.length===3&&e[0].dataType!==e[2].dataType)throw new Error(\"Input types are mismatched\")},rd=(e,t,r)=>{if(r.length===0)return\"0u\";let o=r.length===1&&e!==1||r.length===2&&r[0]!==e,n=r[r.length-1]!==t,s=\"0u\";return o||(s+=`+ m * ${r[r.length-1]}u`),n||(s+=\"+n\"),s},nd=(e,t)=>{let r=e[0].dims.slice(),o=e[1].dims.slice(),[n,s,u]=_r.getShapeOfGemmResult(r,t.transA,o,t.transB,e.length===3?e[2].dims:void 0),d=[n,s];if(!d)throw new Error(\"Can't use gemm on the given tensors\");let a=k.size(d),m=\"\";t.transA&&t.transB?m=\"value += a[k * M + m] * b[n * K + k];\":t.transA&&!t.transB?m=\"value += a[k * M + m] * b[k * N + n];\":!t.transA&&t.transB?m=\"value += a[m * K + k] * b[n * K + k];\":!t.transA&&!t.transB&&(m=\"value += a[m * K + k] * b[k * N + n];\");let g=Me(e[0].dataType),x=t.alpha===1?\"\":\"value *= alpha;\",b=e.length===3?`value += beta * c[${rd(n,s,e[2].dims)}];`:\"\",w=[`@group(0) @binding(0) var<storage, read> a : array<${g}>;`,`@group(0) @binding(1) var<storage, read> b : array<${g}>;`];e.length===3&&w.push(`@group(0) @binding(2) var<storage, read> c : array<${g}>;`);let v=y=>`\n  const M: u32 = ${n}u;\n  const N: u32 = ${s}u;\n  const K: u32 = ${u}u;\n  const alpha = ${g}(${t.alpha});\n  const beta = ${g}(${t.beta});\n\n  ${w.join(`\n`)}\n  @group(0) @binding(${e.length}) var<storage, read_write> output : array<${g}>;\n\n  ${y.mainStart()}\n    ${y.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${g}(0);\n    for (var k: u32 = 0u; k<${u}u; k++) {\n      ${m}\n    }\n\n    ${x}\n    ${b}\n    output[global_id.x] = value;\n\n  }`;return{name:\"Gemm\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:v}},Mi=(e,t)=>{td(e.inputs),e.compute(nd(e.inputs,t))},Bi=e=>ie(e)});var od,ad,id,sd,Di,Wi,zi=H(()=>{\"use strict\";De();ge();Pe();ve();od={name:\"InstanceNormalization\"},ad=(e,t)=>{let r=e[0].dims,o=r,n=2,s=k.sizeToDimension(r,n),u=k.sizeFromDimension(r,n),d=r[1],a=L(\"x\",e[0].dataType,[r[0],r[1],u]),m=L(\"scale\",e[1].dataType,e[1].dims),g=L(\"bias\",e[2].dataType,e[2].dims),x=X(\"output\",e[0].dataType,[r[0],r[1],u]),b=[a,m,g,x],w=a.type.value,v=64,y=S=>`\n\n  const C: u32 = ${d};\n  const normSize: u32 = ${u};\n  const epsilon: f32 = ${t.epsilon};\n  var<workgroup> meanShared : ${w};\n  var<workgroup> squaredNormShared : ${w};\n  var<workgroup> workgroupShared : array<${w}, ${v}>;\n  const workgroupSize = ${v}u;\n  ${S.declareVariables(...b)}\n  ${S.mainStart(v)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${w} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${a.get(\"batch\",\"channel\",\"h\")};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${w}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${a.get(\"batch\",\"channel\",\"h\")} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${w}(normSize) + epsilon);\n    let channelScale = invStdDev * ${m.getByOffset(\"channel\")};\n    let channelShift = ${g.getByOffset(\"channel\")} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${a.get(\"batch\",\"channel\",\"h\")} * channelScale + channelShift;\n      ${x.set(\"batch\",\"channel\",\"h\",\"value\")};\n    }\n  }`;return{...od,shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:s}}),getShaderSource:y}},id=(e,t,r,o,n,s,u,d)=>{let a=lt(u),m=L(\"input\",t.dataType,t.dims,a),g=L(\"scale\",r.dataType,r.dims,a),x=L(\"bias\",o.dataType,o.dims,a),b=64,w=a===1?\"vec2f\":`mat2x${a}f`,v=a===1?\"f32\":`vec${a}f`,y=(D,_)=>`${w}(${D}, ${_})`,S=n*u/a,A=Math.ceil(s/b),R=D=>`\n  const H: u32 = ${s};\n  const C: u32 = ${u/a};\n  const imageSize: u32 = ${s*u/a};\n\n  ${D.declareVariables(m)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${w}>;\n\n  ${D.mainStart(b)}\n    let currentImageNumber = global_idx / ${b} / C;\n    let currentChannelNumber = (global_idx / ${b}) % C;\n    let wgId = global_idx % ${b};\n    let wgOffset = wgId * ${A};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${A}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${qe(\"f32\",a)};\n    var squaredSum = ${qe(\"f32\",a)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${v}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${y(\"sum\",\"squaredSum\")};\n  }`,W=e.compute({name:\"InstanceNormComputeMean\",shaderCache:{hint:JSON.stringify({components:a,n,h:s,c:u})},getRunData:()=>({outputs:[{dims:[n,u,b,2],dataType:1}],dispatchGroup:{x:n*u/a}}),getShaderSource:R},{inputs:[t],outputs:[-1]})[0],M=D=>`\n  const H: u32 = ${s};\n  const C: u32 = ${u/a};\n  const imageSize: u32 = ${b*u/a};\n  const epsilon: f32 = ${d};\n\n  @group(0) @binding(0) var<storage, read> input : array<${w}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${g.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${x.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${w}>;\n\n  ${D.mainStart()}\n    ${D.guardAgainstOutOfBoundsWorkgroupSizes(S)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${qe(\"f32\",a)};\n    var squaredSum = ${qe(\"f32\",a)};\n    for (var i: u32 = 0; i < ${b}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${b}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${v}(scale[currentChannelNumber]);\n    let channelShift = ${v}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${y(\"channelScale\",\"channelShift\")};\n  }`;return e.compute({name:\"InstanceNormComputeChannelScaleShift\",shaderCache:{hint:JSON.stringify({components:a,n,h:s,c:u,epsilon:d})},getRunData:()=>({outputs:[{dims:[n,u,2],dataType:1}],dispatchGroup:{x:Math.ceil(S/64)}}),getShaderSource:M},{inputs:[W,r,o],outputs:[-1]})[0]},sd=(e,t,r)=>{let o=t[0].dims,n=o,s=o[0],u=o[o.length-1],d=k.sizeFromDimension(o,1)/u,a=lt(u),m=k.size(n)/a,g=L(\"input\",t[0].dataType,t[0].dims,a),x=X(\"output\",t[0].dataType,n,a),b=Me(t[0].dataType),w=a===1?\"vec2f\":`mat2x${a}f`,v=a===1?b:`vec${a}<${b}>`,y=id(e,t[0],t[1],t[2],s,d,u,r.epsilon),S=A=>`\n  const H: u32 = ${d};\n  const C: u32 = ${u/a};\n\n  @group(0) @binding(0) var<storage, read> input : array<${g.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${w}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${x.type.storage}>;\n\n  ${A.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${v}(scale[0]), ${v}(scale[1]));\n  }`;e.compute({name:\"InstanceNormalization\",shaderCache:{hint:`${r.cacheKey}`},getRunData:()=>({outputs:[{dims:n,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(m/64)}}),getShaderSource:S},{inputs:[t[0],y]})},Di=e=>ie({epsilon:e.epsilon,format:e.format}),Wi=(e,t)=>{t.format===\"NHWC\"?sd(e,e.inputs,t):e.compute(ad(e.inputs,t))}});var ud,ld,Vi,Gi,Ni=H(()=>{\"use strict\";De();ge();Pe();ve();ud=e=>{if(!e||e.length<2)throw new Error(\"layerNorm requires at least 2 inputs.\")},ld=(e,t,r)=>{let o=e[0].dims,n=e[1],s=e[2],u=o,d=k.normalizeAxis(t.axis,o.length),a=k.sizeToDimension(o,d),m=k.sizeFromDimension(o,d),g=k.size(n.dims),x=s?k.size(s.dims):0;if(g!==m||s&&x!==m)throw new Error(`Size of X.shape()[axis:] == ${m}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${g} and bias size of ${x}`);let b=[];for(let M=0;M<o.length;++M)M<d?b.push(o[M]):b.push(1);let w=lt(m),v=Me(e[0].dataType),y=[L(\"x\",e[0].dataType,e[0].dims,w),L(\"scale\",n.dataType,n.dims,w)];s&&y.push(L(\"bias\",s.dataType,s.dims,w)),y.push(X(\"output\",e[0].dataType,u,w));let S=r>1,A=r>2;S&&y.push(X(\"meanDataOutput\",1,b)),A&&y.push(X(\"invStdOutput\",1,b));let R=M=>`\n  const normSize: f32 = ${m};\n  const normSizeVectorized: u32 = ${m/w};\n  const epsilon: f32 = ${t.epsilon};\n\n  ${M.declareVariables(...y)}\n  ${M.mainStart()}\n    ${M.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${qe(\"f32\",w)};\n    var meanSquareVector = ${qe(\"f32\",w)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${At(v,w,\"x[h + offset]\")};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${ht(\"meanVector\",w)} / normSize;\n    let meanSquare = sqrt(${ht(\"meanSquareVector\",w)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${At(v,w,\"x[j + offset]\")};\n      let f32scale = ${At(v,w,\"scale[j]\")};\n      output[j + offset] = ${y[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${s?`+ ${At(v,w,\"bias[j]\")}`:\"\"}\n      );\n    }\n\n    ${S?\"meanDataOutput[global_idx] = mean\":\"\"};\n    ${A?\"invStdOutput[global_idx] = 1 / meanSquare\":\"\"};\n  }`,W=[{dims:u,dataType:e[0].dataType}];return S&&W.push({dims:b,dataType:1}),A&&W.push({dims:b,dataType:1}),{name:\"LayerNormalization\",shaderCache:{hint:`${t.cacheKey}|${r}|${e.length}`},getRunData:()=>({outputs:W,dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:R}},Vi=e=>ie({axis:e.axis,epsilon:e.epsilon}),Gi=(e,t)=>{ud(e.inputs),e.compute(ld(e.inputs,t,e.outputCount))}});var dd,Ui,Li=H(()=>{\"use strict\";ge();ir();dd=e=>{if(!e||e.length!==2)throw new Error(\"MatMul requires 2 inputs.\");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error(\"shared dimension does not match.\")},Ui=e=>{dd(e.inputs);let t=Qe.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error(\"Can't use matmul on the given tensors\");e.compute(Lr(e.inputs,{activation:\"\",activationCacheKey:\"\"},t))}});var cd,pd,fd,md,hd,gd,yd,bd,wd,Fi,Hi,ji=H(()=>{\"use strict\";De();ge();Pe();ve();cd=e=>{if(!e||e.length<1)throw new Error(\"Too few inputs\");if(e[0].dataType!==1)throw new Error(\"Input type must be float.\");if(e.length>=2){let t=e[0].dims.length*2===e[1].dims[0];if(e.length===4&&(t=e[3].dims[0]*2===e[1].dims[0]),!t)throw new Error(\"The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].\")}},pd=(e,t,r,o,n,s,u)=>{let d=r.length,a=\"\";for(let m=d-1;m>=0;--m)a+=`\n            k = i32(${e.indicesGet(\"indices\",m)}) - ${n[m]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${r[m]}) {\n              break;\n            }\n            offset += k * ${o[m]};\n        `;return`\n          value = ${s}(${u});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${a}\n            value = x[offset];\n          }\n      `},fd=(e,t,r,o,n)=>{let s=r.length,u=\"\";for(let d=s-1;d>=0;--d)u+=`\n                k = i32(${e.indicesGet(\"indices\",d)}) - ${n[d]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2*(r[d]-1)};\n                  k = k % _2n_1;\n                  if(k >= ${r[d]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${o[d]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${u}\n              value = x[offset];\n          `},md=(e,t,r,o,n)=>{let s=r.length,u=\"\";for(let d=s-1;d>=0;--d)u+=`\n                k = i32(${e.indicesGet(\"indices\",d)}) - ${n[d]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${r[d]}) {\n                  k = ${r[d]-1};\n                }\n                offset += k * ${o[d]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${u}\n              value = x[offset];\n          `},hd=(e,t,r,o,n)=>{let s=r.length,u=\"\";for(let d=s-1;d>=0;--d)u+=`\n                k = i32(${e.indicesGet(\"indices\",d)}) - ${n[d]};\n                if (k < 0)  {\n                  k += ${r[d]};\n                }\n                if (k >= ${r[d]}) {\n                  k -= ${r[d]};\n                }\n                offset += k * ${o[d]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${u}\n              value = x[offset];\n          `},gd=(e,t,r,o,n,s)=>{switch(n.mode){case 0:return pd(e,t,r,o,n.pads,s,n.value);case 1:return fd(e,t,r,o,n.pads);case 2:return md(e,t,r,o,n.pads);case 3:return hd(e,t,r,o,n.pads);default:throw new Error(\"Invalid mode\")}},yd=(e,t,r,o)=>{let n=t[0].dims,s=k.padShape(n.slice(),r.pads),u=k.size(s),d=k.computeStrides(n),a=X(\"output\",t[0].dataType,s),m=L(\"x\",t[0].dataType,n),g=gd(a,s,n,d,r,o);return`\n              ${e.declareVariables(m,a)}\n              ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n\n              let indices = ${a.offsetToIndices(\"global_idx\")};\n\n              var value = ${o}(0);\n              ${g}\n              output[global_idx] = value;\n          }`},bd=(e,t)=>{let r=k.padShape(e[0].dims.slice(),t.pads);return{name:\"Pad\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(k.size(r)/64)}}),getShaderSource:o=>yd(o,e,t,\"f32\")}},wd=(e,t)=>{if(e.length>1){let r=e[1].getBigInt64Array(),o=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,n=e[0].dims.length,s=new Int32Array(2*n).fill(0);if(e.length>=4){let d=e[3].getBigInt64Array();for(let a=0;a<d.length;a++)s[Number(d[a])]=Number(r[a]),s[Number(d[a])+n]=Number(r[a+d.length])}else r.forEach((d,a)=>s[Number(a)]=Number(d));let u=[];return s.forEach(d=>u.push(d)),ie({mode:t.mode,value:o,pads:u})}else return t},Fi=(e,t)=>{cd(e.inputs);let r=wd(e.inputs,t);e.compute(bd(e.inputs,r),{inputs:[0]})},Hi=e=>{let t=e.mode,r=e.value,o=e.pads;return ie({mode:t,value:r,pads:o})}});var Hr,Ki,qi,Yi,Xi,Ji,Zi,Qi,es,ts,rs,ns,os,as,is,ss=H(()=>{\"use strict\";ge();Pe();ve();Hr=e=>{if(!e||e.length!==1)throw new Error(\"Pool ops requires 1 input.\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"Pool ops supports 1-D or 2-D inputs only for now.\")},Ki=(e,t,r)=>{let o=t.format===\"NHWC\",n=e.dims.slice();o&&n.splice(1,0,n.pop());let s=Object.hasOwnProperty.call(t,\"dilations\"),u=t.kernelShape.slice(),d=t.strides.slice(),a=s?t.dilations.slice():[],m=t.pads.slice();Ct.adjustPoolAttributes(r,n,u,d,a,m);let g=Ct.computePoolOutputShape(r,n,d,a,u,m,t.autoPad),x=Object.assign({},t);s?Object.assign(x,{kernelShape:u,strides:d,pads:m,dilations:a,cacheKey:t.cacheKey}):Object.assign(x,{kernelShape:u,strides:d,pads:m,cacheKey:t.cacheKey});let b=g.slice();return b.push(b.splice(1,1)[0]),[x,o?b:g]},qi=(e,t,r,o,n,s,u,d)=>{let a=n.format===\"NHWC\",m=r,g=t.type.value,x=m.length,b=k.size(o),w=X(\"output\",t.type.tensor,o);if(n.kernelShape.length<=2){let v=n.kernelShape[n.kernelShape.length-1],y=n.strides[n.strides.length-1],S=n.pads[n.pads.length/2-1],A=n.pads[n.pads.length-1],R=x-(a?2:1),W=\"\",M=\"\",D=\"\";if(S+A!==0?W=`\n                for (var i: u32 = 0u; i < ${v}u; i++) {\n                  xIndices[${R}] = indices[${R}] * ${y} - ${S} + i;\n                  if (xIndices[${R}] < 0 || xIndices[${R}] >= ${m[R]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${s}\n                }`:W=`\n                for (var i: u32 = 0u; i < ${v}u; i++) {\n                  xIndices[${R}] = indices[${R}] * ${y} - ${S} + i;\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${s}\n                }`,n.kernelShape.length===2){let z=n.kernelShape[n.kernelShape.length-2],F=n.strides[n.strides.length-2],q=n.pads[n.pads.length/2-2],le=n.pads[n.pads.length-2],B=x-(a?3:2),K=m[B];q+le!==0?M=`\n                for (var j: u32 = 0u; j < ${z}u; j++) {\n                  xIndices[${B}] = indices[${B}] * ${F} - ${q} + j;\n                  if (xIndices[${B}] < 0 || xIndices[${B}] >= ${K}) {\n                    pad+= ${v};\n                    continue;\n                  }\n              `:M=`\n                for (var j: u32 = 0u; j < ${z}u; j++) {\n                  xIndices[${B}] = indices[${B}] * ${F} - ${q} + j;\n                `,D=`\n              }\n            `}return`\n            ${e.declareVariables(t,w)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n\n              let indices = ${w.offsetToIndices(\"global_idx\")};\n              var xIndices = ${w.offsetToIndices(\"global_idx\")};\n\n              var value: ${g} = ${g}(${d});\n              var pad = 0;\n              ${M}\n              ${W}\n              ${D}\n              ${u}\n\n              output[global_idx] = value;\n            }`}else{if(a)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let v=k.size(n.kernelShape),y=k.computeStrides(n.kernelShape),S=y.length,A=n.pads.length,R=n.pads.reduce((D,_)=>D+_),W=\"\";return R?W=`\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${s}\n              }`:W=`\n              }\n              let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n              ${s}\n            `,`\n            ${e.declareVariables(t,w)}\n\n            const pads = array<u32, ${A}>(${n.pads.map(D=>`${D}u`).join(\",\")});\n            const inputDims = array<u32, ${x}>(${m.map(D=>`${D}u`).join(\",\")});\n            const kernelStrides = array<u32, ${S}>(${y.map(D=>`${D}u`).join(\",\")});\n            const strides = array<u32, ${S}>(${n.strides.map(D=>`${D}u`).join(\",\")});\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n\n              let indices = ${w.offsetToIndices(\"global_idx\")};\n              let xIndices = ${w.offsetToIndices(\"global_idx\")};\n\n              var offsets: array<u32, ${S}>;\n\n              var value = ${w.type.value}(${d});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${v}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${S-1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${S-1}] = offset;\n\n                isPad = false;\n                for (var j = ${x-S}u; j < ${x}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${x-S}u]\n                    + offsets[j - ${x-S}u] - pads[j - 2u];\n                  ${W}\n              }\n              ${u}\n\n              output[global_idx] = value;\n            }`}},Yi=e=>({format:e.format,autoPad:[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),Xi=(e,t,r,o)=>{let[n,s]=Ki(t,o,r),u=k.size(n.kernelShape),d=L(\"x\",t.dataType,t.dims),a=d.type.value,m=\"value += x_val;\",g=\"\";return n.countIncludePad?g+=`value /= ${a}(${u});`:g+=`value /= ${a}(${u} - pad);`,{name:e,shaderCache:{hint:o.cacheKey},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(k.size(s)/64)}}),getShaderSource:x=>qi(x,d,t.dims,s,n,m,g,\"0.0\")}},Ji=e=>{let t=e.count_include_pad!==0,r=Yi(e);if(r.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");return ie({countIncludePad:t,...r})},Zi=(e,t)=>{Hr(e.inputs),e.compute(Xi(\"AveragePool\",e.inputs[0],!1,t))},Qi={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[],cacheKey:\"\"},es=e=>{let t=e.format;return{format:t,...Qi,cacheKey:t}},ts=(e,t)=>{Hr(e.inputs),e.compute(Xi(\"GlobalAveragePool\",e.inputs[0],!0,t))},rs=(e,t,r,o)=>{let[n,s]=Ki(t,o,r),u=`\n      value = max(x_val, value);\n    `,d=\"\",a=L(\"x\",t.dataType,t.dims);return{name:e,shaderCache:{hint:o.cacheKey},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(k.size(s)/64)}}),getShaderSource:m=>qi(m,a,t.dims,s,n,u,d,\"-1e5\")}},ns=(e,t)=>{Hr(e.inputs),e.compute(rs(\"MaxPool\",e.inputs[0],!1,t))},os=e=>{let t=e.storage_order,r=e.dilations,o=Yi(e);if(t!==0)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(o.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");return ie({storageOrder:t,dilations:r,...o})},as=e=>{let t=e.format;return{format:t,...Qi,cacheKey:t}},is=(e,t)=>{Hr(e.inputs),e.compute(rs(\"GlobalMaxPool\",e.inputs[0],!0,t))}});var jr=H(()=>{\"use strict\"});var us=H(()=>{\"use strict\";jr()});var ls,ds=H(()=>{\"use strict\";ls=\"1.17.0-dev.20231103-1439da36fe\"});var cs,Wn,ps=H(()=>{\"use strict\";ds();cs=\"warning\",Wn={wasm:{},webgl:{},webgpu:{},versions:{common:ls},set logLevel(e){if(e!==void 0){if(typeof e!=\"string\"||[\"verbose\",\"info\",\"warning\",\"error\",\"fatal\"].indexOf(e)===-1)throw new Error(`Unsupported logging level: ${e}`);cs=e}},get logLevel(){return cs}};Object.defineProperty(Wn,\"logLevel\",{enumerable:!0})});var fs,ms=H(()=>{\"use strict\";ps();fs=Wn});var hs=H(()=>{\"use strict\"});var gs=H(()=>{\"use strict\";Kr()});var bs=H(()=>{\"use strict\"});var ws=H(()=>{\"use strict\";Kr()});var Kr=H(()=>{\"use strict\";hs();gs();bs();ws()});var qr=H(()=>{\"use strict\";Kr()});var vs=H(()=>{\"use strict\";jr();qr()});var $s=H(()=>{\"use strict\";vs()});var xs=H(()=>{\"use strict\"});var Ss=H(()=>{\"use strict\";jr();qr()});var Cs=H(()=>{\"use strict\";Ss()});var As=H(()=>{\"use strict\";us();ms();$s();qr();xs();Cs()});var Sd,Cd,Is,Es=H(()=>{\"use strict\";As();De();ve();Sd=(e,t,r)=>{let o=e===t,n=e<t&&r<0,s=e>t&&r>0;if(o||n||s)throw new Error(\"Range these inputs' contents are invalid.\")},Cd=(e,t,r,o)=>{let n=Math.abs(Math.ceil((t-e)/r)),s=[n],u=n,d=X(\"output\",o,s),a=d.type.storage,m=g=>`\n        ${g.declareVariables(d)}\n        ${g.mainStart()}\n        ${g.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n        output[global_idx] = ${a}(${e}) + ${a}(global_idx) * ${a}(${r});\n      }`;return{name:\"Range\",shaderCache:{hint:[e,t,r].map(g=>g.toString()).join(\"_\")},getShaderSource:m,getRunData:()=>({outputs:[{dims:s,dataType:o}],dispatchGroup:{x:Math.ceil(u/64)}})}},Is=e=>{let t=0,r=0,o=0;e.inputs[0].dataType===6?(t=e.inputs[0].getInt32Array()[0],r=e.inputs[1].getInt32Array()[0],o=e.inputs[2].getInt32Array()[0]):e.inputs[0].dataType===1&&(t=e.inputs[0].getFloat32Array()[0],r=e.inputs[1].getFloat32Array()[0],o=e.inputs[2].getFloat32Array()[0]),fs.webgpu.validateInputContent&&Sd(t,r,o),e.compute(Cd(t,r,o,e.inputs[0].dataType),{inputs:[]})}});var Ad,Id,Ed,Td,Od,_d,Rd,Pd,Md,Bd,kd,Dd,Wd,zd,Vd,Ts,Os,_s=H(()=>{\"use strict\";ge();Pe();ve();Ad=(e,t)=>{if(e.every(r=>r>0||(()=>{throw new Error(\"Resize requires scales input values to be positive\")})),e.length>0){if(t.mode===\"linear\"){if(!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for linear mode\")}else if(t.mode===\"cubic\"&&!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for cubic mode\")}},Id=(e,t,r)=>{t.every(n=>n>=0&&n<r||(()=>{throw new Error(\"Resize requires axes input values to be positive and less than rank\")}));let o=new Array(r).fill(1);return t.forEach((n,s)=>o[n]=e[s]),o},Ed=(e,t,r,o,n,s)=>{let[u,d,a]=r>10?[1,2,3]:[-1,e.length>1?1:-1,-1],m=e[0].dims.length;if(u>0&&e.length>u&&e[u].dims.length>0)e[u].getFloat32Array().forEach(g=>s.push(g));else if(t.coordinateTransformMode===\"tf_crop_and_resize\")throw new Error(\"Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize\");if(d>0&&e.length>d&&e[d].dims.length>0){if(e[d].getFloat32Array().forEach(g=>o.push(g)),o.length!==0&&o.length!==m&&r>=18&&o.length!==t.axes.length)throw new Error(\"Resize requires scales input size to be same as input rank or axes size for opset 18 and up\");Ad(o,t),t.axes.length>0&&Id(o,t.axes,m).forEach((g,x)=>o[x]=g)}if(a>0&&e.length>a&&(e[a].getBigInt64Array().forEach(g=>n.push(Number(g))),n.length!==m||r>=18&&n.length===t.axes.length))throw new Error(\"Resize requires sizes input size to be same as input rank or axes size for opset 18 and up\");if(t.axes.length>0){if(o.length!==t.axes.length)throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');if(n.length!==t.axes.length)throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified')}if(typeof o<\"u\"&&typeof n<\"u\"&&o.length>0&&n.length>m)throw new Error(\"Resize requires only of scales or sizes to be specified\")},Td=e=>\"fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { \"+(()=>{switch(e){case\"asymmetric\":return\"return xResized / xScale;\";case\"pytorch_half_pixel\":return\"if (lengthResized > 1) {                     return (xResized + 0.5) / xScale - 0.5;                   } else {                     return 0.0;                   }\";case\"tf_half_pixel_for_nn\":return\"return (xResized + 0.5) / xScale;\";case\"align_corners\":return\"if (lengthResized == 1) {                     return 0.0;                   } else {                     return xResized * (lengthOriginal - 1) / (lengthResized - 1);                   }\";case\"tf_crop_and_resize\":return\"if (lengthResized > 1) {                     return roiStart * (lengthOriginal - 1) +                           (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1);                   } else {                     return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1);                   }\";case\"half_pixel_symmetric\":return[\"const outputWidth = xScale * lengthResized;\",\"const adjustment = lengthResized / outputWidth;\",\"const center = lengthOriginal / 2;\",\"const offset = center * (1 - adjustment);\",\"return offset + ((xResized + 0.5) / xScale) - 0.5;\"].join(`\n`);case\"half_pixel\":return\"return ((xResized + 0.5) / xScale) - 0.5;\";default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+\"}\",Od=(e,t)=>\"fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {\"+(()=>{switch(e){case\"round_prefer_ceil\":return\"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }\";case\"floor\":return\"return floor(xOriginal);\";case\"ceil\":return\"return ceil(xOriginal);\";case\"round_prefer_floor\":return\"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }\";case\"simple\":default:if(t<11)return\"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }\";throw new Error(`Nearest mode ${e} is not supported`)}})()+\"}\",_d=(e,t,r)=>{let o=new Array(r).fill(0).concat(new Array(r).fill(1)),n=e.length===0?o:e.slice();return t.length>0?(t.forEach((s,u)=>{o[s]=n[u],o[u+r]=n[t.length+u]}),o):n},Rd=(e,t,r,o)=>{let n=[];if(r.length>0)if(o.length>0){if(e.forEach(s=>n.push(s)),Math.max(...o)>e.length)throw new Error(\"axes is out of bound\");o.forEach((s,u)=>n[s]=r[u])}else r.forEach(s=>n.push(s));else{if(t.length===0)throw new Error(\"Resize requires either scales or sizes.\");n=e.map((s,u)=>Math.round(s*t[u]))}return n},Pd=(e,t,r,o)=>{let n=(()=>{switch(o.keepAspectRatioPolicy){case\"not_larger\":return o.axes.length>0?Math.min(...o.axes.map(u=>r[u]),Number.MAX_VALUE):Math.min(...r,Number.MAX_VALUE);case\"not_smaller\":return o.axes.length>0?Math.max(...o.axes.map(u=>r[u]),Number.MIN_VALUE):Math.max(...r,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${o.keepAspectRatioPolicy} is not supported`)}})();r.fill(1,0,r.length);let s=e.slice();return o.axes.length>0?(o.axes.forEach(u=>r[u]=n),o.axes.forEach(u=>s[u]=Math.round(e[u]*r[u]))):(r.fill(n,0,r.length),s.forEach((u,d)=>s[d]=Math.round(u*r[d]))),s},Md=(e,t,r,o,n)=>`\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${e.type.indices}) -> array<f32, ${r.length}> {\n      const inputShape = array<u32, ${t.length}>(${t.map(s=>`${s}u`).join(\",\")});\n      const outputShape = array<u32, ${r.length}>(${r.map(s=>`${s}u`).join(\",\")});\n      const scales = array<f32, ${o.length}>(${o.map(s=>`${s}f`).join(\",\")});\n      const roi = array<f32, ${n.length}>(${n.map(s=>`${s}f`).join(\",\")});\n      var originalIndices: array<f32, ${r.length}>;\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var outputIndex = ${r.length===1?\"outputIndices\":\"outputIndices[i]\"};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${t.length}]);\n        }\n      }\n      return originalIndices;\n    }`,Bd=(e,t,r,o,n,s,u)=>`\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n        const inputShape = array<u32, ${r.length}>(${r.map(d=>`${d}u`).join(\",\")});\n        const outputShape = array<u32, ${o.length}>(${o.map(d=>`${d}u`).join(\",\")});\n        const scales = array<f32, ${n.length}>(${n.map(d=>`${d}f`).join(\",\")});\n        const roi = array<f32, ${s.length}>(${s.map(d=>`${d}f`).join(\",\")});\n        var inputIndices: ${e.type.indices};\n        for (var i:u32 = 0; i < ${o.length}; i++) {\n          var outputIndex = ${o.length===1?\"outputIndices\":\"outputIndices[i]\"};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${r.length}]);\n            if (!${u} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${e.indicesSet(\"inputIndices\",\"i\",\"inputIndex\")}\n        }\n        return inputIndices;\n    }`,kd=(e,t)=>`\n    fn checkInputIndices(inputIndices: ${e.type.indices}) -> bool {\n      const inputShape = array<u32, ${t.length}>(${t.map(r=>`${r}u`).join(\",\")});\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var inputIndex = ${t.length===1?\"inputIndices\":\"inputIndices[i]\"};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`,Dd=(e,t,r,o,n,s,u)=>{let[d,a,m,g]=r.length===2?[-1,0,1,-1]:n[1]===1?[0,2,3,1]:[0,1,2,3];return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${e.type.indices};\n      inputIndices[${a}] = max(0, min(row, ${r[a]} - 1));\n      inputIndices[${m}] = max(0, min(col, ${r[m]} - 1));\n      if (${r.length} > 2) {\n        inputIndices[${g}] = channel;\n        inputIndices[${d}] = batch;\n      };\n      return input[${e.indicesToOffset(\"inputIndices\")}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${a}];\n      var col:f32 = originalIndices[${m}];\n      if (${s} && (row < 0 || row > (${r[a]} - 1) || col < 0 || col > ${r[m]} - 1)) {\n        return ${u};\n      }\n      row = max(0, min(row, ${r[a]} - 1));\n      col = max(0, min(col, ${r[m]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${r.length>2}) {\n        channel = u32(originalIndices[${g}]);\n        batch = u32(originalIndices[${d}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},Wd=(e,t,r,o,n,s,u,d,a,m)=>{let[g,x]=r.length===2?[0,1]:n[1]===1?[2,3]:[1,2],b=w=>{let v=w===g?\"row\":\"col\";return`\n      fn ${v}CubicInterpolation(inputIndices: ${e.type.indices}, outputIndices: ${t.type.indices}) -> f32 {\n        var outputIndex = ${o.length===1?\"outputIndices\":`outputIndices[${w}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${n[w]},\n        f32(${o[w]}), f32(${r[w]}), ${s[w]}, ${s[w]} + ${r.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${d} && (originalIdx < 0 || originalIdx > (${r[w]} - 1))) {\n          return ${a};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${v}: f32 = originalIdx + f32(i);\n          if (${v} < 0 || ${v} >= ${r[w]}) {\n            if (${m}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${d}) {\n              return ${a};\n            } else {\n              ${v} = max(0, min(${v}, ${r[w]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${e.type.indices} = inputIndices;\n          inputIndicesCopy[${w}] = u32(${v});\n          data[i + 1] = ${w===g?`input[${e.indicesToOffset(\"inputIndicesCopy\")}];`:`\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${b(g)};\n    ${b(x)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${u} * onePlusAbsS - 5 * ${u}) * onePlusAbsS + 8 * ${u}) * onePlusAbsS - 4 * ${u};\n    coeffs[1] = ((${u} + 2) * absS - (${u} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${u} + 2) * oneMinusAbsS - (${u} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${u} * twoMinusAbsS - 5 * ${u}) * twoMinusAbsS + 8 * ${u}) * twoMinusAbsS - 4 * ${u};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n    var inputIndices: ${e.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `},zd=(e,t,r,o,n,s)=>{let u=e.dims,d=_d(s,t.axes,u.length),a=Rd(u,o,n,t.axes),m=o.slice();o.length===0&&(m=u.map((S,A)=>S===0?1:a[A]/S),t.keepAspectRatioPolicy!==\"stretch\"&&(a=Pd(u,a,m,t)));let g=X(\"output\",e.dataType,a),x=L(\"input\",e.dataType,u),b=k.size(a),w=u.length===a.length&&u.every((S,A)=>S===a[A]),v=t.coordinateTransformMode===\"tf_crop_and_resize\",y=S=>`\n      ${Td(t.coordinateTransformMode)};\n      ${(()=>{switch(t.mode){case\"nearest\":return`\n              ${kd(x,u)};\n              ${Od(t.nearestMode,r)};\n              ${Bd(x,g,u,a,m,d,v)};\n              `;case\"linear\":return`\n              ${Md(g,u,a,m,d)};\n              ${Dd(x,g,u,a,m,v,t.extrapolationValue)};\n              `;case\"cubic\":return`\n            ${Wd(x,g,u,a,m,d,t.cubicCoeffA,v,t.extrapolationValue,t.excludeOutside)};\n            `;default:throw Error(\"Invalid resize mode\")}})()};\n      ${S.declareVariables(x,g)}\n      ${S.mainStart()}\n        ${S.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n        if (${w}) {\n          output[global_idx] = input[global_idx];\n        } else {\n          let outputIndices = ${g.offsetToIndices(\"global_idx\")};\n          var inputIndices: ${x.type.indices};\n          ${(()=>{switch(t.mode){case\"nearest\":return`inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                  if (checkInputIndices(inputIndices)) {\n                    output[global_idx] = input[${x.indicesToOffset(\"inputIndices\")}];\n                  } else {\n                    output[global_idx] = ${t.extrapolationValue};\n                  }`;case\"linear\":return\"output[global_idx] = bilinearInterpolation(outputIndices);\";case\"cubic\":return\"output[global_idx] = bicubicInterpolation(outputIndices);\";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n        }\n      }`;return{name:\"Resize\",shaderCache:{hint:`${t.cacheKey}|${r}|${m.length>0?m:\"\"}|${n.length>0?n:\"\"}`},getShaderSource:y,getRunData:()=>({outputs:[{dims:a,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(b/64)}})}},Vd=e=>{let t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},Ts=(e,t)=>{let r=[],o=[],n=[],s=Vd(e);Ed(e.inputs,t,s,r,o,n),e.compute(zd(e.inputs[0],t,s,r,o,n),{inputs:[0]})},Os=e=>{let t=e.antialias,r=e.axes,o=e.coordinateTransformMode,n=e.cubicCoeffA,s=e.excludeOutside!==0,u=e.extrapolationValue,d=e.keepAspectRatioPolicy,a=e.mode,m=e.nearestMode===\"\"?\"simple\":e.nearestMode;return ie({antialias:t,axes:r,coordinateTransformMode:o,cubicCoeffA:n,excludeOutside:s,extrapolationValue:u,keepAspectRatioPolicy:d,mode:a,nearestMode:m})}});var Gd,Nd,Rs,Ps,Ms=H(()=>{\"use strict\";De();ge();Pe();ve();Gd=e=>{if(!e||e.length<3)throw new Error(\"layerNorm requires at least 3 inputs.\");let t=e[0],r=e[1],o=e[2];if(t.dataType!==r.dataType||t.dataType!==o.dataType)throw new Error(\"All inputs must have the same data type\");if(t.dims.length!==3&&t.dims.length!==2)throw new Error(\"Input must be 2D or 3D\");if(r.dims.length!==3&&r.dims.length!==2)throw new Error(\"Skip must be 2D or 3D\");let n=t.dims[t.dims.length-1],s=t.dims[t.dims.length-2];if(r.dims[r.dims.length-1]!==n)throw new Error(\"Skip must have the same hidden size as input\");if(r.dims[r.dims.length-2]!==s)throw new Error(\"Skip must have the same sequence length as input\");if(o.dims.length!==1)throw new Error(\"Gamma must be 1D\");if(o.dims[o.dims.length-1]!==n)throw new Error(\"Gamma must have the same hidden size as input\");if(e.length>3){let u=e[3];if(u.dims.length!==1)throw new Error(\"Beta must be 1D\");if(u.dims[u.dims.length-1]!==n)throw new Error(\"Beta must have the same hidden size as input\")}if(e.length>4){let u=e[4];if(u.dims.length!==1)throw new Error(\"Bias must be 1D\");if(u.dims[u.dims.length-1]!==n)throw new Error(\"Bias must have the same hidden size as input\")}},Nd=(e,t,r,o)=>{let n=e[0].dims,s=k.size(n),u=n,d=s,a=n.slice(-1)[0],m=o?n.slice(0,-1).concat(1):[],g=e.length>3,x=e.length>4,b=o&&r>1,w=o&&r>2,v=r>3,y=lt(a),S=[L(\"x\",e[0].dataType,e[0].dims,y),L(\"skip\",e[1].dataType,e[1].dims,y),L(\"gamma\",e[2].dataType,e[2].dims,y)];g&&S.push(L(\"beta\",e[3].dataType,e[3].dims,y)),x&&S.push(L(\"bias\",e[4].dataType,e[4].dims,y)),S.push(X(\"output\",e[0].dataType,u,y)),b&&S.push(X(\"meanOutput\",1,m)),w&&S.push(X(\"invStdOutput\",1,m)),v&&S.push(X(\"inputSkipBiasSum\",e[0].dataType,u,y));let A=Me(e[0].dataType),R=M=>`\n      const hiddenSize: f32 = ${a};\n      const hiddenSizeVectorized: u32 = ${a/y};\n      const epsilon: f32 = ${t.epsilon};\n\n      ${M.declareVariables(...S)}\n\n      ${M.mainStart()}\n        ${M.guardAgainstOutOfBoundsWorkgroupSizes(d/a)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${qe(\"f32\",y)};\n        var squareSum = ${qe(\"f32\",y)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${x?\"bias[i]\":\"0.0\"};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${v?\"inputSkipBiasSum[offset + i] = value;\":\"\"}\n          output[offset + i] = value;\n          let f32Value = ${At(A,y,\"value\")};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${ht(\"sum\",y)} / hiddenSize;\n        let variance = sqrt(${ht(\"squareSum\",y)} / hiddenSize - mean * mean + epsilon);\n        ${b?\"meanOutput[global_idx] = mean;\":\"\"}\n        ${w?\"invStdOutput[global_idx] = 1.0 / variance;\":\"\"}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${A}(mean)) / ${A}(variance) * gamma[i]\n           + ${g?\"beta[i]\":\"0.0\"};\n        }\n      }`,W=[{dims:u,dataType:e[0].dataType}];return r>1&&W.push({dims:m,dataType:1}),r>2&&W.push({dims:m,dataType:1}),r>3&&W.push({dims:n,dataType:e[0].dataType}),{name:\"SkipLayerNormalization\",shaderCache:{hint:t.cacheKey},getShaderSource:R,getRunData:()=>({outputs:W,dispatchGroup:{x:Math.ceil(d/a/64)}})}},Rs=(e,t)=>{Gd(e.inputs);let o=[0];e.outputCount>1&&o.push(-3),e.outputCount>2&&o.push(-3),e.outputCount>3&&o.push(3),e.compute(Nd(e.inputs,t,e.outputCount,!1),{outputs:o})},Ps=e=>{let t=e.epsilon;return ie({epsilon:t})}});var Ud,Yr,Ld,Bs,Fd,Hd,ks,Ds,Ws=H(()=>{\"use strict\";De();ge();Pe();ve();Ud=(e,t)=>{if(!e||e.length<1)throw new Error(\"too few inputs\");if(t.axes.length!==0){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error(\"axes, starts and ends must have the same length\")}else if(t.starts.length!==t.ends.length)throw new Error(\"starts and ends must have the same length\");e.slice(1).forEach((r,o)=>{if(e[o+1].dataType!==6&&e[o+1].dataType!==7)throw new Error(`Input ${o} must be an array of int32 or int64`)})},Yr=(e,t)=>{let r=[];if(e.length>t)if(e[t].dataType===7)e[t].getBigInt64Array().forEach(o=>r.push(Number(o)));else if(e[t].dataType===6)e[t].getInt32Array().forEach(o=>r.push(Number(o)));else throw new Error(`Input ${t} must be an array of int32 or int64`);return r},Ld=(e,t)=>{if(e.length>1){let r=Yr(e,1),o=Yr(e,2),n=Yr(e,3);return n.length===0&&(n=[...Array(e[0].dims.length).keys()]),ie({starts:r,ends:o,axes:n})}else return t},Bs=(e,t,r,o,n)=>{let s=e;return e<0&&(s+=r[o[t]]),n[t]<0?Math.max(0,Math.min(s,r[o[t]]-1)):Math.max(0,Math.min(s,r[o[t]]))},Fd=(e,t,r,o)=>`fn calculateInputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n          var inputIndices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${r.length}; i >= 0; i--) {\n            var outputIndex = ${o.length===1?\"outputIndices\":\"outputIndices[i]\"};\n            var inputIndex = outputIndex * steps[i] + starts[i] + carry;\n            carry = inputIndex / inputShape[i];\n            inputIndex = inputIndex % inputShape[i];\n            if (signs[i] < 0) {\n              inputIndex = inputShape[i] - inputIndex - 1u + starts[i];\n            }\n            ${r.length===1?\"inputIndices\":\"inputIndices[i]\"} = inputIndex;\n          }\n          return inputIndices;\n      }`,Hd=(e,t)=>{let r=e[0].dims,o=k.size(r),n=t.axes.length>0?k.normalizeAxes(t.axes,r.length):[...Array(r.length).keys()],s=Yr(e,4);s.forEach(y=>y!==0||(()=>{throw new Error(\"step cannot be 0\")})),s.length===0&&(s=Array(n.length).fill(1));let u=t.starts.map((y,S)=>Bs(y,S,r,n,s)),d=t.ends.map((y,S)=>Bs(y,S,r,n,s));if(n.length!==r.length)for(let y=0;y<r.length;++y)n.includes(y)||(u.splice(y,0,0),d.splice(y,0,r[y]),s.splice(y,0,1));let a=s.map(y=>Math.sign(y));s.forEach((y,S,A)=>{if(y<0){let R=(d[S]-u[S])/y,W=u[S],M=W+R*s[S];u[S]=M,d[S]=W,A[S]=-y}});let m=r.slice(0);n.forEach((y,S)=>{m[y]=Math.ceil((d[y]-u[y])/s[y])});let g={dims:m,dataType:e[0].dataType},x=X(\"output\",e[0].dataType,m),b=L(\"input\",e[0].dataType,r),w=k.size(m),v=y=>`\n      ${y.declareVariables(b,x)}\n        const signs = array<i32, ${a.length}>(${a.map(S=>`${S}i`).join(\",\")});\n        const starts = array<u32, ${u.length}>(${u.map(S=>`${S}u`).join(\",\")});\n        const ends = array<u32, ${d.length}>(${d.map(S=>`${S}u`).join(\",\")});\n        const steps = array<u32, ${s.length}>(${s.map(S=>`${S}u`).join(\",\")});\n        const inputShape = array<u32, ${r.length}>(${r.map(S=>`${S}u`).join(\",\")});\n\n        ${Fd(b,x,r,m)}\n        ${y.mainStart()}\n          ${y.guardAgainstOutOfBoundsWorkgroupSizes(w)}\n          let outputIndices = ${x.offsetToIndices(\"global_idx\")};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${x.setByOffset(\"global_idx\",b.getByIndices(\"inputIndices\"))}\n      }`;return{name:\"Slice\",shaderCache:{hint:`${t.cacheKey}|${e[4]?.dims??\"\"}`},getShaderSource:v,getRunData:()=>({outputs:[g],dispatchGroup:{x:Math.ceil(o/64)}})}},ks=(e,t)=>{Ud(e.inputs,t);let r=Ld(e.inputs,t);e.compute(Hd(e.inputs,r),{inputs:[0]})},Ds=e=>{let t=e.starts,r=e.ends,o=e.axes;return ie({starts:t,ends:r,axes:o})}});var jd,Kd,zs,Vs,Gs=H(()=>{\"use strict\";ge();Pe();ve();jd=e=>{if(!e||e.length!==1)throw new Error(\"Softmax op requires 1 input.\")},Kd=(e,t)=>{let r=Me(e.dataType),o=e.dims,n=k.size(o),s=64,u=t.axis;if(u<0&&(u=o.length+u),u<o.length-1)throw new Error(\"softmax only supports last axis for now.\");let d=o[u],a=n/d,m=lt(d),g=d/m,x=m===1?r:`vec${m}<${r}>`,b=(y,S)=>S===4?`max(max(${y}.x, ${y}.y), max(${y}.z, ${y}.w))`:S===2?`max(${y}.x, ${y}.y)`:S===3?`max(max(${y}.x, ${y}.y), ${y}.z)`:y,w=r===\"f32\"?`var threadMax = ${x}(-3.402823e+38f);`:`var threadMax = ${x}(-65504.0h);`;return{name:\"Softmax\",getRunData:()=>({outputs:[{dims:o,dataType:e.dataType}],dispatchGroup:{x:a}}),getShaderSource:y=>`\n      var<workgroup> rowMaxShared : ${x};\n      var<workgroup> rowSumShared : ${x};\n      var<workgroup> threadShared : array<${x}, ${s}>;\n\n      @group(0) @binding(0) var<storage, read> x : array<${x}>;\n      @group(0) @binding(1) var<storage, read_write> result : array<${x}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${x} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${x}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n\n      @compute @workgroup_size(${s}, 1, 1)\n      fn main(@builtin(local_invocation_id) local_id : vec3<u32>, @builtin(global_invocation_id) global_id : vec3u) {\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${s};\n        let row = gindex / wg;\n        let cols = ${g};\n        let row_stride : i32 = ${g};\n\n        // find the rows max\n        ${w}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${x}(${b(\"threadShared[0]\",m)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${x}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${x}(${ht(\"threadShared[0]\",m)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`}},zs=(e,t)=>{jd(e.inputs),e.compute(Kd(e.inputs[0],t))},Vs=e=>ie({axis:e.axis})});var qd,Yd,Xd,Jd,Zd,Ns,Us,Ls=H(()=>{\"use strict\";ge();Pe();ve();qd=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\")},Yd=(e,t)=>{let r=[],o=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(n=>r.push(Number(n))),o=r.length),ie({numOutputs:o,axis:t.axis,splitSizes:r})},Xd=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,Jd=e=>{let t=e.length,r=[];for(let o=0;o<t;++o){let n=e[o].setByIndices(\"indices\",\"input[global_idx]\");t===1?r.push(n):o===0?r.push(`if (outputNumber == ${o}u) { ${n} }`):o===t-1?r.push(`else { ${n} }`):r.push(`else if (outputNumber == ${o}) { ${n} }`)}return`\n      fn writeBufferData(outputNumber: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${r.join(`\n`)}\n      }`},Zd=(e,t)=>{let r=e[0].dims,o=k.size(r),n=e[0].dataType,s=r.length,u=t.axis,d=u<0?r.length+u:u,a=new Array(t.numOutputs),m=L(\"input\",n,r),g=new Array(t.numOutputs),x=[],b=[],w=0;for(let S=0;S<t.numOutputs;S++){w+=t.splitSizes[S],g[S]=w;let A=r.slice();A[t.axis]=t.splitSizes[S],b.push(A),a[S]=X(`output${S}`,n,b[S]),x.push({dims:b[S],dataType:e[0].dataType})}let v=s<2?\"indices\":`indices[${d}]`,y=S=>`\n  ${S.declareVariables(m,...a)}\n  const sizeInConcatAxis = array<u32, ${g.length}>(${g.map(A=>`${A}u`).join(\",\")});\n  ${Xd(g.length)}\n  ${Jd(a)}\n\n  ${S.mainStart()}\n    ${S.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n\n    var indices = ${m.offsetToIndices(\"global_idx\")};\n    let outputNumber = calculateOutputIndex(${v});\n    if (outputNumber != 0) {\n        ${v} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;return{name:\"Split\",shaderCache:{hint:t.cacheKey},getShaderSource:y,getRunData:()=>({outputs:x,dispatchGroup:{x:Math.ceil(o/64)}})}},Ns=(e,t)=>{qd(e.inputs);let r=e.inputs.length===1?t:Yd(e.inputs,t);e.compute(Zd(e.inputs,r),{inputs:[0]})},Us=e=>{let t=e.axis,r=e.splitSizes,o=e.numOutputs<0?r.length:e.numOutputs;if(o!==r.length)throw new Error(\"numOutputs and splitSizes lengh must be equal\");return ie({axis:t,numOutputs:o,splitSizes:r})}});var Fs,Qd,ec,tc,Hs,js=H(()=>{\"use strict\";De();ge();ve();Fs=e=>Array.from(e.getBigInt64Array(),Number),Qd=e=>{if(!e||e.length!==2)throw new Error(\"Tile requires 2 inputs.\");if(e[0].dataType!==1&&e[0].dataType!==6&&e[0].dataType!==12)throw new Error(\"Tile only support float, int32, and uint32 data types\");if(e[1].dataType!==7)throw new Error(\"Tile `repeats` input should be of int64 data type\");if(e[1].dims.length!==1)throw new Error(\"Tile `repeats` input should be 1-D\");if(Fs(e[1]).length!==e[0].dims.length)throw new Error(\"Tile `repeats` input should have same number of elements as rank of input data tensor\")},ec=(e,t)=>{let r=[];for(let o=0;o<e.length;++o)r.push(e[o]*t[o]);return r},tc=e=>{let t=e[0].dims,r=Fs(e[1]),o=ec(t,r),n=k.size(o),s=e[0].dataType,u=L(\"input\",s,t),d=X(\"output\",s,o),a=m=>`\n      const inputShape = ${u.indices(...t)};\n      ${m.declareVariables(u,d)}\n      ${m.mainStart()}\n      ${m.guardAgainstOutOfBoundsWorkgroupSizes(n)}\n      let outputIndices = ${d.offsetToIndices(\"global_idx\")};\n      var inputIndices: ${u.type.indices};\n      for (var i = 0; i < ${t.length}; i++) {\n        let inputDimValue = ${d.indicesGet(\"outputIndices\",\"i\")}  % ${u.indicesGet(\"inputShape\",\"i\")};\n\n        ${u.indicesSet(\"inputIndices\",\"i\",\"inputDimValue\")}\n      }\n      ${d.setByOffset(\"global_idx\",u.getByIndices(\"inputIndices\"))}\n    }`;return{name:\"Tile\",shaderCache:{hint:`${r}`},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(n/64)}}),getShaderSource:a}},Hs=e=>{Qd(e.inputs),e.compute(tc(e.inputs),{inputs:[0]})}});var rc,nc,Ks,qs=H(()=>{\"use strict\";De();ge();ve();rc=(e,t,r,o,n)=>{let s=k.size(r),u=Math.ceil(s/4),d=X(\"outputData\",n,r,4),a=L(\"aData\",t[1].dataType,t[1].dims,4),m=L(\"bData\",t[2].dataType,t[2].dims,4),g=L(\"cData\",t[0].dataType,t[0].dims,4),x,b=(w,v,y)=>`select(${v}, ${w}, ${y})`;if(!o)x=d.setByOffset(\"global_idx\",b(a.getByOffset(\"global_idx\"),m.getByOffset(\"global_idx\"),g.getByOffset(\"global_idx\")));else{let w=(v,y,S=\"\")=>{let A=`aData[indexA${y}][componentA${y}]`,R=`bData[indexB${y}][componentB${y}]`,W=`bool(cData[indexC${y}] & ${4278190080>>>(3-y)*8}u)`;return`\n            let outputIndices${y} = ${d.offsetToIndices(`global_idx * 4u + ${y}u`)};\n            let offsetA${y} = ${a.broadcastedIndicesToOffset(`outputIndices${y}`,d)};\n            let offsetB${y} = ${m.broadcastedIndicesToOffset(`outputIndices${y}`,d)};\n            let offsetC${y} = ${g.broadcastedIndicesToOffset(`outputIndices${y}`,d)};\n            let indexA${y} = offsetA${y} / 4u;\n            let indexB${y} = offsetB${y} / 4u;\n            let indexC${y} = offsetC${y} / 4u;\n            let componentA${y} = offsetA${y} % 4u;\n            let componentB${y} = offsetB${y} % 4u;\n            ${v}[${y}] = ${S}(${b(A,R,W)});\n          `};n===9?x=`\n            var data = vec4<u32>(0);\n            ${w(\"data\",0,\"u32\")}\n            ${w(\"data\",1,\"u32\")}\n            ${w(\"data\",2,\"u32\")}\n            ${w(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:x=`\n            ${w(\"outputData[global_idx]\",0)}\n            ${w(\"outputData[global_idx]\",1)}\n            ${w(\"outputData[global_idx]\",2)}\n            ${w(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(g,a,m,d)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n        ${x}\n      }`},nc=e=>{let t=e[1].dims,r=e[2].dims,o=e[0].dims,n=e[1].dataType,s=!(k.areEqual(t,r)&&k.areEqual(r,o)),u=t,d=k.size(t);if(s){let a=Qe.calcShape(Qe.calcShape(t,r,!1),o,!1);if(!a)throw new Error(\"Can't perform where op on the given tensors\");u=a,d=k.size(u)}return{name:\"Where\",getShaderSource:a=>rc(a,e,u,s,n),getRunData:()=>({outputs:[{dims:u,dataType:n}],dispatchGroup:{x:Math.ceil(d/64/4)}})}},Ks=e=>{e.compute(nc(e.inputs))}});var Ys,Xs=H(()=>{\"use strict\";ca();fa();ja();ni();ii();_n();wi();Si();Ii();Oi();Pi();ki();zi();Ni();Li();ji();ss();Es();Mr();_s();Ms();Ws();Gs();Ls();js();rr();In();qs();Ys=new Map([[\"Abs\",[ma]],[\"Acos\",[ha]],[\"Acosh\",[ga]],[\"Add\",[Ka]],[\"ArgMax\",[da,Cn]],[\"ArgMin\",[la,Cn]],[\"Asin\",[ya]],[\"Asinh\",[ba]],[\"Atan\",[wa]],[\"Atanh\",[va]],[\"AveragePool\",[Zi,Ji]],[\"BiasAdd\",[pa]],[\"BiasSplitGelu\",[Ha]],[\"Cast\",[xa,$a]],[\"Ceil\",[Ca]],[\"ClipV10\",[An]],[\"Clip\",[Sa]],[\"Concat\",[oi,ai]],[\"Conv\",[Pn,Rn]],[\"ConvTranspose\",[bi,yi]],[\"Cos\",[Aa]],[\"Cosh\",[Ia]],[\"Div\",[qa]],[\"Einsum\",[$i,xi]],[\"Elu\",[Ea,kr]],[\"Equal\",[Ya]],[\"Erf\",[Ta]],[\"Exp\",[Oa]],[\"Expand\",[Ai]],[\"Floor\",[_a]],[\"FusedConv\",[Pn,Rn]],[\"Gather\",[Ti,Ei]],[\"GatherElements\",[Ri,_i]],[\"Gelu\",[Ra]],[\"Gemm\",[Mi,Bi]],[\"GlobalAveragePool\",[ts,es]],[\"GlobalMaxPool\",[is,as]],[\"Greater\",[Qa]],[\"GreaterOrEqual\",[ti]],[\"InstanceNormalization\",[Wi,Di]],[\"LayerNormalization\",[Gi,Vi]],[\"LeakyRelu\",[Pa,kr]],[\"Less\",[ei]],[\"LessOrEqual\",[ri]],[\"Log\",[Fa]],[\"MatMul\",[Ui]],[\"MaxPool\",[ns,os]],[\"Mul\",[Xa]],[\"Neg\",[Ba]],[\"Not\",[Ma]],[\"Pad\",[Fi,Hi]],[\"Pow\",[Ja]],[\"Range\",[Is]],[\"Reciprocal\",[ka]],[\"ReduceMin\",[ra,Ye]],[\"ReduceMean\",[Jo,Ye]],[\"ReduceMax\",[ta,Ye]],[\"ReduceSum\",[oa,Ye]],[\"ReduceProd\",[na,Ye]],[\"ReduceL1\",[Zo,Ye]],[\"ReduceL2\",[Qo,Ye]],[\"ReduceLogSum\",[ia,Ye]],[\"ReduceLogSumExp\",[ea,Ye]],[\"ReduceSumSquare\",[aa,Ye]],[\"Relu\",[Da]],[\"Resize\",[Ts,Os]],[\"Sigmoid\",[Wa]],[\"Sin\",[za]],[\"Sinh\",[Va]],[\"Slice\",[ks,Ds]],[\"SkipLayerNormalization\",[Rs,Ps]],[\"Split\",[Ns,Us]],[\"Sqrt\",[Ga]],[\"Softmax\",[zs,Vs]],[\"Sub\",[Za]],[\"Tan\",[Na]],[\"Tanh\",[Ua]],[\"ThresholdedRelu\",[La,kr]],[\"Tile\",[Hs]],[\"Transpose\",[zo,Vo]],[\"Where\",[Ks]]])});var Xr,Js=H(()=>{\"use strict\";De();mt();ve();Xr=class{constructor(t){this.backend=t;this.repo=new Map,this.attributesBound=!1}getArtifact(t){return this.repo.get(t)}setArtifact(t,r){this.repo.set(t,r)}run(t,r,o,n,s,u,d){let a=this.backend.device,m=this.backend.getComputePassEncoder();m.setPipeline(t.computePipeline);let g=[];for(let b of n)g.push({binding:g.length,resource:{buffer:b.buffer}});for(let b of s)g.push({binding:g.length,resource:{buffer:b.buffer}});d&&g.push({binding:g.length,resource:d});let x=a.createBindGroup({layout:t.computePipeline.getBindGroupLayout(0),entries:g,label:t.programInfo.name});if(m.setBindGroup(0,x),m.dispatchWorkgroups(...u),this.backend.pendingDispatchNumber++,this.backend.isQueryEnabled()){typeof this.backend.queryData>\"u\"&&(this.backend.queryData=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE));let b=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST);this.backend.endComputePass(),this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet,0,2,this.backend.queryData.buffer,0),this.backend.getCommandEncoder().copyBufferToBuffer(this.backend.queryData.buffer,0,b.buffer,0,this.backend.querySetCount*8),this.backend.flush();let w=this.backend.currentKernelId,v=this.backend.kernels.get(w),y=`[${v[0]}] ${v[1]}`;b.buffer.mapAsync(GPUMapMode.READ).then(()=>{let S=new BigUint64Array(b.buffer.getMappedRange()),A=S[0],R=S[1];b.buffer.unmap(),typeof this.backend.queryTimeBase>\"u\"&&(this.backend.queryTimeBase=A);let W=Number(A-this.backend.queryTimeBase),M=Number(R-this.backend.queryTimeBase);if(!Number.isSafeInteger(W)||!Number.isSafeInteger(M))throw new RangeError(\"incorrect timestamp range\");this.backend.gpuDataManager.release(b.id);let D=\"\";r.forEach((z,F)=>{D+=`input[${F}]: [${z.dims}] | ${Qt(z.dataType)}, `});let _=\"\";o.forEach((z,F)=>{_+=`output[${F}]: [${z.dims}] | ${Qt(z.dataType)}, `}),console.log(`[profiling] kernel \"${w}|${y}\" ${D}${_}execution time: ${M-W} ns`)})}this.backend.pendingDispatchNumber>=16&&this.backend.flush()}dispose(){}build(t,r){let o=this.backend.device,n=[];o.features.has(\"shader-f16\")&&n.push(\"enable f16;\");let s=ko(r),u=t.getShaderSource(s),d=`${n.join(`\n`)}\n${s.additionalImplementations}\n${u}`,a=o.createShaderModule({code:d,label:t.name});Ee(\"verbose\",()=>`[WebGPU] shader code: ${d}`);let m=o.createComputePipeline({compute:{module:a,entryPoint:\"main\"},layout:\"auto\",label:t.name});return{programInfo:t,computePipeline:m}}normalizeDispatchGroupSize(t){let r=typeof t==\"number\"?t:t.x,o=typeof t==\"number\"?1:t.y||1,n=typeof t==\"number\"?1:t.z||1,s=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(r<=s&&o<=s&&n<=s)return[r,o,n];let u=r*o*n,d=Math.ceil(Math.sqrt(u));if(d>s){if(d=Math.ceil(Math.cbrt(u)),d>s)throw new Error(\"Total dispatch size exceeds WebGPU maximum.\");return[d,d,d]}else return[d,d,1]}}});var oc,ac,Jr,Zs=H(()=>{\"use strict\";mt();To();Po();Xs();Js();oc=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);let r=[];for(let o=0;o<e.length;++o){let n=e[o].dataType;switch(t[o]){case\"none\":{r.push(\"\");break}case\"type\":{r.push(`${n}`);break}case\"rank\":{let s=e[o].dims.length;r.push(`${n};${s}`);break}case\"dims\":{let s=e[o].dims.join(\",\");r.push(`${n};${s}`);break}default:throw new Error(`unsupported input dependency: ${t[o]}`)}}return r.join(\"|\")},ac=(e,t)=>{let r=e.name;return e.shaderCache?.hint&&(r+=\"[\"+e.shaderCache.hint+\"]\"),r+=`:${oc(t,e.shaderCache?.inputDependencies??new Array(t.length).fill(\"dims\"))}`,r},Jr=class{constructor(){this.currentKernelId=null;this.commandEncoder=null;this.computePassEncoder=null;this.pendingDispatchNumber=0;this.querySetCount=2;this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(this.currentKernelId===null)throw new Error(\"currentKernelCustomData(): currentKernelId is null. (should not happen)\");let t=this.kernelCustomData.get(this.currentKernelId);return t||(t={},this.kernelCustomData.set(this.currentKernelId,t)),t}async initialize(t){if(!navigator.gpu)throw new Error(\"WebGpuBackend: WebGPU is not available.\");let r=await navigator.gpu.requestAdapter();if(!r)throw new Error(\"WebGpuBackend: Failed to get GPU adapter.\");this.env=t;let o=[],n={requiredLimits:{maxComputeWorkgroupStorageSize:r.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:r.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:r.limits.maxStorageBufferBindingSize,maxBufferSize:r.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:r.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:r.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:r.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:r.limits.maxComputeWorkgroupSizeZ},requiredFeatures:o};r.features.has(\"timestamp-query\")&&o.push(\"timestamp-query\"),r.features.has(\"shader-f16\")&&o.push(\"shader-f16\"),this.device=await r.requestDevice(n),this.gpuDataManager=Ro(this),this.programManager=new Xr(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,Io(t.logLevel,!!t.debug),this.device.onuncapturederror=s=>{s.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${s.error.message}`)},Object.defineProperty(this.env.webgpu,\"device\",{value:this.device})}dispose(){typeof this.querySet<\"u\"&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){let t={};this.isQueryEnabled()&&(typeof this.querySet>\"u\"&&(this.querySet=this.device.createQuerySet({type:\"timestamp\",count:this.querySetCount})),t.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:0,endOfPassWriteIndex:1}),this.computePassEncoder=this.getCommandEncoder().beginComputePass(t)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){this.commandEncoder&&(this.endComputePass(),this.device.queue.submit([this.getCommandEncoder().finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0)}isQueryEnabled(){return!!(this.device.features.has(\"timestamp-query\")&&this.env.webgpu.profilingMode===\"default\")}run(t,r,o,n,s){let u=[];for(let A=0;A<r.length;++A){let R=this.gpuDataManager.get(r[A].data);if(!R)throw new Error(`no GPU data for input: ${r[A].data}`);u[A]=R}let d=ac(t,r),a=this.programManager.getArtifact(d),{outputs:m,dispatchGroup:g,programUniforms:x}=t.getRunData(r),b=o.length===0?m.map((A,R)=>R):o;if(b.length!==m.length)throw new Error(`Output size ${b.length} must be equal to ${m.length}.`);let w=[],v=[];for(let A=0;A<m.length;++A){if(!Number.isInteger(b[A])||b[A]<-3||b[A]>=m.length)throw new Error(`Invalid output index: ${b[A]}`);if(b[A]===-3)continue;let R=b[A]===-1,W=b[A]===-2,M=R||W?s(m[A].dataType,m[A].dims):n(b[A],m[A].dataType,m[A].dims),D=this.gpuDataManager.get(M.data);if(!D)throw new Error(`no GPU data for output: ${M.data}`);if(R&&this.temporaryData.push(D),W){let _=this.kernelPersistentData.get(this.currentKernelId);_||(_=[],this.kernelPersistentData.set(this.currentKernelId,_)),_.push(D)}w.push(M),v.push(D)}let y;if(x){let A=0,R=0,W=[],M=1;x.forEach(z=>{let F=typeof z.data==\"number\"?[z.data]:z.data,q;switch(F.length){case 1:q=4;break;case 2:q=8;break;case 3:q=16;break;case 4:q=16;break;case 5:q=16;break;case 6:q=16;break;default:throw new Error(`unsupported data length: ${F.length}`)}(R===5||R===6)&&(q=16),q>M&&(M=q),A=Math.ceil(A/q)*q,R=F.length,W.push(A),A+=F.length*4}),A=Math.ceil(A/M)*M;let D=new ArrayBuffer(A);x.forEach((z,F)=>{let q=W[F],le=typeof z.data==\"number\"?[z.data]:z.data;z.type===\"int32\"?new Int32Array(D,q,le.length).set(le):z.type===\"uint32\"?new Uint32Array(D,q,le.length).set(le):new Float32Array(D,q,le.length).set(le)});let _=this.gpuDataManager.create(A,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(_.buffer,0,D,0,A),this.gpuDataManager.release(_.id),y={offset:0,size:A,buffer:_.buffer}}let S=this.programManager.normalizeDispatchGroupSize(g);return a||(a=this.programManager.build(t,S),this.programManager.setArtifact(d,a)),Ee(\"info\",()=>`[ProgramManager] run \"${t.name}\" (key=${d}) with ${S[0]}x${S[1]}x${S[2]}`),this.programManager.run(a,r,w,u,v,S,y),w}upload(t,r){this.gpuDataManager.upload(t,r)}memcpy(t,r){this.gpuDataManager.memcpy(t,r)}async download(t,r){await this.gpuDataManager.download(t,r)}alloc(t){return this.gpuDataManager.create(t).id}free(t){return this.gpuDataManager.release(t)}createKernel(t,r,o,n){let s=Ys.get(t);if(!s)throw new Error(`kernel not implemented: ${t}`);this.kernels.set(r,[t,n,s[0],[s[1],o]])}releaseKernel(t){let r=this.kernelPersistentData.get(t);if(r){for(let o of r)this.gpuDataManager.release(o.id);this.kernelPersistentData.delete(t)}this.kernelCustomData.delete(t),this.kernels.delete(t)}computeKernel(t,r,o){let n=this.kernels.get(t);if(!n)throw new Error(`kernel not created: ${t}`);let[s,u,d,a]=n;if(this.currentKernelId!==null)throw new Error(`kernel \"[${s}] ${u}\" is not allowed to be called recursively`);this.currentKernelId=t,a[0]&&(a[1]=a[0](a[1]),a[0]=void 0),Ee(\"info\",()=>`[WebGPU] Start to run kernel \"[${s}] ${u}\"...`);let m=this.env.debug;this.temporaryData=[];try{return m&&this.device.pushErrorScope(\"validation\"),d(r,a[1]),0}catch(g){return o.push(Promise.resolve(`[WebGPU] Kernel \"[${s}] ${u}\" failed. ${g}`)),1}finally{m&&o.push(this.device.popErrorScope().then(g=>g?`GPU validation error for kernel \"[${s}] ${u}\": ${g.message}`:null));for(let g of this.temporaryData)this.gpuDataManager.release(g.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(t,r,o,n){let s=this.sessionExternalDataMapping.get(t);s||(s=new Map,this.sessionExternalDataMapping.set(t,s));let u=s.get(r),d=this.gpuDataManager.registerExternalBuffer(o,n,u?.[1]);return s.set(r,[d,o]),d}unregisterBuffers(t){let r=this.sessionExternalDataMapping.get(t);r&&(r.forEach(o=>this.gpuDataManager.unregisterExternalBuffer(o[1])),this.sessionExternalDataMapping.delete(t))}getBuffer(t){let r=this.gpuDataManager.get(t);if(!r)throw new Error(`no GPU data for buffer: ${t}`);return r.buffer}createDownloader(t,r,o){return async()=>{let n=await yn(this,t,r);return Eo(n.buffer,o)}}}});var Qs={};Ir(Qs,{init:()=>ic});var sr,zn,ic,eu=H(()=>{\"use strict\";De();Zs();mt();ge();sr=class e{constructor(t,r,o,n){this.module=t;this.dataType=r;this.data=o;this.dims=n}getFloat32Array(){if(this.dataType!==1)throw new Error(\"Invalid data type\");let t=k.size(this.dims);return t===0?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,t)}getBigInt64Array(){if(this.dataType!==7)throw new Error(\"Invalid data type\");let t=k.size(this.dims);return t===0?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,t)}getInt32Array(){if(this.dataType!==6)throw new Error(\"Invalid data type\");let t=k.size(this.dims);return t===0?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,t)}reshape(t){if(k.size(t)!==k.size(this.dims))throw new Error(\"Invalid new shape\");return new e(this.module,this.dataType,this.data,t)}},zn=class{constructor(t,r,o){this.module=t;this.backend=r;this.customDataOffset=0;this.customDataSize=0;let n=t.HEAPU32,s=o>>2;this.opKernelContext=n[s++];let u=n[s++];this.outputCount=n[s++],this.customDataOffset=n[s++],this.customDataSize=n[s++];let d=[];for(let a=0;a<u;a++){let m=n[s++],g=n[s++],x=n[s++],b=[];for(let w=0;w<x;w++)b.push(n[s++]);d.push(new sr(t,m,g,b))}this.inputs=d}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(t,r){let o=r?.inputs?.map(d=>typeof d==\"number\"?this.inputs[d]:d)??this.inputs,n=r?.outputs??[],s=(d,a,m)=>new sr(this.module,a,this.output(d,m),m),u=(d,a)=>{let m=er(d);if(!m)throw new Error(`Unsupported data type: ${d}`);let g=m*k.size(a);return new sr(this.module,d,this.backend.gpuDataManager.create(g).id,a)};return this.backend.run(t,o,n,s,u)}output(t,r){let o=this.module.stackSave();try{let n=this.module.stackAlloc((1+r.length)*4),s=n>>2;this.module.HEAPU32[s++]=r.length;for(let u=0;u<r.length;u++)this.module.HEAPU32[s++]=r[u];return this.module._JsepOutput(this.opKernelContext,t,n)}catch(n){throw new Error(`Failed to generate kernel's output[${t}] with dims [${r}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${n}`)}finally{this.module.stackRestore(o)}}},ic=async(e,t)=>{let r=e.jsepInit;if(r&&navigator.gpu){if(!t.wasm.simd)throw new Error(\"Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP\");let o=new Jr;await o.initialize(t),r(o,n=>o.alloc(n),n=>o.free(n),(n,s,u,d=!1)=>{if(d)Ee(\"verbose\",()=>`[WebGPU] jsepCopyGpuToGpu: src=${n}, dst=${s}, size=${u}`),o.memcpy(n,s);else{Ee(\"verbose\",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${n}, gpuDataId=${s}, size=${u}`);let a=e.HEAPU8.subarray(n,n+u);o.upload(s,a)}},async(n,s,u)=>{Ee(\"verbose\",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${n}, dataOffset=${s}, size=${u}`),await o.download(n,()=>e.HEAPU8.subarray(s,s+u))},(n,s,u)=>o.createKernel(n,s,u,t.debug||t.webgpu.profilingMode===\"default\"?e.UTF8ToString(e._JsepGetNodeName(s)):`${s}`),n=>o.releaseKernel(n),(n,s,u,d)=>{Ee(\"verbose\",()=>`[WebGPU] jsepRun: sessionHandle=${u}, kernel=${n}, contextDataOffset=${s}`);let a=new zn(e,o,s);return o.computeKernel(n,a,d)})}}});var wo;wo=uo();var Ru=go(),pn,fn=!1,Er=!1,bo=!1,Pu=()=>{try{return typeof SharedArrayBuffer>\"u\"?!1:(typeof MessageChannel<\"u\"&&new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch{return!1}},Mu=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},Bu=(e,t)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-simd.wasm\":t?\"ort-wasm-threaded.wasm\":\"ort-wasm.wasm\",vo=async e=>{if(fn)return Promise.resolve();if(Er)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if(bo)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");Er=!0;let t=e.initTimeout,r=e.numThreads,o=e.simd,n=r>1&&Pu(),s=o&&Mu(),u=e.wasmPaths,d=typeof u==\"string\"?u:void 0,a=Bu(s,n),m=typeof u==\"object\"?u[a]:void 0,g=!1,x=[];if(t>0&&x.push(new Promise(b=>{setTimeout(()=>{g=!0,b()},t)})),x.push(new Promise((b,w)=>{let v=n?Ru:wo,y={locateFile:(S,A)=>{if(n&&S.endsWith(\".worker.js\")&&typeof Blob<\"u\")return URL.createObjectURL(new Blob([yo()],{type:\"text/javascript\"}));if(S.endsWith(\".wasm\")){if(m)return m;let R=d??A;return a===\"ort-wasm-simd.wasm\"?R+\"ort-wasm-simd.jsep.wasm\":a===\"ort-wasm-simd-threaded.wasm\"?R+\"ort-wasm-simd-threaded.jsep.wasm\":R+a}return A+S}};if(n)if(typeof Blob>\"u\")y.mainScriptUrlOrBlob=(void 0)(__dirname,\"ort-wasm-threaded.js\");else{let S=`var ortWasmThreaded=${v.toString()};`;y.mainScriptUrlOrBlob=new Blob([S],{type:\"text/javascript\"})}v(y).then(S=>{Er=!1,fn=!0,pn=S,b()},S=>{Er=!1,bo=!0,w(S)})})),await Promise.race(x),g)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},Re=()=>{if(fn&&pn)return pn;throw new Error(\"WebAssembly is not initialized yet.\")};var Be=(e,t)=>{let r=Re(),o=r.lengthBytesUTF8(e)+1,n=r._malloc(o);return r.stringToUTF8(e,n,o),t.push(n),n},Zt=(e,t,r,o)=>{if(typeof e==\"object\"&&e!==null){if(r.has(e))throw new Error(\"Circular reference in options\");r.add(e)}Object.entries(e).forEach(([n,s])=>{let u=t?t+n:n;if(typeof s==\"object\")Zt(s,u+\".\",r,o);else if(typeof s==\"string\"||typeof s==\"number\")o(u,s.toString());else if(typeof s==\"boolean\")o(u,s?\"1\":\"0\");else throw new Error(`Can't handle extra config type: ${typeof s}`)})},Ae=e=>{let t=Re(),r=t.stackSave();try{let o=t.stackAlloc(8);t._OrtGetLastError(o,o+4);let n=t.HEAP32[o/4],s=t.HEAPU32[o/4+1],u=s?t.UTF8ToString(s):\"\";throw new Error(`${e} ERROR_CODE: ${n}, ERROR_MESSAGE: ${u}`)}finally{t.stackRestore(r)}};var $o=e=>{let t=Re(),r=0,o=[],n=e||{};try{if(e?.logSeverityLevel===void 0)n.logSeverityLevel=2;else if(typeof e.logSeverityLevel!=\"number\"||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(e?.logVerbosityLevel===void 0)n.logVerbosityLevel=0;else if(typeof e.logVerbosityLevel!=\"number\"||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);e?.terminate===void 0&&(n.terminate=!1);let s=0;return e?.tag!==void 0&&(s=Be(e.tag,o)),r=t._OrtCreateRunOptions(n.logSeverityLevel,n.logVerbosityLevel,!!n.terminate,s),r===0&&Ae(\"Can't create run options.\"),e?.extra!==void 0&&Zt(e.extra,\"\",new WeakSet,(u,d)=>{let a=Be(u,o),m=Be(d,o);t._OrtAddRunConfigEntry(r,a,m)!==0&&Ae(`Can't set a run config entry: ${u} - ${d}.`)}),[r,o]}catch(s){throw r!==0&&t._OrtReleaseRunOptions(r),o.forEach(u=>t._free(u)),s}};var ku=e=>{switch(e){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},Du=e=>{switch(e){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},Wu=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly=\"1\"),e.executionProviders&&e.executionProviders.some(r=>(typeof r==\"string\"?r:r.name)===\"webgpu\")&&(e.enableMemPattern=!1)},zu=(e,t,r)=>{for(let o of t){let n=typeof o==\"string\"?o:o.name;switch(n){case\"xnnpack\":n=\"XNNPACK\";break;case\"webnn\":if(n=\"WEBNN\",typeof o!=\"string\"){let u=o;if(u?.deviceType){let d=Be(\"deviceType\",r),a=Be(u.deviceType,r);Re()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ae(`Can't set a session config entry: 'deviceType' - ${u.deviceType}.`)}if(u?.powerPreference){let d=Be(\"powerPreference\",r),a=Be(u.powerPreference,r);Re()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ae(`Can't set a session config entry: 'powerPreference' - ${u.powerPreference}.`)}}break;case\"webgpu\":if(n=\"JS\",typeof o!=\"string\"){let u=o;if(u?.preferredLayout){if(u.preferredLayout!==\"NCHW\"&&u.preferredLayout!==\"NHWC\")throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${u.preferredLayout}`);let d=Be(\"preferredLayout\",r),a=Be(u.preferredLayout,r);Re()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ae(`Can't set a session config entry: 'preferredLayout' - ${u.preferredLayout}.`)}}break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported execution provider: ${n}`)}let s=Be(n,r);Re()._OrtAppendExecutionProvider(e,s)!==0&&Ae(`Can't append execution provider: ${n}.`)}},xo=e=>{let t=Re(),r=0,o=[],n=e||{};Wu(n);try{let s=ku(n.graphOptimizationLevel??\"all\"),u=Du(n.executionMode??\"sequential\"),d=typeof n.logId==\"string\"?Be(n.logId,o):0,a=n.logSeverityLevel??2;if(!Number.isInteger(a)||a<0||a>4)throw new Error(`log serverity level is not valid: ${a}`);let m=n.logVerbosityLevel??0;if(!Number.isInteger(m)||m<0||m>4)throw new Error(`log verbosity level is not valid: ${m}`);let g=typeof n.optimizedModelFilePath==\"string\"?Be(n.optimizedModelFilePath,o):0;if(r=t._OrtCreateSessionOptions(s,!!n.enableCpuMemArena,!!n.enableMemPattern,u,!!n.enableProfiling,0,d,a,m,g),r===0&&Ae(\"Can't create session options.\"),n.executionProviders&&zu(r,n.executionProviders,o),n.freeDimensionOverrides)for(let[x,b]of Object.entries(n.freeDimensionOverrides)){if(typeof x!=\"string\")throw new Error(`free dimension override name must be a string: ${x}`);if(typeof b!=\"number\"||!Number.isInteger(b)||b<0)throw new Error(`free dimension override value must be a non-negative integer: ${b}`);let w=Be(x,o);t._OrtAddFreeDimensionOverride(r,w,b)!==0&&Ae(`Can't set a free dimension override: ${x} - ${b}.`)}return n.extra!==void 0&&Zt(n.extra,\"\",new WeakSet,(x,b)=>{let w=Be(x,o),v=Be(b,o);t._OrtAddSessionConfigEntry(r,w,v)!==0&&Ae(`Can't set a session config entry: ${x} - ${b}.`)}),[r,o]}catch(s){throw r!==0&&t._OrtReleaseSessionOptions(r),o.forEach(u=>t._free(u)),s}};De();var ru=!1,sc=e=>{let t=Re(),r=t.stackSave();try{let o=t.stackAlloc(8);return t._OrtGetInputOutputCount(e,o,o+4)!==0&&Ae(\"Can't get session input/output count.\"),[t.HEAP32[o/4],t.HEAP32[o/4+1]]}finally{t.stackRestore(r)}},uc=(e,t)=>{Re()._OrtInit(e,t)!==0&&Ae(\"Can't initialize onnxruntime.\")},nu=async e=>{uc(e.wasm.numThreads,tr(e.logLevel));{let t=(eu(),Mt(Qs)).init;await t(Re(),e)}ru=!0},ur=new Map,ou=()=>ru,Vn=e=>{let t=Re(),r=t._malloc(e.byteLength);if(r===0)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,r),[r,e.byteLength]},Gn=(e,t)=>{let r=Re(),o=0,n=0,s=0,u=[],d=[],a=[];try{[n,u]=xo(t),o=r._OrtCreateSession(e[0],e[1],n),o===0&&Ae(\"Can't create a session.\");let[m,g]=sc(o),x=[],b=[],w=[];for(let y=0;y<m;y++){let S=r._OrtGetInputName(o,y);S===0&&Ae(\"Can't get an input name.\"),d.push(S),x.push(r.UTF8ToString(S))}for(let y=0;y<g;y++){let S=r._OrtGetOutputName(o,y);S===0&&Ae(\"Can't get an output name.\"),a.push(S);let A=r.UTF8ToString(S);b.push(A);{let R=typeof t?.preferredOutputLocation==\"string\"?t.preferredOutputLocation:t?.preferredOutputLocation?.[A]??\"cpu\";if(R!==\"cpu\"&&R!==\"cpu-pinned\"&&R!==\"gpu-buffer\")throw new Error(`Not supported preferred output location: ${R}.`);w.push(R)}}let v=null;return w.some(y=>y===\"gpu-buffer\")&&(s=r._OrtCreateBinding(o),s===0&&Ae(\"Can't create IO binding.\"),v={handle:s,outputPreferredLocations:w,outputPreferredLocationsEncoded:w.map(y=>hn(y))}),ur.set(o,[o,d,a,v]),[o,x,b]}catch(m){throw d.forEach(g=>r._OrtFree(g)),a.forEach(g=>r._OrtFree(g)),s!==0&&r._OrtReleaseBinding(s),o!==0&&r._OrtReleaseSession(o),m}finally{r._free(e[0]),n!==0&&r._OrtReleaseSessionOptions(n),u.forEach(m=>r._free(m))}},au=(e,t)=>{let r=Vn(e);return Gn(r,t)},iu=e=>{let t=Re(),r=ur.get(e);if(!r)throw new Error(`cannot release session. invalid session id: ${e}`);let[o,n,s,u]=r;u&&t._OrtReleaseBinding(u.handle),t.jsepUnregisterBuffers?.(e),n.forEach(d=>t._OrtFree(d)),s.forEach(d=>t._OrtFree(d)),t._OrtReleaseSession(o),ur.delete(e)},tu=(e,t,r,o,n)=>{if(!e){t.push(0);return}let s=Re(),u=e[0],d=e[1],a=e[3],m,g;if(u===\"string\"&&a===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");if(a===\"gpu-buffer\"){let w=e[2].gpuBuffer,v=er(mn(u));g=d.reduce((y,S)=>y*S,1)*v,m=s.jsepRegisterBuffer(o,n,w,g)}else{let w=e[2];if(Array.isArray(w)){g=4*w.length,m=s._malloc(g),r.push(m);let v=m/4;for(let y=0;y<w.length;y++){if(typeof w[y]!=\"string\")throw new TypeError(`tensor data at index ${y} is not a string`);s.HEAPU32[v++]=Be(w[y],r)}}else g=w.byteLength,m=s._malloc(g),r.push(m),s.HEAPU8.set(new Uint8Array(w.buffer,w.byteOffset,g),m)}let x=s.stackSave(),b=s.stackAlloc(4*d.length);try{let w=b/4;d.forEach(y=>s.HEAP32[w++]=y);let v=s._OrtCreateTensor(mn(u),m,g,b,d.length,hn(a));v===0&&Ae(`Can't create tensor for input/output. session=${o}, index=${n}.`),t.push(v)}finally{s.stackRestore(x)}},su=async(e,t,r,o,n,s)=>{let u=Re(),d=ur.get(e);if(!d)throw new Error(`cannot run inference. invalid session id: ${e}`);let[a,m,g,x]=d,b=t.length,w=o.length,v=0,y=[],S=[],A=[],R=[],W=u.stackSave(),M=u.stackAlloc(b*4),D=u.stackAlloc(b*4),_=u.stackAlloc(w*4),z=u.stackAlloc(w*4);try{[v,y]=$o(s);for(let ae=0;ae<b;ae++)tu(r[ae],S,R,e,t[ae]);for(let ae=0;ae<w;ae++)tu(n[ae],A,R,e,b+o[ae]);let F=M/4,q=D/4,le=_/4,B=z/4;for(let ae=0;ae<b;ae++)u.HEAPU32[F++]=S[ae],u.HEAPU32[q++]=m[t[ae]];for(let ae=0;ae<w;ae++)u.HEAPU32[le++]=A[ae],u.HEAPU32[B++]=g[o[ae]];if(x){let{handle:ae,outputPreferredLocations:we,outputPreferredLocationsEncoded:j}=x;if(m.length!==b)throw new Error(`input count from feeds (${b}) is expected to be always equal to model's input count (${m.length}).`);for(let Se=0;Se<b;Se++){let Oe=t[Se];await u._OrtBindInput(ae,m[Oe],S[Se])!==0&&Ae(`Can't bind input[${Se}] for session=${e}.`)}for(let Se=0;Se<w;Se++){let Oe=o[Se];n[Se]?.[3]?u._OrtBindOutput(ae,g[Oe],A[Se],0)!==0&&Ae(`Can't bind pre-allocated output[${Se}] for session=${e}.`):u._OrtBindOutput(ae,g[Oe],0,j[Oe])!==0&&Ae(`Can't bind output[${Se}] to ${we[Se]} for session=${e}.`)}}let K;x?K=await u._OrtRunWithBinding(a,x.handle,w,_,v):K=await u._OrtRun(a,D,M,b,z,w,_,v),K!==0&&Ae(\"failed to call OrtRun().\");let xe=[];for(let ae=0;ae<w;ae++){let we=u.HEAPU32[_/4+ae];if(we===A[ae]){xe.push(n[ae]);continue}let j=u.stackSave(),Se=u.stackAlloc(4*4),Oe=!1,Ie,Ce=0;try{u._OrtGetTensorData(we,Se,Se+4,Se+8,Se+12)!==0&&Ae(`Can't access output tensor data on index ${ae}.`);let Ne=Se/4,Le=u.HEAPU32[Ne++];Ce=u.HEAPU32[Ne++];let N=u.HEAPU32[Ne++],de=u.HEAPU32[Ne++],pe=[];for(let Te=0;Te<de;Te++)pe.push(u.HEAPU32[N/4+Te]);u._OrtFree(N);let ze=pe.reduce((Te,ke)=>Te*ke,1);Ie=Qt(Le);let Ue=x?.outputPreferredLocations[o[ae]];if(Ie===\"string\"){if(Ue===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");let Te=[],ke=Ce/4;for(let Ge=0;Ge<ze;Ge++){let Xe=u.HEAPU32[ke++],Fe=Ge===ze-1?void 0:u.HEAPU32[ke]-Xe;Te.push(u.UTF8ToString(Xe,Fe))}xe.push([Ie,pe,Te,\"cpu\"])}else if(Ue===\"gpu-buffer\"&&ze>0){let Te=u.jsepGetBuffer(Ce),ke=er(Le);if(ke===void 0||!So(Ie))throw new Error(`Unsupported data type: ${Ie}`);Oe=!0,xe.push([Ie,pe,{gpuBuffer:Te,download:u.jsepCreateDownloader(Te,ze*ke,Ie),dispose:()=>{u._OrtReleaseTensor(we)}},\"gpu-buffer\"])}else{let Te=Tr(Ie),ke=new Te(ze);new Uint8Array(ke.buffer,ke.byteOffset,ke.byteLength).set(u.HEAPU8.subarray(Ce,Ce+ke.byteLength)),xe.push([Ie,pe,ke,\"cpu\"])}}finally{u.stackRestore(j),Ie===\"string\"&&Ce&&u._free(Ce),Oe||u._OrtReleaseTensor(we)}}return x&&u._OrtClearBoundOutputs(x.handle),xe}finally{u.stackRestore(W),S.forEach(F=>u._OrtReleaseTensor(F)),A.forEach(F=>u._OrtReleaseTensor(F)),R.forEach(F=>u._free(F)),v!==0&&u._OrtReleaseRunOptions(v),y.forEach(F=>u._free(F))}},uu=e=>{let t=Re(),r=ur.get(e);if(!r)throw new Error(\"invalid session id\");let o=r[0],n=t._OrtEndProfiling(o);n===0&&Ae(\"Can't get an profile file name.\"),t._OrtFree(n)},lu=e=>{let t=[];for(let r of e){let o=r[2];!Array.isArray(o)&&\"buffer\"in o&&t.push(o.buffer)}return t};self.onmessage=e=>{switch(e.data.type){case\"init-wasm\":try{vo(e.data.in).then(()=>postMessage({type:\"init-wasm\"}),t=>postMessage({type:\"init-wasm\",err:t}))}catch(t){postMessage({type:\"init-wasm\",err:t})}break;case\"init-ort\":try{nu(e.data.in).then(()=>postMessage({type:\"init-ort\"}),t=>postMessage({type:\"init-ort\",err:t}))}catch(t){postMessage({type:\"init-ort\",err:t})}break;case\"create_allocate\":try{let{model:t}=e.data.in,r=Vn(t);postMessage({type:\"create_allocate\",out:r})}catch(t){postMessage({type:\"create_allocate\",err:t})}break;case\"create_finalize\":try{let{modeldata:t,options:r}=e.data.in,o=Gn(t,r);postMessage({type:\"create_finalize\",out:o})}catch(t){postMessage({type:\"create_finalize\",err:t})}break;case\"create\":try{let{model:t,options:r}=e.data.in,o=au(t,r);postMessage({type:\"create\",out:o})}catch(t){postMessage({type:\"create\",err:t})}break;case\"release\":try{let t=e.data.in;iu(t),postMessage({type:\"release\"})}catch(t){postMessage({type:\"release\",err:t})}break;case\"run\":try{let{sessionId:t,inputIndices:r,inputs:o,outputIndices:n,options:s}=e.data.in;su(t,r,o,n,s).then(u=>{postMessage({type:\"run\",out:u},lu(u))},u=>{postMessage({type:\"run\",err:u})})}catch(t){postMessage({type:\"run\",err:t})}break;case\"end-profiling\":try{let t=e.data.in;uu(t),postMessage({type:\"end-profiling\"})}catch(t){postMessage({type:\"end-profiling\",err:t})}break;case\"is-ort-env-initialized\":try{let t=ou();postMessage({type:\"is-ort-env-initialized\",out:t})}catch(t){postMessage({type:\"is-ort-env-initialized\",err:t})}break;default:}};})();\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, env, InferenceSession} from 'onnxruntime-common';\n\nimport {OrtWasmMessage, SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport {initializeWebAssembly} from './wasm-factory';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker|undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\n\n// resolve; reject\ntype PromiseCallbacks<T = void> = [(result: T) => void, (reason: unknown) => void];\n\nlet initWasmCallbacks: PromiseCallbacks;\nlet initOrtCallbacks: PromiseCallbacks;\nconst createSessionAllocateCallbacks: Array<PromiseCallbacks<SerializableModeldata>> = [];\nconst createSessionFinalizeCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst createSessionCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst releaseSessionCallbacks: Array<PromiseCallbacks<void>> = [];\nconst runCallbacks: Array<PromiseCallbacks<SerializableTensorMetadata[]>> = [];\nconst endProfilingCallbacks: Array<PromiseCallbacks<void>> = [];\nconst isOrtEnvInitializedCallbacks: Array<PromiseCallbacks<boolean>> = [];\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      break;\n    case 'init-ort':\n      if (ev.data.err) {\n        initOrtCallbacks[1](ev.data.err);\n      } else {\n        initOrtCallbacks[0]();\n      }\n      break;\n    case 'create_allocate':\n      if (ev.data.err) {\n        createSessionAllocateCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionAllocateCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create_finalize':\n      if (ev.data.err) {\n        createSessionFinalizeCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionFinalizeCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create':\n      if (ev.data.err) {\n        createSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'release':\n      if (ev.data.err) {\n        releaseSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        releaseSessionCallbacks.shift()![0]();\n      }\n      break;\n    case 'run':\n      if (ev.data.err) {\n        runCallbacks.shift()![1](ev.data.err);\n      } else {\n        runCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'end-profiling':\n      if (ev.data.err) {\n        endProfilingCallbacks.shift()![1](ev.data.err);\n      } else {\n        endProfilingCallbacks.shift()![0]();\n      }\n      break;\n    case 'is-ort-env-initialized':\n      if (ev.data.err) {\n        isOrtEnvInitializedCallbacks.shift()![1](ev.data.err);\n      } else {\n        isOrtEnvInitializedCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    default:\n  }\n};\n\nconst scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src : undefined;\n\nexport const initializeWebAssemblyInstance = async(): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    if (initialized) {\n      return;\n    }\n    if (initializing) {\n      throw new Error('multiple calls to \\'initWasm()\\' detected.');\n    }\n    if (aborted) {\n      throw new Error('previous call to \\'initWasm()\\' failed.');\n    }\n\n    initializing = true;\n\n    // overwrite wasm filepaths\n    if (env.wasm.wasmPaths === undefined) {\n      if (scriptSrc && scriptSrc.indexOf('blob:') !== 0) {\n        env.wasm.wasmPaths = scriptSrc.substr(0, +(scriptSrc).lastIndexOf('/') + 1);\n      }\n    }\n\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      const workerUrl = URL.createObjectURL(new Blob(\n          [\n            // This require() function is handled by esbuild plugin to load file content as string.\n            // eslint-disable-next-line @typescript-eslint/no-require-imports\n            require('./proxy-worker/main')\n          ],\n          {type: 'text/javascript'}));\n      proxyWorker = new Worker(workerUrl, {name: 'ort-wasm-proxy-worker'});\n      proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n      proxyWorker.onmessage = onProxyWorkerMessage;\n      URL.revokeObjectURL(workerUrl);\n      initWasmCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-wasm', in : env.wasm};\n      proxyWorker.postMessage(message);\n    });\n\n  } else {\n    return initializeWebAssembly(env.wasm);\n  }\n};\n\nexport const initializeRuntime = async(env: Env): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      initOrtCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-ort', in : env};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initRuntime(env);\n  }\n};\n\nexport const createSessionAllocate = async(model: Uint8Array): Promise<SerializableModeldata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableModeldata>((resolve, reject) => {\n      createSessionAllocateCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create_allocate', in : {model}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSessionAllocate(model);\n  }\n};\n\nexport const createSessionFinalize = async(modeldata: SerializableModeldata, options?: InferenceSession.SessionOptions):\n    Promise<SerializableSessionMetadata> => {\n      if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n        ensureWorker();\n        return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n          createSessionFinalizeCallbacks.push([resolve, reject]);\n          const message: OrtWasmMessage = {type: 'create_finalize', in : {modeldata, options}};\n          proxyWorker!.postMessage(message);\n        });\n      } else {\n        return core.createSessionFinalize(modeldata, options);\n      }\n    };\n\nexport const createSession =\n    async(model: Uint8Array, options?: InferenceSession.SessionOptions): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      createSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create', in : {model, options}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      releaseSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'release', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputs: TensorMetadata[], outputIndices: number[],\n    outputs: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some(t => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some(t => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      runCallbacks.push([resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[];  // every input is on CPU.\n      const message: OrtWasmMessage =\n          {type: 'run', in : {sessionId, inputIndices, inputs: serializableInputs, outputIndices, options}};\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      endProfilingCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'end-profiling', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n\nexport const isOrtEnvInitialized = async(): Promise<boolean> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<boolean>((resolve, reject) => {\n      isOrtEnvInitializedCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'is-ort-env-initialized'};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    return core.isOrtEnvInitialized();\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {readFile} from 'node:fs/promises';\nimport {env, InferenceSession, InferenceSessionHandler, SessionHandler, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, TensorMetadata} from './proxy-messages';\nimport {createSession, createSessionAllocate, createSessionFinalize, endProfiling, initializeRuntime, isOrtEnvInitialized, releaseSession, run} from './proxy-wrapper';\nimport {isGpuBufferSupportedType} from './wasm-common';\n\nlet runtimeInitializationPromise: Promise<void>|undefined;\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, {gpuBuffer: tensor.gpuBuffer}, 'gpu-buffer'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const {gpuBuffer, download, dispose} = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, {dataType, dims: tensor[1], download, dispose});\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async createSessionAllocate(path: string): Promise<SerializableModeldata> {\n    // fetch model from url and move to wasm heap. The arraybufffer that held the http\n    // response is freed once we return\n    const response = await fetch(path);\n    if (response.status !== 200) {\n      throw new Error(`failed to load model: ${path}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    return createSessionAllocate(new Uint8Array(arrayBuffer));\n  }\n\n  async loadModel(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    if (!(await isOrtEnvInitialized())) {\n      if (!runtimeInitializationPromise) {\n        runtimeInitializationPromise = initializeRuntime(env);\n      }\n      await runtimeInitializationPromise;\n      runtimeInitializationPromise = undefined;\n    }\n\n    if (typeof pathOrBuffer === 'string') {\n      if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n        // node\n        const model = await readFile(pathOrBuffer);\n        [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n      } else {\n        // browser\n        // fetch model and move to wasm heap.\n        const modelData: SerializableModeldata = await this.createSessionAllocate(pathOrBuffer);\n        // create the session\n        [this.sessionId, this.inputNames, this.outputNames] = await createSessionFinalize(modelData, options);\n      }\n    } else {\n      [this.sessionId, this.inputNames, this.outputNames] = await createSession(pathOrBuffer, options);\n    }\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType, options: InferenceSession.RunOptions):\n      Promise<SessionHandler.ReturnType> {\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor|null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs =\n        inputArray.map((t, i) => encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`));\n    const outputs = outputArray.map(\n        (t, i) => t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null);\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {cpus} from 'node:os';\nimport {Backend, env, InferenceSession, InferenceSessionHandler} from 'onnxruntime-common';\n\nimport {initializeWebAssemblyInstance} from './wasm/proxy-wrapper';\nimport {OnnxruntimeWebAssemblySessionHandler} from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (typeof env.wasm.simd !== 'boolean') {\n    env.wasm.simd = true;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    const numCpuLogicalCores = typeof navigator === 'undefined' ? cpus().length : navigator.hardwareConcurrency;\n    env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  async init(): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyInstance();\n  }\n  createInferenceSessionHandler(path: string, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(buffer: Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OnnxruntimeWebAssemblyBackend} from './backend-wasm';\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport {registerBackend, env} from 'onnxruntime-common';\nimport {version} from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = BUILD_DEFS.DISABLE_TRAINING ? require('./backend-wasm-inference').wasmBackend :\n                                                    require('./backend-wasm-training').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_WEBGPU && typeof navigator !== 'undefined' && navigator.gpu) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n  if (BUILD_DEFS.DISABLE_TRAINING) {\n    registerBackend('xnnpack', wasmBackend, 9);\n    registerBackend('webnn', wasmBackend, 9);\n  }\n}\n\nObject.defineProperty(env.versions, 'web', {value: version, enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0-dev.20231103-1439da36fe';\n"],
  "mappings": ";;;;;wgBAAA,IAcMA,GACAC,GAYOC,GA0CAC,GArEbC,GAAAC,EAAA,kBAcML,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACI,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBT,GAAS,IAAIM,CAAI,EACxC,GAAIG,IAAmB,OACrBT,GAAS,IAAIM,EAAM,CAAC,QAAAC,EAAS,SAAAC,CAAQ,CAAC,MACjC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIT,GAAyB,QAAQK,CAAI,EAC3CI,IAAM,IACRT,GAAyB,OAAOS,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIT,GAAyB,OAAQS,IACnD,GAAIV,GAAS,IAAIC,GAAyBS,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnEP,GAAyB,OAAOS,EAAG,EAAGJ,CAAI,EAC1C,OAGJL,GAAyB,KAAKK,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAUaH,GAAiB,MAAMQ,GAAqD,CACvF,IAAMC,EAAeD,EAAa,SAAW,EAAIV,GAA2BU,EACtEE,EAAS,CAAA,EACf,QAAWC,KAAeF,EAAc,CACtC,IAAMG,EAAcf,GAAS,IAAIc,CAAW,EAC5C,GAAIC,EAAa,CACf,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,SAGF,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAI,GAEpD,MAAMA,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACLD,GACHH,EAAO,KAAK,CAAC,KAAMC,EAAa,IAAKG,CAAC,CAAC,EAEzCF,EAAY,QAAU,WAEtB,OAAOA,EAAY,cAKzB,MAAM,IAAI,MAAM,oCAAoCF,EAAO,IAAII,GAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,CAC1G,ICrGA,IAAAC,GAAAC,EAAA,kBA2EAC,OC3EA,IAMaC,GANbC,GAAAC,EAAA,kBAMaF,GAAU,mCCNvB,IAQIG,GAESC,GAVbC,GAAAC,EAAA,kBAIAC,KAIIJ,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAC,OAAQI,EAAO,EAE1B,IAAI,SAASC,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDN,GAAgBM,EAClB,EACA,IAAI,UAAQ,CACV,OAAON,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAC,WAAY,EAAI,CAAC,IC/BzD,IAmKaM,GAnKbC,GAAAC,EAAA,kBAGAC,KAgKaH,GAAWA,KCnKxB,IASaI,GA0FAC,GAnGbC,GAAAC,EAAA,kBASaH,GAAkB,CAACI,EAAgBC,IAA4C,CAC1F,IAAMC,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQF,EAAO,KAAK,CAAC,EAC5BE,EAAO,OAASF,EAAO,KAAK,CAAC,EAC7B,IAAMG,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAJ,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,IAEtBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,GAGxB,IAAMM,EAAcL,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/DM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASK,EAAI,EAAGA,EAAIV,EAAQU,IAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IAAK,CAC9B,IAAMC,GAAMjB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMlB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1E,GAAMR,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,EAAIL,IAAmB,GACzB,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE1EL,EAAgB,UAAY,QAAUc,EAAI,IAAMC,EAAI,IAAM,EAAI,IAAMC,EAAI,IACxEhB,EAAgB,SAASa,EAAGD,EAAG,EAAG,CAAC,EAGvC,OAAOb,EAAO,UAAS,MAEvB,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaL,GAAoB,CAACG,EAAgBC,IAAiD,CACjG,IAAME,EAAkB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EACpEiB,EACJ,GAAIjB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAgB,EACApB,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBqB,EAAWrB,EAAO,KAAK,CAAC,IAExBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBqB,EAAWrB,EAAO,KAAK,CAAC,GAE1B,IAAMM,EAAcL,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhGM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIH,IAAY,SACVA,EAAQ,SAAW,QAAcoB,IAAa,GAAKpB,EAAQ,SAAW,QACrEoB,IAAa,GAAMpB,EAAQ,SAAW,OAASA,EAAQ,SAAW,OACrE,MAAM,IAAI,MAAM,+CAAgD,EAKpE,IAAMqB,EAAO,EACTC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEf,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BU,EAAQjB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QAASU,EAAI,EAAGA,EAAIV,EAASD,EACxBmB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMP,IAC/FK,EAAM,KAAKG,CAAa,GAAMvB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKI,CAAa,GAAMxB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKK,CAAa,GAAMzB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKM,CAAa,EAAIZ,IAAmB,GAC3C,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAI5E,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOY,CACT,IC/LA,IAiBaO,GAkFAC,GA8IAC,GAWAC,GASAC,GArQbC,GAAAC,EAAA,kBAIAC,KAaaP,GAAiB,CAACQ,EAAqCC,IAA0C,CAC5G,GAAID,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIC,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAC,OAAAC,EAAQ,MAAAC,CAAK,EAAIF,EAElBG,EAAOH,EAAQ,MAAQ,CAAC,KAAM,IAAK,KAAM,CAAC,EAC5CI,EACAC,EAEA,OAAQF,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAQA,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMG,EAAcN,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DO,EACFP,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACzGQ,EAASP,EAASC,EAClBO,EAAcF,IAAiB,OAAS,IAAI,aAAaC,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGE,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBR,EAAQS,EAAiBT,EAAS,EAAGU,EAAiB,GAG3FZ,IAAgB,QAClBI,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdP,IAAiB,OACnBW,EAAiBV,EAAS,EACjBD,IAAiB,OAC1BQ,EAAiB,EACjBE,EAAiBT,EACjBQ,EAAiBR,EAAS,GACjBD,IAAiB,QAC1BU,EAAiB,EACjBD,EAAiBR,EACjBO,EAAiBP,EAAS,GAG5B,QAASW,EAAI,EAAGA,EAAIX,EACfW,IAAKR,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FD,EAAYM,GAAgB,GAAKhB,EAAOY,CAAa,EAAIN,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYO,GAAgB,GAAKjB,EAAOa,CAAa,EAAIP,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYQ,GAAgB,GAAKlB,EAAOc,CAAa,EAAIR,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9Ec,IAAmB,IAAMJ,IAAkB,KAC7CL,EAAYS,GAAgB,GAAKnB,EAAOe,CAAa,EAAIT,EAAS,CAAC,GAAKD,EAAS,CAAC,GAOtF,OAFqBG,IAAiB,OAAS,IAAIa,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,EACxD,IAAIkB,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,CAEzG,EAKaV,GAAkB,MAC3B6B,EACArB,IACyC,CAE3C,IAAMsB,EAAiB,OAAQ,iBAAsB,KAAeD,aAAiB,iBAC/EE,EAAiB,OAAQ,UAAe,KAAeF,aAAiB,UACxEG,EAAgB,OAAQ,YAAiB,KAAeH,aAAiB,YACzEI,EAAW,OAAOJ,GAAU,SAE9BK,EACAC,EAA+C3B,GAAW,CAAA,EAG9D,GAAIsB,EAAgB,CAElB,IAAMM,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAI5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MAMlB,GALIrB,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADA2B,EAAwB3B,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7E2B,EAAsB,aAAe,OAEvCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,OAE9ByB,EAAsB,aAAe,OACrCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAGhC2B,EAAgB,UAAUR,EAAO,EAAG,CAAC,EACrCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCsB,EAAgB,CACzB,IAAItB,EACAC,EAiBJ,GAfIF,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,eAEhBC,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,OAGZrB,IAAY,SACd2B,EAAwB3B,GAE1B2B,EAAsB,OAAS,OAC/BA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAE1BF,IAAY,OAAW,CACzB,IAAM8B,EAAa,SAAS,cAAc,QAAQ,EAElDA,EAAW,MAAQ5B,EACnB4B,EAAW,OAAS7B,EAEpB,IAAM4B,EAAkBC,EAAW,WAAW,IAAI,EAElD,GAAID,GAAmB,KACrBA,EAAgB,aAAaR,EAAO,EAAG,CAAC,EACxCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CyB,EAAOL,EAAM,aAENG,EAAe,CAExB,GAAIxB,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAM4B,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAM5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MACpB,OAAAQ,EAAgB,UAAUR,EAAO,EAAG,EAAGnB,EAAOD,CAAM,EACpDyB,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,KACzD0B,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EACvBX,GAAemC,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAMJ,EAAS,SAAS,cAAc,QAAQ,EACxCK,EAAUL,EAAO,WAAW,IAAI,EACtC,GAAI,CAACP,GAAS,CAACY,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAMb,EACfa,EAAS,OAAS,IAAK,CACrBN,EAAO,MAAQM,EAAS,MACxBN,EAAO,OAASM,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGN,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMO,EAAMF,EAAQ,aAAa,EAAG,EAAGL,EAAO,MAAOA,EAAO,MAAM,EAElED,EAAsB,OAASC,EAAO,OACtCD,EAAsB,MAAQC,EAAO,MACrCG,EAAQxC,GAAe4C,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOnC,GAAemC,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKalC,GAAoB,CAC7B2C,EAAsCpC,IAAgD,CACxF,GAAM,CAAC,MAAAE,EAAO,OAAAD,EAAQ,SAAAoC,EAAU,QAAAC,CAAO,EAAItC,EAErCuC,EAAO,CAAC,EAAGtC,EAAQC,EAAO,CAAC,EACjC,OAAO,IAAIkB,GAAO,CAAC,SAAU,UAAW,KAAM,UAAW,QAAAgB,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC5F,EAKa5C,GAAsB,CAC/B8C,EAA0CxC,IAAkD,CAC9F,GAAM,CAAC,SAAAyC,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAItC,EAC5C,OAAO,IAAIoB,GAAO,CAAC,SAAU,aAAc,KAAMqB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC7G,EAKa3C,GAAyB,CAClC+C,EAAS3C,EAAwCwC,IACjD,IAAInB,GAAO,CAAC,SAAU,aAAc,KAAAsB,EAAM,KAAM3C,EAAQ,KAAMwC,GAAQ,CAACxC,EAAO,MAAM,CAAC,CAAC,ICvQ1F,IAWa4C,GAcAC,GAcTC,GACSC,GAxCbC,GAAAC,EAAA,kBAWaL,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,UAAW,WAAW,EACvB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACvB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAkB,GACTC,GAAc,IAAK,CAC9B,GAAI,CAACD,GAAiB,CACpBA,GAAkB,GAClB,IAAMI,EAA2B,OAAO,cAAkB,KAAe,OAAO,cAAc,MAAS,WACjGC,EACF,OAAO,eAAmB,KAAe,OAAO,eAAe,MAAS,WAExED,IACFN,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DM,IACFP,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAGxE,ICxDA,IAWaO,GAkBAC,GA7BbC,GAAAC,EAAA,kBAIAC,KAOaJ,GAAiBK,GAAoC,CAChE,IAAIC,EAAO,EACX,QAASC,EAAI,EAAGA,EAAIF,EAAK,OAAQE,IAAK,CACpC,IAAMC,EAAMH,EAAKE,CAAC,EAClB,GAAI,OAAOC,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQD,CAAC,8BAA8BC,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQD,CAAC,0CAA0CC,CAAG,EAAE,EAE/EF,GAAQE,EAEV,OAAOF,CACT,EAKaL,GAAgB,CAACQ,EAAgBJ,IAAmC,CAC/E,OAAQI,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIC,GAAOD,EAAO,KAAMA,EAAO,KAAMJ,CAAI,EAClD,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,KAAMD,EAAO,KACb,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,UACH,OAAO,IAAIK,GAAO,CAChB,SAAU,UACV,QAASD,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,UAAWD,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCI,EAAO,QAAQ,mBAAmB,EAE1F,ICzDA,IAwBaE,GAxBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAEAC,KACAC,KAgBaN,GAAP,KAAa,CAyCjB,YACIO,EAEAC,EAA8EC,EAAwB,CAExGC,GAAW,EAEX,IAAIC,EACAC,EAEJ,GAAI,OAAOL,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBI,EAAOJ,EAAK,KACZK,EAAOL,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMM,EAAgCC,GAAsC,IAAIH,CAAI,EACpF,GAAI,CAACE,EACH,MAAM,IAAI,UAAU,qBAAqBF,CAAI,uCAAuC,EAEtF,GAAI,EAAEJ,EAAK,gBAAgBM,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUN,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAII,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBJ,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GAAKI,IAAS,WAAaA,IAAS,WAAaA,IAAS,SAAWA,IAAS,SAAWA,IAAS,UAC7FA,IAAS,OACZ,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBJ,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIQ,EACAC,EAEJ,GAAI,OAAOT,GAAS,SAMlB,GAFAI,EAAOJ,EACPS,EAAYP,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAiD,EAIvEO,EAAOP,MACF,CAEL,IAAMS,EAAwBH,GAAsC,IAAIP,CAAI,EAC5E,GAAIU,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BV,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAID,IAAS,UAIX,MAAM,IAAI,UACN,+FAA+F,EAC1FA,IAAS,UAAYA,IAAS,QAYvCQ,EAAQE,EAA8B,KAAKT,EAAM,MAAM,EAIvDO,EAAQE,EAA8B,KAAKT,CAAI,UAExCA,aAAgBS,EACzBF,EAAOP,MAEP,OAAM,IAAI,UAAU,KAAKG,CAAI,kCAAkCM,CAAqB,EAAE,UAO1FD,EAAYR,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMW,EAAmB,OAAOX,EAAK,CAAC,EACtC,GAAIW,IAAqB,SACvBP,EAAO,SACPI,EAAOR,UACEW,IAAqB,UAC9BP,EAAO,OAIPI,EAAO,WAAW,KAAKR,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCW,CAAgB,GAAG,MAE3E,CAEL,IAAMC,EACFC,GAAsC,IAAIb,EAAK,WAA8C,EACjG,GAAIY,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCZ,EAAK,WAAW,GAAG,EAE9EI,EAAOQ,EACPJ,EAAOR,EAKX,GAAIS,IAAc,OAEhBA,EAAY,CAACD,EAAK,MAAM,UACf,CAAC,MAAM,QAAQC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAyC,EAE/DJ,EAAOI,EAEP,KAAK,QAAUD,EACf,KAAK,aAAe,MAItB,IAAMM,EAAOC,GAAcV,CAAI,EAE/B,GAAI,KAAK,SAAWS,IAAS,KAAK,QAAQ,OACxC,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAG9F,KAAK,KAAOV,EACZ,KAAK,KAAOC,EACZ,KAAK,KAAOS,CACd,CAIA,aAAa,UACTE,EACAC,EACoB,CACtB,OAAOC,GAAgBF,EAAOC,CAAO,CACvC,CAEA,OAAO,YACHE,EAA4BF,EAAoC,CAClE,OAAOG,GAAkBD,EAASF,CAAO,CAC3C,CAEA,OAAO,cACHI,EAAgCJ,EAAsC,CACxE,OAAOK,GAAoBD,EAAWJ,CAAO,CAC/C,CAEA,OAAO,iBACHb,EAASmB,EAAwClB,EAAwB,CAC3E,OAAOmB,GAAuBpB,EAAMmB,EAAQlB,CAAI,CAClD,CAKA,UAAUY,EAAgC,CACxC,OAAOQ,GAAgB,KAAMR,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOS,GAAkB,KAAMT,CAAO,CACxC,CAgDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACN,gJAC2E,EAEjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAKA,MAAM,QAAQU,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aAAc,CACjB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMnB,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXmB,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXnB,UAGP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQH,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOuB,GAAc,KAAMvB,CAAI,CACjC,KClaF,IAwUawB,GAxUbC,GAAAC,EAAA,kBAIAC,KAoUaH,GAASA,KCxUtB,IAeaI,GAfbC,GAAAC,EAAA,kBAGAC,KAIAC,KAQaJ,GAAP,MAAOK,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBC,EAA+BC,EAAiB,CAC1E,IAAMC,EAA4C,CAAA,EAC9CC,EAAsB,CAAA,EAE1B,GAAI,OAAOJ,GAAU,UAAYA,IAAU,MAAQA,aAAiBK,IAAU,MAAM,QAAQL,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIM,EAAiB,GAErB,GAAI,OAAOL,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBI,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQJ,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DK,EAAiB,GAEjB,QAAWC,KAAQN,EAAM,CACvB,GAAI,OAAOM,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEJ,EAAQI,CAAI,EAAI,KAGlB,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIM,EAAY,GACVC,EAAW,OAAO,oBAAoBR,CAAI,EAChD,QAAWM,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKT,EAA4DM,CAAI,GACvEG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBH,EAAQI,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAON,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDE,EAAUH,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWM,KAAQ,KAAK,WACtB,GAAI,OAAOP,EAAMO,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBJ,EAAQI,CAAI,EAAI,KAMpB,IAAMI,EAAU,MAAM,KAAK,QAAQ,IAAIX,EAAOG,EAASC,CAAO,EACxDQ,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAOA,aAAa,OACTG,EAAyCd,EAA8BC,EACvEc,EAAqB,CAEvB,IAAIC,EACAb,EAA0B,CAAA,EAE9B,GAAI,OAAOW,GAAS,UAElB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7Cc,aAAgB,YAEzB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAGpDc,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAAoB,CACnF,IAAMG,EAASH,EACXI,EAAa,EACbC,EAAaL,EAAK,WACtB,GAAI,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,EAAa,GAAKA,GAAcD,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAE,EAAaL,EAAK,WAAaI,EAC3B,OAAOjB,GAAS,SAAU,CAE5B,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,GAAc,GAAKD,EAAaC,EAAaF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAaC,CAAU,IAAI,EAE7F,GAAI,OAAOH,GAAS,UAAYA,IAAS,KACvCZ,EAAUY,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7C,OAAOd,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAkC,UAE/C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,EAEtDgB,EAAuB,IAAI,WAAWC,EAAQC,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAyD,EAK/E,IAAMC,GADMjB,EAAQ,oBAAsB,CAAA,GACjB,IAAIkB,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAE9DvB,EAAU,MADA,MAAMwB,GAAeF,CAAY,GACnB,8BAA8BJ,EAAsBb,CAAO,EACzF,OAAO,IAAIN,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KCrNF,IAocayB,GApcbC,GAAAC,EAAA,kBAGAC,KAicaH,GAA4CA,KCpczD,IAAAI,GAAAC,EAAA,oBCAA,IAgBMC,GAGOC,GAnBbC,GAAAC,EAAA,kBAGAC,KAIAC,KASML,GAA0B,gHAGnBC,GAAP,MAAOK,CAAe,CAC1B,YAAoBC,EAA+B,CACjD,KAAK,QAAUA,CACjB,CAGA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,aAAa,OAAOC,EAA+CC,EAA+B,CAEhG,IAAMC,EAA+BF,EAAgB,WAAa,GAC5DG,EAAoCH,EAAgB,gBAAkB,GACtEI,EAA0BH,GAAkB,CAAA,EAI5CI,GADMD,EAAQ,oBAAsB,CAAA,GACjB,IAAIE,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAC9DC,EAAU,MAAMC,GAAeH,CAAY,EACjD,GAAIE,EAAQ,6BAA8B,CACxC,IAAMR,EAAU,MAAMQ,EAAQ,6BAC1BP,EAAgB,gBAAiBA,EAAgB,WAAYE,EAAWC,EAAgBC,CAAO,EACnG,OAAO,IAAIN,EAAgBC,CAAO,MAElC,OAAM,IAAI,MAAMP,EAAe,CAEnC,CAWA,wBAAwBiB,EAAkBC,EAA+BC,EAAiB,CAExF,IAAMC,EAA4C,CAAA,EAC9CR,EAAsB,CAAA,EAE1B,GAAI,OAAOK,GAAU,UAAYA,IAAU,MAAQA,aAAiBI,IAAU,MAAM,QAAQJ,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIK,EAAiB,GAErB,GAAI,OAAOJ,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBG,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQH,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DI,EAAiB,GAEjB,QAAWC,KAAQL,EAAM,CACvB,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEH,EAAQG,CAAI,EAAI,KAGlB,GAAI,OAAOJ,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIK,EAAY,GACVC,EAAW,OAAO,oBAAoBP,CAAI,EAChD,QAAWK,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKR,EAAmDK,CAAI,GAC9DG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBF,EAAQG,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDP,EAAUM,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWK,KAAQ,KAAK,WACtB,GAAI,OAAON,EAAMM,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBH,EAAQG,CAAI,EAAI,KAIpB,MAAO,CAACH,EAASR,CAAO,CAC1B,CASA,uCAAuCe,EAAkC,CACvE,IAAMC,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAIA,MAAM,aAAaX,EAAkBC,EAA+BC,EAAiB,CACnF,GAAM,CAACC,EAASR,CAAO,EAAI,KAAK,wBAAwBK,EAAOC,EAAMC,CAAI,EACnEQ,EAAU,MAAM,KAAK,QAAQ,aAAaV,EAAOG,EAASR,CAAO,EACvE,OAAO,KAAK,uCAAuCe,CAAO,CAC5D,CAEA,MAAM,qBAAqBI,EAAoBC,EAAuB,CACpE,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,wBAAwBA,EAAuB,CACnD,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,KC5LF,IAqIaC,GArIbC,GAAAC,EAAA,kBAIAC,KAiIaH,GAA0CA,KCrIvD,IAAAI,GAAA,GAAAC,GAAAD,GAAA,sBAAAE,GAAA,WAAAC,GAAA,oBAAAC,GAAA,QAAAC,GAAA,oBAAAC,KAAA,IAAAC,GAAAC,EAAA,kBAmBAC,KACAC,KACAC,KACAC,KACAC,KACAC,OCxBA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,cAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAW,SCAxB,IAAAG,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAW,IAAM,CACnB,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,IAAIC,EAAED,EAAUE,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EAC1DJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,EAAEC,IAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,IAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,IAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,EAAEI,CAAC,EAAEL,EAAEC,EAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,EAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,EAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,EAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,EAAEC,EAAEC,KAAIX,EAAE,eAAeQ,EAAEC,EAAEC,EAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,EAAEC,IAAIV,EAAE,iBAAiBQ,EAAEC,EAAEC,CAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAE,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAa,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE,GAAGC,EAAEC,EAAEC,EAChP,GAAGJ,EAAG,CAAC,IAAIK,EAAG,cAAcC,EAAG,cAAgBL,EAAEF,EAAEO,EAAG,QAAQL,CAAC,EAAE,IAAI,UAAU,IAAIC,EAAE,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAE1B,IAAIA,EAAEwB,EAAExB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAE,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAE,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAACnB,EAAEC,IAAI,CAAC,cAAQ,SACnfD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,4BAA4B,MAASuB,GAAIC,KAAEA,EAAEE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAK5B,IAAa4B,EAAE5B,GAAgB4B,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGC,EAAExB,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIK,EAAE1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GACvfwB,EAAE,CAACzB,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,GAAE,IAAI0B,EAAGhC,EAAE,OAAO,QAAQ,IAAI,KAAK,OAAO,EAAEiC,EAAEjC,EAAE,UAAU,QAAQ,MAAM,KAAK,OAAO,EAAE,OAAO,OAAOA,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAErB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIkC,EAAElC,EAAE,aAAakC,EAAElC,EAAE,YAAY,IAAImC,EAAcnC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BoC,GAAE,iCAAiC,EACve,IAAIC,EAAEC,EAAEC,EAAE,GAAGC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,GAAGC,GAAG,SAASC,IAAI,CAAC,IAAI5C,EAAEkC,EAAE,OAAOrC,EAAE,MAAMyC,EAAE,IAAI,UAAUtC,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAO2C,EAAE,IAAI,WAAWxC,CAAC,EAAEH,EAAE,OAAO0C,GAAE,IAAI,WAAWvC,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQ4C,EAAE,IAAI,YAAYzC,CAAC,EAAEH,EAAE,QAAQ6C,GAAG,IAAI,aAAa1C,CAAC,EAAEH,EAAE,QAAQ8C,GAAG,IAAI,aAAa3C,CAAC,CAAC,CAAC,IAAI6C,EAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAE,SAASC,IAAI,CAAC,IAAIhD,EAAEH,EAAE,OAAO,MAAM,EAAEgD,EAAG,QAAQ7C,CAAC,CAAC,CAAC,IAAIiD,GAAE,EAAEC,GAAG,KAAKC,GAAE,KACnY,SAASlB,GAAEjC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI8B,EAAE9B,CAAC,EAAEoC,EAAE,GAAGC,EAAE,EAAErC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASoD,EAAGpD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIqD,GAAyB,GAAvBA,GAAE,qBAAwB,CAACD,EAAGC,EAAC,EAAE,CAAC,IAAIC,GAAGD,GAAEA,GAAExD,EAAE,WAAWA,EAAE,WAAWyD,GAAG/B,CAAC,EAAEA,EAAE+B,EAAE,CAAC,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGqD,IAAGtB,EAAE,OAAO,IAAI,WAAWA,CAAC,EAAE,GAAGL,EAAE,OAAOA,EAAE1B,CAAC,EAAE,KAAK,iDAAkD,CACnc,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAAC+B,IAAIX,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAGyB,EAAE,OAAO,IAAI,QAAQ,CAACxB,EAAEC,IAAI,CAACuB,EAAEzB,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC2B,EAAE,0CAA0C3B,CAAC,EAAE8B,GAAE9B,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEmD,GAAE,OAAOtB,GAAe,OAAO,YAAY,sBAA/B,YAAqDqB,EAAGlD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAgB,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA0B,EAAE,kCAAkC1B,CAAC,EAAE0B,EAAE,2CAA2C,EAAS2B,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC9W,IAAI0D,GAAEC,GAAG,CAAC,OAAO5D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,UAAUG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IACnf,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EACjgB,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,EAAE,cAAcC,EACzf,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAK+B,EAAE,SAAS9B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EACrfE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IACzf,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAK+B,EAAE,SAAS9B,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EACpgB,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GACnf,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SACvfG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAC9f,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,IAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKsC,EAAE,SAASrC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,CAAC,EAAE,KAAKqD,GAAEpD,CAAC,EAAE,YAAYoD,GAAEnD,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAC9eG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAC1f,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,EAAE7B,IAAI,CAAC,EAAE,WAAWoD,GAAEnD,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK+B,GAAG,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKiC,EAAE,SAAShC,IACrgB,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC4B,EAAE1B,KAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK2B,GAAG,SAASoB,KAAI,EAAEA,GAAE/C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EAAE,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,IAAIgE,GAAGhE,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAC1b,SAASoE,GAAGjE,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACuC,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CACnN,IAAIyB,GAAG,EAAEC,GAAG,EAAEC,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACrE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQoE,GAAG,OAAOA,GAAG,OAAOpE,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EACxgB0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGqE,GAAG9B,GAAEvC,EAAEC,CAAC,EAAE,GAAGqE,GAAGtE,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEsE,GAAG,CAACvE,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EACnf,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEoE,GAAExE,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAWyE,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG3E,GAAG,CAAC,IAAIC,EAAEqE,GAAGtE,CAAC,EAAE,EAAEE,EAAE0E,GAAG3E,CAAC,EAAE,OAAAC,GAAGqE,GAAGvE,EAAEuC,GAAErC,EAAED,CAAC,EAASC,CAAC,EAAE2E,GAAG,CAAC,EAAEC,GAAG,CAAC9E,EAAEC,IAAI,CAAC4E,GAAG,OAAO,EAAE,IAAI3E,EAAE,IAAID,IAAI,EAAEC,EAAEqC,GAAEvC,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE4E,GAAG,KAAU3E,GAAL,IAAOsC,EAAEvC,IAAI,CAAC,EAAE0C,GAAG1C,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO4E,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAIjF,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IACtf,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAG,gBAAgB,EAAEjB,EAAE,IAAIA,KAAK8E,GAAYA,GAAG9E,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAE8E,GAAG9E,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEgF,GAAG/E,CAAC,CAAC,OAAO+E,EAAE,EAAEA,GAAGC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGrF,EAAE,CAAC,IAAIC,EAAE,MAAMqE,GAAGtE,CAAC,EAAE,CAAC,EAAE,OAAAuE,GAAGvE,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACtb,SAASqF,GAAGtF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE+C,GAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEgD,GAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS+C,GAAEyB,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1B,GAAEhD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDyE,GAAE1B,GAAEhD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCyE,GAAE1B,GAAEhD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUyE,EAAC,CAAC,SAASjF,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI+C,GAAEhD,EAAE,SAAS,EAAE0E,IAAGhB,GAAE1D,EAAE,YAAY,CAAC,EAAEqE,GAAGC,IAAItB,EAAC,EAAE,GAAG/C,GAAEyE,GAAE1E,EAAE,QAAQ,EAAEC,IAAGyE,GAAE1E,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,GAAEhD,EAAE,SAASgD,GAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,GAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEgD,GAAEvD,GAAEuD,EAAC,EAAS,GAAGxD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEwD,GAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAE+B,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGqC,EAAErC,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,EAAEoD,GAAEpD,CAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WAAW,MAAM,KACnf,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,KAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EAAE,GAAG,EAAED,EAAEC,CAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,UAAU,EACngB,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE+C,GAAE,EAAEA,IAAGhD,EAAE,GAAG,EAAEC,KAAIyD,GAAE1D,EAAE,GAAG,IAAI,EAAEqE,GAAGC,IAAItB,IAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GACvf,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ+C,IAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,IAAH,GAASA,IAAH,GAAMU,GAAE1D,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI+C,IAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,IAAH,GAASA,IAAH,GAAMU,GAAE1D,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,KAAKD,EAAEP,EAAE,SAASQ,CAAC,IAAIR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EACzgB,GAAG,EAAED,EAAEC,CAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,EAAE2E,GAAGnF,CAAC,EAAKQ,EAAE,OAAOT,EAAS,GAAEqC,EAAE,IAAI5B,EAAEV,IAAI,CAAC,EAASU,EAAE,OAAO,EAAC,CAAC,SAAS+E,GAAEzF,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACgC,GAAEhC,CAAC,CAAC,CAAC,CAAC,SAASyF,GAAG1F,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACuF,GAAE,KAAKxF,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQgC,IAAIuD,GAAE,IAAI,IAAIxF,GAAG8B,GAAE,EAAEpB,IAAO+E,KAAJ,GAAWD,GAAE,SAAN,IAAeC,GAAE,EAAEH,GAAEI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAEzF,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI2F,GAAE,EAAE/E,GAAE,KAAKiF,GAAG,EAAEH,GAAE,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC9c,SAASnF,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACiG,GAAG,CAAC,QAAQlG,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASmG,IAAI,CAAC,IAAIpG,EAAE4E,GAAG,KAAK,EAAE3E,EAAED,EAAE,GAAGyC,EAAEzC,GAAG,IAAI,CAAC,EAAEC,EAAEwC,EAAEzC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE0F,GAAE,CAAC,EAAE,IAAIzF,EAAE6F,GAAG9F,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE+F,KAAKF,GAAG9F,CAAC,EAAEC,EAAE8F,GAAG9F,CAAC,EAAED,GAAGuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEE,EAASF,CAAC,CAC5N,SAASqG,GAAGrG,EAAE,CAAC,GAAG,CAACoC,EAAE,CAAC,GAAOwD,KAAJ,EAAM,CAAC,IAAI3F,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACiC,IAAI0D,GAAG3F,EAAEF,EAAE,GAAGC,GAAG,CAAC0F,GAAE,EAAEH,GAAE,IAAIa,GAAGzF,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,KAAK+B,EAAE6D,GAAGxD,EAAE3B,GAAE,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,OAAON,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE4F,GAAG5F,IAAI4F,GAAG,MAAM/F,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI2F,GAAE,EAAE/E,GAAEuF,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAE,IAAIc,GAAG1F,EAAC,CAAC,EAAE,MAAU+E,KAAJ,GAAOA,GAAE,EAAEH,GAAEe,EAAE,EAAEC,GAAG5F,EAAC,EAAEA,GAAE,KAAKsF,GAAG,QAAQhG,GAAG,CAAC,GAAG,CAACiC,EAAE,GAAG,CAAC,GAAGjC,EAAE,EAAE,CAAC6B,EAAc,GAAG,CAACK,EAAEA,EAAElC,EAAEkC,EAAML,IAAkBnC,EAAE,QAAOA,EAAE,OAAOM,CAAC,EAC7hBiC,EAAE,IAAGjB,EAAEhB,EAAE,IAAI4D,GAAG5D,CAAC,CAAC,CAAC,OAAOC,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,CAAC,GAAG6B,GAAE,kBAAkB2D,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAAC,SAASY,GAAG1G,EAAE,CAAC,OAAOqG,GAAGpG,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CACnM,IAAI0G,GAAG,CAAC,EAAE,SAAS3G,EAAEC,EAAEC,EAAE,CAAC,OAAOwG,GAAG,SAAS,CAAC,MAAM7G,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIiE,GAAGjE,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEgE,GAAGlE,EAAEmE,KAAWD,EAAG,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,IAAI,GAAG,EAAE,SAASlE,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EACnfF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGF,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAClf,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGsE,GAAExE,EAAE,YAAY,CAAC,EAAEyE,GAAGC,IAAI1E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGD,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,CAAC,EAAE,EAAE,SAASD,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAC5fG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGqC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,GAAGwE,GAAEvE,EAAE,YAAY,CAAC,EAAEwE,GAAGC,IAAIzE,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEuC,EAAExC,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAC7f,IAAW2G,IAAIjD,GAAE3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEK,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACN,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEmC,EAAEzC,IAAI,GAAG,IAAI,CAAC,EAAE,GAAG,KAAK,IAAII,EAAEG,EAAC,EAAEiC,EAAEvC,IAAI,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE2E,GAAG3E,CAAC,EAAEC,EAAE0E,GAAG1E,CAAC,EAAEM,GAAEH,GAAGqC,EAAEvC,GAAG,IAAI,CAAC,EAAEF,EAAEyC,EAAEvC,EACnf,GAAG,IAAI,CAAC,EAAED,IAAIwC,EAAEvC,GAAG,IAAI,CAAC,EAAED,EAAEwC,EAAEvC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACiC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASjC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE6E,GAAG7E,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE6E,GAAG7E,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,IAAI,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAD,KAAK,EAASsC,GAAE,WAAWvC,IAAI,IAAI,EAAEC,IAAI,EAAEA,GAAGC,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,SAASF,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEsC,GAAE,OAAO,GAAG,WAAWvC,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KACpfD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAE+B,EAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAE,KAAK9B,CAAC,EAAEwC,GAAG,EAAE,IAAIvC,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAE,SAASL,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAA8E,GAAG,EAAE,QAAQ,SAAS7E,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAsB,IAApBE,EAAEqC,EAAEzC,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEiC,EAAElC,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEiC,EAAElC,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE8E,GAAG,EAAEvC,EAAEzC,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEqC,EAAExC,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,EAAE,EAAE,IACrf,GAAG,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEmC,EAAExC,GAAG,IAAI,CAAC,EAAEM,GAAEkC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,EAAE8B,GAAEjC,EAAEE,IAAI,CAAC,EAAEE,EAAEwE,GAAGlF,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAM6B,EAAGC,GAAGuC,GAAG3D,EAAE,CAAC,CAAC,EAAEA,EAAE,OAAO,GAAGA,EAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAkC,EAAEtC,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,EAAE,EAAEkF,GAAG,EAAE,SAAStF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmF,GAAGtF,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GAC7V,UAAU,CAAC,SAASH,EAAEE,EAAE,CAAoH,GAAnHA,EAAEA,EAAE,QAAQA,EAAEwF,GAAGxF,CAAC,EAAEiC,EAAEjC,EAAE2G,GAAG3G,CAAC,EAAEgC,EAAEC,EAAE,EAAES,GAAG,EAAEE,GAAG,QAAQX,EAAE,CAAC,EAAEc,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIhD,EAAEgD,GAAEA,GAAE,KAAKhD,EAAE,CAAC,CAAC,OAAOD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE0G,EAAE,EAA4D,GAA1D1D,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAKpD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC4B,EAAE,sDAAsD5B,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,QAAQ,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAC1dF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,KAAKZ,EAAE,yBAAyBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BsC,EAAE,GAAGnC,CAAC,EAC1fH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAC/dP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EACteH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EACtV,IAAI4E,GAAG/E,EAAE,QAAQG,IAAI4E,GAAG/E,EAAE,QAAQsC,EAAE,IAAInC,CAAC,EAAEyG,GAAG5G,EAAE,MAAMG,IAAIyG,GAAG5G,EAAE,MAAMsC,EAAE,IAAInC,CAAC,EAAE4G,GAAG5G,IAAI4G,GAAGzE,EAAE,IAAInC,CAAC,EAAE8G,GAAG,KAAKA,GAAG3E,EAAE,IAAI,EAAE4E,GAAG/G,IAAI+G,GAAG5E,EAAE,IAAInC,CAAC,EAAEgH,GAAGhH,IAAIgH,GAAG7E,EAAE,IAAInC,CAAC,EAAEuG,GAAGvG,IAAIuG,GAAGpE,EAAE,IAAInC,CAAC,EAAE6F,GAAG,KAAKA,GAAG1D,EAAE,IAAI,EAAEmE,GAAGtG,IAAIsG,GAAGnE,EAAE,IAAInC,CAAC,EAAEwG,GAAG,KAAKA,GAAGrE,EAAE,IAAI,EAAEtC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAAO,SAASgH,GAAG7G,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,WAAWmH,GAC5enH,EAAE,UAAUiH,GAAGjH,EAAE,aAAakH,GAAGlH,EAAE,aAAagE,GAAEhE,EAAE,aAAa,CAACG,EAAEC,EAAEC,IAAIqE,GAAGvE,EAAEuC,GAAEtC,EAAEC,CAAC,EAAEL,EAAE,gBAAgByE,GAAG,IAAI2C,GAAE9D,GAAE,SAAS+D,GAAI,CAACD,IAAGE,GAAG,EAAEF,KAAI9D,GAAE+D,EAAG,EAClJ,SAASC,IAAI,CAAC,SAASnH,GAAG,CAAC,GAAG,CAACiH,KAAIA,GAAE,GAAGpH,EAAE,UAAU,GAAG,CAACuC,GAAG,CAAiE,GAAhE4B,GAAGlB,EAAE,EAAEhD,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAKA,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEkD,GAAG,QAAQ9C,CAAC,CAAC,CAAC+D,GAAGjB,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,EAAEE,IAAG,CAAC,GAAGpD,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQmD,GAAG,EAAEgB,GAAGnB,CAAE,EAAE,EAAEI,KAAIpD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EAAE,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAC1e,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAsH,GAAG,EAGvGvH,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAO,IC5E1B,IAAA0H,GAAAC,GAAA,QCAA,IAAAC,GAAAC,GAAA,QCAA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAmB,IAAM,CAC3B,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,SAASC,GAAG,CAAC,OAAAC,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASD,EAAC,CAAC,SAASE,GAAG,CAAC,OAAAH,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASE,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAL,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASI,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAP,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASM,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAT,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASQ,CAAE,CAAC,SAASC,GAAI,CAAC,OAAAX,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASU,EAAE,CAAC,IAAIC,EAAEf,EAAUgB,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EACrVJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,GAAEC,EAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,IAAI,EAAEE,GAAEH,GAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,IAAI,EAAE,OAAAK,IAAIC,KAAIP,GAAEO,GAAEL,GAAEI,CAAC,EAAEL,EAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,IAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,GAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,IAAGX,EAAE,QAAQW,EAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,IAAGX,EAAE,mBAAmBW,EAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,IAAGX,EAAE,cAAcW,EAAC,EAAEX,EAAE,mBAAmB,CAACW,GAAEC,EAAEC,GAAEC,KAAIX,EAAE,eAAeQ,GAAEC,EAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,IAAG,CAACR,EAAE,kBAAkBQ,EAAC,CAAC,EAAEX,EAAE,cAAcW,IAAGR,EAAE,UAAUQ,EAAC,EAAEX,EAAE,qBAAqB,CAACW,GAAEC,EAAEC,KAAIV,EAAE,iBAAiBQ,GAAEC,EAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAY,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE1B,EAAE,wBAAwB,GAAG2B,EAAE,GAAG,SAASC,EAAGzB,EAAE,CAAC,OAAOH,EAAE,WAAWA,EAAE,WAAWG,EAAEwB,CAAC,EAAEA,EAAExB,CAAC,CAAC,IAAI0B,EAAGC,EAAEC,EAC7U,GAAGN,EAAE,CAAC,IAAIO,EAAG,cAAcC,EAAG,cAAgBN,EAAEH,EAAES,EAAG,QAAQN,CAAC,EAAE,IAAI,UAAU,IAAIE,EAAG,CAACzB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAS4B,EAAG,aAAa5B,EAAEC,EAAE,OAAO,MAAM,GAAG0B,EAAG3B,IAAIA,EAAEyB,EAAGzB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAG0B,EAAE,CAAC1B,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAE4B,EAAG,SAAS5B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACT,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAAClB,EAAEC,IAAI,CAAC,cAAQ,SACtfD,EAAQC,CAAE,EAAEL,EAAE,QAAQ,IAAI,6BAA6B,IAAIG,EAAE,GAAG,CAACA,EAAE,IAAyB,OAAOC,EAAE,CAAC,MAAM,QAAQ,MAAM,yGAAyG,EAAEA,CAAE,CAAC,OAAO,OAAOD,EAAE,MAAM,MAASoB,GAAIC,KAAEA,EAAEG,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAM,OAAO3C,EAAe,KAAeA,IAAc2C,EAAE3C,GAAgB2C,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGF,IAAII,EAAG1B,GAAG,CAAC,IAAIC,EAC9hB,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIO,EAAG5B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAAG0B,EAAE,CAAC3B,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,IAAGmB,GAAgB,OAAO,YAApB,MAAkC,OAAO,YAAY,KAAsB,aACrd,IAAIS,EAAG,QAAQ,IAAI,KAAK,OAAO,EAAEC,GAAG,QAAQ,MAAM,KAAK,OAAO,EAAEV,IAAIS,EAAG,IAAI/B,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,EAAEgC,GAAG,IAAIhC,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,GAAG,IAAIiC,EAAGpC,EAAE,OAAOkC,EAAGG,EAAErC,EAAE,UAAUmC,GAAG,OAAO,OAAOnC,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAGrB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIsC,GAAEtC,EAAE,aAAasC,GAAEtC,EAAE,YAAY,IAAIuC,GAAcvC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BwC,GAAE,iCAAiC,EAAE,IAAIrD,GAAEsD,EAAEC,GAAGC,GAAE,GAAGC,GAAExD,GAAEG,GAAGE,GAAGE,GAAGE,EAAGE,GAChc,SAASV,IAAG,CAAC,IAAIc,EAAEhB,GAAE,OAAOa,EAAE,MAAMZ,GAAE,IAAI,UAAUe,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAOP,GAAG,IAAI,WAAWU,CAAC,EAAEH,EAAE,OAAOT,GAAG,IAAI,WAAWY,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQL,GAAG,IAAI,YAAYQ,CAAC,EAAEH,EAAE,QAAQH,EAAG,IAAI,aAAaM,CAAC,EAAEH,EAAE,QAAQD,GAAG,IAAI,aAAaI,CAAC,CAAC,CAAC,IAAI0C,GAAG7C,EAAE,gBAAgB,SACtS,GAD+S,SAAS6C,IAAIL,GAAE,wDAAwDK,GAAG,wBAAwB,EAC9YnB,EAAEvC,GAAEa,EAAE,mBAAmBA,EAAE,WAAWb,GAAEa,EAAE,mBAAmBb,GAAE,IAAI,YAAY,OAAO,CAAC,QAAQ0D,GAAG,MAAM,QAAQ,MAAM,OAAO,EAAE,CAAC,EAAE,EAAE1D,GAAE,kBAAkB,mBAAmB,MAAMkD,EAAE,6NAA6N,EAAEZ,GAAGY,EAAE,2GAA2G,EACrgB,MAAM,YAAY,EAAEhD,GAAE,EAAEwD,GAAG1D,GAAE,OAAO,WAAW,IAAI2D,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAE,SAASC,IAAI,CAAC,OAAOX,IAAe,EAAEU,EAAE,CAAC,IAAIE,GAAE,EAAEC,GAAG,KAAKC,GAAE,KAAK,SAASC,IAAI,CAACH,KAAInD,EAAE,wBAAwBA,EAAE,uBAAuBmD,EAAC,CAAC,CAAC,SAASI,IAAI,CAA2D,GAA1DJ,KAAInD,EAAE,wBAAwBA,EAAE,uBAAuBmD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIlD,EAAEkD,GAAEA,GAAE,KAAKlD,EAAE,CAAC,CAAC,CAClW,SAASqC,GAAErC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAIkC,EAAElC,CAAC,EAAEwC,GAAE,GAAGC,GAAE,EAAEzC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASqD,GAAGrD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIsD,GAAEA,GAAE,8BAA8BD,GAAGC,EAAC,IAAIA,GAAE7B,EAAG6B,EAAC,GAAG,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGsD,IAAGnB,GAAE,OAAO,IAAI,WAAWA,EAAC,EAAE,GAAGP,EAAG,OAAOA,EAAG5B,CAAC,EAAE,KAAK,iDAAkD,CACpa,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAACmC,KAAIf,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAG2B,EAAE,OAAO,IAAI,QAAQ,CAAC1B,EAAEC,IAAI,CAACyB,EAAE3B,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC+B,EAAE,0CAA0C/B,CAAC,EAAEkC,GAAElC,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEoD,GAAE,OAAOnB,IAAe,OAAO,YAAY,sBAA/B,YAAqDkB,GAAGnD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAe,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA8B,EAAE,kCAAkC9B,CAAC,EAAE8B,EAAE,2CAA2C,EAASuB,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC7W,IAAI0D,GAAEC,GAAG,CAAC,OAAO5D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,UAAUG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IACnf,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EACngB,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EACnf,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IACxf,CAAC,CAACxB,EAAE,EAAE0B,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KACngB,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACxB,EAAE,EAAE0B,IAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAC5f,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EACnf,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAC1fC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,EAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OACrfG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EACnf,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,EAAC,EAAE,KAAKqD,GAAEpD,CAAC,EAAE,YAAYoD,GAAEnD,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IACrf,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAAqBG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAClf,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAACxB,EAAE,EAAE0B,IAAI,CAAC,EAAE,WAAWoD,GAAEnD,EAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKlB,EAAG,EAAE,SAASmB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GACnf+C,KAAI,CAACjE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKlB,EAAE,EAAE,SAASmB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC3B,EAAE,EAAE6B,KAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKtB,EAAG,EAAE,SAASqE,KAAI,EAAEA,GAAE/C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EAClb,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,SAASgE,GAAGhE,EAAE,CAACA,EAAE,UAAU,EAAEA,EAAE,UAAU,IAAI,CAAC,CAAC,CAAC,SAASiE,GAAGjE,EAAE,EAAEA,EAAEkE,GAAE,GAAGlE,CAAC,IAAIqC,GAAE,EAAE6B,GAAE,GAAGlE,CAAC,CAAC,CAAC,SAASmE,GAAGnE,EAAE,CAAC,IAAIC,EAAEiE,GAAE,GAAG,EAAE,GAAG,CAACjE,EAAE,MAAO,GAAEiE,GAAE,GAAG,KAAKjE,CAAC,EAAEiE,GAAE,GAAGlE,EAAE,EAAE,EAAEC,EAAEA,EAAE,GAAGD,EAAE,GAAG,IAAIE,EAAE,CAAC,IAAI,MAAM,cAAcF,EAAE,GAAG,IAAIA,EAAE,GAAG,YAAYA,EAAE,EAAE,EAAE,OAAAsB,GAAGrB,EAAE,MAAM,EAAEA,EAAE,YAAYC,EAAEF,EAAE,EAAE,EAAS,CAAC,CACvX,IAAIoE,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACrE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQoE,GAAG,OAAOA,GAAG,OAAOpE,EAAE,kBAAkB,kBAAkBA,EAAE,MAAMC,EAAEC,CAAC,EAAEF,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GACpf,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAE0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGqE,GAAGlF,EAAE,EAAEa,EAAEC,CAAC,EAAE,GAAG,SAASqE,GAAGtE,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,CAAC,EAAEyC,GAAEzC,EAAM+C,GAAG,IAAGmB,GAAE,GAAG,EAAKrE,EAAE,QAAOA,EAAE,OAAOG,CAAC,EAAEwC,GAAE,IAAGrB,EAAEnB,EAAE,IAAI+D,GAAG/D,CAAC,CAAC,CAAC,CACjM,IAAIwE,GAAGxE,GAAG,CAAK,GAAJyC,GAAEzC,EAAKuB,EAAE,MAAMkD,GAAGzE,CAAC,EAAE,SAASsE,GAAGtE,CAAC,CAAC,EAAEkE,GAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC3C,EAAE2C,GAAE,GAAG,EAAEA,GAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAACvB,GAAG,QAAQ,IAAI,CAACQ,GAAG,EAAEe,GAAE,GAAG,IAAId,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,UAAU,CAACc,GAAE,sBAAsBA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAG9B,GAAc,EAAE,EAAE,GAAG,SAASpC,EAAE,CAACyC,GAAEzC,CAAC,EAAE,GAAG,CAAC,kBAAkB,EAAE,GAAG,UAAU,CAAC,QAAQA,KAAKkE,GAAE,GAAGF,GAAGhE,CAAC,EAAE,IAAIA,KAAKkE,GAAE,GAAGF,GAAGhE,CAAC,EAAEkE,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,CAAC,EAAE,GAAG,SAASlE,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,OAAOkE,GAAE,GAAGjE,CAAC,EAAEiE,GAAE,GAAG,KAAKlE,CAAC,EAAEkE,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQlE,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,EAAE0E,GAAGzE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,EACtf,GAAG,UAAU,CAACiE,GAAE,GAAG,QAAQlE,GAAGA,EAAE,CAAC,CAAC,EAAE,GAAGA,GAAG,IAAI,QAAQC,GAAG,CAACD,EAAE,UAAUK,GAAG,CAACA,EAAEA,EAAE,KAAK,IAAIC,EAAED,EAAE,IAAI,GAAGA,EAAE,cAAcA,EAAE,cAAcsE,GAAG,EAAE,CAAC,IAAIpE,GAAE2D,GAAE,GAAG7D,EAAE,EAAE,EAAEE,GAAEA,GAAE,YAAYF,EAAEA,EAAE,YAAY,EAAE6B,EAAE,0CAA0C5B,EAAE,uBAAuBD,EAAE,aAAa,qCAAqC,CAAC,MAA0BC,IAAjB,eAAmBsE,GAAG,EAA0BtE,IAAhB,cAAkB6D,GAAG9D,CAAC,EAA4BC,IAAlB,gBAAoB2D,GAAG5D,EAAE,MAAM,EAAyBC,IAAf,cAAiBD,EAAEA,EAAE,OAAOC,EAAE4D,GAAE,GAAG7D,CAAC,EAAE,OAAO6D,GAAE,GAAG7D,CAAC,EAAE2D,GAAG1D,CAAC,EAAEoE,GAAGrE,CAAC,EAAE6D,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQ5D,CAAC,EAClgB,CAAC,EAAEA,EAAE,GAAG,GAA2BA,IAAjB,eAAmB4D,GAAE,GAAG7D,EAAE,MAAM,EAAE,YAAY,CAAC,IAAI,QAAQ,CAAC,EAAqBC,IAAX,UAAaN,EAAE,OAAO,GAAGC,EAAED,CAAC,GAAoBM,IAAV,QAAY,MAAM,UAAUD,EAAE,SAAS,KAAKA,EAAE,IAAI,EAA2BA,EAAE,SAAnB,eAA0BL,EAAE,YAAYK,CAAC,EAA0BC,IAAhB,cAAkBT,EAAEQ,EAAE,OAAO,EAAE,GAAGA,EAAE,IAAI,EAAOC,GAAG4B,EAAE,kCAAkC5B,CAAC,CAAC,EAAEN,EAAE,QAAQK,GAAG,CAAC,MAAA6B,EAAE,yBAAyB7B,EAAE,SAAS,IAAIA,EAAE,OAAO,KAAKA,EAAE,OAAO,EAAQA,CAAE,EAAEiB,IAAItB,EAAE,GAAG,UAAU,SAASK,EAAE,CAACL,EAAE,UAAU,CAAC,KAAKK,CAAC,CAAC,CAAC,CAAC,EAAEL,EAAE,GAAG,QAAQ,SAASK,EAAE,CAACL,EAAE,QAAQK,CAAC,CAAC,CAAC,GAC/f,IAAIH,EAAE,CAAC,EAAEC,EAAE,CAAC,SAAS,UAAU,QAAQ,UAAU,EAAEC,EAAE,IAAIA,KAAKD,EAAEN,EAAE,eAAeO,CAAC,GAAGF,EAAE,KAAKE,CAAC,EAAEJ,EAAE,YAAY,CAAC,IAAI,OAAO,SAASE,EAAE,UAAUL,EAAE,qBAAqBhB,EAAW,WAAWG,GAAE,WAAWuD,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,SAASvC,EAAE,CAACA,EAAE,CAAC,EAAE,GAAG,UAAU,CAAC,IAAIA,EAAEyB,EAAG,kCAAkC,EAAEzB,EAAE,IAAI,OAAOA,CAAC,EAAEkE,GAAE,GAAG,KAAKlE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,OAAGkE,GAAE,GAAG,QAAR,IAAiBA,GAAE,GAAG,EAAEA,GAAE,GAAGA,GAAE,GAAG,CAAC,CAAC,GAAUA,GAAE,GAAG,IAAI,CAAC,CAAC,EAAErE,EAAE,QAAQqE,GAAE,IAAIW,GAAG7E,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EACzbA,EAAE,oBAAoB,UAAU,CAAC,IAAIG,EAAE2E,GAAG,EAAE1E,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE8E,GAAG7E,EAAEA,EAAED,CAAC,EAAE+E,GAAG9E,CAAC,CAAC,EAAE,SAASwE,GAAGzE,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,CAAC,EAAEwE,GAAGxE,CAAC,CAAC,CAACH,EAAE,iBAAiB,SAASG,EAAEC,EAAE,CAACD,EAAEgF,GAAG,MAAM,KAAK,CAAChF,EAAEC,CAAC,CAAC,EAAE8C,GAAG,EAAEmB,GAAE,GAAGlE,CAAC,EAAEiF,GAAGjF,CAAC,CAAC,EAAE,SAASkF,GAAGlF,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACX,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI4F,GAAG,EAAEC,GAAG,EAC/b,SAASC,GAAGrF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAEgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAEmF,GAAGtF,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASmF,GAAGtF,EAAEC,EAAEC,EAAEC,EAAE,CAA6B,GAA5BH,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAkB,OAAO,kBAApB,IAAsC,OAAO+B,EAAE,qFAAqF,EAAE,EAAE,IAAI9B,EAAE,CAAC,EAAE,OAAGmB,GAAOnB,EAAE,SAAN,EAAoBiF,GAAGrF,EAAEC,EAAEC,EAAEC,CAAC,GAAEH,EAAE,CAAC,GAAGE,EAAE,GAAGF,EAAE,GAAGG,EAAE,GAAGC,CAAC,EAASmB,GAAGvB,EAAE,GAAG,cAAc,YAAYA,EAAEI,CAAC,EAAE,GAAG+D,GAAGnE,CAAC,EAAC,CAAC,SAASuF,GAAGvF,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAEgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAASsF,GAAGxF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CACrc,IAAIwF,GAAGzF,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEyF,GAAG,CAAC1F,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GACpf,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEuF,GAAG,CAAC3F,EAAEC,EAAEC,IAAIwF,GAAG1F,EAAEb,EAAE,EAAEc,EAAEC,CAAC,EAAE,SAAS0F,GAAG5F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG7F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG9F,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAEgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAAS6F,GAAG/F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGhG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGjG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGlG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASgG,GAAGnG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC9d,SAASiG,GAAGpG,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,CAAC,CAAC,CAAC,SAASqG,GAAGrG,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAASqG,GAAGtG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIqG,GAAGvG,GAAG,CAAC,GAAG,CAACwC,GAAE,GAAG,CAAC,GAAGxC,EAAE,EAAE,CAAC+C,GAAG,EAAE,GAAG,CAACxB,EAAE0D,GAAGxC,EAAC,EAAE+B,GAAG/B,EAAC,CAAC,OAAOxC,EAAE,CAACA,aAAa8D,IAAc9D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa8D,IAAc9D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,EAAE,SAASuG,GAAGxG,EAAE,CAACA,KAAK,EAAe,OAAO,QAAQ,IAA5B,aAAiC,QAAQ,GAAGX,EAAE,EAAEW,GAAG,EAAEA,CAAC,EAAE,MAAM,KAAK4E,EAAE,EAAE5E,GAAG,IAAI,QAAQ,MAAMX,EAAE,EAAEW,GAAG,EAAE,CAAC,EAAE,CAACH,EAAE,kCAAkC2G,GAAG,SAAS5B,IAAI,CAAC,IAAI5E,EAAE2E,GAAG,EAAE3E,IAAIwG,GAAGxG,CAAC,EAAEuG,GAAG,IAAIE,GAAG,CAAC,EAAE,CAAC5G,EAAE,aAAa+E,GACpf,IAAI8B,GAAE1G,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW2G,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAE,SAASC,EAAG7G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAE,CAAC,OAAOgB,EAAEgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAE,GAAG,CAAC,SAASuG,EAAG9G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGiB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIyG,EAAG/G,GAAG,CAAC,IAAIC,EAAEwF,GAAGzF,CAAC,EAAE,EAAEE,EAAE8G,GAAG/G,CAAC,EAAE,OAAAC,GAAGyF,GAAG3F,EAAEE,EAAED,CAAC,EAASC,CAAC,EAAE+G,EAAG,CAAC,EAAEC,EAAG,CAAClH,EAAEC,IAAI,CAACgH,EAAG,OAAO,EAAE,IAAI/G,EAAE,IAAID,IAAI,EAAEC,EAAEf,EAAE,EAAEa,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAEgH,EAAG,KAAU/G,GAAL,IAAOb,EAAE,EAAEY,IAAI,CAAC,EAAEN,EAAG,EAAEM,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAOgH,CAAE,EAAEE,EAAGnH,GAAG,CAAC,IAAIC,EAAEmH,GAAG,EAAE,OAAApH,EAAEA,EAAE,EAAE+E,GAAG9E,CAAC,EAASD,CAAC,EACve,SAASuE,EAAEvE,EAAEC,EAAE,CAAC,IAAIC,EAAE,UAAU,OAAO,EAAEC,EAAE,UAAU,OAAOgH,EAAG,IAAI,CAAC,QAAQ/G,EAAEiH,GAAG,EAAEnH,CAAC,EAAEG,EAAED,GAAG,EAAEE,EAAE,EAAEA,EAAEJ,EAAEI,IAAI,CAAC,IAAIC,GAAEJ,EAAE,EAAEG,CAAC,EAAEX,EAAG,EAAEU,EAAEC,IAAI,CAAC,EAAEC,EAAC,CAAC,OAAO+G,GAAGtH,EAAEE,EAAEE,EAAEH,CAAC,CAAC,CAAC,CAAC,CAC3J,IAAIsH,GAAG,CAAC,EAAEC,EAAG,CAAC,EAAEC,EAAG,IAAI,CAAC,GAAG,CAACC,EAAG,CAAC,IAAI1H,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAKuH,EAAYA,EAAGvH,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAEuH,EAAGvH,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEyH,EAAGxH,CAAC,CAAC,OAAOwH,CAAE,EAAEA,EACtW,SAASC,GAAG3H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAAuH,EAAG,EAAE,QAAQ,SAAStH,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAwB,IAAtBE,EAAEb,EAAE,EAAES,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEtB,EAAE,EAAEqB,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEtB,EAAE,EAAEqB,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,CAAC,SAASyH,GAAG5H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAEuH,EAAG,EAAElI,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEb,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,CAAC,SAAS0H,EAAG7H,EAAE,CAAC,OAAOuB,EAAEgD,EAAE,GAAG,EAAEvE,CAAC,EAAE,EAAE,CAAC,SAAS8H,GAAG9H,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAEgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAC/c,SAAS4H,GAAG/H,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmB,EAAEgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,IAAI4H,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,SAASC,GAAGjI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAEF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEf,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEM,GAAEhB,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,GAAE,EAAEA,GAAED,GAAEC,KAAI,CAAC,IAAIC,EAAEtB,EAAE,EAAEmB,EAAEE,KAAI,CAAC,EAAEE,GAAEsH,GAAGhI,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAMiC,EAAGC,GAAGmC,GAAG3D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAhB,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,CAAC,IAAI8H,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGpI,EAAE,CAAC,IAAIC,EAAE,MAAMwF,GAAGzF,CAAC,EAAE,CAAC,EAAE,OAAA0F,GAAG1F,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACjf,IAAIoI,GAAG,CAACrI,EAAEC,IAAI,CAAClB,EAAE,EAAE,IAAIiB,EAAEC,IAAI,CAAC,CAAC,EAC/B,SAASqI,GAAGtI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE+C,GAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEgD,GAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS+C,GAAEyE,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1E,GAAEhD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDyH,GAAE1E,GAAEhD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCyH,GAAE1E,GAAEhD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUyH,EAAC,CAAC,SAASjI,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,GAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI+C,GAAEhD,EAAE,SAAS,EAAE0H,IAAG9B,GAAE5F,EAAE,YAAY,CAAC,EAAEoH,GAAGC,IAAIrE,EAAC,EAAE,GAAG/C,GAAEyH,GAAE1H,EAAE,QAAQ,EAAEC,IAAGyH,GAAE1H,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,GAAEhD,EAAE,SAASgD,GAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,GAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEgD,GAAEvD,GAAEuD,EAAC,EAAS,GAAGxD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEwD,GAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAEpB,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGd,EAAE,EAAEc,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,EAAEoD,GAAEpD,CAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WACxf,MAAM,KAAK,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GACzfF,GAAEE,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,GAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,GAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE+C,GAAE,EAAEA,IAAGhD,EAAE,GAAG,EAAEC,KAAI2F,GAAE5F,EAAE,GAAG,IAAI,EAAEoH,GAAGC,IAAIrE,IAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GACnf,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ+C,IAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,IAAH,GAASA,IAAH,GAAM4C,GAAE5F,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI+C,IAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,IAAH,GAASA,IAAH,GAAM4C,GAAE5F,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,EAAEP,EAAE,SAASQ,EAAC,IACrgBR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,EAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAE0H,GAAGlI,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEoI,GAAG3H,GAAEV,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS+H,GAAGzI,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACoC,GAAEpC,CAAC,CAAC,CAAC,CAAC,SAASyI,GAAG1I,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACuI,GAAG,KAAKxI,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQoC,KAAImG,GAAG,IAAI,IAAIxI,GAAGkC,GAAE,EAAExB,IAAO+H,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAE9F,IAAI,EAAE2F,GAAGI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAEzI,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI2I,GAAE,EAAE/H,GAAE,KAAKiI,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC7e,SAASnI,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACiJ,GAAG,CAAC,QAAQlJ,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASmJ,IAAI,CAAC,IAAIpJ,EAAEgH,GAAG,KAAK,EAAE/G,EAAED,EAAE,GAAGT,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEC,EAAEV,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE0I,GAAG,CAAC,EAAE,IAAIzI,EAAE6I,GAAG9I,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE+I,KAAKF,GAAG9I,CAAC,EAAEC,EAAE8I,GAAG9I,CAAC,EAAED,GAAGA,EAAEC,EAAEb,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAASD,CAAC,CAAC,SAASqJ,IAAI,CAAC,IAAIrJ,EAAEX,EAAE,EAAEwB,GAAE,GAAG,IAAI,CAAC,EAAE,OAAAb,EAAEsC,EAAE0G,GAAGhJ,CAAC,CAAC,EAAE,EAAE8C,GAAU9C,EAAE,CAAC,CACtS,SAASsJ,GAAGtJ,EAAE,CAAC,GAAG,CAACwC,GAAE,CAAC,GAAOoG,KAAJ,EAAM,CAAC,IAAI3I,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACqC,KAAIsG,GAAG3I,EAAEF,EAAE,GAAGC,GAAG,CAAC0I,GAAE,EAAEH,GAAG,IAAIc,GAAG1I,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,EAAEiJ,GAAG,CAAC,OAAO9I,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE4I,GAAG5I,IAAI4I,GAAG,MAAM/I,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI2I,GAAE,EAAE/H,GAAEuI,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAG,IAAIe,GAAG3I,EAAC,CAAC,EAAE,MAAU+H,KAAJ,GAAOA,GAAE,EAAEH,GAAGgB,EAAE,EAAEC,GAAG7I,EAAC,EAAEA,GAAE,KAAKsI,GAAG,QAAQhJ,GAAGoG,GAAGpG,CAAC,CAAC,GAAGkC,GAAE,kBAAkBuG,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAC/d,SAASa,GAAG3J,EAAE,CAAC,OAAOsJ,GAAGrJ,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAACiE,GAAE,GAAG,EAChD,IAAI0F,GAAG,CAAC,KAAKtF,GAAGG,GAAGY,GAAGE,GAAGC,GAAGI,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGO,EAAGC,EAAGa,GAAGC,GAAGC,EAAGC,GAAGC,GAAGE,EAAE,EAAE4B,GAAG,CAAC,EAAE,SAAS7J,EAAEC,EAAEC,EAAE,CAAC,OAAOyJ,GAAG,SAAS,CAAC,MAAM9J,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIkF,GAAGlF,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEiF,GAAGnF,EAAEoF,KAAWD,EAAG,EAAE,EAAE,SAASnF,EAAE,CAAC8J,GAAG9J,IAAI,EAAE,CAACqB,EAAE,EAAE,CAACD,EAAG,OAAO,EAAE,EAAE8C,GAAE,GAAG,CAAC,EAAE,EAAE,SAASlE,EAAE,CAACA,KAAK,EAAEuB,EAAE,YAAY,CAAC,IAAI,gBAAgB,OAAOvB,CAAC,CAAC,EAAEiE,GAAGjE,CAAC,CAAC,EAAE,EAAEsF,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEI,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAE,IAAI,GAAG,EAAE,SAAStG,EAAEC,EAAE,CAACD,KAAK,EAAEA,GAAGC,IAAI,EAAE,WAAW,IAAI2E,GAAG,CAAC,EAAErD,EAAE,YAAY,CAAC,aAAavB,EAC5f,IAAI,cAAc,CAAC,GAAGA,EAAEkE,GAAE,GAAGlE,CAAC,IAAIA,EAAE,YAAY,CAAC,IAAI,cAAc,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,EAAE,EAAE,EAAEwG,GAAG,EAAE,SAASxG,EAAE,CAACsB,GAAG4C,GAAE,GAAGlE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEA,GAAGA,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAC3f,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEC,GAAGyG,GAAE1G,EAAE,YAAY,CAAC,EAAE2G,GAAGC,IAAI5G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAED,EAAEZ,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EACrf,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEA,GAAGC,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,EAAEZ,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEX,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAClf,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGd,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEC,GAAGwG,GAAEzG,EAAE,YAAY,CAAC,EAAE0G,GAAGC,IAAI3G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEE,EAAEb,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAAE,IAAW8J,IAAIpG,GAAE3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,EAAE6G,EAAG,EAAEC,EACpf,EAAE,SAAS9G,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEM,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACT,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEE,GAAE,KAAK,IAAIJ,EAAEG,EAAC,EAAEhB,EAAE,EAAES,GAAG,IAAI,CAAC,EAAE,GAAGQ,GAAEnB,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE+G,EAAG/G,CAAC,EAAEC,EAAE8G,EAAG9G,CAAC,EAAEM,GAAEH,GAAGb,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEF,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAED,IAAIV,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAED,EAAEV,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACqC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASrC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEiH,EAAGjH,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EACtfC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEiH,EAAGjH,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,MAAA6C,IAAI,EAAO,QAAS,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,WAAW,YAAY,IAAI,EAAE,EAAE,UAAU,CAAC,OAAOxB,EAAE,cAAc,KAAK,EAAE,OAAO,UAAU,mBAAmB,EAAE,EAAE,SAAStB,EAAEC,EAAEC,EAAEC,EAAE,CAAmC,IAAlC+D,GAAE,GAAGjE,IAAI,EAAEsH,GAAG,OAAOrH,EAAED,EAAEE,IAAI,GAAG,EAAMA,EAAE,EAAEA,EAAED,EAAEC,IAAIoH,GAAGpH,CAAC,EAAER,EAAG,EAAEM,EAAEE,IAAI,CAAC,EAAE,OAAO,EAAEH,EAAE4D,GAAG,CAAC5D,EAAE,CAAC,EAAE4J,GAAG5J,CAAC,GAAG,MAAM,KAAKuH,EAAE,CAAC,EAAE,EAAE,SAASvH,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEd,EAAE,EAAE,OAAO,GAAGa,GAAGC,GAAG,WAAWD,EAAE,MAAM,GAAG,QAAQE,EACxf,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAAKD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAEnB,GAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,GAAE,KAAKoB,CAAC,EAAElB,GAAE,EAAE,IAAImB,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAEsH,GAAG,EAAEC,GAAG,EAAEpD,GAAG,EAAEqD,EAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEE,GAAG,EAAEjJ,IAAGa,EAAE,WAAW,EAAEyI,GAAG,EAAE,SAAStI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmI,GAAGtI,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GACrW,UAAU,CAAC,SAASH,EAAEE,EAAEC,EAAE,CAAC,OAAAD,EAAEA,EAAE,QAAQA,EAAEwI,GAAGxI,CAAC,EAAEoC,EAAEpC,EAAE8J,GAAG9J,CAAC,EAAEgE,GAAE,GAAG,KAAK5B,EAAE,EAAE,EAAEM,GAAG,QAAQN,EAAE,CAAC,EAAEC,GAAGpC,EAAEiD,GAAG,EAASlD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE4J,EAAE,EAAO,GAAL1G,GAAG,EAAKtD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAACgC,EAAE,sDAAsDhC,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,SAASA,EAAE,MAAM,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAAEF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASyC,EAAE,GAAGtC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiByC,EAAE,GAAGtC,EAAEC,CAAC,EAC7ZJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,KAAKZ,EAAE,yBAAyByC,EAAE,GAAGtC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4ByC,EAAE,IAAItC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6ByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0ByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0ByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAC7dL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiByC,EAAE,IAAItC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkByC,EAAE,IAAItC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASyC,EAAE,IAAItC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkByC,EAAE,IAAItC,CAAC,EAC5dH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcyC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAeyC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmByC,EAAE,IAAItC,CAAC,EACxeH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQyC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYyC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiByC,EAAE,IAAItC,CAAC,EAAE,IAAI2E,GAAG9E,EAAE,cAAc,KAAK8E,GAAG9E,EAAE,cAAcyC,EAAE,IAAI,EAAE0E,GAAGnH,EAAE,QAAQG,IAAIgH,GAAGnH,EAAE,QAAQyC,EAAE,IAAItC,CAAC,EAAE0J,GAAG7J,EAAE,MAAMG,IAAI0J,GAAG7J,EAAE,MAAMyC,EAAE,IAAItC,CAAC,EAAEH,EAAE,sBAAsB,KAAKA,EAAE,sBAAsByC,EAAE,IAAI,EAC7d,IAAIwH,GAAGjK,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyJ,GAAGjK,EAAE,yBAAyByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,4BAA4B,KAAKA,EAAE,4BAA4ByC,EAAE,IAAI,EAC1K,IAAIgF,GAAG,CAACtH,EAAEC,EAAEC,EAAEC,KAAKmH,GAAGhF,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuE,GAAG1E,IAAI0E,GAAGpC,EAAE,IAAItC,CAAC,EAAEiF,GAAGpF,EAAE,yBAAyBG,IAAIiF,GAAGpF,EAAE,yBAAyByC,EAAE,IAAItC,CAAC,EAAEyG,GAAG5G,EAAE,2BAA2B,KAAK4G,GAAG5G,EAAE,2BAA2ByC,EAAE,IAAI,EAAEyH,GAAG/J,IAAI+J,GAAGzH,EAAE,IAAItC,CAAC,EAAE8E,GAAG,CAAC9E,EAAEC,KAAK6E,GAAGxC,EAAE,IAAItC,EAAEC,CAAC,EAAEmH,GAAG,KAAKA,GAAG9E,EAAE,IAAI,EAAEyC,GAAG/E,IAAI+E,GAAGzC,EAAE,IAAItC,CAAC,EAAEqH,GAAGrH,IAAIqH,GAAG/E,EAAE,IAAItC,CAAC,EAAEgF,GAAGnF,EAAE,WAAW,CAACG,EAAEC,KAAK+E,GAAGnF,EAAE,WAAWyC,EAAE,IAAItC,EAAEC,CAAC,EAAEuJ,GAAGxJ,IAAIwJ,GAAGlH,EAAE,IAAItC,CAAC,EAAE6I,GAAG,KAAKA,GAAGvG,EAAE,IAAI,EAAEiH,GAAGvJ,IAAIuJ,GAAGjH,EAAE,IAAItC,CAAC,EAAEyJ,GAAG,KAAKA,GAAGnH,EAAE,IAAI,EAAEzC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAC1d,SAASmK,GAAGhK,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,aAAaC,EAAED,EAAE,YAAY,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,iBAAiBkD,GAAGlD,EAAE,WAAWb,GAAEa,EAAE,WAAWwH,GAAGxH,EAAE,UAAUuH,GAAGvH,EAAE,aAAakF,GAAGlF,EAAE,aAAagE,GAAEhE,EAAE,aAAa8F,GAAG9F,EAAE,gBAAgB4F,GAAG5F,EAAE,WAAWkE,GAAGlE,EAAE,QAAQqE,GAAE,IAAI+F,GAAG/G,GAAE,SAASgH,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAK/G,GAAEgH,EAAG,EAC/b,SAASC,IAAI,CAAC,SAASnK,GAAG,CAAC,GAAG,CAACiK,KAAKA,GAAG,GAAGpK,EAAE,UAAU,GAAG,CAAC2C,MAAIjB,GAAGsD,GAAGjC,EAAE,EAAE9C,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAK,CAAC0B,GAAE,CAAC,GAAG1B,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEgD,GAAG,QAAQ5C,CAAC,CAAC,CAAC4E,GAAGhC,EAAE,CAAC,CAAE,CAAC,GAAG,EAAE,EAAEG,IAAG,GAAGzB,EAAEzB,EAAGD,CAAC,EAAE0B,GAAGsD,GAAGjC,EAAE,EAAE,YAAY/C,CAAC,MAAM,CAAC,GAAGA,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQ8C,GAAG,QAAQ9C,EAAE,OAAO,MAAM,CAAC,EAAEgF,GAAGlC,EAAE,EAAE,EAAEK,KAAInD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EACpiB,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAAC,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAsK,GAAG,EAGzHrL,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAe,IC7FlC,IAAAwL,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,0/ECAA,IAUIC,GASEC,GAMFC,GACAC,GACAC,GACAC,GAEEC,GAwBAC,GAyBAC,GAWOC,GA8GAC,GAxMbC,GAAAC,EAAA,kBAeEZ,GACmE,KAG/DC,GAE2B,KAK7BE,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAC5C,GAAI,CAEF,OAAI,OAAO,kBAAsB,IACxB,IAKL,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SAAS,IAAI,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,EAClE,CAAC,CAAC,EACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SAAS,IAAI,WAAW,CACzC,EAAK,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAK,GAAK,EAAG,GAAI,EACvF,IAAK,GAAI,IAAK,GAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAI,IAAK,IAAK,EAAG,GAAI,EACzF,CAAC,CAAC,CACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,CAACK,EAAkBC,IACrCD,EAIKC,EAAa,8BAAgC,qBAE7CA,EAAa,yBAA2B,gBAItCL,GAAwB,MAAMM,GAA+C,CACxF,GAAIZ,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAyD,EAE3E,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAsD,EAGxED,GAAe,GAGf,IAAMY,EAAUD,EAAM,YAChBE,EAAaF,EAAM,WACnBG,EAAOH,EAAM,KAEbD,EAAaG,EAAa,GAAKX,GAAuB,EACtDO,EAAUK,GAAQX,GAAgB,EAElCY,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAeb,GAAgBK,EAASC,CAAU,EAClDQ,EAAmB,OAAOH,GAAc,SAAWA,EAAUE,CAAY,EAAI,OAE/EE,EAAY,GAEVC,EAA8B,CAAC,EA6ErC,GA1EIR,EAAU,GACZQ,EAAM,KAAK,IAAI,QAASC,GAAY,CAClC,WAAW,IAAM,CACfF,EAAY,GACZE,EAAQ,CACV,EAAGT,CAAO,CACZ,CAAC,CAAC,EAIJQ,EAAM,KAAK,IAAI,QAAQ,CAACC,EAASC,IAAW,CAC1C,IAAMC,EAAUb,EAAab,GAAyBD,GAChD4B,EAAiC,CACrC,WAAY,CAACC,EAAkBC,IAA4B,CACzD,GAAuChB,GAAce,EAAS,SAAS,YAAY,GAC/E,OAAO,KAAS,IAClB,OAAO,IAAI,gBAAgB,IAAI,KAC3B,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAGhC,GAAIA,EAAS,SAAS,OAAO,EAAG,CAC9B,GAAIP,EACF,OAAOA,EAGT,IAAMS,EAASX,GAAsBU,EAGnC,OAAIT,IAAiB,qBACZU,EAAS,0BACPV,IAAiB,8BACnBU,EAAS,mCAIbA,EAASV,CAClB,CAEA,OAAOS,EAAkBD,CAC3B,CACF,EAEA,GAAuCf,EACrC,GAAI,OAAO,KAAS,IAClBc,EAAO,oBAA2B,SAAK,UAAW,sBAAsB,MACnE,CACL,IAAMI,EAAmB,uBAAuBL,EAAQ,SAAS,CAAC,IAClEC,EAAO,oBAAsB,IAAI,KAAK,CAACI,CAAgB,EAAG,CAAC,KAAM,iBAAiB,CAAC,CACrF,CAGFL,EAAQC,CAAM,EAAE,KAEZK,GAAU,CACR7B,GAAe,GACfD,GAAc,GACdD,GAAO+B,EACPR,EAAQ,CACV,EAECS,GAAS,CACR9B,GAAe,GACfC,GAAU,GACVqB,EAAOQ,CAAI,CACb,CAAC,CACP,CAAC,CAAC,EAEF,MAAM,QAAQ,KAAKV,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DP,CAAO,IAAI,CAE1F,EAEaN,GAAc,IAAqB,CAC9C,GAAIP,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IC9MA,IAKaiC,GAeAC,GA6BAC,GAjDbC,GAAAC,EAAA,kBAGAC,KAEaL,GAAkB,CAACM,EAAcC,IAA6B,CACzE,IAAMC,EAAOC,GAAY,EAEnBC,EAAaF,EAAK,gBAAgBF,CAAI,EAAI,EAC1CK,EAAaH,EAAK,QAAQE,CAAU,EAC1C,OAAAF,EAAK,aAAaF,EAAMK,EAAYD,CAAU,EAC9CH,EAAO,KAAKI,CAAU,EAEfA,CACT,EAMaV,GACT,CAACW,EAAkCC,EAAgBC,EAClDC,IAAuC,CACtC,GAAI,OAAOH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIE,EAAK,IAAIF,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CE,EAAK,IAAIF,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACI,EAAKC,CAAK,IAAM,CAChD,IAAMC,EAAQL,EAAUA,EAASG,EAAMA,EACvC,GAAI,OAAOC,GAAU,SACnBhB,GAAoBgB,EAAkCC,EAAO,IAAKJ,EAAMC,CAAO,UACtE,OAAOE,GAAU,UAAY,OAAOA,GAAU,SACvDF,EAAQG,EAAMD,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BF,EAAQG,EAAOD,EAAS,IAAM,GAAG,MAEjC,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMSf,GAAkBiB,GAA0B,CACvD,IAAMX,EAAOC,GAAY,EAEnBW,EAAQZ,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMa,EAAeb,EAAK,WAAW,CAAC,EACtCA,EAAK,iBAAiBa,EAAcA,EAAe,CAAC,EACpD,IAAMC,EAAYd,EAAK,OAAOa,EAAe,CAAC,EACxCE,EAAsBf,EAAK,QAAQa,EAAe,EAAI,CAAC,EACvDG,EAAeD,EAAsBf,EAAK,aAAae,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGJ,CAAO,gBAAgBG,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAhB,EAAK,aAAaY,CAAK,CACzB,CACF,IC/DA,IAQaK,GARbC,GAAAC,EAAA,kBAKAC,KACAC,KAEaJ,GAAiBK,GAA6D,CACzF,IAAMC,EAAOC,GAAY,EACrBC,EAAmB,EACjBC,EAAmB,CAAC,EAEpBC,EAA0CL,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCK,EAAW,iBAAmB,UAE5B,OAAOL,EAAQ,kBAAqB,UAAY,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1FA,EAAQ,iBAAmB,GAAKA,EAAQ,iBAAmB,EAC7D,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCK,EAAW,kBAAoB,UACtB,OAAOL,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBK,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIN,GAAS,MAAQ,SACnBM,EAAgBC,GAAgBP,EAAQ,IAAKI,CAAM,GAGrDD,EAAmBF,EAAK,qBACpBI,EAAW,iBAAmBA,EAAW,kBAAoB,CAAC,CAACA,EAAW,UAAYC,CAAa,EACnGH,IAAqB,GACvBK,GAAe,2BAA4B,EAGzCR,GAAS,QAAU,QACrBS,GAAoBT,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACU,EAAKC,IAAU,CAC7F,IAAMC,EAAgBL,GAAgBG,EAAKN,CAAM,EAC3CS,EAAkBN,GAAgBI,EAAOP,CAAM,EAEjDH,EAAK,sBAAsBE,EAAkBS,EAAeC,CAAe,IAAM,GACnFL,GAAe,iCAAiCE,CAAG,MAAMC,CAAK,GAAG,CAErE,CAAC,EAGI,CAACR,EAAkBC,CAAM,CAClC,OAASU,EAAG,CACV,MAAIX,IAAqB,GACvBF,EAAK,sBAAsBE,CAAgB,EAE7CC,EAAO,QAAQW,GAASd,EAAK,MAAMc,CAAK,CAAC,EACnCD,CACR,CACF,IChEA,IAQME,GAeAC,GAWAC,GAoBAC,GAkEOC,GAxHbC,GAAAC,EAAA,kBAKAC,KACAC,KAEMR,GAA4BS,GAAmD,CACnF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMR,GAAoBS,GAAmD,CAC3E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMR,GAAwBS,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMC,EAAUD,EAAQ,MAAM,QACzBC,EAAQ,+BAEXA,EAAQ,6BAA+B,KAIrCD,EAAQ,oBACRA,EAAQ,mBAAmB,KAAKE,IAAO,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAC5FF,EAAQ,iBAAmB,GAE/B,EAEMR,GACF,CAACW,EAA8BC,EAC9BC,IAA2B,CAC1B,QAAWH,KAAME,EAAoB,CACnC,IAAIE,EAAS,OAAOJ,GAAO,SAAWA,EAAKA,EAAG,KAG9C,OAAQI,EAAQ,CACd,IAAK,UACHA,EAAS,UACT,MACF,IAAK,QAEH,GADAA,EAAS,QACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAeL,EACrB,GAAIK,GAAc,WAAY,CAC5B,IAAMC,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBF,EAAa,WAAYF,CAAM,EACnEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,gBAAiB,CACjC,IAAMC,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBF,EAAa,gBAAiBF,CAAM,EACxEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDL,EAAa,eAAe,GAAG,CAEhG,CACF,CACA,MACF,IAAK,SAEH,GADAD,EAAS,KACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMW,EAAgBX,EACtB,GAAIW,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErG,IAAML,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBI,EAAc,gBAAiBR,CAAM,EACzEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDC,EAAc,eAAe,GAAG,CAEjG,CACF,CACA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCP,CAAM,EAAE,CACjE,CAEA,IAAMQ,EAAmBL,GAAgBH,EAAQD,CAAM,EACnDM,GAAY,EAAE,4BAA4BR,EAAsBW,CAAgB,IAAM,GACxFF,GAAe,oCAAoCN,CAAM,GAAG,CAEhE,CACF,EAESb,GAAqBO,GAAkE,CAClG,IAAMe,EAAOJ,GAAY,EACrBR,EAAuB,EACrBE,EAAmB,CAAC,EAEpBW,EAAkDhB,GAAW,CAAC,EACpET,GAAqByB,CAAc,EAEnC,GAAI,CACF,IAAMlB,EAAyBT,GAAyB2B,EAAe,wBAA0B,KAAK,EAChGjB,EAAgBT,GAAiB0B,EAAe,eAAiB,YAAY,EAC7EC,EACF,OAAOD,EAAe,OAAU,SAAWP,GAAgBO,EAAe,MAAOX,CAAM,EAAI,EAEzFa,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EAA+B,OAAOJ,EAAe,wBAA2B,SAClFP,GAAgBO,EAAe,uBAAwBX,CAAM,EAC7D,EAcJ,GAZAF,EAAuBY,EAAK,yBACxBjB,EAAwB,CAAC,CAACkB,EAAe,kBAAmB,CAAC,CAACA,EAAe,iBAAkBjB,EAC/F,CAAC,CAACiB,EAAe,gBAAiB,EAAGC,EAAiBC,EAAkBC,EACxEC,CAA4B,EAC5BjB,IAAyB,GAC3BS,GAAe,+BAAgC,EAG7CI,EAAe,oBACjBxB,GAAsBW,EAAsBa,EAAe,mBAAoBX,CAAM,EAGnFW,EAAe,uBACjB,OAAW,CAACK,EAAMC,CAAK,IAAK,OAAO,QAAQN,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAOC,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMC,EAAad,GAAgBY,EAAMhB,CAAM,EAC3CU,EAAK,6BAA6BZ,EAAsBoB,EAAYD,CAAK,IAAM,GACjFV,GAAe,wCAAwCS,CAAI,MAAMC,CAAK,GAAG,CAE7E,CAGF,OAAIN,EAAe,QAAU,QAC3BQ,GAAoBR,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACS,EAAKH,IAAU,CACpG,IAAMd,EAAgBC,GAAgBgB,EAAKpB,CAAM,EAC3CK,EAAkBD,GAAgBa,EAAOjB,CAAM,EAEjDU,EAAK,0BAA0BZ,EAAsBK,EAAeE,CAAe,IAAM,GAC3FE,GAAe,qCAAqCa,CAAG,MAAMH,CAAK,GAAG,CAEzE,CAAC,EAGI,CAACnB,EAAsBE,CAAM,CACtC,OAASqB,EAAG,CACV,MAAIvB,IAAyB,GAC3BY,EAAK,0BAA0BZ,CAAoB,EAErDE,EAAO,QAAQsB,GAASZ,EAAK,MAAMY,CAAK,CAAC,EACnCD,CACR,CACF,IClMA,IAiCaE,GAqCAC,GAsCAC,GAMAC,GAoCAC,GAoBAC,GAMAC,GAhLbC,GAAAC,EAAA,kBAiCaR,GAA8BS,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaR,GAA8BS,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaR,GAAwBS,GACpB,CAAC,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,OAAW,MAAS,EAAEA,CAAQ,EAKxGR,GAAqCM,GAEoD,CAChG,OAAQA,EAAM,CACZ,IAAK,UACH,OAAO,YACT,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKSL,GAAwBQ,GAAkE,CACrG,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaP,GAA4BI,GAAyDA,IAAS,WACvGA,IAAS,SAAWA,IAAS,SAAWA,IAAS,QAAUA,IAAS,WAAaA,IAAS,SAKjFH,GAA4BO,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,IC/LA,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,GAzCbC,GAAAC,EAAA,kBAKAC,KAOMT,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACS,EAAeC,IAA0B,CAEtD,QAAQ,IAAI,IAAIX,GAAeU,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAIC,CAAO,EAAE,CAChF,EAKaP,GAAkB,CAACQ,EAA2BC,IAA0B,CACnFX,GAAiBU,EACjBT,GAAQU,CACV,EAKaR,GAAM,CAACS,EAAoBC,IAAuB,CAC7D,IAAMC,EAAeC,GAAqBH,CAAQ,EAC5CI,EAAcD,GAAqBf,EAAc,EACnDc,GAAgBE,GAClBjB,GAAMe,EAAc,OAAOD,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKaT,GAAwB,IAAIa,IAAiC,CACpEhB,IACFE,GAAI,GAAGc,CAAI,CAEf,IC7CA,IAOaC,GAPbC,GAAAC,EAAA,kBAKAC,KAEaH,GAAa,CAACI,EAAyBC,IAE5C,IAAKC,GAAkCD,CAAI,GAAGD,CAAU,ICThE,IAAAG,GAAAC,EAAA,oBCAA,IA2EMC,GAEFC,GACEC,GAYOC,GAkCPC,GAoOOC,GAhWbC,GAAAC,EAAA,kBAIAC,KAEAC,KAqEMT,GAA4BU,GAAiB,KAAK,KAAKA,EAAO,EAAE,EAAI,GAEtET,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GACT,MAAMQ,EAAwBC,EAAsBC,EAAsBC,IAC/C,CACrB,IAAMC,EAAaf,GAAyBa,CAAY,EAClDG,EAAgBL,EAAQ,OAAO,aAEjC,CAAC,KAAMI,EAAY,MAAO,eAAe,SAAW,eAAe,QAAQ,CAAC,EAChF,GAAI,CACF,IAAME,EAAiBN,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBM,EAAe,mBACXL,EAA+B,EAAuBI,EACtD,EAA4BD,CAChC,EACAJ,EAAQ,MAAM,EAEd,MAAMK,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEFZ,GAAN,KAAmD,CAiBjD,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,2BAA6B,CAAC,EACnC,KAAK,eAAiB,CAAC,EACvB,KAAK,gBAAkB,IAAI,GAC7B,CAEA,OAAOS,EAAeC,EAAwB,CAC5C,IAAMC,EAAiBD,EAAK,OACtBE,EAAYF,EAAK,WACjBG,EAAYH,EAAK,WACjBX,EAAOV,GAAyBwB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIL,CAAE,EAC7C,GAAI,CAACK,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAIA,EAAa,eAAiBD,EAChC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAE9C,CAAC,iBAAkB,GAAM,KAAAhB,EAAM,MAAO,eAAe,UAAY,eAAe,QAAQ,CAAC,EAGvFQ,EAAcQ,EAAsB,eAAe,EACzD,IAAI,WAAWR,CAAW,EAAE,IAAI,IAAI,WAAWI,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAI5B,IAAMT,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBAAmBS,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGf,CAAI,EAEhGiB,GAAU,UAAW,IAAM,qCAAqCP,CAAE,GAAG,EAErE,KAAK,2BAA2B,KAAKM,CAAqB,CAC5D,CAEA,OAAOE,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAErE,IAAMrB,EAAOV,GAAyB8B,EAAmB,YAAY,EAG/Db,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACXa,EAAmB,QAAQ,OAAQ,EAAGC,EAAwB,QAAQ,OAAQ,EAAGrB,CAAI,CAC3F,CAEA,uBAAuBsB,EAAmBnB,EAAsBoB,EAAoC,CAClG,IAAIb,EACJ,GAAIa,EAAgB,CAElB,GADAb,EAAK,KAAK,gBAAgB,IAAIa,CAAc,EACxCb,IAAO,OACT,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIY,IAAWC,EACb,OAAAN,GACI,UACA,IAAM,uDAAuDd,CAAY,WACrEO,CAAE,6BAA6B,EAChCA,EAET,KAAK,gBAAgB,OAAOa,CAAc,CAC5C,MACEb,EAAKlB,GAAmB,EAG1B,YAAK,aAAa,IAAIkB,EAAI,CAAC,QAAS,CAAC,GAAAA,EAAI,OAA2B,OAAAY,CAAM,EAAG,aAAAnB,CAAY,CAAC,EAC1F,KAAK,gBAAgB,IAAImB,EAAQZ,CAAE,EACnCO,GACI,UACA,IAAM,uDAAuDd,CAAY,WAAWO,CAAE,eAAe,EAClGA,CACT,CAEA,yBAAyBY,EAAyB,CAChD,IAAMZ,EAAK,KAAK,gBAAgB,IAAIY,CAAM,EACtCZ,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B,KAAK,gBAAgB,OAAOY,CAAM,EAClCL,GAAU,UAAW,IAAM,4DAA4DP,CAAE,EAAE,EAE/F,CAGA,OAAOV,EAAcwB,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMnB,EAAaf,GAAyBU,CAAI,EAE5CE,EAGEuB,GAAaD,EAAQ,eAAe,WAAa,eAAe,QAEhEE,GAAaF,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIC,GAAaC,EAAW,CAC1B,IAAMC,EAAcF,EAAY,KAAK,YAAc,KAAK,mBACpDG,EAAUD,EAAY,IAAItB,CAAU,EACnCuB,IACHA,EAAU,CAAC,EACXD,EAAY,IAAItB,EAAYuB,CAAO,GAEjCA,EAAQ,OAAS,EACnB1B,EAAY0B,EAAQ,IAAI,EAGxB1B,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,CAE1E,MAEEtB,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,EAGxE,IAAMK,EAAU,CAAC,GAAIrC,GAAmB,EAAG,OAA2B,OAAQU,CAAS,EACvF,YAAK,aAAa,IAAI2B,EAAQ,GAAI,CAAC,QAAAA,EAAS,aAAc7B,CAAI,CAAC,EAE/DiB,GAAU,UAAW,IAAM,uCAAuCjB,CAAI,WAAW6B,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAInB,EAAkC,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQA,EAAuB,CAC7B,IAAMoB,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAAb,GAAU,UAAW,IAAM,sCAAsCP,CAAE,gBAAgBoB,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAOpB,CAAE,EAC3B,KAAK,eAAe,KAAKoB,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAASpB,EAAeN,EAAkD,CAC9E,IAAM0B,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,qBAAqB,EAGvC,MAAMrC,GAAgB,KAAK,QAASqC,EAAW,QAAQ,OAAQA,EAAW,aAAc1B,CAAe,CACzG,CAEA,uBAA8B,CAC5B,QAAWkB,KAAU,KAAK,2BAExBA,EAAO,QAAQ,EAEjB,KAAK,2BAA6B,CAAC,EACnC,QAAWA,KAAU,KAAK,gBAEnBA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAE7D,KAAK,YAAY,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,GAEpCA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAEpE,KAAK,mBAAmB,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,EAErDA,EAAO,QAAQ,EAGnB,KAAK,eAAiB,CAAC,CACzB,CAEA,SAAU,CACR,KAAK,YAAY,QAASM,GAAY,CACpCA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASM,GAAY,CAC3CA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAASS,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,GAChC,CACF,EAEapC,GAAuB,IAAIqC,IACpC,IAAItC,GAAmB,GAAGsC,CAAI,ICjWlC,IAGMC,GAsBOC,GAzBbC,GAAAC,EAAA,kBAGMH,GAAN,KAAgC,CAC9B,YAAYI,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,YACR,KAAK,UACD,OAAO,oBAAoB,IAAI,EAAE,KAAK,EAAE,IAAIC,GAAQ,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAAE,KAAK,GAAG,GAEzG,KAAK,SACd,CACF,EASaJ,GAAkEG,GAC3E,IAAIJ,GAA0BI,CAAS,IC1B3C,IAKaE,GAaAC,GAoEAC,EAiHAC,GA0MAC,GAkDAC,GACAC,GApcbC,GAAAC,EAAA,kBAKaR,GAAN,KAAiB,CAOtB,OAAO,gBAAgBS,EAAqBC,EAAiD,CAC3F,OAAQD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAK,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAClD,CACF,EAGaT,GAAN,KAAoB,CAQzB,OAAO,UAAUU,EAA0BC,EAA0BC,EAAW,GAAoC,CAClH,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EACFlB,GAAW,gBAAgB,CAACW,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EAAG,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CAAC,EACzG,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAASC,EAAIN,EAAW,EAAI,EAAGM,GAAKH,EAAOG,IAAK,CAC9C,IAAMC,EAAON,EAAQK,EAAI,EAAI,EAAIR,EAAMG,EAAQK,CAAC,EAC1CE,EAAON,EAAQI,EAAI,EAAI,EAAIP,EAAMG,EAAQI,CAAC,EAEhD,GAAIC,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEFJ,EAAMD,EAAQG,CAAC,EAAI,KAAK,IAAIC,EAAMC,CAAI,CACxC,CAEA,OAAOJ,CACT,CAOA,OAAO,iBAAiBK,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAASN,EAAI,EAAGA,GAAKK,EAAWL,IAC9B,GAAIG,EAAME,EAAYL,CAAC,IAAM,GAAKG,EAAME,EAAYL,CAAC,IAAMI,EAAWE,EAAYN,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAGajB,EAAN,MAAMwB,CAAU,CAIrB,OAAO,KAAKC,EAAiC,CAC3C,OAAOD,EAAU,0BAA0BC,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,kBAAkBA,EAAyBC,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,wCAAwCD,EAAK,MAAM,cAAc,EAE/G,OAAOD,EAAU,0BAA0BC,EAAMC,EAAMD,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyBC,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,sCAAsCD,EAAK,MAAM,cAAc,EAE7G,OAAOD,EAAU,0BAA0BC,EAAM,EAAGC,CAAI,CAC1D,CAKA,OAAO,0BAA0BD,EAAyBE,EAAeC,EAAqB,CAC5F,IAAIC,EAAO,EACX,QAASZ,EAAIU,EAAOV,EAAIW,EAAKX,IAAK,CAGhC,GAAIQ,EAAKR,CAAC,EAAI,EACZ,MAAM,IAAI,MAEN,+GAA+G,EAErHY,GAAQJ,EAAKR,CAAC,CAChB,CACA,OAAOY,CACT,CAEA,OAAO,eAAeJ,EAA4C,CAChE,IAAMK,EAAOL,EAAK,OAClB,GAAIK,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC9BC,EAAQD,EAAO,CAAC,EAAI,EACpBC,EAAQD,EAAO,CAAC,EAAIL,EAAKK,EAAO,CAAC,EACjC,QAASb,EAAIa,EAAO,EAAGb,GAAK,EAAG,EAAEA,EAC/Bc,EAAQd,CAAC,EAAIc,EAAQd,EAAI,CAAC,EAAIQ,EAAKR,EAAI,CAAC,EAE1C,OAAOc,CACT,CAKA,OAAO,cAAcL,EAAcM,EAA4B,CAC7D,GAAIN,EAAO,CAACM,GAAcN,GAAQM,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAON,EAAO,EAAIA,EAAOM,EAAaN,CACxC,CAEA,OAAO,cAAcO,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAIC,GAAK,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACvE,CAQA,OAAO,gBAAgB1B,EAAsB4B,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKC,GAAM7B,EAAE6B,CAAC,CAAC,EAEpB7B,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAASkB,EAAyBY,EAA2C,CAClF,IAAMP,EAAOL,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACW,EAAGnB,IAAMmB,EAAIC,EAAIpB,CAAC,EAAIoB,EAAIpB,EAAIa,CAAI,CAAC,CACtD,CAOA,OAAO,SAASQ,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACF,EAAGnB,IAAMmB,IAAMG,EAAOtB,CAAC,CAAC,CAC/C,CACF,EAEahB,GAAN,MAAMuC,CAAa,CAUxB,OAAO,qBACHC,EAA2BC,EAA8BC,EAAuBZ,EAChFa,EAAqBC,EAAsB,CAC7C,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IACxCA,GAAOH,EAAY,OACrBA,EAAY,KAAKD,EAAUI,EAAM,CAAC,CAAC,EAEnCH,EAAYG,CAAG,EAAIJ,EAAUI,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMf,EAAQ,QAChB,GAAIA,EAAQe,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhEf,EAAQ,KAAK,CAAC,EAKlB,QAASe,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMF,EAAU,QAClB,GAAIA,EAAUE,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEF,EAAU,KAAK,CAAC,EAKpB,QAASE,EAAM,EAAGA,EAAMH,EAAY,OAAS,EAAGG,IAC9C,GAAIA,EAAMD,EAAK,QACb,GAAIA,EAAKC,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5DD,EAAK,KAAK,CAAC,EAKf,QAASC,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAAO,CACjD,GAAIH,EAAYG,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAID,EAAKC,CAAG,GAAKH,EAAYG,CAAG,GAAKD,EAAKC,EAAMH,EAAY,MAAM,GAAKA,EAAYG,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACHJ,EAA8BX,EAA4Ba,EAC1DD,EAAgCE,EAAgBE,EAAwBC,EAAwB,CAClG,GAAKA,EAIL,IAAIH,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIX,EAAQ,SAAYW,EAAU,OAAS,EACzC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAYD,EAAU,OAAS,EAC7C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASI,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CN,EAAa,wBACTE,EAAUI,GAAOC,EAAgB,EAAI,EAAE,EAAGhB,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAChGA,EAAMJ,EAAU,OAAS,EAAGM,CAAO,EAE3C,CAaA,OAAO,uBACHP,EAA2BC,EAA8BX,EAAmBa,EAC5ED,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMO,EAAa,CAACP,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACTC,EAAkBC,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACpFC,CACT,CAYA,OAAO,uBACHP,EAA8BQ,EAA+BnB,EAAmBa,EAChFD,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,GAAKQ,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACP,EAAU,CAAC,EAAGQ,EAAW,CAAC,CAAC,EAE/C,OAAAV,EAAa,mBAAmB,GAAOE,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACrGC,CACT,CAKA,OAAe,mBACXR,EAA2BC,EAA8BO,EAAsBlB,EAC/Ea,EAA8BD,EAAgCE,EAAgBG,EAAkB,CAClG,GAAIP,EACF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAK,CAAC,MAGnB,SAASH,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAKT,EAAa,wBACzBE,EAAUI,EAAM,CAAC,EAAGf,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAAKA,EAAMJ,EAAU,OAAS,EACxGM,CAAO,CAAC,CAGlB,CAIA,OAAe,wBACXG,EAAgBC,EAAgBC,EAAkBC,EAAgBT,EAAgBU,EAClFC,EAAsBR,EAA0B,CAClD,IAAMS,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIN,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAH,EAAKU,CAAY,EAAI,EACrBV,EAAKW,CAAY,EAAI,EACd,KAAK,OAAQL,EAASM,GAAWL,EAAU,CAAC,EACrD,IAAK,aACL,IAAK,aACH,GAAIC,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBP,EAASC,EAAS,GAAKA,EACX,GAAKA,EAASE,EAASH,EAC7D,OAAAN,EAAKU,CAAY,EACgB,KAAK,MAAjCP,IAAY,cAA4BU,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC/Db,EAAKW,CAAY,EAAIE,EAAYb,EAAKU,CAAY,EAC3C,KAAK,OAAQJ,EAASO,EAAYJ,GAAUF,EAAU,CAAC,CAChE,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAQD,EAASN,EAAKU,CAAY,EAAIV,EAAKW,CAAY,EAAIC,GAAWL,EAAU,CAAC,CAEjG,CACF,EAEalD,GAAN,KAAe,CAIpB,OAAO,qBACHyD,EAA8BC,EAAoBC,EAA+BC,EACjFC,EAAkD,CACpD,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAAChE,GAAc,iBAAiBgE,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAGa9D,GAAW,sBACXC,GAAW,uBCpcxB,IAiBagE,GAqMPC,GAoCOC,GAUAC,GAOAC,GAiBAC,GAcAC,GAgBAC,GAsBPC,GAuSOC,EAaAC,EAyDPC,GA+EOC,GAYAC,GAeAC,GAvyBbC,GAAAC,EAAA,kBAGAC,KACAC,KAaalB,GAAiB,GAqMxBC,GAAoB,CAACkB,EAAcC,IAAiD,CACxF,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQD,EAAM,CACZ,QACE,OAAOC,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAE7B,QACE,MAAM,IAAI,MAAM,sBAAsBD,CAAI,EAAE,CAChD,CACF,EAEajB,GAA8B,CAACiB,EAAgBC,EAAsB,IAAM,CACtF,IAAMC,EAAapB,GAAkBkB,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAOalB,GAA8BmB,GACnB,CAAC,CAAC,KAAM,SAAU,KAAMA,CAAI,EAAG,CAAC,KAAM,SAAU,KAAMC,EAAU,eAAeD,CAAI,CAAC,CAAC,EAMhGlB,GAAoBoB,GAE3BA,EAAO,IAAM,EACR,EACEA,EAAO,IAAM,EACf,EAGF,EASInB,GAAa,CAACoB,EAAW,MAAOL,EAAqBM,EAAQ,MACpE,CAACN,GAAcA,IAAe,EACzB,GAAGK,CAAQ,IAAIC,CAAK,IAGtB,MAAMN,CAAU,IAAIK,CAAQ,KAAKC,CAAK,IASlCpB,GAAY,CAACmB,EAAkBL,EAAoBM,IAC1DD,IAAa,MACRC,EAELN,IAAe,EACV,OAAOM,CAAK,IAGd,MAAMN,CAAU,KAAKM,CAAK,IAQtBnB,GAAY,CAACoB,EAAcP,IAClCA,IAAe,EACV,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAC1CP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,MAClBP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAGlCA,EAaHnB,GACF,CAACmB,EAAcC,EAAoBC,EAAuCC,EACzEV,IAAuC,CACtC,IAAMW,EAAa,OAAOF,GAAgB,SACpCG,EAAOD,EAAaF,EAAcA,EAAY,OAC9CI,EAAe,CAAC,GAAG,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAC,EACzCE,EAAcF,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFX,EAAapB,GAAkB2B,EAAYR,CAAU,EACrDe,EAAY,OAAOd,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtEe,EAAc,OAAOf,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEF,EAAO,CAAC,QAASe,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQR,CAAU,EAExFS,EAAgBC,GAA+B,OAAOA,GAAQ,SAAWA,EAAM,GAAGA,CAAG,IAErFC,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBT,EAAa,YAAc,GAC3CU,EAAQ,GAAGD,CAAa,GAAGb,CAAI,SAC/Be,EAAU,GAAGF,CAAa,GAAGb,CAAI,WACnCgB,EAAa,GACjB,QAASC,EAAI,EAAGA,EAAIZ,EAAO,EAAGY,IAC5BD,GAAc;AAAA,aACTC,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC5BA,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC7BA,CAAC,UAAUA,CAAC;AAAA,oBACNA,CAAC;AAAA,MAGfD,GAAc,WAAWX,EAAO,CAAC,eAEjC,IAAMa,EAAgCb,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,oBAAoBR,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzBwB,CAAU;AAAA;AAAA,KAIJG,EAAmBC,IACvBR,EAAmB,gBAAkB,GAC9BP,EAAO,EAAIe,EAAY,OAAOpB,CAAI,IAAIoB,CAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAIhB,GAAQ,EACV,QAASY,EAAIZ,EAAO,EAAGY,GAAK,EAAGA,IAC7BI,EAAQ,KAAK,GAAGN,CAAO,IAAIE,CAAC,gBAAgBA,CAAC,IAAI,EAIrD,IAAMK,EAAgCjB,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,aAAaR,EAAK,OAAO;AAAA,aAC3B6B,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGlBE,EAAmBC,IACvBZ,EAAmB,gBAAkB,GAC9BP,EAAO,EAAImB,EAAa,OAAOxB,CAAI,IAAIwB,CAAU,KAGpDC,EAAU,IAAIC,IAChBrB,IAAS,EAAI,KAAO,GAAGb,EAAK,OAAO,IAAIkC,EAAK,IAAIhB,CAAY,EAAE,KAAK,GAAG,CAAC,IAErEiB,EAAa,CAACH,EAAoBI,KAClCvB,EAAO,EACF,GAAGmB,CAAU,GAEb,GAAGA,CAAU,IAAII,EAAG,IAIzBC,GAAa,CAACL,EAAoBI,GAAoB7B,KACtDM,EAAO,EACF,GAAGmB,CAAU,IAAIzB,EAAK,IAEtB,GAAGyB,CAAU,IAAII,EAAG,KAAK7B,EAAK,IAInC+B,EAAoE,CAAC,EACrEC,EAA6B,CAACP,EAAoBQ,KAA0B,CAChFpB,EAAmB,2BAA6B,GAChD,IAAMqB,GAAU,GAAGD,GAAO,IAAI,uBAAuBhC,CAAI,SACzD,GAAIiC,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIT,CAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASJ,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAAK,CAClC,IAAMW,GAAMI,GAAO,WAAW,gBAAiBf,GAAIe,GAAO,KAAO3B,CAAI,EACrEgB,GAAQ,KAAK,GAAGM,EAAWZ,EAASE,EAAC,CAAC,OAAOW,EAAG,MAAMD,EAAWb,EAAOG,EAAC,CAAC,GAAG,CAC/E,CACA,OAAAa,EAAyCG,EAAO,EAC5C,MAAMA,EAAO,mBAAmBD,GAAO,KAAK,OAAO;AAAA,sBACzCX,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGpD,GAAGY,EAAO,IAAIT,CAAU,GACjC,EAEMU,GAAc,CAACC,EAAuBpC,MAAmB,IAAM,CACnE,GAAIP,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAImC,CAAM,KAAKpC,EAAK,IAC7B,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,mBAAmBpC,EAAK,8BAA8BA,EAAK,UAC9E,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,mBAAmBpC,EAAK,UAC3C,GAAIP,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,8DAA8DpC,EAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CP,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG4C,GAAeD,IAA2B,IAAM,CACpD,GAAI3C,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAImC,CAAM,IACnB,GAAI3C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAImC,CAAM,OACvB,GAAI3C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAImC,CAAM,OACvB,GAAI3C,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmBQ,CAAI,IAAImC,CAAM,oBAAoBnC,CAAI,IAAImC,CAAM,sBAAsBnC,CAAI,IAChGmC,CAAM,wBAAwBnC,CAAI,IAAImC,CAAM,oBAEhD,MAAM,IAAI,MAAM,6CAA6C3C,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG6C,GAA6BhC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBR,EAAK,OAAO,QAAQgB,CAAS;AAAA,aACrD4B,GAAY,OAAOpC,CAAI,WAAW,CAAC;AAAA,KAGpCsC,EAAoBjC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIuC,CAAc,QAAQ/B,CAAS;AAAA,iBACjCR,CAAI,aAAayB,EAAQe,EAAU,CAAC;AAAA,IAE/C,GAAG,EAEGC,GAAM,IAAIhB,IAA0C,CACxD,GAAIA,EAAQ,SAAWpB,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMqC,GAAoBjB,EAAQ,IAAIf,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAIL,IAAS,EACJ+B,GAAY,IAAI,EACd/B,IAAS,EACX+B,GAAYM,GAAkB,CAAC,CAAC,GAEvC9B,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI0C,EAAiB,IAE3C,EAEMC,GAAgBnB,GAChBnB,EAAO,EACF+B,GAAYZ,CAAU,GAE7BZ,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAIvCoB,GAA6BvC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBR,EAAK,OAAO,YAAYgB,CAAS;AAAA,MAChE0B,GAAY,OAAOlC,CAAI,YAAa,OAAO,CAAC;AAAA,KAGtC6C,GAAoBxC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIuC,CAAc,YAAY/B,CAAS;AAAA,UAC5CR,CAAI,aAAayB,EAAQe,EAAU,CAAC;AAAA,IAExC,GAAG,EAiEH,MAAO,CACL,KA/BW,IAAM,CACjB,IAAMM,EAAQ,CAAC,EACf,OAAK1C,IACH0C,EAAM,KAAK,SAAShC,CAAK,MAAMtB,EAAK,OAAO,IAAIU,EAAY,KAAK,GAAG,CAAC,IAAI,EACxE4C,EAAM,KAAK,SAAS/B,CAAO,MAAMvB,EAAK,OAAO,IAAII,EAAU,eAAeM,CAAW,EAAE,KAAK,GAAG,CAAC,IAAI,GAElGU,EAAmB,iBACrBkC,EAAM,KAAK5B,CAA6B,EAEtCN,EAAmB,iBACrBkC,EAAM,KAAKxB,CAA6B,EAEtCV,EAAmB,4BACrB,OAAO,OAAOkB,CAAwC,EAAE,QAAQiB,IAAQD,EAAM,KAAKC,EAAI,CAAC,EAEtFnC,EAAmB,KACrBkC,EAAM,KAAKD,EAAiB,EAE1BjC,EAAmB,cACrBkC,EAAM,KAAKF,EAA0B,EAEnChC,EAAmB,KACrBkC,EAAM,KAAKR,CAAiB,EAE1B1B,EAAmB,cACrBkC,EAAM,KAAKT,EAA0B,EAEhCS,EAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAAtD,EACA,gBAAA2B,EACA,gBAAAI,EACA,2BAAAQ,EACA,QAAAN,EACA,WAAAE,EACA,WAAAE,GACA,IAxEU,IAAImB,IAAkD,CAChE,GAAIA,EAAgB,SAAW3C,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMN,GAAQiD,EAAgB3C,CAAI,EAClC,GAAI,OAAON,IAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAM2C,GAAoBM,EAAgB,MAAM,EAAG3C,CAAI,EAAE,IAAIK,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAIL,IAAS,EACJ6B,GAAY,KAAMnC,EAAK,EACrBM,IAAS,EACX6B,GAAYQ,GAAkB,CAAC,EAAG3C,EAAK,GAE9Ca,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI0C,EAAiB,KAAK3C,EAAK,IAErD,EAoDE,YAAAmC,GACA,aAnDmB,CAACV,EAAoBzB,KACpCM,EAAO,EACF6B,GAAYV,EAAYzB,EAAK,GAEpCa,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAAKzB,EAAK,MA8CrD,IAAA0C,GACA,YAAAL,GACA,aAAAO,GAEA,MAAOxC,EAAU,QAAU,SAC3B,KAAAH,EACA,QAAAe,EACA,MAAAD,EACA,KAAAT,CACF,CACF,EAWSvB,EACT,CAACkB,EAAcR,EAAcU,EAAuCT,EAAsB,IACtFZ,GAAoBmB,EAAMR,EAAMU,EAAa,GAAMT,CAAU,EAWxDV,EACT,CAACiB,EAAcR,EAAcU,EAAuCT,EAAsB,IACtFZ,GAAoBmB,EAAMR,EAAMU,EAAa,GAAOT,CAAU,EAuDhET,GAAN,KAA+C,CAC7C,YAAoBiE,EAAmD,CAAnD,6BAAAA,EAoDpB,KAAQ,eAAkC,CAAC,EAC3C,KAAQ,SAAgD,CAAC,EAezD,KAAQ,cAAgB,CApEgD,CAExE,sCAAsCpD,EAA6B,CAGjE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAUqD,EAAiD7E,GAAgB,CACzE,IAAM8E,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAExEI,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EAAuB;AAAA,wDAEA;AAAA,qDAEnCE,EAAsBF,EACxB,gCACA,sCAAsC,KAAK,wBAAwB,CAAC,EAAI,KAAK,wBAAwB,CAAC,CAAC;AAAA,6BAClF,KAAK,wBAAwB,CAAC,CAAC,yBAChDH,EAAiBC,EAAiBC,CAAc,mBAExD,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,gBAAgBC,EAAyBC,EAA8B,CAC7E,KAAK,eAAe,KAAKD,CAAQ,EAC7BA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,EAE7FA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,EAEnG,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/ChD,EAAcgD,EAAS,KAAK,QAClC,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAWhD,CAAW,IAC3G,CAEA,oBAAoBmD,EAAoC,CACtD,OAAOA,EAAU,IAAIC,GAAK,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACpF,CAEA,gBAAgB7D,EAAcR,EAA4B,CACxD,YAAK,SAAS,KAAK,CAAC,KAAAQ,EAAM,KAAAR,CAAI,CAAC,EACxB,IACT,CAIQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMsE,EAA4B,CAAC,EACnC,OAAW,CAAC,KAAA9D,EAAM,KAAAR,CAAI,IAAK,KAAK,SAC9BsE,EAAgB,KAAK,GAAG9D,CAAI,IAAIR,CAAI,EAAE,EAGxC,MAAO;AAAA,0BACesE,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OAAO,KAAK,mBAAmB,EAAI,KAAK,eAAe,IAAI7C,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CACrF,CACF,EAEahC,GAAsB8E,GAA4C,IAAI/E,GAAiB+E,CAAa,EAYpG7E,GAAmB,CAAC8E,EAA4BC,IAA0C,CACrG,IAAMC,EAASF,EAAQ,OACjBrE,EAAiB,CAAC,EACxB,QAASsB,EAAI,EAAGA,EAAIiD,EAAQjD,IAAK,CAC/B,IAAMN,EAAMuD,EAAS,EAAIjD,EACnBkD,EAAIH,EAAQrD,CAAG,GAAK,GAChBsD,EAASA,EAAS,OAAS,EAAIhD,CAAC,GAAK,GACvC,GAAKkD,IAAM,GACjBxE,EAAK,QAAQgB,CAAG,CAEpB,CACA,OAAOhB,CACT,EAGaR,GAAwBkB,GAA0BA,GAAQ,ICvyBvE,IAcM+D,GAMAC,GAGAC,GAGAC,GAWOC,GA+CAC,GAKAC,GAzFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMX,GAAkB,CAACY,EAAmBC,IACvCA,GAAQA,EAAK,SAAWD,EAAa,CAAC,GAAI,IAAI,MAAMA,CAAS,EAAE,KAAK,CAAE,EAAE,QAAQ,EAAIC,EAEnFZ,GAAiB,CAACa,EAA+BD,IACnDE,EAAU,gBAAgBD,EAAYd,GAAgBc,EAAW,OAAQD,CAAI,CAAC,EAE5EX,GAAmB,CAACW,EAAgBG,EAAcC,EAAsBC,IAAkC,CAC9G,IAAMC,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAcD,EAAO,KAAK,OAAO,QAAQD,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAASG,EAAI,EAAGA,EAAIJ,EAAM,EAAEI,EAC1BD,EAAY,KAAKF,EAAM,WAAW,IAAKJ,EAAKO,CAAC,EAAG,KAAKA,CAAC,GAAG,CAAC,EAE5D,OAAAD,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEahB,GAA6B,CAACkB,EAAyBC,IAAoC,CACtG,IAAMC,EAAgBF,EAAY,SAC5BT,EAAYS,EAAY,KAAK,OAC7BR,EAAOb,GAAgBY,EAAWU,CAAQ,EAC1CE,EAAoBC,GAAqBb,CAAS,EAClDc,EAAczB,GAAeoB,EAAY,KAAMR,CAAI,EACnDc,EAAiBH,EAAoBE,EAAY,OAASA,EAC1DE,EAAgBJ,EAAoBZ,EAAYS,EAAY,KAC5DH,EAASW,EAAe,SAAUN,EAAeI,CAAc,EAC/DV,EAAQa,EAAc,IAAKP,EAAeK,CAAa,EAEvDG,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBf,EAAOC,CAAM,CAAC;AAAA;AAAA,IAElFhB,GAAiBW,EAAMD,EAAWK,EAAOC,CAAM,CAAC;AAAA;AAAA,IAEhDc,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5Dd,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAcD,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,KAEpE,MAAO,CACL,KAAM,YACN,YAAa,CAAC,KAAM,GAAGK,CAAQ,GAAI,kBAAmBE,EAAoB,CAAC,MAAM,EAAI,CAAC,MAAM,CAAC,EAC7F,WAAab,GAAW,CACtB,IAAMsB,EAAalB,EAAU,KAAKW,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUf,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,EAClE,gBAAiBT,EACb,CACE,CAAC,KAAM,SAAU,KAAMS,CAAU,EACjC,GAAGC,GAA2BvB,EAAO,CAAC,EAAE,IAAI,EAC5C,GAAGuB,GAA2BR,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAMO,CAAU,CACnC,CACN,CACF,EACA,gBAAAF,CACF,CACF,EAEa3B,GAAY,CAAC+B,EAAyBC,IAA0C,CAC3FrC,GAAeoC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQhC,GAA2BgC,EAAQ,OAAO,CAAC,EAAGC,EAAW,IAAI,CAAC,CAChF,EAEa/B,GAA4B+B,GACrCC,GAA4B,CAAC,KAAMD,EAAW,IAAgB,CAAC,IC1FnE,IAYME,GAaAC,GAaAC,GAaAC,GAYAC,GAQAC,GAYAC,GAcAC,GASAC,GAaOC,GA0EPC,GAkCOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAvQbC,GAAAC,EAAA,kBAKAC,KAGAC,KACAC,KACAC,KAEM1B,GAAqC,CACzC,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,oCACX,UAAW,6BACX,GAAI,6BACJ,GAAI,oCACJ,OAAQ,uBACV,EAEMC,GAA2C,CAC/C,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,wBACX,UAAW,wBACX,GAAI,wBACJ,GAAI,wBACJ,OAAQ,uBACV,EAEMC,GAA4C,CAChD,IAAK,aACL,IAAK,aACL,KAAM,IACN,IAAK,IACL,KAAM,IACN,UAAW,IACX,UAAW,IACX,GAAI,IACJ,GAAI,IACJ,OAAQ,GACV,EAEMC,GAA8C,CAClD,IAAK,YACL,IAAK,YACL,IAAK,YACL,KAAM,YACN,UAAW,YACX,UAAW,iBACX,GAAI,YACJ,GAAI,kBACJ,OAAQ,gBACV,EAEMC,GAAmB,CAACuB,EAAsBC,IAA2B,CACzE,IAAMC,EAAM,CAAC,EACb,QAASC,EAAIF,EAAOD,EAAcG,EAAIF,EAAM,EAAEE,EAC5CD,EAAI,KAAKC,CAAC,EAEZ,OAAOD,CACT,EAEMxB,GAA4B,CAAC0B,EAA0BC,IAAkD,CAC7G,IAAMC,EAAc,CAAC,EACfL,EAAOG,EAAM,OACnB,QAASG,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,IACxBD,EAAY,KAAKF,EAAMG,CAAG,CAAC,EAG/B,IAAMC,EAAcH,EAAK,IAAIE,GAAOH,EAAMG,CAAG,CAAC,EAC9C,MAAO,CAACD,EAAaE,CAAW,CAClC,EAEM7B,GAAuB,CAACyB,EAAiBC,IAA6B,CAC1E,IAAMJ,EAAOG,EAAM,OAASC,EAAK,OAC3BI,EAAc,CAAC,EACjBC,EAAW,EACf,QAASH,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,GACxBE,EAAY,KAAKL,EAAMM,GAAU,CAAC,EAElCD,EAAY,KAAK,CAAC,EAGtB,OAAOA,CACT,EAEM7B,GAAuB,CAACyB,EAAgBJ,IAA0B,CACtE,QAASE,EAAI,EAAGA,EAAIE,EAAK,OAAQ,EAAEF,EACjC,GAAIE,EAAKA,EAAK,OAASF,EAAI,CAAC,IAAMF,EAAO,EAAIE,EAC3C,MAAO,GAGX,MAAO,EACT,EAEMtB,GAAqB,CAACwB,EAAgBJ,IAA2B,CACrE,IAAMC,EAAM,CAAC,EACb,GAAI,CAACtB,GAAqByB,EAAMJ,CAAI,EAAG,CACrC,QAASE,EAAI,EAAGA,EAAIF,EAAM,EAAEE,EACtBE,EAAK,QAAQF,CAAC,IAAM,IACtBD,EAAI,KAAKC,CAAC,EAGdE,EAAK,QAAQM,GAAQT,EAAI,KAAKS,CAAI,CAAC,CACrC,CACA,OAAOT,CACT,EAEapB,GACT,CAAC8B,EAAcC,EAAqCC,EAA+BC,EAClFC,EAA0BV,EAAuBE,IAAuC,CACvF,IAAMS,EAAaH,EAAO,CAAC,EAAE,KAEvBI,EAAaC,EAAU,KAAKb,CAAW,EACvCc,EAAaD,EAAU,KAAKX,CAAW,EAEvCa,EAAQC,EAAc,KAAMR,EAAO,CAAC,EAAE,SAAUG,CAAU,EAC1DM,EAASC,EAAe,SAAUR,EAAgBV,CAAW,EAE7DmB,EAAgB,GAEhBC,EAAsB;AAAA,+CACaH,EAAO,KAAK,OAAO,KAAKE,CAAa;AAAA,SAgD9E,MAAO,CACL,KAAAb,EACA,YAAAC,EACA,gBAhDuBc,GAA+B;AAAA,UACpDA,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBN,EAAOE,CAAM,CAAC;AAAA,UACjFG,CAAmB;AAAA;AAAA;AAAA;AAAA,WAIlBC,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA,2CAGLA,CAAa;AAAA;AAAA;AAAA,4BAG5BF,EAAO,KAAK,OAAO,IAAIhD,GAAiBwC,CAAU,CAAC;AAAA;AAAA,wDAEvBU,CAAa;AAAA,6BACxCF,EAAO,KAAK,OAAO,IAAIF,EAAM,YAAY,YAAY,CAAC;AAAA,yBAC1DhD,GAAU0C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,wCAKNU,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAM3BnD,GAAgByC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAS3CQ,EAAO,YACH,cACA,GACIR,IAAe,OAAS,eAAeQ,EAAO,KAAK,OAAO,wBAClC,GAAG/C,GAAmBuC,CAAU,CAAC,EAAE,EAAE,CAAC;AAAA;AAAA,WASxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUU,CAAc,CAAC,EACvD,cAAe,CAAC,EAAGE,CAAU,EAC7B,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAME,CAAU,CAAC,CACtD,EACF,CACF,EAEErC,GACF,CAAC6C,EAAyBhB,EAAciB,EACvCd,IAAiG,CAChG,IAAMe,EACFF,EAAQ,OAAO,SAAW,EAAIC,EAAaE,GAAiCH,EAAQ,OAAQC,CAAU,EAEtGG,EAAcF,EAAkB,KAChCE,EAAY,SAAW,GAAK,CAACF,EAAkB,oBACjDE,EAAcJ,EAAQ,OAAO,CAAC,EAAE,KAAK,IAAI,CAACK,EAAG9B,IAAMA,CAAC,GAEtD,IAAM+B,EAAgBf,EAAU,cAAca,EAAaJ,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAEpFvB,EAAO6B,EACPb,EAAQO,EAAQ,OAAO,CAAC,EACtBO,EAAetD,GAAmBwB,EAAMuB,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EACvEO,EAAa,OAAS,IACxBd,EAAQO,EAAQ,QACZQ,GAA2BR,EAAQ,OAAO,CAAC,EAAGO,CAAY,EAAG,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAChG9B,EAAO5B,GAAiB4B,EAAK,OAAQgB,EAAM,KAAK,MAAM,GAGxD,GAAM,CAACf,EAAaE,CAAW,EAAI9B,GAA0B2C,EAAM,KAAMhB,CAAI,EACzEgC,EAAmB/B,EACnBwB,EAAkB,WACpBO,EAAmB1D,GAAqB2B,EAAa4B,CAAa,GAGpEN,EAAQ,QACJ9C,GACI8B,EAAM,CAAC,KAAMkB,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACT,CAAK,EAAGN,EAChFa,EAAQ,OAAO,CAAC,EAAE,SAAUS,EAAkB7B,CAAW,EAC7D,CAAC,OAAQ,CAACa,CAAK,CAAC,CAAC,CACvB,EAESrC,GAAmB,CAAC4C,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEa5C,GAAiB,CAAC2C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa3C,GAAiB,CAAC0C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa1C,GAAwB,CAACyC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEazC,GAAkB,CAACwC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEaxC,GAAkB,CAACuC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEavC,GAAmB,CAACsC,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEatC,GAAkB,CAACqC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEarC,GAAwB,CAACoC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEapC,GAAqB,CAACmC,EAAyBC,IAAuC,CACjG9C,GAAa6C,EAAS,qBAAsBC,EAAY,QAAQ,CAClE,ICzQA,IAYMS,GAoBAC,GACOC,GA4EAC,GAUPC,GAeAC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GAsBOC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAtXbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KACAC,KAEMhC,GAAkBiC,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAYMhC,GAAkBiC,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,YAAY,aAAa,CAAC,IAAK,EAAE,EACpFhC,GACT,CAACiC,EAAcC,EAAqCH,EAA+BI,EAClFC,EAAqBC,EAA0BC,EAAW,GAAOC,EAAoB,KAAuB,CAC3G,IAAMC,EAAwB,CAAC,EACzBC,EAAaV,EAAO,CAAC,EAAE,KAEvBW,EAAOC,EAAU,cAAcP,EAAWL,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/Da,EAAkB,CAACL,GAAqBG,EAAK,SAAW,EAC9DD,EAAW,QAAQ,CAACI,EAAGC,IAAM,CACvBF,GAAmBF,EAAK,QAAQI,CAAC,GAAK,EACpCR,GACFE,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKK,CAAC,CAEtB,CAAC,EAED,IAAME,EAAoB,CAAC,EAErBf,EAAQgB,EAAc,KAAMjB,EAAO,CAAC,EAAE,SAAUU,CAAU,EAC1DQ,EAASC,EAAe,SAAUb,EAAgBG,CAAW,EAC7DW,EAAMhB,EAASH,EAAOiB,EAAQP,CAAI,EAClCU,EAAwB,iBAAiBpB,EAAM,gBAAgB,cAAc,CAAC,IAC9EqB,EAAqB,OAAOD,CAAqB,IACjDE,EAAqB,OAAOF,CAAqB,IACjDG,EAAmBJ,EAAI,CAAC,IAAM,GAAM,GAAKG,EAC3CE,GAAcL,EAAI,CAAC,IAAM,GAAME,EAAqBD,GAAyB;AAAA,EAAOD,EAAI,CAAC,EAE7F,QAASM,EAAI,EAAGC,EAAI,EAAGD,EAAI1B,EAAO,CAAC,EAAE,KAAK,OAAQ0B,IAE5Cb,GAAmBF,EAAK,QAAQe,CAAC,GAAK,GACpCnB,GACFoB,IAGFF,EAAY,YAAYC,CAAC,eAAeA,CAAC,MAAM1B,EAAO,CAAC,EAAE,KAAK0B,CAAC,CAAC,MAAMA,CAAC;AAAA,kBAC/DN,EAAI,CAAC,EAAE,SAAS,WAAW,EAAI,oBAAoBM,CAAC,IAAM,EAAE;AAAA,kBAC5DzB,EAAM,WAAW,eAAgByB,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,kBAC5CD,CAAS;AAAA,mBAGjBT,EAAQ,KAAK,GAAGf,EAAM,WAAW,eAAgByB,EAAGR,EAAO,WAAW,gBAAiBS,CAAC,CAAC,CAAC,GAAG,EAC7FA,KAIJ,IAAMC,EAAahB,EAAU,KAAKH,CAAW,EAkB7C,MAAO,CACL,KAAAP,EACA,YAAAC,EACA,gBApBuB0B,GAA+B;AAAA,UACpDA,EAAa,iBAAiB5B,EAAOiB,CAAM,CAAC;AAAA;AAAA,UAE5CW,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCD,CAAU,CAAC;AAAA,8BAC5C3B,EAAM,KAAK,OAAO;AAAA,gCAChBiB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDF,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBI,EAAI,CAAC,CAAC;AAAA,YACNI,CAAe;AAAA,YACfJ,EAAI,CAAC,CAAC;AAAA,YACNK,CAAS;AAAA,YACTL,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAIF,EAAO,YAAY,aAAc,OAAO,EAAIE,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,WAO1F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMX,EAAa,SAAUH,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAES1D,GACT,CAAC8B,EAA+B8B,IAAmD,CACjF,IAAMnB,EAAiB,CAAC,EACxB,OAAIX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQ+B,GAAKpB,EAAK,KAAK,OAAOoB,CAAC,CAAC,CAAC,EAEzDC,GACH,CAAC,KAAArB,EAAM,SAAUmB,EAAW,SAAU,kBAAmBA,EAAW,iBAAiB,CAAC,CAC5F,EAEE3D,GACF,CAAC8D,EAAyB/B,EAAc4B,EAA8B1B,IAA6B,CACjG,IAAMJ,EAASiC,EAAQ,OACjBC,EACFlC,EAAO,SAAW,EAAI8B,EAAa5D,GAAiC8B,EAAQ8B,CAAU,EAE1FG,EAAQ,QACJhE,GACIiC,EAAM,CAAC,KAAMgC,EAAkB,QAAQ,EAAG,CAAClC,EAAO,CAAC,CAAC,EACpDkC,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAIlE,GAAOoC,EACpF8B,EAAkB,KAAMlC,EAAO,CAAC,EAAE,SAAUkC,EAAkB,SAC9DA,EAAkB,iBAAiB,EACvC,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEE9D,GAAoB,CAAC6D,EAAyBH,IAAuC,CACzF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,eAAgBH,EANf,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,qBACL,CAC8D,CAChE,EAEM5B,GAAgB,CAAC4D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,EACL,CAC0D,CAC5D,EAEM3B,GAAgB,CAAC2D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,sBACvC,sBACL,CAC0D,CAC5D,EAEM1B,GAAuB,CAAC0D,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,qBACL,CACiE,CACnE,EAEMzB,GAAiB,CAACyD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAKnC,EAAM,WAAW,eAAgByB,EAAG,CAAC,CAAC,EAIvD,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMxB,GAAkB,CAACwD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAiB7B9D,GAAiB8D,EAAS,aAAcH,EAhBb,CAAC7B,EAAOiB,EAAQP,IAAS,CAClD,IAAI0B,EAAO,EACX,QAASX,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,KAE1C0B,GAAQJ,EAAQ,OAAO,CAAC,EAAE,KAAKP,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAczB,EAAM,YAAY,aAAa,CAAC,KAC9C,eAAeiB,EAAO,KAAK,KAAK,UAAUmB,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEM3D,GAAiB,CAACuD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAK,gBAAgBV,CAAC,QAAQ,EAI1C,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMtB,GAAkB,CAACsD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,aAAcH,EANb,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC4D,CAC9D,EAEMrB,GAAiB,CAACqD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,YAAaH,EANZ,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC2D,CAC7D,EAEMpB,GAAuB,CAACoD,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,oBACvC,EACL,CACiE,CACnE,EAEMnB,GACF,CAACwD,EAA0B3B,EAAyBH,IAAwC,CAC1F,GAAIG,EAAK,SAAW,EAClB,MAAO,EAAAH,EAGT,IAAIoB,EAAa,EACbW,EAAa,EACjB,QAASC,EAAM,EAAGA,EAAM7B,EAAK,OAAQ6B,IAC/B7B,EAAK,QAAQ6B,CAAG,IAAM,GACxBZ,GAAcU,EAAME,CAAG,EAEvBD,GAAcD,EAAME,CAAG,EAO3B,OAAOD,EAAa,IAAMX,EAAa,IACzC,EAES7C,GAAa,CAACkD,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FrD,GAAgBwD,EAASH,CAAU,EAEnCW,GAAiBR,EAASH,CAAU,CAExC,EAEa9C,GAAW,CAACiD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FzD,GAAc4D,EAASH,CAAU,EAEjCY,GAAeT,EAASH,CAAU,CAEtC,EAEa7C,GAAW,CAACgD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FxD,GAAc2D,EAASH,CAAU,EAEjCa,GAAeV,EAASH,CAAU,CAEtC,EAEa5C,GAAkB,CAAC+C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FvD,GAAqB0D,EAASH,CAAU,EAExCc,GAAsBX,EAASH,CAAU,CAE7C,EAEa3C,GAAY,CAAC8C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FtD,GAAeyD,EAASH,CAAU,EAElCe,GAAgBZ,EAASH,CAAU,CAEvC,EAEa1C,GAAY,CAAC6C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FpD,GAAeuD,EAASH,CAAU,EAElCgB,GAAgBb,EAASH,CAAU,CAEvC,EAEazC,GAAa,CAAC4C,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FnD,GAAgBsD,EAASH,CAAU,EAEnCiB,GAAiBd,EAASH,CAAU,CAExC,EAEaxC,GAAY,CAAC2C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FlD,GAAeqD,EAASH,CAAU,EAElCkB,GAAgBf,EAASH,CAAU,CAEvC,EAEavC,GAAkB,CAAC0C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FjD,GAAqBoD,EAASH,CAAU,EAExCmB,GAAsBhB,EAASH,CAAU,CAE7C,EAEatC,GAAe,CAACyC,EAAyBH,IAAuC,CACvFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5F1D,GAAkB6D,EAASH,CAAU,EAErCoB,GAAmBjB,EAASH,CAAU,CAE1C,EAEarC,GAAyBqC,GAClCE,GAA4BF,CAAiE,ICvXjG,IAcMqB,GAeAC,GAKOC,GA4BAC,GA4BAC,GA1FbC,GAAAC,EAAA,kBAOAC,KAEAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQMT,GACF,CAACS,EAA+BC,IAC5BC,GACI,CAAC,KAAMD,EAAW,KAAM,SAAUA,EAAW,SAAU,gBAAiBA,EAAW,eAAe,CAAC,EAElGT,GAAS,CAACW,EAAyBF,IAA0C,CACxFX,GAAea,EAAQ,MAAM,EAC7B,IAAMC,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIJ,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEI,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEMI,EACFP,EAAQ,OAAO,SAAW,EAAIF,EAAaV,GAAoCY,EAAQ,OAAQF,CAAU,EAC7GE,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMD,EAAkB,QAAQ,EAAG,CAACP,EAAQ,OAAO,CAAC,CAAC,EAAGC,EAAa,CAACM,EAAkB,IAAI,IACvFA,EAAkB,QAAQ,EAC9C,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEajB,GAAS,CAACU,EAAyBF,IAA0C,CACxFX,GAAea,EAAQ,MAAM,EAC7B,IAAMC,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIJ,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEI,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEMI,EACFP,EAAQ,OAAO,SAAW,EAAIF,EAAaV,GAAoCY,EAAQ,OAAQF,CAAU,EAC7GE,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMD,EAAkB,QAAQ,EAAG,CAACP,EAAQ,OAAO,CAAC,CAAC,EAAGC,EAAa,CAACM,EAAkB,IAAI,IACvFA,EAAkB,QAAQ,EAC9C,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEahB,GAA4BO,GACrCC,GAA4BD,CAAoE,IC3FpG,IASMW,GAkBAC,GAkCOC,GA7DbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMN,GAAkBO,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMN,GAA4BM,GAA+C,CAC/E,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAExBE,EAAWF,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3BG,EAAaC,EAAU,KAAKH,CAAW,EAAI,EAE3CI,EAAWL,EAAO,CAAC,EAAE,SACrBM,EAAQC,EAAc,QAASF,EAAUJ,EAAa,CAAC,EACvDO,EAAOD,EAAc,OAAQF,EAAU,CAACH,CAAQ,EAAG,CAAC,EACpDO,EAAWF,EAAc,WAAYF,EAAUJ,EAAa,CAAC,EAC7DS,EAASC,EAAe,SAAUN,EAAUJ,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAjBuBS,GAA+B;AAAA,qBACrCV,CAAQ;AAAA,IACzBU,EAAa,iBAAiBN,EAAOE,EAAMC,EAAUC,CAAM,CAAC;AAAA;AAAA,IAE5DE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA,kBAClDG,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCE,EAAK,YAAY,uBAAuB,CAAC,MAAMC,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFC,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEaf,GAAWkB,GAAkC,CACxDpB,GAAeoB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnB,GAAyBmB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAeMC,GA4BAC,GAcOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAIAC,GA8BAC,GAWPC,GAMOC,GAKAC,GAIAC,GAIAC,GAQAC,GAGAC,GAeAC,GAcAC,GAMAC,GAIAC,GAIAC,GAOAC,GAMAC,GAIAC,GAIAC,GAIAC,GAKAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAOAC,GA5QbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMM1C,GACF,CAAC2C,EAA4BC,EAAkBC,EAAuBC,EACrEC,EAAmCC,IAA8C,CAChF,IAAMC,EAAU,KAAK,KAAKL,EAAW,CAAC,EAElCM,EAAa,GACb,OAAOH,GAAa,SACtBG,EAAa,GAAGH,CAAQ,MAExBG,EAAaH,EAAS,GAAG,EAG3B,IAAMI,EAAQC,EAAc,YAAaP,EAAe,CAACI,CAAO,EAAG,CAAC,EAC9DI,EAASC,EAAe,aAAcR,EAAgB,CAACG,CAAO,EAAG,CAAC,EAExE,MAAO;AAAA,IACTN,EAAa,iBAAiBQ,EAAOE,CAAM,CAAC;AAAA;AAAA,IAE5CL,GAA4B,EAAE;AAAA;AAAA,IAE9BL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCM,CAAO,CAAC;AAAA;AAAA,cAEnDE,EAAM,YAAY,YAAY,CAAC;AAAA,MACvCE,EAAO,YAAY,aAAcH,CAAU,CAAC;AAAA,IAE9C,EAEEjD,GACF,CAACkD,EAAmBI,EAAcR,EAAmCC,EACpEQ,EAAmBV,EAAyBK,EAAM,YAA2B,CAC5E,KAAAI,EACA,YAAa,CAAC,KAAMC,CAAQ,EAC5B,gBAAiBb,GAAgB3C,GAC7B2C,EAAcc,EAAU,KAAKN,EAAM,IAAI,EAAGA,EAAM,SAAUL,EAAgBC,EAAUC,CAAwB,EAChH,WAAaU,IAAkB,CAC7B,QAAS,CAAC,CAAC,KAAMP,EAAM,KAAM,SAAUL,CAAc,CAAC,EACtD,cACI,CAAC,EAAG,KAAK,KAAKW,EAAU,KAAKC,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAAC,CACtG,EACF,GAESxD,GAAOyD,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaxD,GAAQwD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEavD,GAASuD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEatD,GAAQsD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEarD,GAASqD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapD,GAAQoD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACanD,GAASmD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOalD,GAAuBmD,GAChCC,GAA4BD,CAA0B,EAG7ClD,GAAO,CAACiD,EAAyBC,IAAqC,CACjF,IAAIE,EACJ,OAAQF,EAAW,GAAI,CACrB,QACEE,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EF,EAAW,EAAE,EAAE,CAClH,CACAD,EAAQ,QACJ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQG,EAAM,OAAWF,EAAW,SAAUA,EAAW,EAAE,CAAC,CAClH,EAOajD,GAAU,CAACgD,EAAyBC,IAAqC,CACpF,IAAMG,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QACJ1D,GACI0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,GAAK,SAAS,CAAC,0BAA2B;AAAA,4BACnDI,CAAQ,YAAYA,CAAQ,IAAIH,EAAW,GAAG;AAAA,4BAC9CG,CAAQ,YAAYA,CAAQ,IAAIH,EAAW,GAAG;AAAA,EAEhEA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EACMhD,GAAoCqD,GAAkD,CAC1F,IAAMC,EAAOD,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAIE,GAC9DC,EAAOH,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAII,GACpE,OAAOR,GAA4B,CAAC,IAAAK,EAAK,IAAAE,CAAG,CAAC,CAC/C,EAEavD,GAAQ8C,GAAkC,CACrD,IAAMC,EAAahD,GAAiC+C,EAAQ,MAAM,EAClEhD,GAAQgD,EAASC,CAAU,CAC7B,EAEa9C,GAAQ6C,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa5C,GAAO4C,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa3C,GAAQ2C,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMa1C,GAAwB2C,GACjCC,GAA4BD,CAA6B,EAEhD1C,GAAM,CAACyC,EAAyBC,IAAsC,CACjFD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,YAAYA,CAAC,IAAK;AAAA,gCACvBV,EAAW,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAS1CA,EAAW,QAAQ,CAAC,CAC1B,EAEazC,GAAU,CAAC4C,EAAkBQ,EAAU,QAAU;AAAA,YAClDA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,iBAEFR,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,GAM5B3C,GAAOuC,GAAkC,CACpD,IAAMI,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,YAAYA,CAAC,IAAKnD,GAAQ,QAAQ4C,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC9F,EAEa1C,GAAOsC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEarC,GAASqC,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapC,GAAQoC,GAAkC,CACrD,IAAMI,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,OAAQW,GAAK,SAASA,CAAC,sBAAsBA,CAAC,0BACjEnD,GAAQ,QAAQ4C,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC7C,EAEavC,GAAY,CAACmC,EAAyBC,IAAsC,CACvFD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,YAAaW,GAAK,8BAA8BA,CAAC,KAAKA,CAAC,KAAKA,CAAC,sBAChF,sCAAsCV,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,CACtF,EAEanC,GAAOkC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa5C,GAAOiC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa3C,GAAcgC,GAAkC,CAC3DA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,aAAcW,GAAK,OAAOA,CAAC,EAAE,CAAC,CAChG,EAEa1C,GAAQ+B,GAAkC,CACrDA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,OAAQW,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,oBAAoB,CAAC,CAC5F,EAEazC,GAAW8B,GAAkC,CACxDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,UAAWW,GAAK,sBAAsBA,CAAC,KAAK,CAAC,CAC/G,EAEaxC,GAAO6B,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa5B,GAAQ4B,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa3B,GAAQ2B,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa1B,GAAO0B,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEazB,GAAQyB,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaxB,GAAkB,CAACwB,EAAyBC,KACvDD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,kBAAmBW,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,8BAC5E,wDAAwDV,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,EAC/F,GAGIxB,GAAOuB,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,IC9QA,IAUMa,GAkBAC,GAwCOC,GApEbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMP,GAAkCO,GAA+C,CACrF,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCC,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMC,EAAQC,EAAc,QAASH,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEI,EAAOD,EAAc,OAAQH,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEK,EAASC,EAAe,SAAUN,EAAO,CAAC,EAAE,SAAUC,EAAa,CAAC,EAEpEM,EAAaC,EAAU,KAAKP,CAAW,EAAI,EAsBjD,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKO,EAAa,EAAuB,CAAC,CACpE,GACA,gBA1BuBE,GAA+B;AAAA;AAAA,yBAEjCT,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9CS,EAAa,iBAAiBP,EAAOE,EAAMC,CAAM,CAAC;AAAA;AAAA,IAElDK,GAAQ,OAAO,CAAC;AAAA;AAAA,IAEhBD,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9DF,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEaX,GAAiBiB,GAAkC,CAC9DnB,GAAemB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlB,GAA+BkB,EAAQ,MAAM,CAAC,CAChE,ICvEA,IAiBMC,GAsHAC,GAqDAC,GAQOC,GAIAC,GAIAC,GAMAC,GAIAC,GAsBAC,GAIAC,GAMAC,GAMAC,GAMAC,GAlQbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KASMjB,GACF,CAACkB,EAA4BC,EAA0BC,EAA0BC,EAChFC,EAAoBC,EAAsBC,EAA8BC,EAAeC,EACvFC,EAAoBC,IAAsC,CACzD,IAAMC,EAAaC,EAAU,KAAKT,CAAU,EACtCU,EAAU,KAAK,KAAKF,EAAa,CAAC,EAEpCG,EACAC,EACA,OAAOT,GAAa,SACtBQ,EAAmBC,EAAmB,CAACC,EAAGC,IAAM,GAAGX,CAAQ,KAAKU,CAAC,MAAMC,CAAC,KAC/D,OAAOX,GAAa,WAC7BQ,EAAmBC,EAAmBT,GAEtCQ,EAAmBR,EAAS,OAC5BS,EAAmBT,EAAS,QAG9B,IAAIY,EAAgB,GACdC,EAASC,EAAe,aAAcX,EAAYN,EAAY,CAAC,EAC/Da,EAAIK,EAAc,QAASd,EAAON,EAAO,CAAC,EAC1CgB,EAAII,EAAc,QAASb,EAAON,EAAO,CAAC,EAChD,GAAIG,EAAa,CACf,IAAMiB,EAAkBC,GAA4B,CAClD,IAAMC,EAAUZ,EAAU,eAAeW,CAAI,EACvCE,EAAoB,CAAC,EAC3B,QAASC,EAAIH,EAAK,OAAS,EAAGG,GAAK,EAAGA,IAAK,CACzC,IAAMC,EAAMR,EAAO,WAAW,gBAAiBO,EAAIvB,EAAW,OAASoB,EAAK,MAAM,EAClFE,EAAQ,KAAK,GAAGD,EAAQE,CAAC,CAAC,QAAQC,CAAG,MAAMJ,EAAKG,CAAC,CAAC,IAAI,CACxD,CACA,OAAOD,EAAQ,OAAS,EAAIA,EAAQ,KAAK,GAAG,EAAI,IAClD,EAEAP,EAAgB;AAAA,0CACkBC,EAAO,KAAK,OAAO;AAAA,qBACxCG,EAAerB,CAAK,CAAC;AAAA;AAAA;AAAA,0CAGAkB,EAAO,KAAK,OAAO;AAAA,qBACxCG,EAAepB,CAAK,CAAC;AAAA;AAAA,SAGpC,CAEA,IAAI0B,EACJ,GAAIxB,EACF,GAAIC,EAAa,CACf,IAAMwB,EAAgBjB,EAAU,KAAKX,CAAK,IAAM,EAC1C6B,EAAgBlB,EAAU,KAAKV,CAAK,IAAM,EAC5C2B,GAAiBC,EACnBF,EAAaT,EAAO,YAChB,aACAJ,EACIc,EAAgB,GAAGb,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFc,EAAgB,GAAGb,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,CAAC,CAAC,EAEjGW,EAAa;AAAA,kCACST,EAAO,gBAAgB,iBAAiB,CAAC;AAAA;AAAA;AAAA,cAI3DA,EAAO,YACH,aAAcJ,EAAiBC,EAAE,YAAY,cAAc,EAAGC,EAAE,YAAY,cAAc,CAAC,CAAC,CAAC;AAAA,WAGzG,MACEW,EAAaT,EAAO,YAChB,aAAcJ,EAAiBC,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAEzF,CACL,GAAI,CAACZ,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAM0B,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACcA,CAAC,MAAMd,EAAO,gBAAgB,qBAAqBc,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,+BAA+BA,CAAC;AAAA,yBACjCA,CAAC,+BAA+BA,CAAC;AAAA,wBAClCA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIpB,EAAiBqB,EAAaC,CAAW,CAAC;AAAA,WAE9E,EACI3B,IAAe,EACjBmB,EAAa;AAAA;AAAA,cAETG,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCH,EAAa;AAAA,cACTG,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACH/B,EAAa,iBAAiBgB,EAAGC,EAAGE,CAAM,CAAC;AAAA;AAAA,UAE3CT,GAA4B,EAAE;AAAA,UAC9BQ,CAAa;AAAA;AAAA,UAEblB,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCa,CAAO,CAAC;AAAA,UAC3De,CAAU;AAAA,QAEhB,EAEE7C,GACF,CAACsD,EAAcC,EAAkBtB,EAAeC,EAAeX,EAC9DI,EAAmC6B,EAAyBvB,EAAE,WAA0B,CACvF,IAAMwB,EAAc,CAAC5B,EAAU,SAASI,EAAE,KAAMC,EAAE,IAAI,EAClDwB,EAAczB,EAAE,KAChBL,EAAaC,EAAU,KAAKI,EAAE,IAAI,EAElCZ,EAAY,GAIhB,GAAIoC,EAAa,CACf,IAAME,EAAkBC,GAAc,UAAU3B,EAAE,KAAMC,EAAE,KAAM,EAAK,EACrE,GAAI,CAACyB,EACH,MAAM,IAAI,MAAM,8CAA+C,EAEjED,EAAcC,EACd/B,EAAaC,EAAU,KAAK6B,CAAW,EACvC,IAAMZ,EAAgBjB,EAAU,KAAKI,EAAE,IAAI,IAAM,EAC3Cc,EAAgBlB,EAAU,KAAKK,EAAE,IAAI,IAAM,EAG7C2B,EAAkB,EACtB,QAASlB,EAAI,EAAGA,EAAIe,EAAY,OAAQf,IAAK,CAC3C,IAAMmB,EAAO7B,EAAE,KAAKA,EAAE,KAAK,OAASU,CAAC,GAAK,EACpCoB,EAAO7B,EAAE,KAAKA,EAAE,KAAK,OAASS,CAAC,GAAK,EAC1C,GAAImB,IAASC,EACXF,GAAmBC,MAEnB,MAEJ,EACID,EAAkB,IAAM,GAAKf,GAAiBC,KAChD1B,EAAY,GAEhB,MAEEA,EAAY,GAGd,MAAO,CACL,KAAAiC,EACA,YAAa,CAAC,KAAMC,CAAQ,EAC5B,gBAAkBtC,GAAiBlB,GAC/BkB,EAAcgB,EAAE,KAAMC,EAAE,KAAMwB,EAAarC,EAAWoC,EAAalC,EAAUU,EAAE,SAAUC,EAAE,SAC3FsB,EAAgB7B,CAAwB,EAC5C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM+B,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAK5B,EAAa,GAA0B,CAAsB,CAAC,CAC7F,EACF,CACF,EAEE3B,GACF,CAAC+D,EAAyBV,EAAc/B,EAA8BI,EACrE4B,EAAmBC,IAAkC,CACpDQ,EAAQ,QAAQhE,GACZsD,EAAMC,GAAY,GAAIS,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGzC,EAAUI,EACtE6B,CAAc,CAAC,CACrB,EAEStD,GAAO8D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa/B,GAAO6D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa9B,GAAS4D,GAAkC,CACtD/D,GACI+D,EAAS,QAAU,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEa7B,GAAO2D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa5B,GAAO0D,GAAkC,CACpD,IAAMC,EAAO3B,EAAc,QAAS0B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7F/D,GACI+D,EAAS,MAAQ,CAAC,OAAQ,CAAC,EAAG9B,IAAM,cAAc,CAAC,IAAIA,CAAC,IAAK,OAAQ,CAAC,EAAGA,IAAM,qBAAqB,CAAC,IAAIA,CAAC,GAAG,EAC7G;AAAA,wBACkB+B,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAV1EA,IAAS,MAAQ,QAAU,EAW5B;AAAA;AAAA,oCAEkBA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAEjB,CACP,EAEa1D,GAAOyD,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAAC/B,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa1B,GAAWwD,GAAkC,CACxD/D,GACI+D,EAAS,UAAY,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEazB,GAAQuD,GAAkC,CACrD/D,GACI+D,EAAS,OAAS,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACnG,QAAwB,CAC9B,EAEaxB,GAAkBsD,GAAkC,CAC/D/D,GACI+D,EAAS,iBAAmB,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAC3G,OAAW,QAAwB,CACzC,EAEavB,GAAeqD,GAAkC,CAC5D/D,GACI+D,EAAS,cAAgB,CAAC,OAAQ,CAAC/B,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EACxG,OAAW,QAAwB,CACzC,ICtQA,IAcMgC,GAqBAC,GAUAC,GAmBAC,GAqEOC,GAKAC,GA1IbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMV,GAAkBW,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAGlC,IAAMC,EAAYD,EAAO,CAAC,EAAE,SACtBE,EAAsBF,EAAO,CAAC,EAAE,KAAK,OAE3C,QAAWG,KAASH,EAAQ,CAE1B,GAAIG,EAAM,WAAaF,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAIpD,GAAIE,EAAM,KAAK,SAAWD,EACxB,MAAM,IAAI,MAAM,0CAA0C,CAE9D,CACF,EAEMZ,GAA2Bc,GAAoC;AAAA;AAAA,gCAErCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBb,GAAmB,CAACS,EAAkCK,IAA0B,CACpF,IAAMD,EAAkBJ,EAAO,OAEzBM,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAO,YAAY,aAAcL,EAAOO,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,qBAAqBC,CAAC,QAAQC,CAAa,IAAI,EACrDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,0BAA0BC,CAAC,OAAOC,CAAa,IAAI,CAEtE,CACA,OAAOF,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMd,GAA0B,CAACQ,EAA+BS,IAA8B,CAC5F,IAAMC,EAAaV,EAAO,CAAC,EAAE,KAAK,MAAM,EACxC,GAAIS,GAAQC,EAAW,QAAUD,EAAQ,GAAKC,EAAW,OACvD,MAAM,IAAI,MAAM,8DAA+D,EAEjF,IAAMC,EAAgBF,EAAO,EAAKC,EAAW,OAASD,EAAOA,EAGvDG,EAAcF,EAAW,MAAM,CAAC,EACtC,QAASH,EAAI,EAAGA,EAAIP,EAAO,OAAQO,IAAK,CACtC,IAAMM,EAAab,EAAOO,CAAC,EAAE,KAAK,MAAM,EACxC,QAASO,EAAY,EAAGA,EAAYJ,EAAW,OAAQI,IAErD,GAAIA,IAAcH,EAChBC,EAAYD,CAAY,GAAKE,EAAWC,CAAS,UAG1CJ,EAAWI,CAAS,IAAMD,EAAWC,CAAS,EACrD,MAAM,IAAI,MAAM,kCAAkC,CAGxD,CAEA,IAAMC,EAAaC,EAAU,KAAKJ,CAAW,EAEvCK,EAAmB,IAAI,MAAcjB,EAAO,MAAM,EAClDkB,EAAY,IAAI,MAAqBlB,EAAO,MAAM,EAClDmB,EAAWnB,EAAO,CAAC,EAAE,SAEvBoB,EAAc,EAClB,QAASb,EAAI,EAAGA,EAAIP,EAAO,OAAQ,EAAEO,EACnCa,GAAepB,EAAOO,CAAC,EAAE,KAAKI,CAAY,EAC1CM,EAAiBV,CAAC,EAAIa,EAEtBF,EAAUX,CAAC,EAAIc,EAAc,QAAQd,CAAC,GAAIY,EAAUnB,EAAOO,CAAC,EAAE,IAAI,EAGpE,IAAMF,EAASiB,EAAe,SAAUH,EAAUP,CAAW,EAEvDW,EAAclB,EAAO,WAAW,UAAWM,CAAY,EACvDa,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiB,GAAGP,EAAWb,CAAM,CAAC;AAAA;AAAA,wCAEfY,EAAiB,MAAM,KAAKA,EAAiB,IAAIV,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GjB,GAAwB2B,EAAiB,MAAM,CAAC;AAAA;AAAA,IAEhDQ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCV,CAAU,CAAC;AAAA;AAAA,oBAEhDV,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEbkB,CAAW;AAAA;AAAA,QAE9CA,CAAW;AAAA;AAAA;AAAA,MAGbhC,GAAiB2B,EAAWb,CAAM,CAAC;AAAA,KAEvC,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGI,CAAI,EAAE,EAC7B,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMG,EAAa,SAAUZ,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAS,CACF,CACF,EAEa/B,GAAS,CAACiC,EAAyBC,IAAuC,CACrFtC,GAAeqC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlC,GAAwBkC,EAAQ,OAAQC,EAAW,IAAI,CAAC,CAC1E,EAEajC,GAAyBiC,GAClCC,GAA4B,CAAC,KAAMD,EAAW,IAAc,CAAC,IC3IjE,IAuBaE,GAeAC,GASAC,GA/CbC,GAAAC,EAAA,kBAuBaJ,GAAc,CAACK,EAAmBC,IAAqB,CAClE,OAAQD,EAAW,CACjB,IAAK,GACH,OAAOC,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGD,CAAS,8BAA8B,CAC9D,CACF,EAEaJ,GACT,CAACM,EAAyBC,EAA6B,GAAOC,EAAU,GAAOC,EAAgB,IAKtF,GAGAR,GAAwB,CAACS,EAAkBJ,IAAoC;AAAA,QACpFI,EAAU,iDAAmD,EAAE;AAAA;AAAA,WAE5DJ,EAAa,qCAAuC,EAAE;UClDjE,IAqBaK,GArBbC,GAAAC,EAAA,kBAqBaF,GAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ICrB7B,IAYaG,GAoBAC,GAhCbC,GAAAC,EAAA,kBAGAC,KASaJ,GAAuB,CAACK,EAA0CC,EAAS,KAEnF,CACH,OAAQD,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,0BAA0B,EAC7E,IAAK,UACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,sCAAsC,EACzF,IAAK,OACH,MAAO,CACL,mBAAoB,uBAAuBA,EAAW,OAAQ,yBAAyBA,EAAW,OAAQ,KAC1G,gBAAiBC,EAAS,0DACA,6CAC5B,EAEF,QACE,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,EAAE,CACvD,CACF,EAEaL,GACRI,GAAgF,CAC/E,IAAME,EAAaF,GAAY,YAAwB,GAEvD,GAAIE,IAAe,OAAQ,CACzB,GAAM,CAACC,EAASC,CAAO,EAAIJ,GAAY,mBAAyC,CAACK,GAAUC,EAAQ,EACnG,MAAO,CAAC,WAAAJ,EAAY,QAAAE,EAAS,QAAAD,EAAS,mBAAoB,GAAGD,CAAU,IAAIC,CAAO,IAAIC,CAAO,EAAE,CACjG,CACA,MAAO,CAAC,WAAAF,EAAY,mBAAoBA,CAAU,CACpD,ICzCJ,IA6BMK,GAiBAC,GAyBOC,GAuFPC,GAiBAC,GAKOC,GAgKPC,GAmFOC,GAvabC,GAAAC,EAAA,kBAsBAC,KAEAC,KACAC,KAEAC,KAEMb,GAA6B,CAACc,EAAoBC,IAClDD,EACK;AAAA;AAAA;AAAA,wDAG6CC,EAAY,iBAAmB,EAAE;AAAA,UAI9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3Ed,GAAyB,CAACe,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtEf,GACT,CAACgB,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,KAAe,CACpF,IAAMC,EAAaL,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CO,EAAaN,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CQ,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EACtCP,EAAmBS,EAAaP,EAAc,CAAC,EAC/CS,EAAgBP,EAAYF,EAAc,CAAC,EAEjD,GAAI,GAAIH,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC7D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KACjES,EAAaP,EAAc,CAAC,IAAM,GAAKE,EAAYF,EAAc,CAAC,IAAM,GAAKD,EAAc,CAAC,IAAM,GACtG,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BACvCC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCACjCD,CAAgB;AAAA,eACrCS,CAAU,yCAAyCP,EAAc,CAAC,CAAC,eACtEE,CAAS,0CAA0CF,EAAc,CAAC,CAAC,kBACnED,EAAc,CAAC,CAAC,aAAa,EAEnC,MAAO;AAAA,yCAC4BD,CAAgB,IAAIG,CAAI,MAAMM,EAAaT,CAAgB,MAAMU,CAAU;AAAA,2CACzEP,CAAI,MAAMK,EAAaP,EAAc,CAAC,CAAC,MAAMG,CAAS;AAAA;AAAA,uBAE1EH,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBI,CAAS;AAAA;AAAA,2BAEFF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEG,EAAS,IAAM,iBAAiB;AAAA,IAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCS,CAAU;AAAA;AAAA,mBAErCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,iBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9CH,CAAI;AAAA;AAAA;AAAA,8BAGEQ,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/B5B,GAA2BgB,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInBa,CAAa;AAAA;AAAA;AAAA,sFAI7Cb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAU/BE,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FhB,GAAuBe,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU5D,EAEEd,GAAyB,CAACW,EAAoBC,IAC9CD,EACK;AAAA;AAAA;AAAA,yCAG8BC,EAAY,iBAAmB,EAAE;AAAA,cAI/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DX,GAA2BY,GAC7BA,EAAa,gDAAkD,gDAItDX,GACT,CAACa,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,GACtEM,EAA4B,KAAkB,CAC7C,IAAML,EAAaN,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CM,EAAaP,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CO,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EAE5C,GAAI,EAAEG,EAAaR,EAAc,CAAC,IAAM,GAAKO,EAAaP,EAAc,CAAC,IAAM,GACzEE,EAAYF,EAAc,CAAC,IAAM,GACrC,MAAM,IAAI,MAAM,cAAcQ,CAAU,yCACpCR,EAAc,CAAC,CAAC,gBAAgBO,CAAU,yCAC1CP,EAAc,CAAC,CAAC,eAAeE,CAAS,yCAAyCF,EAAc,CAAC,CAAC,EAAE,EAEzG,IAAMW,EAAgBH,EAAaR,EAAc,CAAC,EAC5CY,EAAgBL,EAAaP,EAAc,CAAC,EAC5CS,EAAgBP,EAAYF,EAAc,CAAC,EAC3Ca,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAGsCL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2BR,EAAc,CAAC,CAAC;AAAA,mDACnDO,CAAU,2BAA2BP,EAAc,CAAC,CAAC;AAAA,YAC5FhB,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRM,CAAS,2BAA2BF,EAAc,CAAC,CAAC;AAAA,uDAC9CM,CAAU,2BAA2BN,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEJ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5CK,CAAI;AAAA;AAAA;AAAA,2DAG2BD,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI7DH,EAAa,oCAAoCG,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUzBA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKlE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMkCK,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7C5B,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKfa,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrBb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvCK,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBhB,GAAwBY,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBrC,MAAO;AAAA,yCAC4BI,CAAI,KAAKM,CAAU,MAAMC,CAAU;AAAA,yCACnCP,CAAI,KAAKK,CAAU,MAAMJ,CAAS;AAAA,yBAClDH,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBG,CAAS;AAAA;AAAA,2BAEJF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEG,EAAS,IAAM,iBAAiB;AAAA,MAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,qBAClEO,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,mBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5CH,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ1BY,CAAa;AAAA;AAAA,CAGf,EAEE1B,GACF,CAAC2B,EAAmBC,EAAkBC,EAAyBC,EAC9DC,EAAuCC,EAAiB,KAAkB,CACzE,IAAMC,EAAcF,EAAY,CAAC,EAC3BG,EAAcH,EAAY,CAAC,EAC3BI,EAAaJ,EAAY,CAAC,EAC1BK,EAAgBN,EAAU,CAAC,EAC3BO,EAAYP,EAAU,CAAC,EACvBQ,EAAYR,EAAU,CAAC,EACvBS,EAAiBT,EAAU,CAAC,EAC5BU,EAAiBC,GAAiBR,EAAaE,CAAU,EACzDO,EAAiBD,GAAiBP,EAAaC,CAAU,EACzDQ,EAAWC,GAA4Bd,EAAU,CAAC,EAAE,KAAK,MAAM,EAC/De,EAAc,IAAM,CACxB,IAAMC,EAAQT,EAAU,KAClBU,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBX,EAAU,KAAK,OAAO,IACpD,QAASY,EAAIH,EAAQ,EAAI,EAAGI,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAV,EAAe,QAAQS,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcF,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBE,CACT,EACMG,EAAc,IAAM,CACxB,IAAMC,EAAQd,EAAU,KAClBS,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBV,EAAU,KAAK,OAAO,IACpD,QAASW,EAAIG,EAAQ,EAAI,EAAGF,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAR,EAAe,QAAQO,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcI,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBJ,CACT,EAwCA,MAvCe;AAAA,kEAC6CZ,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBkB,EAAY,CAAC;AAAA,kBACLR,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBwB,EAAY,CAAC;AAAA,kBACLb,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKSe,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BACnEhB,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBI,EAAiB,cAAgB,GAAGqB,GAAY1B,EAAWgB,CAAQ,CAAC,aAAa,IAChE,EAAsC;AAAA,UAC9Ed,CAAe;AAAA,UACfU,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAK/D,EAEStC,GACT,CAACqD,EAA+BC,EAAoDC,EACnFC,EACAzB,EAAiB,KAAyD,CACzE,IAAM0B,EAASJ,EAAO,CAAC,EAAE,KACnBK,EAASL,EAAO,CAAC,EAAE,KAEnBM,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAYL,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAC5F/C,EAAYsD,EAAc,YAAaT,EAAO,CAAC,EAAE,SAAUQ,CAAS,EACpEhC,EAAY,CAACrB,CAAS,EACtBsB,EAAc,CAAC6B,EAAYC,EAAYC,CAAS,EAChDE,EAAYC,EAAU,KAAKH,CAAS,EAEpCI,EAAYR,EAAOA,EAAO,OAAS,CAAC,EACpCS,EAAWT,EAAOA,EAAO,OAAS,CAAC,EACnCU,EAAYT,EAAOA,EAAO,OAAS,CAAC,EACpCU,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EACjD,CAAC,mBAAAE,EAAoB,gBAAAzC,CAAe,EAAI0C,GAAqBhB,EAAsBc,CAAM,EAGzFG,EAAoBN,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDrD,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD4D,EAAW,CACf,KAAK,KAAKL,EAAYvD,EAAc,CAAC,EAAI2D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKN,EAAYrD,EAAc,CAAC,EAAI2D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYnD,EAAc,CAAC,EAAI2D,EAAkB,CAAC,CAAC,CAC/D,EAEM7B,EAAWC,GAA4BU,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAaL,EAAS,EAAI,EAC1BM,EAAIZ,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGM,EAAYM,EAAWC,EAAWO,CAAU,EAAGA,CAAU,EACxGE,GAAIb,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGO,EAAYM,EAAUC,EAAYM,CAAU,EAAGA,CAAU,EACxGG,EACFtC,EAAe,SAAUe,EAAO,CAAC,EAAE,SAAU,CAACU,EAAWE,EAAWE,EAAYM,CAAU,EAAGA,CAAU,EAC3G5C,EAAU,KAAK6C,CAAC,EAChB7C,EAAU,KAAK8C,EAAC,EAChB9C,EAAU,KAAK+C,CAAM,EACrB,IAAMC,EAAiB,CAACH,EAAGC,EAAC,EACtBhD,GAAU0B,EAAO,OAAS,EAC1ByB,GACF/E,GAAwB0E,EAAY9C,GAASC,EAAiBC,EAAWC,EAAaC,CAAc,EACxG,GAAIJ,GAAS,CACX,IAAMoD,EAAiBhD,EAAiB0C,EAAa,EACrDI,EAAe,KAAKf,EAAc,OAAQT,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM0B,CAAc,CAAC,CAC/F,CACA,IAAMC,GAAmBC,GAA+B;AAAA,2BACnChB,CAAS;AAAA,2BACTE,CAAS;AAAA,0BACVD,CAAQ;AAAA,IAC9Be,EAAa,iBAAiB,GAAGJ,EAAgBD,CAAM,CAAC;AAAA,IACxDP,CAAkB;AAAA,IAClBS,EAAgB;AAAA,IAEVV,EAASzE,GAA2B4E,EAAmB3D,EAAe8B,EAAUlC,CAAS,EAChFV,GAAuByE,EAAmB3D,EAAe8B,EAAUlC,CAAS,CAAC;AAAA,qBAC3EA,EAAU,KAAK,CAAC,GAC/B,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM8C,EAAqB,kBAAkB,EAC3D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGmB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAAQ,EACF,CACF,IC1eJ,IAgCME,GA2HOC,GA3JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAEAC,KAGAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAoBC,EAAoBC,EAAmBC,EAAU,GAC9FC,EAAyBC,EAA4B,GAAOC,EAAoB,EAAGC,EAAoB,EACvGC,EAAmB,EAAGC,EAAW,QAAkB,CAClD,IAAMC,EAAeF,IAA6B,CAChD,OAAQA,GAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkBC,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoBD,EAAgB,oBAAoB,CAC5E,CACF,EACMG,EAAeH,IAA6B,CAChD,OAAQA,GAAkB,CACxB,IAAK,GACH,MAAO,qCACT,IAAK,GACH,MAAO,yCACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,EAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBb,EAAiB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIjCc,EAAkBd,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCe,EAAUf,EAAiB,YAAc,YACzCgB,EAAShB,EAAiB,YAAc,YACxCiB,EAAMjB,EAAiB,MAAQ,MAC/BkB,EAAMlB,EAAiB,MAAQ,MAC/BmB,EAAe;AAAA;AAAA,qBAENnB,EAAiB,cAAgB,aAAa;AAAA,mBAChDiB,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACCE,GAAYb,EAAmBG,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9BK,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYJ,CAAiB,CAAC;AAAA;AAAA,qBAI1Bc,EAAUrB,EAAkBC,GAAaE,EAAW;AAAA,wBACxCI,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SACbP,GAAYD,EAAY;AAAA,wBACxCK,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SAEzCY,EAAU,GAAGV,EAAYJ,CAAiB,CAAC,GAE3Ce,EAAUH,GAAYX,EAAkBC,CAAQ,EAChDc,EACFxB,EAAiBoB,GAAYb,EAAmBG,CAAQ,EAAIU,GAAYZ,EAAmBE,CAAQ,EACjGe,EACFzB,EAAiBoB,GAAYZ,EAAmBE,CAAQ,EAAIU,GAAYb,EAAmBG,CAAQ,EAsBvG,MArBiB;AAAA,MACjBgB,GAAoBrB,EAAYC,EAA2BG,IAAqB,EAAG,CAAC,CAAC;AAAA,yDAClCe,CAAK;AAAA,QACtDxB,EAAiBqB,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtDzB,EAAiBsB,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7Cd,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBT,EAAiB,cAAgB,aAAa;AAAA,QAC7Dc,CAAe;AAAA,QACfa,GAAsBvB,EAASC,CAAU,CAAC;AAAA;AAAA;AAAA,MAK9C,EAESd,GACT,CAACqC,EAA+BC,EAA4BC,EAAgCC,EAC3FC,EAAmBC,EAAkBC,EAAkBC,IAAoD,CAC1G,IAAMnC,EAAiB6B,EAAW,SAAW,OACvCO,EAAapC,EAAiB4B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClES,EAAYP,EAAY,CAAC,EACzBQ,EAAWtC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAYvC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAcxC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DW,EAASzC,IAAmBoC,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMI,EAAc,IAAM,EAGjGE,EAAY1C,EAAiBwC,EAAcF,EAAWC,EACtDI,EAAY3C,EAAiBsC,EAAWC,EAAYC,EACpDI,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDC,EAAoBd,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDe,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,iCAAiCD,CAAQ,EAAE,EAEtE,IAAMrC,EAAmBgC,EAAUzC,GAAkBoC,EAAa,IAAM,EAAI,EAAI,EAAKS,EAAkB,CAAC,EAElGG,EAAaJ,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDI,EAAaL,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDK,EAAY,KAAK,IAAIN,EAAc,CAAC,EAAInC,EAAkBmC,EAAc,CAAC,CAAC,EAE1E3C,EAAY8B,EAAYiB,IAAe,EACvC9C,EAAY8B,EAAYiB,IAAe,EACvC9C,GAAW8B,EAAWiB,IAAc,EAEpCC,EAAeV,EAAS,CAAChC,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAC3D2C,EAAIC,GAA4BzB,EAAO,CAAC,EAAE,QAAQ,EAElD0B,GAAgB,CACpB,qDAAqDb,GAAUhC,IAAqB,EAAI,QAAQ2C,CAAC,IAAMA,CAAC,KACxG,qDAAqDX,EAAS,QAAQW,CAAC,IAAMA,CAAC,IAChF,EACIG,GAAmB;AAAA,qDACwBd,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,8BAChDX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,6EAEsBX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,qCAEjEX,EAAS,MAAQ,EAAE;AAAA,SAElD,OAAIP,IACFoB,GAAc,KAAK,wDAAwDb,EAAS,QAAQW,CAAC,IAAMA,CAAC,IAAI,EACxGG,IAAoB;AAAA,0DAC8Bd,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACpDpD,EAAiB,IAAM,GAAG,GAAGyC,EAAS,MAAQ,EAAE;AAAA,YAIlE,CACL,KAAM,eACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGkB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBU,EAAa;AAAA;AAAA;AAAA;AAAA,UAIbF,GAAc,KAAK,EAAE,CAAC;AAAA,6BACHA,GAAc,MAAM,4CACrCb,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACNE,GAAc,OAAS,CAAC;AAAA;AAAA,+CAER1B,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBE,EAAY,KAAK,GAAG,CAAC;AAAA,wDACd2B,EAAU,eAAe3B,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChED,EAAW,YAAY,CAAC,CAAC,KAAKA,EAAW,YAAY,CAAC,CAAC;AAAA,4CAC9DA,EAAW,KAAK,CAAC,CAAC,KAAKA,EAAW,KAAK,CAAC,CAAC;AAAA,+CACtCA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC7CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEE,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BsB,EAAgB;AAAA,UAEdjE,GACIU,EAAgBC,EAAWC,EAAWC,GAAU+B,EAChDL,EAAW,WAAW,YAAY,EAAiB,GAAOsB,EAAa,CAAC,EAAGA,EAAa,CAAC,EACzFA,EAAa,CAAC,EAAGC,CAAC,CAAC;AAAA,cAEvBX,EACIiB,GAA2Bb,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,CAAS,EACrGS,GACId,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,EAAW,GAAO,OACnFf,CAAyB,CAAC,EACxC,CACF,IC9PJ,IAeayB,GAfbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KACAC,KAMaN,GACT,CAACO,EAA+BC,EAC/BC,IAAqF,CACpF,IAAMC,EAAUH,EAAO,OAAS,EAC1BI,EAAcD,EAAU,8BAAgC,GACxDE,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KACnBO,EAAyBD,EAAO,CAAC,EAAIL,EAAW,MAEhD,CAAC,mBAAAO,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBT,CAAU,EAEvEU,EAAgBV,EAAW,SAAW,OACtCW,EAAcC,GAChBR,EAAQC,EAAQL,EAAW,UAAWA,EAAW,KAAMA,EAAW,QAASU,CAAa,EACtFG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAASC,EAAe,SAAUjB,EAAO,CAAC,EAAE,SAAUY,CAAW,EACjEM,EAAIC,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUK,CAAM,EACjDe,EAAID,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUM,CAAM,EACjDe,EAAY,CAACH,EAAGE,CAAC,EACnBjB,GACFkB,EAAU,KAAKF,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,CAAC,EAGvE,IAAMsB,EAAmBC,GAA+B;AAAA,oCAC1BtB,EAAW,QAAQ,CAAC,CAAC,MAAMA,EAAW,QAAQ,CAAC,CAAC;AAAA,iCACnDA,EAAW,KAAK,CAAC,CAAC,MAAMA,EAAW,KAAK,CAAC,CAAC;AAAA;AAAA,IAEvEsB,EAAa,iBAAiB,GAAGF,EAAWL,CAAM,CAAC;AAAA;AAAA,IAEnDR,CAAkB;AAAA;AAAA,IAElBe,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA,0BAE1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhBL,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACpEA,EAAgB,EAAI,CAAC;AAAA,2CACYJ,CAAsB;AAAA;AAAA,iBAEhDS,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,kDACPV,EAAO,CAAC,CAAC;AAAA,uCACpBA,EAAO,CAAC,CAAC;AAAA,8CACFA,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,yCAE9BI,EAAOM,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIxBL,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA,yCAC9BI,EAAOM,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAK5DA,EAAgBO,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,EACnDA,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,uBACvDE,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAK3EhB,CAAW;AAAA,MACXK,CAAe;AAAA,MACfO,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,KAEzC,MAAO,CACL,KAAM,cACN,YAAa,CAAC,KAAMf,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CACR,KAAMC,EAA6BA,EAA2BU,CAAW,EAAIA,EAC7E,SAAUZ,EAAO,CAAC,EAAE,QACtB,CAAC,EACD,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,ICjGJ,IAcaE,GA6BPC,GAEAC,GAmDAC,GAmBOC,GAgBPC,GAsGAC,GA0BOC,GAnQbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KACAC,KACAC,KACAC,KACAC,KAEahB,GACT,CAACiB,EAA+BC,EAAgCC,EAC/DC,EAA+BC,EAA4BC,IAAqC,CAC/F,IAAMC,EAAYN,EAAW,CAAC,EACxBO,EAAoBP,EAAW,MAAMK,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFG,EAAcD,EAAkB,OAChCE,EAAcR,EAAY,CAAC,EAE3BS,EADqBT,EAAY,MAAM,CAAC,EACA,IAAI,CAACU,EAAGC,IAAMD,GAAKA,EAAI,IAAMT,EAAUU,CAAC,EAAI,EAAE,EAEtFC,EAD2BN,EAAkB,IAAI,CAACI,EAAGC,IAAMD,EAAIR,EAAWS,CAAC,EAAIT,EAAWS,EAAIJ,CAAW,CAAC,EAEnF,IAAI,CAACG,EAAGC,IAAM,KAAK,OAAOD,EAAID,EAAmBE,CAAC,EAAIR,EAAQQ,CAAC,GAAKR,EAAQQ,CAAC,CAAC,CAAC,EAC5G,OAAAC,EAAY,OAAO,EAAG,EAAGP,CAAS,EAClCO,EAAY,OAAOR,EAAgB,EAAI,EAAG,EAAGI,CAAW,EACjDI,CACT,EAcE7B,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtCC,GAAiB,CAAC6B,EAA+BC,IAAqC,CAG1F,GAAI,CAACD,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAME,EAAcF,EAAO,CAAC,EAAE,KAAKC,EAAW,SAAW,OAASD,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFG,EAAkBH,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIC,EAAW,MACvD,GAAIC,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAIH,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMN,EAAcM,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIC,EAAW,UAAU,SAAWP,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIO,EAAW,QAAQ,SAAWP,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIO,EAAW,KAAK,SAAWP,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIO,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWD,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEM5B,GAA4B,CAA2B6B,EAAeD,IAAqC,CAC/G,IAAMb,EAAcc,EAAW,YAAY,MAAM,EAEjD,QAASH,EAAI,EAAGA,EAAIE,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEF,EACvCX,EAAYW,EAAI,CAAC,IAAM,IACzBX,EAAYW,EAAI,CAAC,EAAIE,EAAO,CAAC,EAAE,KAAKF,CAAC,GAGzC,IAAMM,EAAOH,EAAW,KAAK,MAAM,EACnCI,GAAa,yBACTL,EAAO,CAAC,EAAE,KAAMC,EAAW,QAASA,EAAW,UAAWd,EAAaiB,EAAMH,EAAW,SAAW,OACnGA,EAAW,OAAO,EAGtB,IAAMK,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EACrD,cAAO,OAAOK,EAAe,CAAC,YAAAnB,EAAa,KAAAiB,EAAM,SAAUH,EAAW,QAAQ,CAAC,EACxEK,CACT,EAEajC,GAAuB4B,GAAwD,CAC1F,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBS,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAET,EAAW,QAAkB,EACvFb,EAAYa,EAAW,UACvBU,EAAQV,EAAW,MACnBd,EAAcc,EAAW,aACzBG,EAAOH,EAAW,KAClBX,EAAUW,EAAW,QACrBW,EAAYX,EAAW,WAA6B,EAE1D,OAAOY,GACH,CAAC,QAAAH,EAAS,OAAAD,EAAQ,UAAArB,EAAW,MAAAuB,EAAO,YAAAxB,EAAa,KAAAiB,EAAM,QAAAd,EAAS,SAAAsB,EAAU,GAAGL,CAAoB,CAAC,CACxG,EAEMjC,GAAS,CAACwC,EAAyBd,EAA+BC,IAAqC,CAC3G,IAAMc,EAAqB3C,GAA0B6B,EAAYD,CAAM,EAKvE,GAAIC,EAAW,QAAU,EAAG,CAC1Ba,EAAQ,QAAQE,GAA6BhB,EAAQe,CAAkB,CAAC,EACxE,MACF,CAEA,IAAME,EAAiBhB,EAAW,SAAW,OACvCiB,EAAUlB,EAAO,SAAW,EAC5BmB,EAAcnB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACnDG,EAAapB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EAClDI,EAAgBrB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACrDK,EAAetB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BuB,EAAcvB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BD,EAAc9B,GAChB+B,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMC,EAAW,UAAWc,EAAmB,KAAMd,EAAW,QAC1FgB,CAAc,EACZO,EAAYzB,EAAYkB,EAAiB,EAAI,CAAC,EAC9CQ,EAAW1B,EAAYkB,EAAiB,EAAI,CAAC,EAC7CtB,EAAcI,EAAYkB,EAAiB,EAAI,CAAC,EAEhDS,EAAWT,GAAkBK,IAAiBH,GAAeI,IAAgBH,GAC/EnB,EAAW,KAAK,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,EACvD,GAAIyB,GACCJ,IAAiB,GAAKC,IAAgB,GAAKtB,EAAW,UAAU,CAAC,IAAM,GAAKA,EAAW,UAAU,CAAC,IAAM,GACxGA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,GACrFA,EAAW,KAAK,CAAC,IAAM,EAAI,CAE9B,IAAM0B,EAAQ5B,EAAY,CAAC,EACvB6B,EAAWC,EAAWC,EACpBC,GAAe,CAAC,EACtB,GAAId,EAAgB,CAClB,IAAMe,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG9B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAIlE,GAHIA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAE5BN,EAAU,CACZ,IAAMQ,EAAYf,EAAcC,EAAaC,EAC7CO,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG2B,EAAOO,CAAS,CAAC,EACnDL,EAAYG,EAAiB,QAAQ,CAAC,EAAGE,EAAWvC,CAAW,CAAC,EAChEmC,EAAoB,CAAC,EAAGH,EAAOhC,CAAW,CAC5C,MACEiC,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAOR,EAAcC,EAAYC,CAAa,CAAC,EAC9EQ,EAAYG,EAAiB,QAAQ,CAAC,EAAGX,EAAe1B,CAAW,CAAC,EACpEmC,EAAoB,CAACH,EAAOH,EAAYC,EAAU9B,CAAW,EAE/DoC,GAAa,KAAKH,CAAS,EAC3BG,GAAa,KAAKF,CAAS,CAC7B,MACED,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAON,EAAeF,EAAcC,CAAU,CAAC,EAC9ES,EAAY7B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAGL,EAAa0B,CAAa,CAAC,EAC7DS,EAAoB,CAACH,EAAOhC,EAAa6B,EAAYC,CAAQ,EAC7DM,GAAa,KAAKF,CAAS,EAC3BE,GAAa,KAAKH,CAAS,EAEzBV,GACFa,GAAa,KAAK/B,EAAO,CAAC,CAAC,EAE7Bc,EAAQ,QACJqB,GAAwBJ,GAAchB,EAAoBhB,EAAa+B,EAAmBb,CAAc,EACxG,CAAC,OAAQc,EAAY,CAAC,EAC1B,MACF,CAIA,IAAMK,EAAgE,GAGhEJ,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG9B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAIhC,IAAMK,EAAa,CAACrC,EAAO,CAAC,EAAGgC,CAAgB,EAC3Cd,GACFmB,EAAW,KAAKrC,EAAO,CAAC,CAAC,EAI3B,IAAMsC,EAAYrB,EAAiBO,EAAYC,EAAW9B,EACpD4C,EAAYtB,EAAiBtB,EAAc6B,EAAYC,EACvDe,EAAWlB,EAAeC,EAAcF,EAC9CP,EAAQ,QACJ2B,GACIJ,EAAYtB,EAAoBhB,EAAauC,EAAWC,EAAWC,EAAUtB,EAC7EkB,CAAyB,EAC7B,CAAC,OAAQC,CAAU,CAAC,CAC1B,EAEM9D,GAAS,CAACuC,EAAyBb,IAAqC,CAE5E,IAAMV,EAAgBU,EAAW,SAAW,OACtCD,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdvB,EAEI,CAACuB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5Bd,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMV,EAAO,CAAC,EAAGH,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpDX,EAAU,CAAC,CAAC,EAAE,OAAOW,EAAW,OAAO,EACvCb,EAAY,CAAC,CAAC,EAAE,OAAOa,EAAW,SAAS,EAC3Cd,EAAc,CAAC,CAAC,EAAE,OAAOc,EAAW,WAAW,EAC/Cc,EAAqB3C,GAA0B,CAAC,GAAG6B,EAAY,KAAAG,EAAM,QAAAd,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGa,CAAM,EACnHc,EAAQ,QAAQE,GACZhB,EAAQe,EACRhB,GAAeR,EAAgB,CAACQ,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAAC,CAAC,CAAC,CAC3F,EAEavB,GAAO,CAACsC,EAAyBb,IAAqC,CACjF9B,GAAe2C,EAAQ,OAAQb,CAAU,EACrCa,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCvC,GAAOuC,EAASb,CAAU,EAE1B3B,GAAOwC,EAASA,EAAQ,OAAQb,CAAU,CAE9C,IC1QA,IA+BMyC,GA4HOC,GA3JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAIAC,KACAC,KACAC,KAEMR,GACF,CAACS,EAAyBC,EAAU,GAAOC,EAAyBC,EAA4B,GAC/FC,EAAmB,IAAc,CAChC,IAAMC,EAAOC,GAAYF,EAAkB,KAAK,EAC1CG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,iDACT,IAAK,GACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAUT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBR,EAAiB;AAAA;AAAA,QAGA;AAAA;AAAA,QAIjCS,EAAkBT,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCU,EAAUV,EAAiB,iBAAmB,iBAC9CW,EAASX,EAAiB,iBAAmB,iBAC7CY,EAAMZ,EAAiB,MAAQ,MAC/Ba,EAAMb,EAAiB,MAAQ,MAE/Bc,EAAe;AAAA,yBACFd,EAAiB,iBAAmB,gBAAgB;AAAA,uBACtDA,EAAiB,cAAgB,aAAa;AAAA,qBAChDY,CAAG;AAAA,qBACHA,CAAG;AAAA;AAAA,mBAELC,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA;AAAA,kCAGYH,CAAO;AAAA,iBACxBL,CAAI;AAAA;AAAA,kCAEaM,CAAM;AAAA,iBACvBN,CAAI;AAAA;AAAA;AAAA;AAAA,kBAIHQ,CAAG;AAAA,QACbL,CAAa;AAAA,qDACgCJ,CAAgB,KAEzDW,EAAUf,EAAiB;AAAA,0BACbI,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SACoB;AAAA,0BACbD,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SAEPW,EAAU;AAAA,0BACIZ,CAAgB;AAAA,yBACjBJ,EAAiB,iBAAmB,gBAAgB;AAAA;AAAA;AAAA,YAInEA,EAAiB,oCACA,mCAAmC;AAAA;AAAA;AAAA,UAGpDO,EAAYH,CAAgB,CAAC;AAAA;AAAA,eAExBC,CAAI;AAAA,QAwBb,MApBiB;AAAA,IACnBY,GAAoBf,EAAYC,EAA2BC,IAAqB,EAAG,CAAC,CAAC;AAAA,uDAClCC,CAAI;AAAA,MACrDL,EAAiBe,EAAUC,CAAO;AAAA;AAAA;AAAA,uDAGeX,CAAI;AAAA,MACrDL,EAAiBgB,EAAUD,CAAO;AAAA;AAAA;AAAA,iEAGyBV,CAAI;AAAA,wBAC7CD,CAAgB;AAAA;AAAA;AAAA,uBAGjBJ,EAAiB,cAAgB,aAAa;AAAA,QAC7DS,CAAe;AAAA,QACfS,GAAsBjB,EAASC,CAAU,CAAC;AAAA,sDACIE,CAAgB;AAAA;AAAA,IAIlE,EAESZ,GACT,CAAC2B,EAA+BC,EAAqCC,EACpEC,EAAmBC,EAAmBC,EAAkBC,EACxDC,IAAoD,CACnD,IAAM1B,EAAiBoB,EAAW,SAAW,OACvCO,EAAa3B,EAAiBmB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClES,EAAYP,EAAY,CAAC,EACzBQ,EAAW7B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAY9B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAc/B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC7DW,EACFhC,EAAiB2B,EAAa,IAAM,GAAKI,EAAc,IAAM,EAAIF,EAAW,IAAM,GAAKE,EAAc,IAAM,EAGzGE,EAAYjC,EAAiB+B,EAAcF,EAAWC,EACtDI,EAAYlC,EAAiB6B,EAAWC,EAAYC,EACpDI,EAA0CH,EAC5C,CAAC,EAAG,EAAG,CAAC,EACR,CAAEC,GAAa,GAAKC,GAAa,EAAK,EAAI,GAAID,EAAY,GAAKC,GAAa,EAAI,EAAI,GAAI,CAAC,EACvFE,EACFJ,EAAS,CAAC,EAAG,EAAG,CAAC,EAAI,CAACC,GAAa,EAAI,EAAI,EAAGA,EAAY,GAAKC,GAAa,EAAI,EAAI,EAAG,CAAC,EACtFG,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,wCAAwCD,CAAQ,EAAE,EAE7E,IAAMjC,EAAmB4B,EAAS,EAAI,EAChCO,EAAY,KAAK,IAAIJ,EAAc,CAAC,EAAI/B,EAAkB+B,EAAc,CAAC,CAAC,EAG1EK,EAAgB,CACpB,qDAAqDR,EAAS,YAAc,KAAK,KACjF,yDACF,EACIS,EAAmB,GACvB,OAAIhB,IACFe,EAAc,KAAK,wDAAwDR,EAAS,YAAc,KAAK,IAAI,EAC3GS,GAAoB;AAAA,0DAC8BT,EAAS,YAAc,KAAK;AAAA,+BACvDhC,EAAiB,IAAM,GAAG,GAAGgC,EAAS,MAAQ,EAAE;AAAA,YAGlE,CACL,KAAM,wBACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGkB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBK,EAAa;AAAA,UACbF,EAAc,KAAK;AAAA,CAAI,CAAC;AAAA,6BACLA,EAAc,MAAM,4CACrCR,EAAS,YAAc,KAAK;AAAA,oDACYb,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CAC7BA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBE,EAAY,KAAK,GAAG,CAAC;AAAA,wDACdsB,EAAU,eAAetB,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChED,EAAW,YAAYpB,EAAiB,EAAI,CAAC,CAAC,KACrFoB,EAAW,YAAYpB,EAAiB,EAAI,CAAC,CAAC;AAAA;AAAA,gBAG9CoB,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYpB,EAAiB,EAAI,CAAC,EAAI,IAAMoB,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gBAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYpB,EAAiB,EAAI,CAAC,EAAI,IAAMoB,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gFAExFA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,8EAEvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,gDACHA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC9CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEE,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BiB,CAAgB;AAAA,UAEdlD,GACIS,EAAgByB,EAASL,EAAW,WAAW,YAAY,EAAiB,GAAOhB,CAAgB,CAAC;AAAA,UAExG4B,EAASY,GACIR,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,CAAS,EAClFM,GACIT,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,EAAW,GAChF,OAAWb,CAAyB,CAAC,EACxD,CACF,ICxPJ,IA0BMoB,GAsNOC,GAhPbC,GAAAC,EAAA,kBAmBAC,KAEAC,KAEAC,KAGMN,GACF,CAACO,EAA4BC,EAA+BC,EAC3DC,EAAgCC,EAAkBC,EAA+BC,EAAS,GAC1FC,IAA6B,CAC5B,IAAMC,EAAiBN,EAAW,SAAW,OACvCO,EAASD,EAAiB,EAAI,EAC9BE,EAASF,EAAiB,EAAI,EAC9BG,EAAaH,EAAiB,EAAI,EAClCI,EAAaC,EAAU,KAAKV,CAAW,EACvCW,EAAgBR,EAAS,EAAI,EAC7BS,EAAQb,EAAW,MACnBc,EAASf,EAAO,CAAC,EAAE,KACnBgB,EAAwBD,EAAO,CAAC,EAAID,EACpCG,EAAyBF,EAAO,CAAC,EAEnCG,EAAmB;AAAA,iDACoBb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,0BAC9DD,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,KAEvDH,IACFe,GAAoB;AAAA,sDAC0Bb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,2BAClEC,EAAiB,IAAM,GAAG,GAAGF,EAAS,MAAQ,EAAE;AAAA,QAGrE,IAAMc,EAAad,EAAS,EAAI,EAC1Be,EAAIC,EAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACrEG,EAAKD,EAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACvEI,EAAiB,CAACD,EAAIF,CAAC,EACzBjB,GACFoB,EAAe,KAAKF,EAAc,OAAQrB,EAAO,CAAC,EAAE,SAAU,CAACE,EAAYQ,CAAU,CAAC,EAAGS,CAAU,CAAC,EAEtG,IAAMK,EAASC,EAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUE,EAAaiB,CAAU,EAC7EO,EAAe;AAAA,2BACAtB,EAAuB,cAAgB,gBAAgB;AAAA,kBAChEA,EAAuB,cAAgB,gBAAgB;AAAA,kBACvDA,EAAuB,cAAgB,gBAAgB,MAAMS,CAAa;AAAA,wBACpET,EAAuB,cAAgB,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM7CE,CAAQ,MAAMO,CAAa;AAAA,8BAC/BA,CAAa;AAAA,8BACbP,CAAQ;AAAA;AAAA;AAAA,uBAGfA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,oCAExCA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOnBA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA,0BACpDA,CAAQ,wBAAwBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAO/CA,CAAQ;AAAA;AAAA;AAAA;AAAA,wCAINA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAUhBc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMhBgB,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA;AAAA,iDAEjBhB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMdI,CAAU;AAAA;AAAA,gCAErBU,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCASZc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA,oCACjChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCAUTO,CAAa;AAAA,qCACXV,EAAU,YAAc,KAAK;AAAA,YACtDqB,EAAO,IAAI,QAAS,IAAK,QAAS,KAAM,OAAO,CAAC;AAAA;AAAA,SAGhDG,EAAc;AAAA,gCACMH,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBAC5CA,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,qBACxCA,EAAO,WAAW,gBAAiBd,CAAU,CAAC;AAAA,oBAC/Cc,EAAO,WAAW,gBAAiBhB,CAAM,CAAC;AAAA,oBAC1CgB,EAAO,WAAW,gBAAiBf,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI/BQ,CAAsB;AAAA,6CACRA,CAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAQ1CX,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,sCAEvCA,CAAQ,gBAAgBE,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUzCF,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,gBAAgBG,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA,6CAKzBO,CAAqB;AAAA,2CACvBA,CAAqB;AAAA,+BAEtDT,EAAiBe,EAAG,IAAI,QAAS,OAAQ,OAAQ,cAAc,EAC9CA,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CAAC;AAAA,+BAC3CF,EAAE,IAAI,eAAgB,cAAe,cAAe,aAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM/DjB,EAAU,WAAa,KAAK;AAAA,YAClDqB,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,UAG/C,MAAO;AAAA,IACTzB,EAAa,iBAAiB,GAAGwB,EAAgBC,CAAM,CAAC;AAAA,IACxDN,CAAgB;AAAA,2CACuBhB,EAAY,KAAK,GAAG,CAAC;AAAA,8CAClBF,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,0CAC5BC,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,6CAC5CA,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC,KACjFN,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC;AAAA,4CACZN,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,YAGrFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,YAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,0EACxBA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,0EACvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,MAC3GF,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsCY,CAAU,CAAC;AAAA,IAChEN,EAASqB,EAAeC,CAAW,GACnC,EAESlC,GACT,CAACO,EAA+BC,EAC/B2B,IAAqF,CACpF,IAAMzB,EAAUH,EAAO,OAAS,EAE1BE,EAAcD,EAAW,YACzBU,EAAaC,EAAU,KAAKV,CAAW,EAMvC2B,EAAW,CACf,KAAK,KAAKlB,EAAa,EAAE,EACzB,EACA,CACF,EACAmB,GAAU,UAAW,IAAM,uCAAuCD,CAAQ,EAAE,EAE5E,IAAMvB,EAAWyB,GAA4B/B,EAAO,CAAC,EAAE,QAAQ,EAC/D,MAAO,CACL,KAAM,kBACN,YAAa,CAAC,KAAMC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,cAAe,CAAC,EAAG4B,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,QAAS,CAAC,CACR,KAAMD,EAA6BA,EAA2B1B,CAAW,EAAIA,EAC7E,SAAUF,EAAO,CAAC,EAAE,QACtB,CAAC,CACH,GACA,gBAAkBD,GAA+BP,GAC7CO,EAAcC,EAAQC,EAAYC,EAAaC,EAAS0B,EAAS,CAAC,IAAM,GAAKA,EAAS,CAAC,IAAM,EAAG,GAChGvB,CAAQ,CACd,CACF,IClRJ,IAaM0B,GAIAC,GAWAC,GAkCAC,GA4COC,GA8BPC,GAqEAC,GAEAC,GAmDAC,GA6COC,GA/SbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEAC,KACAC,KAEMhB,GACF,CAACiB,EAAeC,EAAgBC,EAAaC,EAAgBC,EAAkBC,KAC1EL,EAAQ,GAAKC,EAASC,GAAOC,EAAS,GAAKC,EAAW,EAAIC,EAE7DrB,GAAoB,CAACsB,EAAkBC,EAAiBC,EAAgBC,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAML,EAAW,CAAC,EACpCC,IAAY,cACdC,EAAKC,CAAI,EAAIE,EACbH,EAAKE,CAAI,EAAIJ,EAAWK,GACfJ,IAAY,eACrBC,EAAKC,CAAI,EAAIH,EAAWK,EACxBH,EAAKE,CAAI,EAAIC,EAEjB,EAEM1B,GACF,CAAC2B,EAA+BC,EAAgCC,EAA8BP,EAC7FQ,EAAeP,EAAgBQ,EAA4BC,EAAwBC,EACnFC,IAA0B,CACzB,IAAMC,EAAcR,EAAW,OAAS,EAClCS,EAAoBF,EAAY,SAAW,EACjD,GAAID,EAAc,SAAW,EAC3B,QAASI,EAAI,EAAGA,EAAIF,EAAa,EAAEE,EACjCJ,EAAc,KAAK,CAAC,EAGxB,IAAMK,EAAYX,EAAW,CAAC,EACxBY,EAAcX,EAAYI,EAAgB,EAAI,CAAC,EAAIF,EACzD,QAASO,EAAI,EAAGG,EAAIb,EAAW,OAASQ,GAAeH,EAAgB,EAAI,GAAIK,EAAIF,EAAa,EAAEE,EAAG,EAAEG,EAAG,CACxG,IAAMC,EAASd,EAAWa,CAAC,EACrBpB,EAAUgB,EAAoBK,EAASV,EAAQM,CAAC,EAAIH,EAAYG,CAAC,EACjEhB,EAAWvB,GAAgB2C,EAAQV,EAAQM,CAAC,EAAGd,EAAKc,CAAC,EAAGT,EAAYY,CAAC,EAAGX,EAAUQ,CAAC,EAAGjB,CAAO,EACnGrB,GAAkBsB,EAAUC,EAASC,EAAMc,EAAGA,EAAIF,CAAW,EACzDC,GACFF,EAAY,KACRH,EAAQM,CAAC,GAAKI,EAAS,GAAKR,EAAcI,CAAC,GAAKT,EAAYY,CAAC,EAAI,GAAKX,EAAUQ,CAAC,EAAI,EAAId,EAAKc,CAAC,EAC/Fd,EAAKc,EAAIF,CAAW,CAAC,CAE7B,CACAD,EAAY,OAAO,EAAG,EAAGI,CAAS,EAClCJ,EAAY,OAAOF,EAAgB,EAAI,EAAG,EAAGO,CAAW,CAC1D,EAQEtC,GACF,CAAoCyC,EAAeC,IAAqC,CACtF,IAAMf,EAAcc,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAClGjB,EAAY,OAAS,EACrB,QAASS,EAAI,EAAGA,EAAIM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEN,EAC3CT,EAAY,KAAKe,EAAO,CAAC,EAAE,KAAKN,CAAC,CAAC,CAEtC,CACA,IAAMS,EAAiBJ,EAAW,SAAW,OAC7Cd,EAAY,OAAO,EAAG,EAAGe,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1Cf,EAAY,OAAOkB,EAAiB,EAAI,EAAG,EAAGH,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMpB,EAAOmB,EAAW,KAAK,MAAM,EAC7BR,EAAcQ,EAAW,YAAY,MAAM,EAC3CT,EAAgBS,EAAW,cAAc,MAAM,EAC/Cf,EAAagB,EAAO,CAAC,EAAE,KACzBd,EAAYa,EAAW,UAAU,MAAM,EAC3C,GAAIb,EAAU,OAAO,CAACe,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5Cd,EAAY,IAAI,MAAMM,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAIJ,EAAUW,EAAW,QAAQ,MAAM,EACvC,GAAIX,EAAQ,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CZ,EAAU,IAAI,MAAMI,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAnC,GACI2B,EAAYC,EAAaC,EAAWa,EAAW,QAASA,EAAW,MAAOnB,EAAMQ,EAASe,EACzFb,EAAeC,CAAW,EAG9B,IAAMa,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EAC/CM,EAAWN,EAAW,SAAW,CACrCd,EAAY,KAAK,IAAI,EAAGL,EAAK,KAAK,GAAG,EAAGQ,EAAQ,KAAK,GAAG,EAAGE,EAAc,KAAK,GAAG,EAAGC,EAAY,KAAK,GAAG,EACxGL,EAAU,KAAK,GAAG,CACpB,EAAE,KAAK,GAAG,EACV,cAAO,OAAOkB,EAAe,CAAC,YAAAnB,EAAa,KAAAL,EAAM,cAAAU,EAAe,YAAAC,EAAa,UAAAL,EAAW,QAAAE,EAAS,SAAAiB,CAAQ,CAAC,EACnGD,CACT,EAES7C,GAAgCwC,GAAiE,CAC5G,IAAMO,EAAuBC,GAAkCR,CAAU,EAEnES,EAAST,EAAW,OACpBpB,EACF,CAAC,SAAU,QAAS,aACnB,YAAY,EAAE,OAAOoB,EAAW,QAAW,IAAc,EAAIA,EAAW,OAAiB,EACxFb,EAAYa,EAAW,UACvBZ,EAAQY,EAAW,MACnBd,EAAcc,EAAW,YACzBnB,EAAOmB,EAAW,KAClBX,EAAUW,EAAW,QACrBU,EAAYV,EAAW,SAA2B,EAClDT,EAAgBS,EAAW,cAC3BR,EAAcQ,EAAW,YAC/B,OAAOW,GAA4B,CACjC,QAAA/B,EACA,OAAA6B,EACA,UAAAtB,EACA,MAAAC,EACA,YAAAF,EACA,cAAAK,EACA,YAAAC,EACA,KAAAX,EACA,QAAAQ,EACA,SAAAqB,EACA,GAAGH,CACL,CAAC,CACH,EAEM9C,GAAiB,CAACwC,EAA+BD,IAA8C,CAGnG,GAAI,CAACC,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAMW,EAAcX,EAAO,CAAC,EAAE,KAAKD,EAAW,SAAW,OAASC,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFY,EAAkBZ,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAIW,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMC,EAAcb,EAAO,CAAC,EAAE,KAAK,CAAC,EAAID,EAAW,MAGnD,GAAIC,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMa,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMrB,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBD,EAAW,UAAU,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEnDH,EAAW,UAAU,SAAWP,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBO,EAAW,QAAQ,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEjDH,EAAW,QAAQ,SAAWP,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBO,EAAW,KAAK,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAC9CH,EAAW,KAAK,SAAWP,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIO,EAAW,cAAc,SAAWP,GAAeO,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4BP,CAAW,GAAG,EAM5D,GADuBO,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GACrDH,EAAW,YAAY,SAAW,GACpDA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAID,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAGMvC,GAAsB,CAAC,EAAG,EAAG,EAAG,CAAC,EAEjCC,GACF,CAACoD,EAAyBd,EAA+BD,IAA8C,CACrG,IAAMgB,EAAqBzD,GAAmCyC,EAAYC,CAAM,EAC1EG,EAAiBJ,EAAW,SAAW,OACvCiB,EAAUhB,EAAO,SAAW,EAClC,GAAIe,EAAmB,QAAU,EAAG,CAClCD,EAAQ,QAAQG,GAAiCjB,EAAQe,CAAkB,CAAC,EAC5E,MACF,CACA,IAAMxB,EAAcwB,EAAmB,YACjCG,EAAY3B,EAAYY,EAAiB,EAAI,CAAC,EAC9CgB,EAAW5B,EAAYY,EAAiB,EAAI,CAAC,EAC7CP,EAAcL,EAAYY,EAAiB,EAAI,CAAC,EAChDiB,EAAepB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BqB,EAAcrB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC9BsB,EAAgBtB,EAAO,CAAC,EAAE,KAAKG,EAAiB,EAAI,CAAC,EAErDoB,EAAYpB,EAAiBe,EAAYC,EAAWvB,EACpD4B,EAAYrB,EAAiBP,EAAcsB,EAAYC,EACvDM,EAAWL,EAAeC,EAAcC,EAExCI,EAAgE,GAIhEC,EAAoBb,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJc,GAA2B5B,EAAO,CAAC,EAAGvC,EAAmB,EACzD,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACsC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACe,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKa,GAIhC,IAAME,EAAsB,CAAC7B,EAAO,CAAC,EAAG2B,CAAgB,EACpDX,IACE,CAACb,GAAkBH,EAAO,CAAC,EAAE,KAAK,SAAW,EAC/C6B,EAAoB,KAAK7B,EAAO,CAAC,EAAE,QAAQ,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAG,CAAC,CAAC,CAAC,EAErE6B,EAAoB,KAAK7B,EAAO,CAAC,CAAC,GAKtCc,EAAQ,QACJgB,GACID,EAAqBd,EAAoBxB,EAAagC,EAAWC,EAAWC,EAAUT,EACtFU,CAAyB,EAC7B,CAAC,OAAQG,CAAmB,CAAC,CACnC,EAEElE,GAAkB,CAACmD,EAAyBf,IAA8C,CAE9F,IAAMV,EAAgBU,EAAW,SAAW,OAEtCC,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdzB,EAEI,CAACyB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACId,EAAO,SAAW,GACpBA,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAI7B,EAAcc,EAAW,aACzBd,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAC6B,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAI5B,EAAYa,EAAW,WACvBb,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIE,EAAUW,EAAW,SACrBX,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIR,EAAOmB,EAAW,KAClBnB,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9BQ,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BF,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAM8B,EACFzD,GAAmC,CAAC,GAAGyC,EAAY,KAAAnB,EAAM,QAAAQ,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGe,CAAM,EACrGc,EAAQ,QAAQG,GACZjB,EAAQe,EACRxB,GAAeF,EAAgB,CAACE,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAC/C,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CAAC,CAAC,CACtF,EAEa3B,GAAgB,CAACkD,EAAyBf,IAA8C,CACnGvC,GAAesD,EAAQ,OAAQf,CAAU,EACrCe,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCnD,GAAgBmD,EAASf,CAAU,EAEnCrC,GAAgBoD,EAASA,EAAQ,OAAQf,CAAU,CAEvD,ICtTA,IAqBMgC,GAEAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GA4HAC,GA4FOC,GAKAC,GApRbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAaMd,GACF,qBACEC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYU,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgBC,EAAe,CACvC,IAAIC,EAAQ,KAAK,gBAAgB,IAAIF,CAAM,EACvCE,IAAU,OACZA,EAAQ,CAACD,CAAK,EAEdC,EAAM,KAAKD,CAAK,EAElB,KAAK,gBAAgB,IAAID,EAAQE,CAAK,CACxC,CAIF,EAEMZ,GAAN,KAAqB,CACnB,YAAYa,EAA+CC,EAAkB,CAAlB,cAAAA,EACzD,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOjB,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBiB,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWN,IAAU,CACvC,IAAMO,EAAOL,EAAOF,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACM,EAAU,MAAM,OAAOrB,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMuB,EAAa,KAAK,YAAYF,EAAW,GAAMC,EAAMP,CAAK,EAChE,KAAK,IAAI,KAAKQ,CAAU,CAC1B,CAAC,EAGGH,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EAC1B,OAAO,CAAC,CAACI,EAAKC,CAAI,IAAOA,EAAK,QAAU,GAAKD,IAAQ,KAAM,EAC3D,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEf,CAACJ,EAAI,MAAM,OAAOrB,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKdqB,EAAI,MAAM,OAAOtB,GAAe,GAAG,CAAC,GAC3C,QAASgB,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMW,EAAO,KAAK,aAAa,IAAIX,CAAM,EACzC,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYL,EAAK,GAAM,KAAK,UAAU,CACxD,CAGA,UAAUN,EAAgBY,EAAkBb,EAAoB,CAC9D,IAAIY,EAAO,KAAK,aAAa,IAAIX,CAAM,EACvC,GAAIW,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKZ,CAAU,CAErC,MACEY,EAAO,CAAC,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACb,CAAU,CAAC,EAExD,KAAK,aAAa,IAAIC,EAAQW,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkBN,EAAyBP,EAAQ,GAAgB,CAC3F,IAAMc,EAAOP,EAAK,OACdQ,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACL,EAAK,MAAM,OAAO3B,EAAe,CAAC,GAAM,CAAC4B,GAAWD,IAAS,GAChE,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMM,EAAeN,EAAK,MAAM,OAAO7B,GAAe,GAAG,CAAC,EACpDyB,EAAa,IAAIpB,GAAWY,CAAK,EAEvC,OAAAkB,GAAc,QAAQ,CAACnB,EAAgBoB,IAAc,CACnD,GAAIpB,IAAW,MAAO,CACpB,GAAIgB,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMK,EAAoBN,EAAOI,EAAa,OAAS,EACvD,GAAIE,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAJ,EAAeT,EAAK,MAAMU,EAASA,EAAUG,CAAiB,EAC1D,KAAK,aACP,GAAI,KAAK,aAAa,SAAWJ,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EACzD,MAAM,IAAI,MAAM,8BAA8B,UAEvCH,EACT,KAAK,YAAc,GACnB,KAAK,aAAeG,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASK,EAAI,EAAGA,EAAIL,EAAa,OAAQK,IAAK,CAC5C,IAAMtB,EAAS,OAAO,aAAa,IAAI,WAAW,CAAC,EAAIoB,CAAC,EACxDX,EAAW,UAAUT,EAAQoB,EAAIE,CAAC,EAClC,KAAK,UAAUtB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAC/C,CACF,MACEQ,EAAW,UAAUT,EAAQoB,CAAC,EAC9B,KAAK,UAAUpB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAEjD,CAAC,EACMQ,CACT,CAQF,EAEMlB,GAA0B,CAACY,EAA+BoB,IAAgD,CAC9G,IAAMC,EAAWrB,EAAO,CAAC,EAAE,SACrBsB,EAAY,IAAI,MAAqBtB,EAAO,MAAM,EACxD,QAASiB,EAAI,EAAGA,EAAIjB,EAAO,OAAQ,EAAEiB,EACnCK,EAAUL,CAAC,EAAIM,EAAc,QAAQN,CAAC,GAAII,EAAUrB,EAAOiB,CAAC,EAAE,IAAI,EAEpE,IAAMO,EAAcJ,EAAe,WAC7BK,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAASC,EAAe,SAAUP,EAAUG,CAAW,EACvDK,EAAoB,CAAC,EACrBC,EAAa,MAAM,KAAKV,EAAe,IAAI,gBAAgB,KAAK,CAAC,EACjEW,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBlB,EAAe,aAAa,OAASU,EAAW,OAC/EV,EAAe,aAAa,QAAQ,CAACZ,EAAMX,IAAW,CACpD,GAAIiC,EAAW,SAASjC,CAAM,EAAG,CAC/B,IAAM0C,EAAcT,EAAW,QAAQjC,CAAM,EAC7CuB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,GAAU,CACzB+B,EAAQ,KAAK,GACTP,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,EAAO6B,EAAO,WAAW,gBAAiBY,CAAW,CAAC,CAAC,EAAE,CAC3G,CAAC,CACH,CACF,CAAC,CACH,MACEnB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,IAAMT,EAAOY,EAAe,aAAa,IAAIvB,CAAM,EACnD,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,sBAAsB,EAExC,GAAIA,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,GAAU,CACzBoC,EAAoB,KAAK,GAAGZ,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,EAAO,GAAGD,CAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDwC,EAAgB,KAAK,WAAWf,EAAUL,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACDkB,EAAqB,KAAK,WAAWtC,CAAM,cAAcA,CAAM,MAC3DuB,EAAe,aAAa,IAAIvB,CAAM,GAAG,QAAQ,KAAKA,CAAM,OAAO,EACvEuC,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAMK,EAAYH,EACd,CACE,GAAGT,EACH,aAAaP,EAAU,IAAI,CAACoB,EAAUzB,IAAMyB,EAAS,aAAa,QAAQzB,CAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGY,EACHG,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACEO,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB,GAAGtB,EAAWK,CAAM,CAAC;AAAA;AAAA,QAEnDiB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCnB,CAAU,CAAC;AAAA,8BAC1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDL,EAAU,IAAI,CAACoB,EAAUzB,IAAM,YAAYA,CAAC,YAAYK,EAAUL,CAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,UAChGwB,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,UACpBd,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,SAE/C,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMP,EAAe,QAAQ,EAC3C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMI,EAAa,SAAUxB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAkB,CACF,CACF,EAEatD,GAAS,CAACwD,EAAyBC,IAAuC,CACrF,IAAM1B,EAAiB,IAAIjC,GAAe0D,EAAQ,OAAQC,EAAW,QAAQ,EAC7ED,EAAQ,QAAQzD,GAAwByD,EAAQ,OAAQzB,CAAc,CAAC,CACzE,EAEa9B,GAAyBwD,GAA0D,CAC9F,IAAM7C,EAAY6C,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOC,GAA4B,CAAC,SAAA9C,CAAQ,CAAC,CAC/C,ICvRA,IASM+C,GAiBAC,GAYAC,GAIAC,GAuCOC,GAjFbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzDG,EAAaD,EAAM,OAASD,EAAW,OAAS,EAAIC,EAAM,OAASD,EAAW,OAC9EG,EAAkBH,EAAW,OAASC,EAAM,OAAS,EAAID,EAAW,OAASC,EAAM,OACvF,KAAOC,EAAaD,EAAM,QAAUE,EAAkBH,EAAW,OAAQ,EAAEE,EAAY,EAAEC,EACvF,GAAIF,EAAMC,CAAU,IAAMF,EAAWG,CAAe,GAAKF,EAAMC,CAAU,IAAM,GAC3EF,EAAWG,CAAe,IAAM,EAClC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEMZ,GAAmB,CAACa,EAA2BC,IAAwC,CAC3F,IAAMC,EAAOF,EAAO,OAASC,EAAO,OAC9BJ,EAAkB,CAAC,EACzB,QAASM,EAAI,EAAGA,EAAID,EAAM,EAAEC,EAC1BN,EAAM,KAAKG,EAAOG,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIF,EAAO,OAAQ,EAAEE,EACnCN,EAAM,KAAKI,EAAOE,CAAC,IAAM,EAAIH,EAAOG,EAAID,CAAI,EAAID,EAAOE,CAAC,CAAC,EAE3D,OAAON,CACT,EAEMT,GAAuB,CAACQ,EAA+BC,IACxDD,EAAW,OAASC,EAAM,OAAUV,GAAiBS,EAAYC,CAAK,EAAIV,GAAiBU,EAAOD,CAAU,EAG3GP,GAA2BM,GAA+C,CAC9E,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDS,EAAwBhB,GAAqBQ,EAAYC,CAAK,EAC9DQ,EAAaC,EAAU,KAAKF,CAAW,EAEvCG,EAAWZ,EAAO,CAAC,EAAE,SACrBa,EAAQC,EAAc,QAASF,EAAUX,CAAU,EACnDc,EAASC,EAAe,SAAUJ,EAAUH,CAAW,EAEvDQ,EAAmBC,GAA+B;AAAA,uBACnCL,EAAM,QAAQ,GAAGZ,CAAU,CAAC;AAAA,IAC/CiB,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,IAC5CG,EAAa,UAAU,CAAC;AAAA,IACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,0BACxCK,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBACtCF,EAAM,KAAK,OAAO;AAAA,0BAChBZ,EAAW,MAAM;AAAA,YAC/BY,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA,UACrCA,EAAM,WAAW,eAAgB,IAAK,CAAC,CAAC;AAAA;AAAA,UAG5CA,EAAM,WACF,eAAgB,IAAKE,EAAO,WAAW,gBAAiB,OAAON,EAAY,OAASR,EAAW,MAAM,EAAE,CAAC,CAAC;AAAA;AAAA;AAAA,MAG7Gc,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,KAExE,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGJ,CAAW,EAAE,EACpC,gBAAAQ,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMR,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEaf,GAAUwB,GAAkC,CACvD5B,GAAe4B,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzB,GAAwByB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxE,ICpFA,IAcMC,GAMAC,GAiEOC,GAGAC,GAxFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMR,GAA0B,CAACQ,EAA+BC,IAA8C,CAC5G,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAeH,EAAO,CAAC,EAAE,KAEzBI,EAAYF,EAAW,OACvBG,EAAOC,EAAU,cAAcL,EAAW,KAAMG,CAAS,EAEzDG,EAAcL,EAAW,MAAM,CAAC,EACtCK,EAAY,OAAOF,EAAM,EAAG,GAAGF,CAAY,EAE3C,IAAMK,EAAeN,EAAWG,CAAI,EAC9BI,EAAaH,EAAU,KAAKC,CAAW,EAEvCG,EAAOC,EAAc,OAAQX,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/DY,EAAUD,EAAc,eAAgBX,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC1Ea,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUO,CAAW,EACjEQ,EAAkB,IAAc,CACpC,IAAMC,EAAcb,EAAa,OAC7Bc,EAAU,yBAAyBL,EAAQ,KAAK,OAAO,OAC3D,QAASM,EAAI,EAAGA,EAAIF,EAAaE,IAC/BD,GAAW,GAAGD,EAAc,EAAI,kBAAkBE,CAAC,IAAM,gBAAgB,MACrEX,EAAY,OAAS,EAAI,iBAAiBF,EAAOa,CAAC,IAAM,eAAe,IAE7ED,GAAW;AAAA,oBACKL,EAAQ,aAAa,gBAAgB,CAAC;AAAA;AAAA,wBAElCJ,CAAY;AAAA;AAAA,4BAERE,EAAK,KAAK,OAAO;AAAA,QAEzC,QAASQ,EAAI,EAAGC,EAAI,EAAGD,EAAId,EAAWc,IAChCA,IAAMb,GACRY,GAAW,GAAGb,EAAY,EAAI,eAAec,CAAC,IAAM,aAAa,eACjEC,GAAKH,IAELC,GAAW,GAAGb,EAAY,EAAI,eAAec,CAAC,IAAM,aAAa,MAC7DX,EAAY,OAAS,EAAI,iBAAiBY,CAAC,IAAM,eAAe,IACpEA,KAGJ,OAAOF,CACT,EAEMG,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBX,EAAME,EAASC,CAAM,CAAC;AAAA,QACpDQ,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCZ,CAAU,CAAC;AAAA,8BAC1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDE,EAAgB,CAAC;AAAA,sBACLL,EAAK,aAAa,aAAa,CAAC;AAAA,UAC5CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,SAEjD,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMM,EAAa,SAAUP,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAW,CACF,CACF,EAEa3B,GAAyBQ,GAClCqB,GAA4B,CAAC,KAAMrB,EAAW,IAAc,CAAC,EAEpDP,GAAS,CAAC6B,EAAyBtB,IAAuC,CACrF,IAAMD,EAASuB,EAAQ,OACvBhC,GAAeS,CAAM,EACrBuB,EAAQ,QAAQ/B,GAAwB+B,EAAQ,OAAQtB,CAAU,CAAC,CACrE,IC5FA,IAcMuB,GAeAC,GAqEOC,GAGAC,GArGbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEMR,GACF,CAACQ,EAA+BC,IAAsD,CACpF,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAsBH,EAAO,CAAC,EAAE,SAChCI,EAAYF,EAAW,OACvBG,EAAeC,EAAU,eAAeJ,CAAU,EAClDK,EAAYD,EAAU,KAAKJ,CAAU,EAErCM,EAAeR,EAAO,CAAC,EAAE,KACzBS,EAAkBT,EAAO,CAAC,EAAE,SAC5BU,EAAcJ,EAAU,KAAKE,CAAY,EAEzCG,EAAOL,EAAU,cAAcL,EAAW,KAAMG,CAAS,EACzDQ,EAAeV,EAAWS,CAAI,EAE9BE,EAAcL,EAAa,MAAM,CAAC,EAClCM,EAAaR,EAAU,KAAKO,CAAW,EAEvCE,EAAQC,EAAc,QAASb,EAAqBD,CAAU,EAC9De,EAAUD,EAAc,UAAWP,EAAiB,CAACC,CAAW,CAAC,EACjEQ,EAASC,EAAe,SAAUhB,EAAqBU,CAAW,EAMlEO,EAAmBC,GAA+B;AAAA,wCACtBhB,EAAa,MAAM,KAAKA,EAAa,IAAIiB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,QAChGD,EAAa,iBAAiBN,EAAOE,EAASC,CAAM,CAAC;AAAA,QACrDG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCP,CAAU,CAAC;AAAA;AAAA,4BAE1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CD,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA,sBAE7BL,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA,4BAKNV,EAAW,MAAM;AAAA,mBAC1BS,CAAI;AAAA;AAAA;AAAA,yBAGEO,EAAO,WAAW,gBAAiB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAMtBX,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,KAO7C,MAAO,CACL,KAAM,iBACN,YAAa,CAAC,KAAMN,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMY,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAM,CACF,CACF,EAES3B,GAAiCQ,GAC1CsB,GAA4B,CAAC,KAAMtB,EAAW,IAAc,CAAC,EAEpDP,GAAiB,CAAC8B,EAAyBvB,IAA+C,CACrG,IAAMD,EAASwB,EAAQ,OACvBjC,GAAeS,CAAM,EACrBwB,EAAQ,QAAQhC,GAAgCgC,EAAQ,OAAQvB,CAAU,CAAC,CAC7E,ICzGA,IAUMwB,GA0BAC,GAmBAC,GAoEOC,GAKAC,GAhIbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UACjCA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC3D,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMT,GAAU,CAACU,EAAWC,EAAWC,IAAoC,CACzE,GAAIA,EAAK,SAAW,EAClB,MAAO,KAGT,IAAMC,EAAcD,EAAK,SAAW,GAAKF,IAAM,GAAOE,EAAK,SAAW,GAAKA,EAAK,CAAC,IAAMF,EACjFI,EAAaF,EAAKA,EAAK,OAAS,CAAC,IAAMD,EAEzCI,EAAS,KACb,OAAKF,IACHE,GAAU,SAASH,EAAKA,EAAK,OAAS,CAAC,CAAC,KAErCE,IACHC,GAAU,MAGLA,CACT,EAEMd,GAAwB,CAACQ,EAA+BO,IAA4C,CACxG,IAAMC,EAASR,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BS,EAAST,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACU,EAAGC,EAAGC,CAAC,EAAIC,GAAS,qBACvBL,EAAQD,EAAW,OAAQE,EAAQF,EAAW,OAAQP,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MAAS,EACpGc,EAAc,CAACJ,EAAGC,CAAC,EACzB,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,qCAAsC,EAExD,IAAMC,EAAaC,EAAU,KAAKF,CAAW,EACzCG,EAAO,GACPV,EAAW,QAAUA,EAAW,OAClCU,EAAO,wCACEV,EAAW,QAAU,CAACA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAUA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAU,CAACA,EAAW,SAC3CU,EAAO,yCAGT,IAAMC,EAAWC,GAA4BnB,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAiBb,EAAW,QAAU,EAAI,GAAK,kBAC/Cc,EAAarB,EAAO,SAAW,EAAI,qBAAqBT,GAAQmB,EAAGC,EAAGX,EAAO,CAAC,EAAE,IAAI,CAAC,KAAO,GAC5FsB,EAAkC,CACtC,sDAAsDJ,CAAQ,KAC9D,sDAAsDA,CAAQ,IAChE,EACIlB,EAAO,SAAW,GACpBsB,EAAgC,KAAK,sDAAsDJ,CAAQ,IAAI,EAEzG,IAAMK,EAAmBC,GAA+B;AAAA,mBACvCd,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,kBACFM,CAAQ,IAAIX,EAAW,KAAK;AAAA,iBAC7BW,CAAQ,IAAIX,EAAW,IAAI;AAAA;AAAA,IAExCe,EAAgC,KAAK;AAAA,CAAI,CAAC;AAAA,uBACvBtB,EAAO,MAAM,6CAA6CkB,CAAQ;AAAA;AAAA,IAErFM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAKlDG,CAAQ;AAAA,8BACIN,CAAC;AAAA,QACvBK,CAAI;AAAA;AAAA;AAAA,MAGNG,CAAc;AAAA,MACdC,CAAU;AAAA;AAAA;AAAA,KAId,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAMd,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMO,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,EAEa9B,GAAO,CAACgC,EAAyBlB,IAAqC,CACjFjB,GAAemC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAsBiC,EAAQ,OAAQlB,CAAU,CAAC,CACnE,EAEab,GAAuBa,GAChCmB,GAA4BnB,CAA+D,ICjI/F,IAgBMoB,GAIAC,GA8FAC,GA2GAC,GAgDOC,GAGAC,GAhRbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMX,GAAW,CACf,KAAM,uBACR,EAEMC,GACF,CAACW,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KAEnBG,EAAcD,EACdE,EAAO,EACPC,EAAYC,EAAU,gBAAgBJ,EAAQE,CAAI,EAClDG,EAAWD,EAAU,kBAAkBJ,EAAQE,CAAI,EACnDI,EAAIN,EAAO,CAAC,EACZO,EAAIC,EAAc,IAAKV,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EAC3EI,EAAQD,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEY,EAAOF,EAAc,OAAQV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/Da,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EACtFQ,EAAY,CAACN,EAAGE,EAAOC,EAAMC,CAAM,EACnCG,EAAWP,EAAE,KAAK,MAClBQ,EAAgB,GAChBC,EAAmBC,GAA+B;AAAA;AAAA,mBAE3CX,CAAC;AAAA,0BACMD,CAAQ;AAAA,yBACTN,EAAW,OAAO;AAAA,gCACXe,CAAQ;AAAA,uCACDA,CAAQ;AAAA,2CACJA,CAAQ,KAAKC,CAAa;AAAA,0BAC3CA,CAAa;AAAA,IACnCE,EAAa,iBAAiB,GAAGJ,CAAS,CAAC;AAAA,IAC3CI,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAOtBD,CAAQ;AAAA;AAAA,4BAECP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAahBO,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOzBP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDAkBJO,CAAQ;AAAA,qCACtBL,EAAM,YAAY,SAAS,CAAC;AAAA,yBACxCC,EAAK,YAAY,SAAS,CAAC;AAAA;AAAA,oBAEhCH,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA,QAC1CI,EAAO,IAAI,QAAS,UAAW,IAAK,OAAO,CAAC;AAAA;AAAA,KAG9C,MAAO,CACL,GAAGzB,GACH,YAAa,CAAC,KAAMa,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAGK,CAAS,CAC9B,GACA,gBAAAa,CACF,CACF,EAEE5B,GACF,CAAC8B,EAAyBC,EAAmBV,EAAmBC,EAAkB,EAAWU,EAAWC,EACvGC,IAAoB,CACnB,IAAMC,EAAaC,GAAiBH,CAAC,EAC/BI,EAAcjB,EAAc,QAASW,EAAM,SAAUA,EAAM,KAAMI,CAAU,EAC3EG,EAAclB,EAAc,QAASC,EAAM,SAAUA,EAAM,KAAMc,CAAU,EAC3EI,EAAanB,EAAc,OAAQE,EAAK,SAAUA,EAAK,KAAMa,CAAU,EAEvEK,EAAK,GAGLC,EAAaN,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC5DO,EAAcP,IAAe,EAAI,MAAQ,MAAMA,CAAU,IACzDQ,EAAiB,CAACC,EAAcC,IAAiB,GAAGJ,CAAU,IAAIG,CAAI,KAAKC,CAAI,IAC/EC,EAAc,EAAIb,EAAIE,EACtBY,EAAS,KAAK,KAAKf,EAAIQ,CAAE,EAEzBQ,EAAuBnB,GAA+B;AAAA,mBAC/CG,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNH,EAAIC,EAAIE,CAAU;AAAA;AAAA,IAEzCN,EAAa,iBAAiBQ,CAAW,CAAC;AAAA,kEACoBI,CAAU;AAAA;AAAA,IAExEZ,EAAa,UAAUW,CAAE,CAAC;AAAA,4CACcA,CAAE;AAAA,+CACCA,CAAE;AAAA,8BACnBA,CAAE;AAAA,4BACJO,CAAM;AAAA;AAAA;AAAA;AAAA,iCAIDA,CAAM;AAAA;AAAA;AAAA,gBAGvBE,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA;AAAA,sBAE9BO,CAAW;AAAA;AAAA;AAAA;AAAA,2BAINC,EAAe,MAAO,YAAY,CAAC;AAAA,KAGlDO,EAAapB,EAAQ,QACvB,CACE,KAAM,0BACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAK,EAAY,EAAG,EAAAH,EAAG,EAAAC,CAAC,CAAC,CAAC,EACzD,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAAC,EAAGA,EAAGO,EAAI,CAAC,EAAG,UAAwB,CAChD,EACA,cAAe,CAAC,EAAG,EAAIP,EAAIE,CAAU,CACvC,GACA,gBAAiBa,CACnB,EACA,CAAC,OAAQ,CAACjB,CAAK,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EACjCH,EAAmBC,GAA+B;AAAA,mBAC3CG,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNK,EAAKP,EAAIE,CAAU;AAAA,yBACrBD,CAAO;AAAA;AAAA,2DAE2BO,CAAU;AAAA,2DACVH,EAAY,KAAK,OAAO;AAAA,0DACzBC,EAAW,KAAK,OAAO;AAAA,kEACfE,CAAU;AAAA;AAAA,IAExEZ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCiB,CAAW,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKrDG,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA,+BACrBK,CAAE;AAAA,gEAC+BA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAO7BE,CAAW;AAAA,yBACvBA,CAAW;AAAA;AAAA,2BAETC,EAAe,eAAgB,cAAc,CAAC;AAAA,KAGnE,OAAOb,EAAQ,QACX,CACE,KAAM,uCACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAK,EAAY,EAAG,EAAAH,EAAG,EAAAC,EAAG,QAAAC,CAAO,CAAC,CAAC,EAClE,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAAC,EAAGD,EAAG,CAAC,EAAG,UAAwB,CAC5C,EACA,cAAe,CAAC,EAAG,KAAK,KAAKa,EAAc,EAAuB,CAAC,CACrE,GACA,gBAAAlB,CACF,EACA,CAAC,OAAQ,CAACsB,EAAY7B,EAAOC,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC3D,EAEErB,GACF,CAAC6B,EAAyBpB,EAA+BC,IAAuC,CAC9F,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACduC,EAAIvC,EAAO,CAAC,EACZM,EAAIN,EAAOA,EAAO,OAAS,CAAC,EAC5BwC,EAAIpC,EAAU,kBAAkBJ,EAAQ,CAAC,EAAIM,EAE7CiB,EAAaC,GAAiBlB,CAAC,EAC/BmC,EAAarC,EAAU,KAAKH,CAAW,EAAIsB,EAC3CE,EAAcjB,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMyB,CAAU,EACnFmB,EAAe9B,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUG,EAAasB,CAAU,EAEnFT,EAAW6B,GAA4B7C,EAAO,CAAC,EAAE,QAAQ,EACzD8C,EAAYrB,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC3DsB,EAAgBtB,IAAe,EAAIT,EAAW,MAAMS,CAAU,IAAIT,CAAQ,IAE1EgC,EAAoB1D,GAAY8B,EAASpB,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGyC,EAAGC,EAAGlC,EAAGP,EAAW,OAAO,EAErGiB,EAAmBC,GAA+B;AAAA,mBAC3CuB,CAAC;AAAA,mBACDlC,EAAIiB,CAAU;AAAA;AAAA,2DAE0BE,EAAY,KAAK,OAAO;AAAA,gEACnBmB,CAAS;AAAA,kEACPF,EAAa,KAAK,OAAO;AAAA;AAAA,IAEvFzB,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDAMsB4B,CAAa,eAAeA,CAAa;AAAA,KAErF3B,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGnB,EAAW,QAAQ,EAAE,EAC5C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAK2C,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAzB,CACF,EACA,CAAC,OAAQ,CAAClB,EAAO,CAAC,EAAGgD,CAAiB,CAAC,CAAC,CAC9C,EAESxD,GAA+BS,GACxCgD,GAA4B,CAAC,QAAShD,EAAW,QAAS,OAAQA,EAAW,MAAM,CAAC,EAE3ER,GAAe,CAAC2B,EAAyBnB,IAA6C,CAC7FA,EAAW,SAAW,OACxBV,GAAkC6B,EAASA,EAAQ,OAAQnB,CAAU,EAErEmB,EAAQ,QAAQ/B,GAA8B+B,EAAQ,OAAQnB,CAAU,CAAC,CAE7E,ICtRA,IAgBMiD,GAMAC,GAiGOC,GAGAC,GA1HbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,CAE3D,EAEMT,GACF,CAACS,EAA+BC,EAAiCC,IAAqC,CACpG,IAAMC,EAASH,EAAO,CAAC,EAAE,KACnBI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EAEfM,EAAcH,EACdI,EAAOC,EAAU,cAAcP,EAAW,KAAME,EAAO,MAAM,EAC7DM,EAAYD,EAAU,gBAAgBL,EAAQI,CAAI,EAClDG,EAAWF,EAAU,kBAAkBL,EAAQI,CAAI,EAEnDI,EAAYH,EAAU,KAAKJ,EAAM,IAAI,EACrCQ,EAAWP,EAAOG,EAAU,KAAKH,EAAK,IAAI,EAAI,EACpD,GAAIM,IAAcD,GAAaL,GAAQO,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEpCC,CAAS,qBAAqBC,CAAQ,EAAE,EAG7D,IAAMC,EAAmB,CAAC,EAC1B,QAASC,EAAI,EAAGA,EAAIX,EAAO,OAAQ,EAAEW,EAC/BA,EAAIP,EACNM,EAAiB,KAAKV,EAAOW,CAAC,CAAC,EAE/BD,EAAiB,KAAK,CAAC,EAI3B,IAAME,EAAaC,GAAiBN,CAAQ,EACtCO,EAAWC,GAA4BlB,EAAO,CAAC,EAAE,QAAQ,EACzDmB,EAAY,CAChBC,EAAc,IAAKpB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAU,EACjEK,EAAc,QAAShB,EAAM,SAAUA,EAAM,KAAMW,CAAU,CAC/D,EACIV,GACFc,EAAU,KAAKC,EAAc,OAAQf,EAAK,SAAUA,EAAK,KAAMU,CAAU,CAAC,EAE5EI,EAAU,KAAKE,EAAe,SAAUrB,EAAO,CAAC,EAAE,SAAUM,EAAaS,CAAU,CAAC,EAEpF,IAAMO,EAAoBpB,EAAc,EAClCqB,EAAkBrB,EAAc,EAElCoB,GACFH,EAAU,KAAKE,EAAe,mBAAkCR,CAAgB,CAAC,EAE/EU,GACFJ,EAAU,KAAKE,EAAe,iBAAgCR,CAAgB,CAAC,EAGjF,IAAMW,EAAmBC,GAA+B;AAAA,0BACpCf,CAAQ;AAAA,oCACEA,EAAWK,CAAU;AAAA,yBAChCd,EAAW,OAAO;AAAA;AAAA,IAEvCwB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA,IAC3CM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,uBAE5CiB,GAAW,MAAOX,CAAU,CAAC;AAAA,6BACvBW,GAAW,MAAOX,CAAU,CAAC;AAAA;AAAA;AAAA,oBAGtCY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA;AAAA;AAAA;AAAA,iBAInDa,GAAU,aAAcb,CAAU,CAAC;AAAA,4BACxBa,GAAU,mBAAoBb,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI9CY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA,uBAChDY,GAAUV,EAAUF,EAAY,UAAU,CAAC;AAAA,6BACrCI,EAAU,CAAC,EAAE,KAAK,KAAK;AAAA,UAC1Cd,EAAO,KAAKsB,GAAUV,EAAUF,EAAY,SAAS,CAAC,GAAK,EAAE;AAAA;AAAA;AAAA;AAAA,MAIjEO,EAAoB,oCAAsC,EAAE;AAAA,MAC5DC,EAAkB,4CAA8C,EAAE;AAAA,KAE5DM,EAAU,CAAC,CAAC,KAAMvB,EAAa,SAAUN,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIsB,GACFO,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAE7DU,GACFM,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAG1D,CACL,KAAM,qBACN,YAAa,CAAC,KAAM,GAAGZ,EAAW,QAAQ,IAAIC,CAAW,IAAIF,EAAO,MAAM,EAAE,EAC5E,WAAY,KAAO,CAAC,QAAA6B,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKpB,EAAY,EAAuB,CAAC,CAAC,GAC/F,gBAAAe,CACF,CACF,EAEShC,GAA4BS,GACrC6B,GAA4B,CAAC,KAAM7B,EAAW,KAAM,QAASA,EAAW,OAAO,CAAC,EAEvER,GAAY,CAACsC,EAAyB9B,IAA0C,CAC3FX,GAAeyC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQxC,GAA2BwC,EAAQ,OAAQ9B,EAAY8B,EAAQ,WAAW,CAAC,CAC7F,IC7HA,IASMC,GAUOC,GAnBbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEML,GAAkBM,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEaL,GAAUM,GAAkC,CACvDP,GAAeO,EAAQ,MAAM,EAC7B,IAAMC,EAAcC,GAAc,UAAUF,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,uCAAwC,EAE1DD,EAAQ,QAAQG,GAAwBH,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGC,CAAW,CAAC,CAChH,IC1BA,IAkBMG,GAmBAC,GA8BAC,GA+BAC,GA2BAC,GA2BAC,GAkBAC,GA0BAC,GAaAC,GA0BOC,GAMAC,GAjPbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KASMhB,GAAkBiB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAIC,EAAYD,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpBC,EAAYD,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAACC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMjB,GACF,CAACkB,EAAuBC,EAA+BC,EACtDC,EAAiCC,EAAgBC,EAAkBC,IAAkC,CACpG,IAAMC,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,sBACKR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI5CP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA,4BAGPN,EAAaM,CAAC,CAAC;AAAA,UAIrC,MAAO;AAAA,oBACOJ,CAAQ,IAAIC,CAAa;AAAA;AAAA;AAAA;AAAA,cAI/BE,CAAK;AAAA;AAAA;AAAA,OAIf,EAEEzB,GACF,CAACiB,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gCAKvC,GAAKP,EAAUO,CAAC,EAAI,EAAE;AAAA;AAAA,4BAE1BP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,gCAIRN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEExB,GACF,CAACgB,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI5CP,EAAUO,CAAC,CAAC;AAAA,wBACfP,EAAUO,CAAC,EAAI,CAAC;AAAA;AAAA,gCAERN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEvB,GACF,CAACe,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA,yBAE9CP,EAAUO,CAAC,CAAC;AAAA;AAAA,2BAEVP,EAAUO,CAAC,CAAC;AAAA,yBACdP,EAAUO,CAAC,CAAC;AAAA;AAAA,gCAELN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEtB,GACF,CAACc,EAAuBC,EAA+BC,EACtDC,EAAiCO,EAA2BL,IAA6B,CACxF,OAAQK,EAAW,KAAM,CACvB,IAAK,GACH,OAAO5B,GACHkB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,KAAML,EAAUK,EAAW,KAAK,EAC9F,IAAK,GACH,OAAO3B,GAAciB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EACnF,IAAK,GACH,OAAO1B,GAAWgB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EAChF,IAAK,GACH,OAAOzB,GAAWe,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EAChF,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEEvB,GACF,CAACwB,EAA4Bb,EAA+BY,EAA2BL,IACzE,CACR,IAAMH,EAAYJ,EAAO,CAAC,EAAE,KACtBG,EAAaW,EAAU,SAASV,EAAU,MAAM,EAAGQ,EAAW,IAAI,EAClEG,EAAaD,EAAU,KAAKX,CAAU,EACtCE,EAAeS,EAAU,eAAeV,CAAS,EAEjDF,EAASc,EAAe,SAAUhB,EAAO,CAAC,EAAE,SAAUG,CAAU,EAChEc,EAAQC,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUI,CAAS,EAExDe,EAAa/B,GAAcc,EAAQC,EAAYC,EAAWC,EAAcO,EAAYL,CAAQ,EAYlG,MAXgB;AAAA,gBACVM,EAAa,iBAAiBI,EAAOf,CAAM,CAAC;AAAA,gBAC5CW,EAAa,UAAU,CAAC;AAAA,gBACxBA,EAAa,sCAAsCE,CAAU,CAAC;AAAA;AAAA,8BAEhDb,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEtCK,CAAQ;AAAA,gBACpBY,CAAU;AAAA;AAAA,YAIlB,EAEF7B,GAAuB,CAACU,EAA+BY,IAA2C,CACtG,IAAMQ,EAAcN,EAAU,SAASd,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGY,EAAW,IAAI,EAC9E,MAAO,CACL,KAAM,MACN,YAAa,CAAC,KAAMA,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMQ,EAAa,SAAUpB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAU,KAAKM,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBP,GAAgBxB,GAAgBwB,EAAcb,EAAQY,EAAY,KAAK,CAC1F,CACF,EAEMrB,GAAgC,CAACS,EAA+BY,IAA6C,CACjH,GAAIZ,EAAO,OAAS,EAAG,CACrB,IAAMqB,EAAerB,EAAO,CAAC,EAAE,iBAAiB,EAC1CsB,EAAStB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAAQA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,EAElFS,EAAYT,EAAO,CAAC,EAAE,KAAK,OAC3BuB,EAAa,IAAI,WAAW,EAAId,CAAS,EAAE,KAAK,CAAC,EACvD,GAAIT,EAAO,QAAU,EAAG,CACtB,IAAMwB,EAAOxB,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAASW,EAAI,EAAGA,EAAIa,EAAK,OAAQb,IAC/BY,EAAW,OAAOC,EAAKb,CAAC,CAAC,CAAC,EAAI,OAAOU,EAAaV,CAAC,CAAC,EACpDY,EAAW,OAAOC,EAAKb,CAAC,CAAC,EAAIF,CAAS,EAAI,OAAOY,EAAaV,EAAIa,EAAK,MAAM,CAAC,CAElF,MACEH,EAAa,QAAQ,CAACI,EAAGd,IAAMY,EAAW,OAAOZ,CAAC,CAAC,EAAK,OAAOc,CAAC,CAAE,EAGpE,IAAMnB,EAAiB,CAAC,EACxB,OAAAiB,EAAW,QAAQE,GAAKnB,EAAK,KAAKmB,CAAC,CAAC,EAE7BC,GAA4B,CAAC,KAAMd,EAAW,KAAM,MAAAU,EAAO,KAAAhB,CAAI,CAAC,CACzE,KACE,QAAOM,CAEX,EAEapB,GAAM,CAACmC,EAAyBf,IAAoC,CAC/E7B,GAAe4C,EAAQ,MAAM,EAC7B,IAAMC,EAAoBrC,GAA8BoC,EAAQ,OAAQf,CAAU,EAClFe,EAAQ,QAAQrC,GAAqBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxF,EAEanC,GAAsBmB,GAAuD,CACxF,IAAMiB,EAAOjB,EAAW,KAClBU,EAAQV,EAAW,MACnBN,EAAOM,EAAW,KACxB,OAAOc,GAA4B,CAAC,KAAAG,EAAM,MAAAP,EAAO,KAAAhB,CAAI,CAAC,CACxD,ICtPA,IAgBMwB,GASAC,GA4BAC,GAwKAC,GAaAC,GA4BOC,GAYAC,GAKPC,GAYOC,GAKAC,GAUPC,GAqBOC,GAKAC,GAgBAC,GAKAC,GAjWbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMnB,GAAkBoB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,4BAA4B,EAE9C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMnB,GAA0C,CAC5CoB,EAAmBC,EAA2BC,IAAyD,CACzG,IAAMC,EAAiBF,EAAW,SAAW,OACvCG,EAA2BJ,EAAM,KAAK,MAAM,EAC9CG,GACFC,EAAyB,OAAO,EAAG,EAAGA,EAAyB,IAAI,CAAE,EAEvE,IAAMC,EAAe,OAAO,eAAe,KAAKJ,EAAY,WAAW,EACjEK,EAAcL,EAAW,YAAY,MAAM,EAC3CM,EAAUN,EAAW,QAAQ,MAAM,EACnCO,EAAsBH,EAAgBJ,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FQ,EAAOR,EAAW,KAAK,MAAM,EACnCS,GAAa,qBAAqBR,EAAkBE,EAA0BE,EAAaC,EAASC,EAAWC,CAAI,EAEnH,IAAME,EAA4BD,GAAa,uBAC3CR,EAAkBE,EAA0BG,EAASC,EAAWF,EAAaG,EAAMR,EAAW,OAAO,EAEnGW,EAAgB,OAAO,OAAO,CAAC,EAAGX,CAAU,EAC9CI,EACF,OAAO,OAAOO,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,UAAAD,EAAW,SAAUP,EAAW,QAAQ,CAAC,EAEnG,OAAO,OAAOW,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,SAAUR,EAAW,QAAQ,CAAC,EAE1F,IAAMY,EAA2BF,EAA0B,MAAM,EACjE,OAAAE,EAAyB,KAAKA,EAAyB,OAAO,EAAG,CAAC,EAAE,CAAC,CAAC,EAC/D,CAACD,EAAeT,EAAiBU,EAA2BF,CAAyB,CAC9F,EAEM9B,GAAsB,CACxBiC,EAA4BC,EAAkBC,EAA2BC,EACzEhB,EAA2BiB,EAAaC,EAAaC,IAA0B,CACjF,IAAMjB,EAAiBF,EAAW,SAAW,OACvCoB,EAAYL,EACZM,EAAWP,EAAE,KAAK,MAClBQ,EAAOF,EAAU,OACjBG,EAAaC,EAAU,KAAKR,CAAW,EACvCS,EAASC,EAAe,SAAUZ,EAAE,KAAK,OAAQE,CAAW,EAElE,GAAIhB,EAAW,YAAY,QAAU,EAAG,CACtC,IAAM2B,EAAK3B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D4B,EAAK5B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD6B,EAAU7B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD8B,EAAQ9B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClD+B,EAAUT,GAAQpB,EAAiB,EAAI,GACzC8B,EAAQ,GACRC,EAAQ,GACRC,EAAW,GAqBf,GApBIL,EAAUC,IAAU,EACtBE,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQX,EAAUW,CAAO,CAAC;AAAA;AAAA;AAAA;AAAA,kCAI5DjB,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAGjBe,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kCAC9Cf,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAIfjB,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMmC,EAAKnC,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7DoC,EAAKpC,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDqC,EAAUrC,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDsC,GAAQtC,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDuC,EAAUjB,GAAQpB,EAAiB,EAAI,GACvCsC,EAAOpB,EAAUmB,CAAO,EAC1BF,EAAUC,KAAU,EACtBL,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQC,CAAI;AAAA,4BACpDb,CAAE;AAAA;AAAA;AAAA,gBAKtBM,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kBAG1EH,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVrB,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,cAExCZ,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2BAExCJ,CAAQ,MAAMA,CAAQ,IAAIF,CAAK;AAAA;AAAA,gBAE1Cc,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRhB,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIhB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMuC,EAAajB,EAAU,KAAKxB,EAAW,WAAW,EAClD0C,EAAgBlB,EAAU,eAAexB,EAAW,WAAW,EAC/D2C,EAAcD,EAAc,OAC5BE,EAAW5C,EAAW,KAAK,OAC3B6C,EAAU7C,EAAW,KAAK,OAAO,CAAC8C,EAAKC,IAAQD,EAAMC,CAAG,EAC1DC,EAAU,GACd,OAAIH,EACFG,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgBlC,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGf+B,EAAU;AAAA;AAAA,8BAEclC,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3CG,CAAG;AAAA,cAGK;AAAA,cACVJ,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,sCAEhBmB,CAAQ,KAAK5C,EAAW,KAAK,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,2CACnD3B,CAAI,KAAKF,EAAU,IAAI6B,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+CAC1CN,CAAW,KAAKD,EAAc,IAAIO,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC/DN,CAAW,KAAK3C,EAAW,QAAQ,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,cAEzFpC,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3BkB,CAAW;AAAA;AAAA,4BAEvBlB,EAAO,KAAK,KAAK,IAAIN,CAAK;AAAA;AAAA;AAAA;AAAA,0CAIZsB,CAAU;AAAA;AAAA,uCAEbE,EAAc,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI5BA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVrB,EAAOqB,CAAW,UAAUrB,CAAI;AAAA,2DACJA,EAAOqB,CAAW;AAAA,oCACzCrB,EAAOqB,CAAW;AAAA,oBAClCK,CAAO;AAAA;AAAA,gBAEX9B,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcMrC,GAA6BmB,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMMlB,GACF,CAACoE,EAAcnD,EAAmBE,EAA2BD,IAAmD,CAC9G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEwC,EAAajB,EAAU,KAAK2B,EAAmB,WAAW,EAE1DrC,EAAIsC,EAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACjDsB,EAAWP,EAAE,KAAK,MAElBG,EAAM,kBACRC,EAAM,GACV,OAAIiC,EAAmB,gBACrBjC,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,KAEzCvB,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,WAEpC,CACL,KAAAS,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,KAAK,CACvG,CACF,EAESnC,GAA8BiB,GAA+D,CACxG,IAAMqD,EAAmBrD,EAAW,oBAAiC,EAE/DsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAIsD,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,OAAOC,GAA4B,CAAC,gBAAAF,EAAiB,GAAGC,CAAI,CAAC,CAC/D,EAEatE,GAAc,CAACwE,EAAyBxD,IAA4C,CAC/FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,cAAe0E,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CACnG,EAEMf,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,EACZ,SAAU,EACZ,EAEaC,GAAoCc,GAA+D,CAC9G,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEatE,GAAoB,CAACqE,EAAyBxD,IAA4C,CACrGtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,oBAAqB0E,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CACxG,EAOMZ,GACF,CAAC8D,EAAcnD,EAAmBE,EAA2BD,IAA+C,CAC1G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEgB,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNJ,EAAIsC,EAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACvD,MAAO,CACL,KAAAmD,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,MAAM,CACxG,CACF,EAES7B,GAAU,CAACmE,EAAyBxD,IAAwC,CACvFtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,UAAWoE,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CAC3F,EAEaV,GAA0BU,GAA2D,CAChG,IAAM0D,EAAe1D,EAAW,cAC1BO,EAAYP,EAAW,UAEvBsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAI0D,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIJ,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAGtF,OAAOC,GAA4B,CAAC,aAAAG,EAAc,UAAAnD,EAAW,GAAG+C,CAAI,CAAC,CACvE,EAEa/D,GAAgCS,GAA2D,CACtG,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEajE,GAAgB,CAACgE,EAAyBxD,IAAwC,CAC7FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,gBAAiBoE,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CAChG,ICpWA,IAUM2D,GAUAC,GAwBOC,GA5CbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GAAwB,CAACQ,EAAeC,EAAeC,IAAwB,CACnF,IAAMC,EAAiBH,IAAUC,EAC3BG,EAA8BJ,EAAQC,GAASC,EAAQ,EACvDG,EAA8BL,EAAQC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA4C,CAEhE,EAEMZ,GAAyB,CAACO,EAAeC,EAAeC,EAAeI,IAAoC,CAC/G,IAAMC,EAAc,KAAK,IAAI,KAAK,MAAMN,EAAQD,GAASE,CAAK,CAAC,EACzDM,EAAwB,CAACD,CAAW,EACpCE,EAAaF,EAEbG,EAASC,EAAe,SAAUL,EAAUE,CAAW,EACvDI,EAAWF,EAAO,KAAK,QAEvBG,EAAmBC,GAA+B;AAAA,UAChDA,EAAa,iBAAiBJ,CAAM,CAAC;AAAA,UACrCI,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,+BACzCG,CAAQ,IAAIZ,CAAK,OAAOY,CAAQ,kBAAkBA,CAAQ,IAAIV,CAAK;AAAA,SAEhG,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,CAACF,EAAOC,EAAOC,CAAK,EAAE,IAAIa,GAAKA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,CAAC,EAC1E,gBAAAF,EACA,WAAY,KACR,CAAC,QAAS,CAAC,CAAC,KAAML,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CAAC,EAC1E,CACF,EAEaf,GAASsB,GAAkC,CACtD,IAAIhB,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EACRc,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CC,GAAI,OAAO,sBACbzB,GAAsBQ,EAAOC,EAAOC,CAAK,EAG3Cc,EAAQ,QAAQvB,GAAuBO,EAAOC,EAAOC,EAAOc,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CACvG,IC9DA,IAgCME,GAoBAC,GASAC,GA8CAC,GA0CAC,GAkCAC,GAaAC,GAwBAC,GA2BAC,GAsBAC,GAkCAC,GAYAC,GAiDAC,GAwEAC,GA2FAC,GAOOC,GAUAC,GAhiBbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KAuBMrB,GAAiB,CAACsB,EAAkBC,IAAuC,CAK/E,GAJAD,EAAO,MAAOE,GAAUA,EAAQ,IAAM,IAAM,CAClB,MAAM,IAAI,MAAM,oDAAoD,CACtE,EAAE,EAEtBF,EAAO,OAAS,GAClB,GAAIC,EAAW,OAAS,UACtB,GAAI,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,gEAAgE,UAEzEC,EAAW,OAAS,SACzB,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEMrB,GAAe,CAACqB,EAA2BG,EAAyBC,IAA2B,CACnGD,EAAK,MAAOD,GAAUA,GAAS,GAAKA,EAAQE,IAAS,IAAM,CACnC,MAAM,IAAI,MAAM,qEAAqE,CACvF,EAAE,EACxB,IAAMC,EAAY,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAD,EAAK,QAAQ,CAACD,EAAOI,IAAUD,EAAUH,CAAK,EAAIF,EAAOM,CAAK,CAAC,EACxDD,CACT,EAEMzB,GACF,CAAC2B,EAA+BN,EAA8BO,EAAsBR,EACnFS,EAAiBC,IAAwB,CACxC,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EAClDL,EAAe,GAAM,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAKD,EAAO,OAAS,EAAK,EAAI,GAAI,EAAE,EACrEH,EAAOG,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAII,EAAgB,GAAKJ,EAAO,OAASI,GAAiBJ,EAAOI,CAAa,EAAE,KAAK,OAAS,EAC5FJ,EAAOI,CAAa,EAAE,gBAAgB,EAAE,QAAST,GAAUQ,EAAI,KAAKR,CAAK,CAAC,UAEjED,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GAAIW,EAAmB,GAAKL,EAAO,OAASK,GAAoBL,EAAOK,CAAgB,EAAE,KAAK,OAAS,EAAG,CAExG,GADAL,EAAOK,CAAgB,EAAE,gBAAgB,EAAE,QAASV,GAAUF,EAAO,KAAKE,CAAK,CAAC,EAC5EF,EAAO,SAAW,GACjBA,EAAO,SAAWI,GAASI,GAAgB,IAAMR,EAAO,SAAWC,EAAW,KAAK,OACtF,MAAM,IAAI,MACN,6FAA6F,EAEnGvB,GAAesB,EAAQC,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3BtB,GAAaqB,EAAQC,EAAW,KAAMG,CAAI,EAAE,QAAQ,CAACF,EAAOI,IAAUN,EAAOM,CAAK,EAAIJ,CAAK,CAE/F,CACA,GAAIW,EAAkB,GAAKN,EAAO,OAASM,IACzCN,EAAOM,CAAe,EAAE,iBAAiB,EAAE,QAASX,GAAUO,EAAM,KAAK,OAAOP,CAAK,CAAC,CAAC,EACnFO,EAAM,SAAWL,GAASI,GAAgB,IAAMC,EAAM,SAAWR,EAAW,KAAK,QACnF,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAID,EAAO,SAAWC,EAAW,KAAK,OACpC,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIQ,EAAM,SAAWR,EAAW,KAAK,OACnC,MAAM,IAAI,MACN,8FAA8F,CAEtG,CACA,GAAI,OAAOD,EAAW,KAAe,OAAOS,EAAU,KAAeT,EAAO,OAAS,GAAKS,EAAM,OAASL,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEEvB,GAA8CiC,GAChD,+JAEC,IAAM,CACL,OAAQA,EAAwB,CAC9B,IAAK,aACH,MAAO,4BACT,IAAK,qBACH,MAAO,sKAKT,IAAK,uBACH,MAAO,oCACT,IAAK,gBACH,MAAO,6LAKT,IAAK,qBACH,MAAO,gUAMT,IAAK,uBACH,MAAO,CACL,8CAA+C,kDAC/C,qCAAsC,4CACtC,oDACF,EAAE,KAAK;AAAA,CAAI,EACb,IAAK,aACH,MAAO,4CACT,QACE,MAAM,IAAI,MAAM,6BAA6BA,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACH,IAEEhC,GAA8B,CAACiC,EAA0BP,IAC3D,+EAAiF,IAAM,CACrF,OAAQO,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIP,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBO,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEEhC,GAAY,CAAC2B,EAAwBP,EAAyBC,IAA2B,CAC7F,IAAMY,EAAS,IAAI,MAAMZ,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/Da,EAAWP,EAAI,SAAW,EAAIM,EAASN,EAAI,MAAM,EACvD,OAAIP,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAACe,EAAGC,IAAM,CACrBH,EAAOE,CAAC,EAAID,EAASE,CAAC,EACtBH,EAAOG,EAAIf,CAAI,EAAIa,EAASd,EAAK,OAASgB,CAAC,CAC7C,CAAC,EACMH,GAEFC,CACT,EAEMjC,GACF,CAACoC,EAA+BpB,EAA2BS,EAA0BN,IACrE,CACV,IAAIkB,EAAwB,CAAC,EAC7B,GAAIZ,EAAM,OAAS,EACjB,GAAIN,EAAK,OAAS,EAAG,CAEnB,GADAiB,EAAW,QAASF,GAAMG,EAAY,KAAKH,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGf,CAAI,EAAIiB,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExCjB,EAAK,QAAQ,CAACe,EAAGC,IAAME,EAAYH,CAAC,EAAIT,EAAMU,CAAC,CAAC,CAClD,MACEV,EAAM,QAASS,GAAMG,EAAY,KAAKH,CAAC,CAAC,MAErC,CACL,GAAIlB,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzDqB,EAAcD,EAAW,IAAI,CAAClB,EAAOI,IAAU,KAAK,MAAMJ,EAAQF,EAAOM,CAAK,CAAC,CAAC,CAEpF,CACA,OAAOe,CACT,EAEFpC,GACF,CAACmC,EAA+BC,EAAgCrB,EAAkBC,IAClE,CACV,IAAMqB,GAAiB,IAAM,CAC3B,OAAQrB,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAIkB,GAAKnB,EAAOmB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGnB,EAAQ,OAAO,SAAS,EAC1E,IAAK,cACH,OAAOC,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAIkB,GAAKnB,EAAOmB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGnB,EAAQ,OAAO,SAAS,EAC1E,QACE,MAAM,IAAI,MAAM,4BAA4BC,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHD,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMuB,EAAsBH,EAAW,MAAM,EAC7C,OAAInB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAASiB,GAAMlB,EAAOkB,CAAC,EAAII,CAAa,EACxDrB,EAAW,KAAK,QAASiB,GAAMK,EAAoBL,CAAC,EAAI,KAAK,MAAME,EAAWF,CAAC,EAAIlB,EAAOkB,CAAC,CAAC,CAAC,IAE7FlB,EAAO,KAAKsB,EAAe,EAAGtB,EAAO,MAAM,EAC3CuB,EAAoB,QAAQ,CAACL,EAAGC,IAAMI,EAAoBJ,CAAC,EAAI,KAAK,MAAMD,EAAIlB,EAAOmB,CAAC,CAAC,CAAC,GAEnFI,CACT,EAEFrC,GACF,CAACsC,EAAuBJ,EAA+BC,EAAgCrB,EACtFU,IAAmC;AAAA,kEAC0Bc,EAAO,KAAK,OAAO,mBAC7EH,EAAY,MAAM;AAAA,sCACYD,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,uCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACnEnB,EAAO,MAAM,KAAKA,EAAO,IAAImB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+BACvDT,EAAI,MAAM,KAAKA,EAAI,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCACrCE,EAAY,MAAM;AAAA,gCAC1BA,EAAY,MAAM;AAAA,4BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,2EAKhBD,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,OAMtFjC,GACF,CAACsC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2BU,EAAwBgB,IAAsC;AAAA,+DAC/BF,EAAO,KAAK,OAAO,QAAQC,EAAM,KAAK,OAAO;AAAA,wCACpEL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC3DE,EAAY,MAAM,KAAKA,EAAY,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACnEnB,EAAO,MAAM,KAAKA,EAAO,IAAImB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,iCACvDT,EAAI,MAAM,KAAKA,EAAI,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,4BACnDM,EAAM,KAAK,OAAO;AAAA,kCACZJ,EAAY,MAAM;AAAA,8BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+EAMdD,EAAW,MAAM;AAAA,mBAC7EM,CAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAYvBD,EAAM,WAAW,eAAgB,IAAK,YAAY,CAAC;AAAA;AAAA;AAAA,OAKzDrC,GAAoB,CAACqC,EAAsBL,IAA0C;AAAA,yCAClDK,EAAM,KAAK,OAAO;AAAA,sCACrBL,EAAW,MAAM,KAAKA,EAAW,IAAID,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,gCAClEC,EAAW,MAAM;AAAA,2BACtBA,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQjF/B,GACF,CAACoC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2B0B,EAA2BC,IAAuC,CAC5F,GAAM,CAACC,EAAUC,EAAWC,EAAUC,CAAU,EAC5CX,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAKpB,EAAO,CAAC,IAAM,EAAM,CAAC,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,CAAC,EAC9F,MAAO;AAAA;AAAA,0BAEayB,EAAM,KAAK,OAAO;AAAA,qBACvBI,CAAS,uBAAuBT,EAAWS,CAAS,CAAC;AAAA,qBACrDC,CAAQ,uBAAuBV,EAAWU,CAAQ,CAAC;AAAA,YAC5DV,EAAW,MAAM;AAAA,uBACNW,CAAU;AAAA,uBACVH,CAAQ;AAAA;AAAA,qBAEVH,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA;AAAA,8CAGZD,EAAO,KAAK,OAAO;AAAA;AAAA,sCAE3BK,CAAS;AAAA,sCACTC,CAAQ;AAAA,YAClCJ,CAAgB,0BAA0BN,EAAWS,CAAS,CAAC,6BACjET,EAAWU,CAAQ,CAAC;AAAA,iBACbH,CAAkB;AAAA;AAAA,8BAELP,EAAWS,CAAS,CAAC;AAAA,8BACrBT,EAAWU,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOtCV,EAAW,OAAS,CAAC;AAAA,wCACOW,CAAU;AAAA,sCACZH,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAY1C,EAEEtC,GACF,CAACmC,EAAsBD,EAAuBJ,EAA+BC,EAC5ErB,EAA2BU,EAAwBsB,EAAqBN,EACxEC,EAA4BM,IAAoC,CAC/D,GAAM,CAACJ,EAAWC,CAAQ,EAAIV,EAAW,SAAW,EAAI,CAAC,EAAG,CAAC,EAAKpB,EAAO,CAAC,IAAM,EAAO,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAE/FkC,EAAoCC,GAAwB,CAChE,IAAMC,EAAYD,IAAQN,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACJO,CAAS,oCAAoCX,EAAM,KAAK,OAAO,oBAC9DD,EAAO,KAAK,OAAO;AAAA,4BACHH,EAAY,SAAW,EAAI,gBAAkB,iBAAiBc,CAAG,GAAG;AAAA,8FACFnC,EAAOmC,CAAG,CAAC;AAAA,cAC3Fd,EAAYc,CAAG,CAAC,UAAUf,EAAWe,CAAG,CAAC,MAAMzB,EAAIyB,CAAG,CAAC,KAAKzB,EAAIyB,CAAG,CAAC,MAAMf,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,cAI3FM,CAAgB,0CAA0CN,EAAWe,CAAG,CAAC;AAAA,mBACpER,CAAkB;AAAA;AAAA;AAAA;AAAA,gBAIrBS,CAAS;AAAA,gBACTA,CAAS,WAAWA,CAAS,OAAOhB,EAAWe,CAAG,CAAC;AAAA,kBACjDF,CAAc;AAAA;AAAA;AAAA,yBAGPP,CAAgB;AAAA,uBAClBC,CAAkB;AAAA;AAAA,gBAEzBS,CAAS,iBAAiBA,CAAS,KAAKhB,EAAWe,CAAG,CAAC;AAAA;AAAA;AAAA,kCAGrCV,EAAM,KAAK,OAAO;AAAA,6BACvBU,CAAG,WAAWC,CAAS;AAAA,0BAC1BD,IAAQN,EAAY,SAASJ,EAAM,gBAAgB,kBAAkB,CAAC,KAAO;AAAA,uGACA;AAAA;AAAA;AAAA,QAIjG,EAEA,MAAO;AAAA,MACPS,EAAiCL,CAAS,CAAC;AAAA,MAC3CK,EAAiCJ,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAO5BE,CAAW,wBAAwBA,CAAW,yBACxDA,CAAW,yBAAyBA,CAAW;AAAA,oBACrCA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BACzDA,CAAW,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CASfR,EAAO,KAAK,OAAO;AAAA,wBACtCC,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAItC,EAEElC,GACF,CAAC8C,EAAyBpC,EAA8BO,EAAsB8B,EAC7E7B,EAA0B8B,IAA6C,CACtE,IAAMnB,EAAaiB,EAAY,KACzB3B,EAAM3B,GAAUwD,EAAUtC,EAAW,KAAMmB,EAAW,MAAM,EAE9DC,EAAcrC,GAAgBoC,EAAYkB,EAAa7B,EAAOR,EAAW,IAAI,EAC7ED,EAASsC,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzBtC,EAASoB,EAAW,IAAI,CAAClB,EAAOI,IAAUJ,IAAU,EAAI,EAAMmB,EAAYf,CAAK,EAAIJ,CAAK,EACpFD,EAAW,wBAA0B,YACvCoB,EAAcpC,GAAkBmC,EAAYC,EAAarB,EAAQC,CAAU,IAG/E,IAAMuB,EAASgB,EAAe,SAAUH,EAAY,SAAUhB,CAAW,EACnEI,EAAQgB,EAAc,QAASJ,EAAY,SAAUjB,CAAU,EAC/DsB,EAAaC,EAAU,KAAKtB,CAAW,EACvCuB,EAAUxB,EAAW,SAAWC,EAAY,QAAUD,EAAW,MAAM,CAACyB,EAAG1B,IAAM0B,IAAMxB,EAAYF,CAAC,CAAC,EACrGO,EAAmBzB,EAAW,0BAA4B,qBAC1D6C,EAAmBC,GAA+B;AAAA,QACtDlE,GAA2CoB,EAAW,uBAAuB,CAAC;AAAA,SAC7E,IAAM,CACP,OAAQA,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHb,GAAkBqC,EAAOL,CAAU,CAAC;AAAA,gBACpCtC,GAA4BmB,EAAW,YAAaO,CAAY,CAAC;AAAA,gBAEjErB,GACIsC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQU,EAAKgB,CAAgB,CAAC;AAAA,gBAEhF,IAAK,SACH,MAAO;AAAA,gBACHxC,GAA0CsC,EAAQJ,EAAYC,EAAarB,EAAQU,CAAG,CAAC;AAAA,gBAEvFrB,GACIoC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQ0B,EAAkBzB,EAAW,kBAAkB,CAAC;AAAA,gBAE1G,IAAK,QACH,MAAO;AAAA,cAEHX,GACImC,EAAOD,EAAQJ,EAAYC,EAAarB,EAAQU,EAAKT,EAAW,YAAayB,EAC7EzB,EAAW,mBAAoBA,EAAW,cAAc,CAAC;AAAA,cAEnE,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,QACF8C,EAAa,iBAAiBtB,EAAOD,CAAM,CAAC;AAAA,QAC5CuB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,cAC1DE,CAAO;AAAA;AAAA;AAAA,gCAGWpB,EAAO,gBAAgB,YAAY,CAAC;AAAA,8BACtCC,EAAM,KAAK,OAAO;AAAA,aACnC,IAAM,CACX,OAAQxB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,iDAE8BwB,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA,2CAE3CxB,EAAW,kBAAkB;AAAA,qBAE9D,IAAK,SACH,MAAO,6DACT,IAAK,QACH,MAAO,4DACT,QACE,MAAM,MAAM,4BAA4BA,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA;AAAA,SAIJ,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIO,CAAY,IAAIR,EAAO,OAAS,EAAIA,EAAS,EAAE,IAC3ES,EAAM,OAAS,EAAIA,EAAQ,EAAE,EACnC,EACA,gBAAAqC,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMzB,EAAa,SAAUgB,EAAY,QAAQ,CAAC,EAC7D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEElD,GAAuCwD,GAAoC,CAC/E,IAAMC,EAAmBD,EAAQ,iBAGjC,OAF2B,IAAI,YAAYC,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEaxD,GAAS,CAACuD,EAAyB/C,IAAuC,CACrF,IAAMD,EAAmB,CAAC,EACpBS,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EACjBF,EAAehB,GAAoCwD,CAAO,EAChEpE,GAAeoE,EAAQ,OAAQ/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAC3EsC,EAAQ,QACJzD,GAAwByD,EAAQ,OAAO,CAAC,EAAG/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC7G,EAEahB,GAAyBO,GAA0D,CAC9F,IAAMiD,EAAYjD,EAAW,UACvBE,EAAOF,EAAW,KAClBkD,EACFlD,EAAW,wBACT+B,EAAc/B,EAAW,YACzBgC,EAAiBhC,EAAW,iBAA6B,EACzD0B,EAAqB1B,EAAW,mBAChCmD,EAA+CnD,EAAW,sBAC1DoD,EAAapD,EAAW,KAExBc,EAA4Bd,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAOqD,GAA4B,CACjC,UAAAJ,EACA,KAAA/C,EACA,wBAAAgD,EACA,YAAAnB,EACA,eAAAC,EACA,mBAAAN,EACA,sBAAAyB,EACA,KAAAC,EACA,YAAAtC,CACF,CAAC,CACH,ICvjBA,IAeMwC,GAyDAC,GAyFOC,GAoBAC,GArLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,IAAMC,EAAoBD,EAAO,CAAC,EAC5BE,EAAmBF,EAAO,CAAC,EAC3BG,EAAoBH,EAAO,CAAC,EAElC,GAAIC,EAAM,WAAaC,EAAK,UAAYD,EAAM,WAAaE,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIC,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAME,EAAaH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CI,EAAiBJ,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIC,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAME,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAIF,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMG,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIF,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMC,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBN,EAAO,CAAC,EACjC,GAAIM,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMF,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CAEA,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMO,EAAmBP,EAAO,CAAC,EACjC,GAAIO,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMH,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEMb,GACF,CAACS,EAA+BQ,EAAqCC,EAAqBC,IACvE,CACb,IAAMC,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAcH,EACdI,EAAaH,EACbR,EAAaO,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCK,EAAmBN,EAAaC,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrEM,EAAejB,EAAO,OAAS,EAC/BkB,EAAelB,EAAO,OAAS,EAC/BmB,EAAgBT,GAAcD,EAAc,EAC5CW,EAAqBV,GAAcD,EAAc,EACjDY,EAA4BZ,EAAc,EAE1Ca,EAAaC,GAAiBnB,CAAU,EACxCoB,EAAY,CAChBC,EAAc,IAAKzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACjEG,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACpEG,EAAc,QAASzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CACvE,EACIL,GACFO,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAElFJ,GACFM,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAEtFE,EAAU,KAAKE,EAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAChFH,GACFK,EAAU,KAAKE,EAAe,eAA8BV,CAAgB,CAAC,EAE3EI,GACFI,EAAU,KAAKE,EAAe,iBAAgCV,CAAgB,CAAC,EAE7EK,GACFG,EAAU,KAAKE,EAAe,mBAAoB1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAEhG,IAAMK,EAAWC,GAA4B5B,EAAO,CAAC,EAAE,QAAQ,EACzD6B,EAAmBC,GAA+B;AAAA,gCAClC1B,CAAU;AAAA,0CACAA,EAAakB,CAAU;AAAA,6BACpCd,EAAW,OAAO;AAAA;AAAA,QAEvCsB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA;AAAA,QAE3CM,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCf,EAAaX,CAAU,CAAC;AAAA;AAAA,oBAEjE2B,GAAW,MAAOT,CAAU,CAAC;AAAA,0BACvBS,GAAW,MAAOT,CAAU,CAAC;AAAA;AAAA;AAAA,4BAG3BJ,EAAe,UAAY,KAAK;AAAA;AAAA;AAAA,YAGhDG,EAA4B,wCAA0C,EAAE;AAAA;AAAA,2BAEzDW,GAAUL,EAAUL,EAAY,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA,qBAI9CW,GAAU,MAAOX,CAAU,CAAC;AAAA,8BACnBW,GAAU,YAAaX,CAAU,CAAC;AAAA,UACtDH,EAAgB,iCAAmC,EAAE;AAAA,UACrDC,EAAqB,6CAA+C,EAAE;AAAA;AAAA,uDAEzBO,CAAQ,aAAaA,CAAQ;AAAA,eACrEV,EAAe,UAAY,KAAK;AAAA;AAAA,SAG/BiB,EAAU,CAAC,CAAC,KAAMpB,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIS,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMvB,EAAY,SAAUX,EAAO,CAAC,EAAE,QAAQ,CAAC,EAGxD,CACL,KAAM,yBACN,YAAa,CAAC,KAAMQ,EAAW,QAAQ,EACvC,gBAAAqB,EACA,WAAY,KAAO,CAAC,QAAAK,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKnB,EAAaX,EAAa,EAAE,CAAC,CAAC,EAC1F,CACF,EAEKZ,GAAgB,CAAC2C,EAAyB3B,IAA8C,CAGnGlB,GAAe6C,EAAQ,MAAM,EAG7B,IAAMD,EAAU,CAAC,CAAC,EACdC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAK,CAAC,EAEhBC,EAAQ,QACJ5C,GAA+B4C,EAAQ,OAAQ3B,EAAY2B,EAAQ,YAAa,EAAU,EAAG,CAAC,QAAAD,CAAO,CAAC,CAC5G,EAEazC,GAAgCe,GAAiE,CAC5G,IAAM4B,EAAU5B,EAAW,QAC3B,OAAO6B,GAA4B,CAAC,QAAAD,CAAO,CAAC,CAC9C,ICxLA,IAiBME,GAkBAC,GAcAC,GAeAC,GAcAC,GAkBAC,GA2EOC,GAYAC,GAvLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAQMb,GAAiB,CAACc,EAA+BC,IAAsC,CAC3F,GAAI,CAACD,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIC,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7DD,EAAO,MAAM,CAAC,EAAE,QAAQ,CAACE,EAAGC,IAAQ,CAClC,GAAIH,EAAOG,EAAM,CAAC,EAAE,WAAa,GAAkBH,EAAOG,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMhB,GAAY,CAACa,EAA+BG,IAA0B,CAC1E,IAAMC,EAAkB,CAAC,EACzB,GAAIJ,EAAO,OAASG,EAClB,GAAIH,EAAOG,CAAG,EAAE,WAAa,EAC3BH,EAAOG,CAAG,EAAE,iBAAiB,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,UACxDL,EAAOG,CAAG,EAAE,WAAa,EAClCH,EAAOG,CAAG,EAAE,cAAc,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,MAE9D,OAAM,IAAI,MAAM,SAASF,CAAG,qCAAqC,EAGrE,OAAOC,CACT,EAEMhB,GACF,CAACY,EAA+BC,IAAiD,CAC/E,GAAID,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBnB,GAAUa,EAAQ,CAAC,EACtCO,EAAiBpB,GAAUa,EAAQ,CAAC,EACtCQ,EAAiBrB,GAAUa,EAAQ,CAAC,EACxC,OAAIQ,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMR,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCS,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,KACE,QAAOP,CAEX,EAEEZ,GACF,CAACqB,EAAeC,EAAeC,EAA+BJ,EAAyBK,IACzE,CACR,IAAIC,EAAWJ,EAIf,OAHIA,EAAQ,IACVI,GAAYF,EAAWJ,EAAKG,CAAK,CAAC,GAEhCE,EAAMF,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,CAAC,CAAC,CAElE,EAEFrB,GACF,CAACc,EAAsBW,EAAuBH,EAA+BI,IAC/D,2CAA2CD,EAAO,KAAK,OAAO,QAAQX,EAAM,KAAK,OAAO;AAAA,8BAC5EA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAEvBQ,EAAW,MAAM;AAAA,gCACVI,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAOjFJ,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA,SAKpErB,GAAyB,CAACS,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBiB,EAAYC,EAAU,KAAKN,CAAU,EACrCJ,EAAQP,EAAW,KAAK,OAAS,EAAKiB,EAAU,cAAcjB,EAAW,KAAMW,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EAC3EC,EAAQ1B,GAAUa,EAAQ,CAAC,EAC/Ba,EAAM,QAASM,GAASA,IAAS,IAAM,IAAM,CACnB,MAAM,IAAI,MAAM,kBAAkB,CACpC,EAAE,EACtBN,EAAM,SAAW,IACnBA,EAAQ,MAAML,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMF,EAASL,EAAW,OAAO,IAAI,CAACmB,EAAOC,IAAMhC,GAAkB+B,EAAOC,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAEjGN,EAAON,EAAW,KAAK,IAAI,CAACqB,EAAKD,IAAMhC,GAAkBiC,EAAKD,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAE/F,GAAIL,EAAK,SAAWI,EAAW,OAC7B,QAASS,EAAI,EAAGA,EAAIT,EAAW,OAAQ,EAAES,EAClCb,EAAK,SAASa,CAAC,IAClBf,EAAO,OAAOe,EAAG,EAAG,CAAC,EACrBd,EAAK,OAAOc,EAAG,EAAGT,EAAWS,CAAC,CAAC,EAC/BR,EAAM,OAAOQ,EAAG,EAAG,CAAC,GAI1B,IAAME,EAAQV,EAAM,IAAIM,GAAQ,KAAK,KAAKA,CAAI,CAAC,EAE/CN,EAAM,QAAQ,CAACM,EAAME,EAAGG,IAAU,CAChC,GAAIL,EAAO,EAAG,CACZ,IAAMM,GAAYlB,EAAKc,CAAC,EAAIf,EAAOe,CAAC,GAAKF,EACnCO,EAASpB,EAAOe,CAAC,EACjBM,EAAWD,EAASD,EAAWZ,EAAMQ,CAAC,EAC5Cf,EAAOe,CAAC,EAAIM,EACZpB,EAAKc,CAAC,EAAIK,EACVF,EAAMH,CAAC,EAAI,CAACF,CACd,CACF,CAAC,EAED,IAAMH,EAAcJ,EAAW,MAAM,CAAC,EACtCJ,EAAK,QAAQ,CAACoB,EAAM1B,IAAM,CACxBc,EAAYY,CAAI,EAAI,KAAK,MAAMrB,EAAKqB,CAAI,EAAItB,EAAOsB,CAAI,GAAKf,EAAMe,CAAI,CAAC,CACzE,CAAC,EAED,IAAMC,EAA+B,CAAC,KAAMb,EAAa,SAAUhB,EAAO,CAAC,EAAE,QAAQ,EAE/Ee,EAASe,EAAe,SAAU9B,EAAO,CAAC,EAAE,SAAUgB,CAAW,EACjEZ,EAAQ2B,EAAc,QAAS/B,EAAO,CAAC,EAAE,SAAUY,CAAU,EAC7DoB,EAAad,EAAU,KAAKF,CAAW,EAEvCiB,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB9B,EAAOW,CAAM,CAAC;AAAA,mCACjBQ,EAAM,MAAM,KAAKA,EAAM,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACjDf,EAAO,MAAM,KAAKA,EAAO,IAAIe,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACtDd,EAAK,MAAM,KAAKA,EAAK,IAAIc,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,mCAC/CR,EAAM,MAAM,KAAKA,EAAM,IAAIQ,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCAC7CT,EAAW,MAAM,KAAKA,EAAW,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,UAE1F/B,GAA0Bc,EAAOW,EAAQH,EAAYI,CAAW,CAAC;AAAA,UACjEkB,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA,gCAC1CjB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDA,EAAO,YAAY,aAAcX,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,SAE9E,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,GAAGH,EAAW,QAAQ,IAAID,EAAO,CAAC,GAAG,MAAQ,EAAE,EAAE,EACrE,gBAAAiC,EACA,WAAY,KAAO,CACjB,QAAS,CAACJ,CAAgB,EAC1B,cAAe,CAAC,EAAG,KAAK,KAAKZ,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEazB,GAAQ,CAAC2C,EAAyBlC,IAAsC,CACnFf,GAAeiD,EAAQ,OAAQlC,CAAU,EACzC,IAAMmC,EAAoBhD,GAAgC+C,EAAQ,OAAQlC,CAAU,EACpFkC,EAAQ,QAAQ5C,GAAuB4C,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAO1F,EAEa3C,GAAwBQ,GAAyD,CAC5F,IAAMK,EAASL,EAAW,OACpBM,EAAON,EAAW,KAClBO,EAAOP,EAAW,KACxB,OAAOQ,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,IC5LA,IAcM6B,GAUAC,GAuHOC,GAKAC,GApJbC,GAAAC,EAAA,kBAQAC,KACAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMR,GAA2B,CAACS,EAAmBC,IAA+C,CAClG,IAAMC,EAAWC,GAA4BH,EAAM,QAAQ,EACrDI,EAAQJ,EAAM,KACdK,EAAaC,EAAU,KAAKF,CAAK,EACjCG,EAAK,GACPC,EAAOP,EAAW,KAItB,GAHIO,EAAO,IACTA,EAAOJ,EAAM,OAASI,GAEpBA,EAAOJ,EAAM,OAAS,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAG5D,IAAMK,EAAOL,EAAMI,CAAI,EACjBE,EAAOL,EAAaI,EACpBE,EAAaC,GAAiBH,CAAI,EAClCI,EAAaJ,EAAOE,EACpBG,EAAYH,IAAe,EAAIT,EAAW,MAAMS,CAAU,IAAIT,CAAQ,IAEtEa,EAAY,CAACC,EAAcL,IAC3BA,IAAe,EACV,WAAWK,CAAI,OAAOA,CAAI,YAAYA,CAAI,OAAOA,CAAI,OACnDL,IAAe,EACjB,OAAOK,CAAI,OAAOA,CAAI,MACpBL,IAAe,EACjB,WAAWK,CAAI,OAAOA,CAAI,QAAQA,CAAI,MAGxCA,EAIHC,EACFf,IAAa,MAAQ,mBAAmBY,CAAS,oBAAsB,mBAAmBA,CAAS,eA8EvG,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CAAC,QAAS,CAAC,CAAC,KAAMV,EAAO,SAAUJ,EAAM,QAAQ,CAAC,EAAG,cAAe,CAAC,EAAGU,CAAI,CAAC,GAChG,gBAhFuBQ,GAAgC;AAAA,sCACrBJ,CAAS;AAAA,sCACTA,CAAS;AAAA,4CACHA,CAAS,KAAKP,CAAE;AAAA;AAAA,2DAEDO,CAAS;AAAA,sEACEA,CAAS;AAAA;AAAA,4DAEnBA,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKLA,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,iCAKxCP,CAAE;AAAA;AAAA;AAAA;AAAA,qBAIdA,CAAE;AAAA;AAAA,qBAEFM,CAAU;AAAA,iCACEA,CAAU;AAAA;AAAA;AAAA,UAGjCI,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAmBIH,CAAS,IAAIC,EAAU,kBAAmBJ,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,0BAKtDG,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeRA,CAAS,IAAIK,GAAU,kBAAmBR,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAc9E,CACF,EAGanB,GAAU,CAAC4B,EAAyBnB,IAAwC,CACvFX,GAAe8B,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ7B,GAAyB6B,EAAQ,OAAO,CAAC,EAAGnB,CAAU,CAAC,CACzE,EAEaR,GAA0BQ,GACnCoB,GAA4B,CAAC,KAAMpB,EAAW,IAAc,CAAC,ICrJjE,IAgBMqB,GAMAC,GAWAC,GASAC,GAqBAC,GAkDOC,GAOAC,GAxHbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMX,GACF,CAACW,EAA+BC,IAAiD,CAC/E,IAAMC,EAAuB,CAAC,EAC1BC,EAAqBF,EAAW,WACpC,OAAID,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQI,GAAKF,EAAW,KAAK,OAAOE,CAAC,CAAC,CAAC,EACpED,EAAaD,EAAW,QAEnBG,GAA4B,CAAC,WAAAF,EAAY,KAAMF,EAAW,KAAM,WAAAC,CAAU,CAAC,CACpF,EAEEZ,GAA4BgB,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,GAEtBf,GAAuBgB,GAAsC,CACjE,IAAMD,EAAkBC,EAAQ,OAC1BC,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAQE,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,uBAAuBC,CAAC,QAAQC,CAAa,IAAI,EACvDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,4BAA4BC,CAAC,OAAOC,CAAa,IAAI,CAExE,CACA,MAAO;AAAA,uDAC8CH,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACpEC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEMhB,GAAyB,CAACQ,EAA+BC,IAA6C,CAC1G,IAAMU,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAWd,EAAO,CAAC,EAAE,SACrBe,EAAOJ,EAAW,OAClBK,EAAOf,EAAW,KAClBgB,EAAgBD,EAAO,EAAKL,EAAW,OAASK,EAAOA,EACvDT,EAAU,IAAI,MAAqBN,EAAW,UAAU,EACxDiB,EAAQC,EAAc,QAASL,EAAUH,CAAU,EACnDS,EAAmB,IAAI,MAAcnB,EAAW,UAAU,EAC1DoB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9BC,EAAc,EAClB,QAASd,EAAI,EAAGA,EAAIR,EAAW,WAAYQ,IAAK,CAC9Cc,GAAetB,EAAW,WAAWQ,CAAC,EACtCW,EAAiBX,CAAC,EAAIc,EACtB,IAAMC,EAAcb,EAAW,MAAM,EACrCa,EAAYvB,EAAW,IAAI,EAAIA,EAAW,WAAWQ,CAAC,EACtDa,EAAa,KAAKE,CAAW,EAC7BjB,EAAQE,CAAC,EAAIgB,EAAe,SAAShB,CAAC,GAAIK,EAAUQ,EAAab,CAAC,CAAC,EACnEY,EAAkB,KAAK,CAAC,KAAMC,EAAab,CAAC,EAAG,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,CAC9E,CACA,IAAM0B,EAAcX,EAAO,EAAI,UAAY,WAAWE,CAAY,IAC5DU,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiBV,EAAO,GAAGX,CAAO,CAAC;AAAA,wCACZa,EAAiB,MAAM,KAAKA,EAAiB,IAAIX,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GnB,GAAyB8B,EAAiB,MAAM,CAAC;AAAA,IACjD7B,GAAoBgB,CAAO,CAAC;AAAA;AAAA,IAE5BqB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,oBAE/CM,EAAM,gBAAgB,YAAY,CAAC;AAAA,8CACTQ,CAAW;AAAA;AAAA,UAE/CA,CAAW;AAAA;AAAA;AAAA,KAInB,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,gBAAA0B,EACA,WAAY,KAAO,CACjB,QAASN,EACT,cAAe,CAAC,EAAG,KAAK,KAAKT,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEanB,GAAQ,CAACoC,EAAyB5B,IAAsC,CACnFb,GAAeyC,EAAQ,MAAM,EAC7B,IAAMC,EACFD,EAAQ,OAAO,SAAW,EAAI5B,EAAaZ,GAAgCwC,EAAQ,OAAQ5B,CAAU,EACzG4B,EAAQ,QAAQrC,GAAuBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC1F,EAEapC,GAAwBO,GAAyD,CAC5F,IAAMe,EAAOf,EAAW,KAClBC,EAAuBD,EAAW,WAClCE,EAAaF,EAAW,WAAuB,EAAIC,EAAW,OAASD,EAAW,WACxF,GAAIE,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAOG,GAA4B,CAAC,KAAAW,EAAM,WAAAb,EAAY,WAAAD,CAAU,CAAC,CACnE,IChIA,IAUM6B,GAIAC,GAyBAC,GAUOC,GAoCAC,GArFbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAcU,GAChB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAGrDT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAChEA,EAAO,CAAC,EAAE,WAAa,GACzB,MAAM,IAAI,MAAM,uDAAuD,EAGzE,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCX,GAAWW,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMT,GAAiB,CAACU,EAA+BC,IAAkD,CACvG,IAAMC,EAAwB,CAAC,EAE/B,QAASC,EAAI,EAAGA,EAAIH,EAAW,OAAQ,EAAEG,EACvCD,EAAY,KAAKF,EAAWG,CAAC,EAAIF,EAAQE,CAAC,CAAC,EAG7C,OAAOD,CACT,EAEaX,GAAyBQ,GAA+C,CACnF,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAA6Bb,GAAWW,EAAO,CAAC,CAAC,EACjDG,EAAcZ,GAAeU,EAAYC,CAAO,EAChDG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAAWP,EAAO,CAAC,EAAE,SACrBQ,EAAQC,EAAc,QAASF,EAAUN,CAAU,EACnDS,EAASC,EAAe,SAAUJ,EAAUJ,CAAW,EAEvDS,EAAmBC,GAA+B;AAAA,2BAC/BL,EAAM,QAAQ,GAAGP,CAAU,CAAC;AAAA,QAC/CY,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,QAC5CG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,4BAC1CK,EAAO,gBAAgB,YAAY,CAAC;AAAA,0BACtCF,EAAM,KAAK,OAAO;AAAA,4BAChBP,EAAW,MAAM;AAAA,8BACfS,EAAO,WAAW,gBAAiB,GAAG,CAAC,OAAOF,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA;AAAA,UAErGA,EAAM,WAAW,eAAgB,IAAK,eAAe,CAAC;AAAA;AAAA,QAExDE,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,OAG1E,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGN,CAAO,EAAE,EAChC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAO,CACF,CACF,EAEanB,GAAQqB,GAAkC,CACrDxB,GAAewB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtB,GAAsBsB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACtE,ICxFA,IAUMC,GA8DAC,GA+BOC,GAvGbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GACF,CAACQ,EAA4BC,EAA+BC,EAA+BC,EAC1FC,IAAuB,CACtB,IAAMC,EAAaC,EAAU,KAAKJ,CAAU,EACtCK,EAAU,KAAK,KAAKF,EAAa,CAAC,EAElCG,EAASC,EAAe,aAAcL,EAAYF,EAAY,CAAC,EAC/DQ,EAAIC,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEW,EAAID,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEY,EAAIF,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAElEa,EACEC,EAAa,CAACL,EAAWE,EAAWC,IAAc,UAAUD,CAAC,KAAKF,CAAC,KAAKG,CAAC,IAC/E,GAAI,CAACV,EACHW,EAAaN,EAAO,YAChB,aACAO,EAAWL,EAAE,YAAY,YAAY,EAAGE,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAChG,CACL,IAAMG,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IAE9CI,EAAc,oBAAoBJ,CAAC,OAAO,cAAiB,EAAIA,GAAK,CAAE,KAC5E,MAAO;AAAA,+BACcA,CAAC,MAAMV,EAAO,gBAAgB,qBAAqBU,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMR,EAAE,2BAA2B,gBAAgBQ,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAMN,EAAE,2BAA2B,gBAAgBM,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAML,EAAE,2BAA2B,gBAAgBK,CAAC,GAAIV,CAAM,CAAC;AAAA,wBACjEU,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIJ,EAAWK,EAAaC,EAAaC,CAAW,CAAC;AAAA,WAErF,EACIlB,IAAe,EACjBU,EAAa;AAAA;AAAA,cAETE,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCF,EAAa;AAAA,cACTE,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACHhB,EAAa,iBAAiBa,EAAGH,EAAGE,EAAGJ,CAAM,CAAC;AAAA,UAC9CR,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCO,CAAO,CAAC;AAAA,UAC3DO,CAAU;AAAA,QAEhB,EAEErB,GAA4BQ,GAA+C,CAC/E,IAAMsB,EAAQtB,EAAO,CAAC,EAAE,KAClBuB,EAAQvB,EAAO,CAAC,EAAE,KAClBwB,EAAQxB,EAAO,CAAC,EAAE,KAClByB,EAAiBzB,EAAO,CAAC,EAAE,SAE3BE,EAAc,EAAEG,EAAU,SAASiB,EAAOC,CAAK,GAAKlB,EAAU,SAASkB,EAAOC,CAAK,GACrFE,EAAcJ,EACdlB,EAAaC,EAAU,KAAKiB,CAAK,EAGrC,GAAIpB,EAAa,CACf,IAAMyB,EAAkBC,GAAc,UAAUA,GAAc,UAAUN,EAAOC,EAAO,EAAK,EAAIC,EAAO,EAAK,EAC3G,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,6CAA8C,EAEhED,EAAcC,EACdvB,EAAaC,EAAU,KAAKqB,CAAW,CACzC,CAEA,MAAO,CACL,KAAM,QACN,gBAAkB3B,GACdR,GAA2BQ,EAAcC,EAAQ0B,EAAaxB,EAAauB,CAAc,EAC7F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKrB,EAAa,GAA0B,CAAgB,CAAC,CACvF,EACF,CACF,EAEaX,GAASoC,GAAkC,CACtDA,EAAQ,QAAQrC,GAAyBqC,EAAQ,MAAM,CAAC,CAC1D,ICzGA,IAqCaC,GArCbC,GAAAC,EAAA,kBAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAOa9B,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAU+B,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACC,GAAQD,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAE1B,CAAC,cAAe,CAAMC,GAAkBC,EAA0B,CAAC,EACnE,CAAC,UAAW,CAACC,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACC,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUC,GAAeC,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACC,GAAeC,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUC,GAAcC,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWC,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EACnB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACf,GAAMC,EAAmB,CAAC,EACzC,CAAC,SAAU,CAACe,GAAQC,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACC,GAAgBC,EAA6B,CAAC,EAClE,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAMC,GAAwBC,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMC,GAAoBC,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAWC,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWC,EAAc,CAAC,EAC7C,CAAC,wBAAyB,CAACC,GAAcC,EAA2B,CAAC,EACrE,CAAC,qBAAsB,CAACC,GAAWC,EAAwB,CAAC,EAC5D,CAAC,YAAa,CAAUC,GAAoBvB,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWwB,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWC,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EAEnB,CAAC,UAAW,CAAMC,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAACC,GAAKC,EAAkB,CAAC,EACjC,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,QAAS,CAACC,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUC,EAAU,CAAC,EACpC,CAAC,YAAa,CAACC,GAAWC,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACC,GAAYD,EAAqB,CAAC,EAClD,CAAC,YAAa,CAACE,GAAWF,EAAqB,CAAC,EAChD,CAAC,YAAa,CAACG,GAAWH,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACI,GAAYJ,EAAqB,CAAC,EAClD,CAAC,WAAY,CAACK,GAAUL,EAAqB,CAAC,EAC9C,CAAC,WAAY,CAACM,GAAUN,EAAqB,CAAC,EAC9C,CAAC,eAAgB,CAACO,GAAcP,EAAqB,CAAC,EACtD,CAAC,kBAAmB,CAACQ,GAAiBR,EAAqB,CAAC,EAC5D,CAAC,kBAAmB,CAACS,GAAiBT,EAAqB,CAAC,EAC5D,CAAC,OAAQ,CAAUU,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACC,GAAeC,EAA4B,CAAC,EACxE,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAACC,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUC,GAA0BnE,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACoE,EAAI,CAAC,EACf,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAACC,EAAK,CAAC,CACnB,CAAC,ICzHD,IAoBaC,GApBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAYaL,GAAN,KAAqB,CAI1B,YAAoBM,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYC,EAAkC,CAC5C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcC,EAA0B,CAClD,KAAK,KAAK,IAAID,EAAKC,CAAQ,CAC7B,CACA,IAAIC,EAAyBC,EAAyCC,EAClEC,EAAmBC,EAAoBC,EACvCC,EAA0D,CAC5D,IAAMC,EAAS,KAAK,QAAQ,OAEtBC,EAAqB,KAAK,QAAQ,sBAAsB,EAC9DA,EAAmB,YAAYR,EAAc,eAAe,EAC5D,IAAMS,EAAU,CAAC,EACjB,QAAWC,KAASP,EAClBM,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQC,EAAM,MAAM,CAAC,CAAC,EAE1E,QAAWC,KAAUP,EACnBK,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQE,EAAO,MAAM,CAAC,CAAC,EAEvEL,GACFG,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAUH,CAAoB,CAAC,EAExE,IAAMM,EAAYL,EAAO,gBACrB,CAAC,OAAQP,EAAc,gBAAgB,mBAAmB,CAAC,EAAG,QAAAS,EAAS,MAAOT,EAAc,YAAY,IAAI,CAAC,EAOjH,GANAQ,EAAmB,aAAa,EAAGI,CAAS,EAE5CJ,EAAmB,mBAAmB,GAAGH,CAAa,EAEtD,KAAK,QAAQ,wBAET,KAAK,QAAQ,eAAe,EAAG,CAC7B,OAAO,KAAK,QAAQ,UAAc,MACpC,KAAK,QAAQ,UAAY,KAAK,QAAQ,eAAe,OAEjD,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,aAAa,GAE5F,IAAMQ,EAAW,KAAK,QAAQ,eAAe,OAEzC,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,QAAQ,EAErF,KAAK,QAAQ,eAAe,EAC5B,KAAK,QAAQ,kBAAkB,EAAE,gBAAgB,KAAK,QAAQ,SAAU,EAAG,EAAG,KAAK,QAAQ,UAAU,OAAQ,CAAC,EAC9G,KAAK,QAAQ,kBAAkB,EAAE,mBAC7B,KAAK,QAAQ,UAAU,OAAQ,EAAGA,EAAS,OAAQ,EAAG,KAAK,QAAQ,cAAgB,CAAC,EACxF,KAAK,QAAQ,MAAM,EAEnB,IAAMC,EAAW,KAAK,QAAQ,gBACxBC,EAAa,KAAK,QAAQ,QAAQ,IAAID,CAAQ,EAC9CE,EAAa,IAAID,EAAW,CAAC,CAAC,KAAKA,EAAW,CAAC,CAAC,GAEtDF,EAAS,OAAO,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACnD,IAAMI,EAAa,IAAI,eAAeJ,EAAS,OAAO,eAAe,CAAC,EAChEK,EAAeD,EAAW,CAAC,EAC3BE,EAAaF,EAAW,CAAC,EAE/BJ,EAAS,OAAO,MAAM,EAElB,OAAO,KAAK,QAAQ,cAAkB,MACxC,KAAK,QAAQ,cAAgBK,GAG/B,IAAME,EAAY,OAAOF,EAAe,KAAK,QAAQ,aAAa,EAC5DG,EAAU,OAAOF,EAAa,KAAK,QAAQ,aAAa,EAE9D,GAAI,CAAC,OAAO,cAAcC,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAGlD,KAAK,QAAQ,eAAe,QAAQR,EAAS,EAAE,EAC/C,IAAIS,EAAc,GAClBrB,EAAiB,QAAQ,CAACsB,EAAOC,IAAM,CACrCF,GAAe,SAASE,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAIG,EAAe,GACnBxB,EAAkB,QAAQ,CAACqB,EAAOC,IAAM,CACtCE,GAAgB,UAAUF,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IAAI,uBAAuBT,CAAQ,IAAIE,CAAU,KAAKM,CAAW,GAAGI,CAAY,mBACpFL,EAAUD,CAAS,KAAK,CAC9B,CAAC,CACH,CAEI,KAAK,QAAQ,uBAAyB,IACxC,KAAK,QAAQ,MAAM,CAEvB,CACA,SAAgB,CAEhB,CACA,MAAMO,EAA0BC,EAAiE,CAC/F,IAAMrB,EAAS,KAAK,QAAQ,OACtBsB,EAAuB,CAAC,EAC1BtB,EAAO,SAAS,IAAI,YAAY,GAClCsB,EAAW,KAAK,aAAa,EAE/B,IAAMC,EAAeC,GAAmBH,CAA2B,EAC7DI,EAAWL,EAAY,gBAAgBG,CAAY,EACnDG,EAAO,GAAGJ,EAAW,KAAK;AAAA,CAAI,CAAC;AAAA,EAAKC,EAAa,yBAAyB;AAAA,EAAKE,CAAQ,GACvFE,EAAe3B,EAAO,mBAAmB,CAAC,KAAA0B,EAAM,MAAON,EAAY,IAAI,CAAC,EAC9EQ,GAAU,UAAW,IAAM,yBAAyBF,CAAI,EAAE,EAE1D,IAAMG,EAAkB7B,EAAO,sBAC3B,CAAC,QAAS,CAAC,OAAQ2B,EAAc,WAAY,MAAM,EAAG,OAAQ,OAAQ,MAAOP,EAAY,IAAI,CAAC,EAElG,MAAO,CAAC,YAAAA,EAAa,gBAAAS,CAAe,CACtC,CAEA,2BAA2B/B,EACE,CAC3B,IAAMgC,EAAI,OAAOhC,GAAkB,SAAWA,EAAgBA,EAAc,EACtEiC,EAAI,OAAOjC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEkC,EAAI,OAAOlC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEmC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIH,GAAKG,GAAqBF,GAAKE,GAAqBD,GAAKC,EAC3D,MAAO,CAACH,EAAGC,EAAGC,CAAC,EAEjB,IAAME,EAAOJ,EAAIC,EAAIC,EACjBG,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EAC/C,GAAIC,EAAkBF,EAAmB,CAEvC,GADAE,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EACvCC,EAAkBF,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACE,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,IC9JA,IAYMC,GA4CAC,GAmBOC,GA3EbC,GAAAC,EAAA,kBAKAC,KACAC,KACAC,KACAC,KACAC,KAGMT,GACF,CAACU,EAAqCC,IAA2E,CAC/G,GAAIA,EAAkB,SAAWD,EAAa,OAC5C,MAAM,IAAI,MAAM,4BAA4BC,EAAkB,MAAM,wCAChED,EAAa,MAAM,GAAG,EAG5B,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIH,EAAa,OAAQ,EAAEG,EAAG,CAC5C,IAAMC,EAAOJ,EAAaG,CAAC,EAAE,SAC7B,OAAQF,EAAkBE,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAGE,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAOL,EAAaG,CAAC,EAAE,KAAK,OAClCD,EAAW,KAAK,GAAGE,CAAI,IAAIC,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAON,EAAaG,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CD,EAAW,KAAK,GAAGE,CAAI,IAAIE,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCL,EAAkBE,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOD,EAAW,KAAK,GAAG,CAC5B,EASEX,GAA0B,CAACgB,EAA0BP,IAAgD,CAGzG,IAAIQ,EAAMD,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3BC,GAAO,IAAMD,EAAY,YAAY,KAAO,KAE9CC,GAAO,IACHlB,GACIU,EACAO,EAAY,aAAa,mBACrB,IAAI,MAAwCP,EAAa,MAAM,EAAE,KAAK,MAAM,CAAC,CAAC,GACnFQ,CACT,EAMahB,GAAN,KAAoB,CAApB,cAiBL,qBAA+B,KAoC/B,KAAQ,eAAyC,KACjD,KAAQ,mBAAiD,KACzD,2BAAwB,EAIxB,mBAAgB,EAQhB,gCAA4E,IAAI,IAlChF,IAAI,yBAAoD,CACtD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAIiB,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAwBA,MAAM,WAAWC,EAAyB,CACxC,GAAI,CAAC,UAAU,IAEb,MAAM,IAAI,MAAM,yCAAyC,EAG3D,IAAMC,EAAU,MAAM,UAAU,IAAI,eAAe,EACnD,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,KAAK,IAAMD,EACX,IAAME,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAEID,EAAQ,SAAS,IAAI,iBAAiB,GACxCC,EAAiB,KAAK,iBAAiB,EAErCD,EAAQ,SAAS,IAAI,YAAY,GACnCC,EAAiB,KAAK,YAAY,EAGpC,KAAK,OAAS,MAAMD,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,eAAiBC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5BC,GAAgBN,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAoBO,GAAM,CAChCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEA,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAAC,MAAO,KAAK,MAAM,CAAC,CACvE,CAEA,SAAgB,CACV,OAAO,KAAK,SAAa,KAC3B,KAAK,SAAS,QAAQ,EAExB,KAAK,eAAe,QAAQ,CAC9B,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,GAAI,CAAC,KAAK,mBAAoB,CAC5B,IAAMC,EAAkD,CAAC,EACrD,KAAK,eAAe,IAClB,OAAO,KAAK,SAAa,MAC3B,KAAK,SAAW,KAAK,OAAO,eAAe,CACzC,KAAM,YACN,MAAO,KAAK,aACd,CAAC,GAEHA,EAAsB,gBAAkB,CACtC,SAAU,KAAK,SACf,0BAA2B,EAC3B,oBAAqB,CACvB,GAGF,KAAK,mBAAqB,KAAK,kBAAkB,EAAE,iBAAiBA,CAAqB,CAC3F,CACA,OAAO,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACR,KAAK,iBACP,KAAK,eAAe,EACpB,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,kBAAkB,EAAE,OAAO,CAAC,CAAC,EAC5D,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEjC,CAEA,gBAA0B,CACxB,MAAI,QAAK,OAAO,SAAS,IAAI,iBAAiB,GAAK,KAAK,IAAI,OAAO,gBAAkB,UAKvF,CAaA,IAAIC,EAAsBC,EAAyCC,EAC/DC,EACAC,EAAmG,CAErG,IAAMC,EAAwB,CAAC,EAC/B,QAASrB,EAAI,EAAGA,EAAIiB,EAAiB,OAAQ,EAAEjB,EAAG,CAChD,IAAMsB,EAAU,KAAK,eAAe,IAAIL,EAAiBjB,CAAC,EAAE,IAAI,EAChE,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BL,EAAiBjB,CAAC,EAAE,IAAI,EAAE,EAEtEqB,EAAWrB,CAAC,EAAIsB,CAClB,CAGA,IAAMjB,EAAMjB,GAAwB4B,EAASC,CAAgB,EACzDM,EAAW,KAAK,eAAe,YAAYlB,CAAG,EAE5C,CAAC,QAAAmB,EAAS,cAAAC,EAAe,gBAAAC,CAAe,EAAIV,EAAQ,WAAWC,CAAgB,EAG/EU,EAAyBT,EAAc,SAAW,EAAIM,EAAQ,IAAI,CAACI,EAAG5B,IAAMA,CAAC,EAAIkB,EACvF,GAAIS,EAAuB,SAAWH,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAeG,EAAuB,MAAM,qBAAqBH,EAAQ,MAAM,GAAG,EAIpG,IAAMK,EAAkC,CAAC,EACnCC,EAAyB,CAAC,EAChC,QAAS9B,EAAI,EAAGA,EAAIwB,EAAQ,OAAQ,EAAExB,EAAG,CAIvC,GAAI,CAAC,OAAO,UAAU2B,EAAuB3B,CAAC,CAAC,GAAK2B,EAAuB3B,CAAC,EAAI,IAC5E2B,EAAuB3B,CAAC,GAAKwB,EAAQ,OACvC,MAAM,IAAI,MAAM,yBAAyBG,EAAuB3B,CAAC,CAAC,EAAE,EAEtE,GAAI2B,EAAuB3B,CAAC,IAAM,GAChC,SAEF,IAAM+B,EAAcJ,EAAuB3B,CAAC,IAAM,GAC5CgC,EAAeL,EAAuB3B,CAAC,IAAM,GAC7CiC,EAAcF,GAAeC,EAC/BZ,EAAyBI,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAC7DmB,EAAmBQ,EAAuB3B,CAAC,EAAGwB,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAChFsB,EAAU,KAAK,eAAe,IAAIW,EAAW,IAAI,EACvD,GAAI,CAACX,EACH,MAAM,IAAI,MAAM,2BAA2BW,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKT,CAAO,EAE7BU,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKZ,CAAO,CAC7B,CACAO,EAAkB,KAAKI,CAAU,EACjCH,EAAY,KAAKR,CAAO,CAC1B,CAMA,IAAIa,EACJ,GAAIT,EAAiB,CACnB,IAAIU,EAAgB,EAChBC,EAAY,EACVC,EAAoB,CAAC,EACvBC,EAAsB,EAC1Bb,EAAgB,QAAQc,GAAK,CAC3B,IAAMlC,EAAO,OAAOkC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KAEnDC,EACJ,OAAQnC,EAAK,OAAQ,CACnB,IAAK,GACHmC,EAAgB,EAChB,MACF,IAAK,GACHA,EAAgB,EAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,IAAK,GACHA,EAAgB,GAChB,MACF,QACE,MAAM,IAAI,MAAM,4BAA4BnC,EAAK,MAAM,EAAE,CAC7D,EAEI+B,IAAc,GAAKA,IAAc,KACnCI,EAAgB,IAEdA,EAAgBF,IAClBA,EAAsBE,GAExBL,EAAgB,KAAK,KAAKA,EAAgBK,CAAa,EAAIA,EAC3DJ,EAAY/B,EAAK,OACjBgC,EAAQ,KAAKF,CAAa,EAC1BA,GAAiB9B,EAAK,OAAS,CACjC,CAAC,EAED8B,EAAgB,KAAK,KAAKA,EAAgBG,CAAmB,EAAIA,EACjE,IAAMG,EAAc,IAAI,YAAYN,CAAa,EACjDV,EAAgB,QAAQ,CAACc,EAAGxC,IAAM,CAChC,IAAM2C,EAASL,EAAQtC,CAAC,EAClBM,GAAO,OAAOkC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACnDA,EAAE,OAAS,QACb,IAAI,WAAWE,EAAaC,EAAQrC,GAAK,MAAM,EAAE,IAAIA,EAAI,EAChDkC,EAAE,OAAS,SACpB,IAAI,YAAYE,EAAaC,EAAQrC,GAAK,MAAM,EAAE,IAAIA,EAAI,EAE1D,IAAI,aAAaoC,EAAaC,EAAQrC,GAAK,MAAM,EAAE,IAAIA,EAAI,CAE/D,CAAC,EAED,IAAMsC,EAEF,KAAK,eAAe,OAAOR,EAAe,eAAe,SAAW,eAAe,OAAO,EAC9F,KAAK,OAAO,MAAM,YAAYQ,EAAkB,OAAQ,EAAGF,EAAa,EAAGN,CAAa,EACxF,KAAK,eAAe,QAAQQ,EAAkB,EAAE,EAChDT,EAAuB,CAAC,OAAQ,EAAG,KAAMC,EAAe,OAAQQ,EAAkB,MAAM,CAC1F,CAGA,IAAMC,EAA0B,KAAK,eAAe,2BAA2BpB,CAAa,EAE5F,OAAKF,IACHA,EAAW,KAAK,eAAe,MAAMP,EAAS6B,CAAuB,EACrE,KAAK,eAAe,YAAYxC,EAAKkB,CAAQ,GAG/CuB,GACI,OACA,IAAM,yBAAyB9B,EAAQ,IAAI,UAAUX,CAAG,UAAUwC,EAAwB,CAAC,CAAC,IACxFA,EAAwB,CAAC,CAAC,IAAIA,EAAwB,CAAC,CAAC,EAAE,EAClE,KAAK,eAAe,IAChBtB,EAAUN,EAAkBY,EAAmBR,EAAYS,EAAae,EACxEV,CAAoB,EAEjBN,CACT,CAEA,OAAOkB,EAAmBzC,EAAwB,CAChD,KAAK,eAAe,OAAOyC,EAAWzC,CAAI,CAC5C,CAEA,OAAO0C,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBG,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASH,EAAWG,CAAe,CAC/D,CAEA,MAAMC,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKC,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAaC,EAAgBC,EAAkBC,EAAoBC,EAAwB,CACzF,IAAMC,EAAKC,GAAwB,IAAIL,CAAM,EAC7C,GAAI,CAACI,EACH,MAAM,IAAI,MAAM,2BAA2BJ,CAAM,EAAE,EAGrD,KAAK,QAAQ,IAAIC,EAAU,CAACD,EAAQG,EAAUC,EAAG,CAAC,EAAG,CAACA,EAAG,CAAC,EAAGF,CAAS,CAAC,CAAC,CAC1E,CAEA,cAAcD,EAAwB,CACpC,IAAMpB,EAAiB,KAAK,qBAAqB,IAAIoB,CAAQ,EAC7D,GAAIpB,EAAgB,CAClB,QAAW5B,KAAQ4B,EACjB,KAAK,eAAe,QAAQ5B,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAOgD,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBK,EAAyBC,EAA6C,CACpG,IAAMC,EAAS,KAAK,QAAQ,IAAIP,CAAQ,EACxC,GAAI,CAACO,EACH,MAAM,IAAI,MAAM,uBAAuBP,CAAQ,EAAE,EAEnD,GAAM,CAACD,EAAQG,EAAUM,EAAaC,CAAU,EAAIF,EACpD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYR,CAAM,KAAKG,CAAQ,2CAA2C,EAE5F,KAAK,gBAAkBF,EAGnBS,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBjB,GAAU,OAAQ,IAAM,kCAAkCO,CAAM,KAAKG,CAAQ,MAAM,EAEnF,IAAMQ,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCF,EAAYH,EAASI,EAAW,CAAC,CAAC,EAC3B,CACT,OAASE,EAAG,CACV,OAAAL,EAAO,KAAK,QAAQ,QAAQ,qBAAqBP,CAAM,KAAKG,CAAQ,aAAaS,CAAC,EAAE,CAAC,EAC9E,CACT,QAAE,CACID,GACFJ,EAAO,KAAK,KAAK,OAAO,cAAc,EAAE,KACpCM,GAAOA,EAAM,qCAAqCb,CAAM,KAAKG,CAAQ,MAAMU,EAAI,OAAO,GAAK,IAAI,CAAC,EAGtG,QAAW5D,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAe6D,EAAmBC,EAAeC,EAAmBlB,EAAsB,CACxF,IAAImB,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EACxEG,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAIH,EAAWG,CAAyB,GAG1E,IAAMC,EAAiBD,EAA0B,IAAIF,CAAK,EACpDI,EAAK,KAAK,eAAe,uBAAuBH,EAAQlB,EAAMoB,IAAiB,CAAC,CAAC,EACvF,OAAAD,EAA0B,IAAIF,EAAO,CAACI,EAAIH,CAAM,CAAC,EAC1CG,CACT,CACA,kBAAkBL,EAAyB,CACzC,IAAMG,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EAC3EG,IACFA,EAA0B,QAAQG,GAAc,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC3G,KAAK,2BAA2B,OAAON,CAAS,EAEpD,CACA,UAAUpB,EAA8B,CACtC,IAAMzB,EAAU,KAAK,eAAe,IAAIyB,CAAS,EACjD,GAAI,CAACzB,EACH,MAAM,IAAI,MAAM,2BAA2ByB,CAAS,EAAE,EAExD,OAAOzB,EAAQ,MACjB,CACA,iBAAiBoD,EAAsBvB,EAAclD,EAClB,CACjC,MAAO,UAAY,CACjB,IAAMK,EAAO,MAAMqE,GAAgB,KAAMD,EAAWvB,CAAI,EACxD,OAAOyB,GAAWtE,EAAK,OAAQL,CAAI,CACrC,CACF,CAEF,ICtiBA,IAAA4E,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAgBMC,GAuCAC,GA6EOF,GApIbG,GAAAC,EAAA,kBAMAC,KAEAC,KACAC,KAEAC,KAKMP,GAAN,MAAMQ,CAAqC,CACzC,YACYC,EAAuCC,EAAkCC,EACjEC,EAAyB,CADjC,YAAAH,EAAuC,cAAAC,EAAkC,UAAAC,EACjE,UAAAC,CAA0B,CAE9C,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMC,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CAChG,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjG,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,QAAQE,EAAwC,CAC9C,GAAID,EAAU,KAAKC,CAAO,IAAMD,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAIN,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMO,CAAO,CAC1E,CACF,EAEMd,GAAN,KAAmD,CAYjD,YAAoBQ,EAA+BO,EAAwBC,EAA2B,CAAlF,YAAAR,EAA+B,aAAAO,EAFnD,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAEvB,IAAME,EAAUT,EAAO,QAGnBU,EAAaF,GAAqB,EACtC,KAAK,gBAAkBC,EAAQC,GAAW,EAC1C,IAAMC,EAAaF,EAAQC,GAAW,EACtC,KAAK,YAAcD,EAAQC,GAAW,EACtC,KAAK,iBAAmBD,EAAQC,GAAW,EAC3C,KAAK,eAAiBD,EAAQC,GAAW,EAEzC,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIF,EAAYE,IAAK,CACnC,IAAMZ,EAAWQ,EAAQC,GAAW,EAC9BR,EAAOO,EAAQC,GAAW,EAC1BI,EAAML,EAAQC,GAAW,EACzBP,EAAiB,CAAC,EACxB,QAASY,EAAI,EAAGA,EAAID,EAAKC,IACvBZ,EAAK,KAAKM,EAAQC,GAAW,CAAC,EAEhCE,EAAO,KAAK,IAAIrB,GAAeS,EAAQC,EAAUC,EAAMC,CAAI,CAAC,CAC9D,CACA,KAAK,OAASS,CAChB,CA/BA,IAAI,kBAA6C,CAC/C,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CA4BA,QAAQI,EAAsBC,EAAyE,CAErG,IAAMC,EACFD,GAAsB,QAAQ,IAAIJ,GAAK,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAC,GAAK,KAAK,OAEzFM,EAAgBF,GAAsB,SAAW,CAAC,EAClDG,EAAqB,CAACC,EAAepB,EAAkBE,IACzD,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,OAAOoB,EAAOlB,CAAI,EAAGA,CAAI,EACtEmB,EAAwB,CAACrB,EAAkBE,IAAwC,CACvF,IAAMoB,EAAcC,GAAqBvB,CAAQ,EACjD,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BtB,CAAQ,EAAE,EAEtD,IAAMwB,EAAaF,EAAclB,EAAU,KAAKF,CAAI,EACpD,OAAO,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,QAAQ,eAAe,OAAOwB,CAAU,EAAE,GAAItB,CAAI,CAC1G,EACA,OAAO,KAAK,QAAQ,IAAIa,EAASE,EAAcC,EAAeC,EAAoBE,CAAqB,CACzG,CAEA,OAAOD,EAAelB,EAAiC,CACrD,IAAMuB,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMxB,EAAO,KAAK,OAAO,YAAY,EAAIC,EAAK,QAAU,CAAsB,EAC1EwB,EAASzB,GAAQ,EACrB,KAAK,OAAO,QAAQyB,GAAQ,EAAIxB,EAAK,OACrC,QAASU,EAAI,EAAGA,EAAIV,EAAK,OAAQU,IAC/B,KAAK,OAAO,QAAQc,GAAQ,EAAIxB,EAAKU,CAAC,EAExC,OAAO,KAAK,OAAO,YAAY,KAAK,gBAAiBQ,EAAOnB,CAAI,CAClE,OAAS0B,EAAG,CACV,MAAM,IAAI,MACN,sCAAsCP,CAAK,gBAAgBlB,CAAI,8GAErDyB,CAAC,EAAE,CACnB,QAAE,CACA,KAAK,OAAO,aAAaF,CAAK,CAChC,CACF,CACF,EAEapC,GAAO,MAAMU,EAAuB6B,IAA4B,CAC3E,IAAMvC,EAAOU,EAAO,SACpB,GAAIV,GAAQ,UAAU,IAAK,CACzB,GAAI,CAACuC,EAAI,KAAK,KACZ,MAAM,IAAI,MACN,mGAAmG,EAEzG,IAAMtB,EAAU,IAAIuB,GACpB,MAAMvB,EAAQ,WAAWsB,CAAG,EAE5BvC,EAEIiB,EAGCwB,GAAiBxB,EAAQ,MAAMwB,CAAI,EAGnCC,GAAgBzB,EAAQ,KAAKyB,CAAG,EAGjC,CAACC,EAAaC,EAAaH,EAAcI,EAAc,KAAU,CAC/D,GAAIA,EACFC,GAAU,UAAW,IAAM,kCAAkCH,CAAG,SAASC,CAAG,UAAUH,CAAI,EAAE,EAC5FxB,EAAQ,OAAO0B,EAAKC,CAAG,MAClB,CACLE,GAAU,UAAW,IAAM,yCAAyCH,CAAG,eAAeC,CAAG,UAAUH,CAAI,EAAE,EACzG,IAAM7B,EAAOF,EAAO,OAAO,SAASiC,EAAKA,EAAMF,CAAI,EACnDxB,EAAQ,OAAO2B,EAAKhC,CAAI,CAC1B,CACF,EAGA,MAAMmC,EAAmBC,EAAoBP,IACxB,CACfK,GACI,UACA,IAAM,wCAAwCC,CAAS,gBAAgBC,CAAU,UAAUP,CAAI,EAAE,EAErG,MAAMxB,EAAQ,SAAS8B,EAAW,IAAMrC,EAAO,OAAO,SAASsC,EAAYA,EAAaP,CAAI,CAAC,CAC/F,EAGJ,CAACQ,EAAcC,EAAgBC,IAAuBlC,EAAQ,aAC1DgC,EAAMC,EAAQC,EACdZ,EAAI,OAASA,EAAI,OAAO,gBAAkB,UAAY7B,EAAO,aAAaA,EAAO,iBAAiBwC,CAAM,CAAC,EACnD,GAAGA,CAAM,EAAE,EAGpEA,GAAmBjC,EAAQ,cAAciC,CAAM,EAGhD,CAACA,EAAgBhC,EAA2BkC,EAAuBC,IAAwC,CACzGP,GACI,UACA,IAAM,mCAAmCM,CAAa,YAAYF,CAAM,uBACpEhC,CAAiB,EAAE,EAC3B,IAAMoC,EAAU,IAAIpD,GAAmBQ,EAAQO,EAASC,CAAiB,EACzE,OAAOD,EAAQ,cAAciC,EAAQI,EAASD,CAAM,CACtD,CAAC,CACP,CACF,ICjMA,IAYIE,GAOEC,GAoBAC,GAWOC,GA+CPC,GAEOC,GAMAC,GAgBAC,GA+FAC,GAMAC,GAoBAC,GAqEAC,GA6NAC,GAgBAC,GApiBbC,GAAAC,EAAA,kBAMAC,KACAC,KACAC,KACAC,KACAC,KAEIpB,GAAoB,GAOlBC,GAA8BoB,GAA4C,CAC9E,IAAMC,EAAOC,GAAY,EACnBC,EAAQF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMG,EAAaH,EAAK,WAAW,CAAC,EAEpC,OADkBA,EAAK,wBAAwBD,EAAeI,EAAYA,EAAa,CAAC,IACtE,GAChBC,GAAe,uCAAwC,EAElD,CAACJ,EAAK,OAAOG,EAAa,CAAC,EAAGH,EAAK,OAAOG,EAAa,EAAI,CAAC,CAAC,CACtE,QAAE,CACAH,EAAK,aAAaE,CAAK,CACzB,CACF,EAOMtB,GAAU,CAACyB,EAAoBC,IAA+B,CAChDL,GAAY,EAAE,SAASI,EAAYC,CAAY,IAC/C,GAChBF,GAAe,+BAAgC,CAEnD,EAMavB,GAAc,MAAM0B,GAA4B,CAE3D3B,GAAQ2B,EAAI,KAAK,WAAaC,GAAqBD,EAAI,QAAQ,CAAC,EAEhC,CAI9B,IAAME,EAAW,cAAuB,KACxC,MAAMA,EAASR,GAAY,EAAGM,CAAG,CACnC,CAEA7B,GAAoB,EACtB,EAkCMI,GAAiB,IAAI,IAEdC,GAAsB,IAAeL,GAMrCM,GAAyB0B,GAAwC,CAC5E,IAAMV,EAAOC,GAAY,EACnBU,EAAkBX,EAAK,QAAQU,EAAM,UAAU,EACrD,GAAIC,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DD,EAAM,UAAU,GAAG,EAEpG,OAAAV,EAAK,OAAO,IAAIU,EAAOC,CAAe,EAC/B,CAACA,EAAiBD,EAAM,UAAU,CAC3C,EAQazB,GACT,CAAC2B,EAAkCC,IAA2E,CAC5G,IAAMb,EAAOC,GAAY,EAErBF,EAAgB,EAChBe,EAAuB,EACvBC,EAAkB,EAClBC,EAAmB,CAAC,EAClBC,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CACF,CAACJ,EAAsBE,CAAM,EAAIG,GAAkBN,CAAO,EAE1Dd,EAAgBC,EAAK,kBAAkBY,EAAU,CAAC,EAAGA,EAAU,CAAC,EAAGE,CAAoB,EACnFf,IAAkB,GACpBK,GAAe,yBAA0B,EAG3C,GAAM,CAACgB,EAAYC,CAAW,EAAI1C,GAA2BoB,CAAa,EAEpEuB,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAIL,EAAYK,IAAK,CACnC,IAAMC,EAAO1B,EAAK,iBAAiBD,EAAe0B,CAAC,EAC/CC,IAAS,GACXtB,GAAe,0BAA2B,EAE5Ca,EAAsB,KAAKS,CAAI,EAC/BJ,EAAW,KAAKtB,EAAK,aAAa0B,CAAI,CAAC,CACzC,CACA,QAASD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMC,EAAO1B,EAAK,kBAAkBD,EAAe0B,CAAC,EAChDC,IAAS,GACXtB,GAAe,2BAA4B,EAE7Cc,EAAuB,KAAKQ,CAAI,EAChC,IAAMC,EAAa3B,EAAK,aAAa0B,CAAI,EACzCH,EAAY,KAAKI,CAAU,EAEK,CAC9B,IAAMC,EAAW,OAAOf,GAAS,yBAA4B,SACzDA,EAAQ,wBACRA,GAAS,0BAA0Bc,CAAU,GAAK,MACtD,GAAIC,IAAa,OAASA,IAAa,cAAgBA,IAAa,aAClE,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzEJ,EAAyB,KAAKI,CAAQ,CACxC,CACF,CAGA,IAAIC,EAAoC,KACxC,OAAkCL,EAAyB,KAAKM,GAAKA,IAAM,YAAY,IACrFf,EAAkBf,EAAK,kBAAkBD,CAAa,EAClDgB,IAAoB,GACtBX,GAAe,0BAA2B,EAG5CyB,EAAe,CACb,OAAQd,EACR,yBAAAS,EACA,gCAAiCA,EAAyB,IAAIM,GAAKC,GAAyBD,CAAC,CAAC,CAChG,GAGFhD,GAAe,IAAIiB,EAAe,CAACA,EAAekB,EAAuBC,EAAwBW,CAAY,CAAC,EACvG,CAAC9B,EAAeuB,EAAYC,CAAW,CAChD,OAASS,EAAG,CACV,MAAAf,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EAEpDlB,IAAoB,GACtBf,EAAK,mBAAmBe,CAAe,EAGrChB,IAAkB,GACpBC,EAAK,mBAAmBD,CAAa,EAEjCiC,CACR,QAAE,CACAhC,EAAK,MAAMY,EAAU,CAAC,CAAC,EACnBE,IAAyB,GAC3Bd,EAAK,0BAA0Bc,CAAoB,EAErDE,EAAO,QAAQkB,GAASlC,EAAK,MAAMkC,CAAK,CAAC,CAC3C,CACF,EAOShD,GACT,CAACwB,EAAmBG,IAA2E,CAC7F,IAAMD,EAAmC5B,GAAsB0B,CAAK,EACpE,OAAOzB,GAAsB2B,EAAWC,CAAO,CACjD,EAES1B,GAAkBgD,GAA4B,CACzD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+CAA+CD,CAAS,EAAE,EAE5E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEnFC,GACFrC,EAAK,mBAAmBqC,EAAe,MAAM,EAG/CrC,EAAK,wBAAwBmC,CAAS,EAEtClB,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACxDjC,EAAK,mBAAmBD,CAAa,EACrCjB,GAAe,OAAOqD,CAAS,CACjC,EAEa/C,GACT,CAACkD,EAA6BC,EAAyBvB,EAAkBmB,EAAmBK,IAChF,CACN,GAAI,CAACF,EAAQ,CACXC,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMvC,EAAOC,GAAY,EAEnBwC,EAAWH,EAAO,CAAC,EACnBI,EAAOJ,EAAO,CAAC,EACfV,EAAWU,EAAO,CAAC,EAErBK,EACAC,EAEJ,GAAIH,IAAa,UAAYb,IAAa,aACxC,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,IAAa,aAAc,CAC7B,IAAMiB,EAAYP,EAAO,CAAC,EAAE,UACtBQ,EAAqBC,GAAqBC,GAA2BP,CAAQ,CAAC,EACpFG,EAAiBF,EAAK,OAAO,CAACO,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIJ,EACnDH,EAAU3C,EAAK,mBAAmBmC,EAAWK,EAAOK,EAAWD,CAAc,CAC/E,KAAO,CACL,IAAMO,EAAOb,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQa,CAAI,EAAG,CAEvBP,EAAiB,EAAIO,EAAK,OAC1BR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB,IAAIS,EAAYT,EAAU,EAC1B,QAASlB,EAAI,EAAGA,EAAI0B,EAAK,OAAQ1B,IAAK,CACpC,GAAI,OAAO0B,EAAK1B,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjEzB,EAAK,QAAQoD,GAAW,EAAIC,GAAgBF,EAAK1B,CAAC,EAAGT,CAAM,CAC7D,CACF,MACE4B,EAAiBO,EAAK,WACtBR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB3C,EAAK,OAAO,IAAI,IAAI,WAAWmD,EAAK,OAAQA,EAAK,WAAYP,CAAc,EAAGD,CAAO,CAEzF,CAEA,IAAMzC,EAAQF,EAAK,UAAU,EACvBsD,EAAatD,EAAK,WAAW,EAAI0C,EAAK,MAAM,EAClD,GAAI,CACF,IAAIa,EAAWD,EAAa,EAC5BZ,EAAK,QAAQc,GAAKxD,EAAK,OAAOuD,GAAU,EAAIC,CAAC,EAC7C,IAAMlB,EAAStC,EAAK,iBAChBgD,GAA2BP,CAAQ,EAAGE,EAASC,EAAgBU,EAAYZ,EAAK,OAChFX,GAAyBH,CAAQ,CAAC,EAClCU,IAAW,GACblC,GAAe,iDAAiD+B,CAAS,WAAWK,CAAK,GAAG,EAE9FD,EAAc,KAAKD,CAAM,CAC3B,QAAE,CACAtC,EAAK,aAAaE,CAAK,CACzB,CACF,EAKKb,GAAM,MACf8C,EAAmBsB,EAAwBC,EAAgCC,EAC3EC,EAA2C/C,IAAoE,CACjH,IAAMb,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,6CAA6CD,CAAS,EAAE,EAE1E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEjFhB,EAAaqC,EAAa,OAC1BpC,EAAcsC,EAAc,OAE9BE,EAAmB,EACnBC,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBlE,EAAK,UAAU,EAChCmE,EAAoBnE,EAAK,WAAWoB,EAAa,CAAC,EAClDgD,EAAmBpE,EAAK,WAAWoB,EAAa,CAAC,EACjDiD,EAAqBrE,EAAK,WAAWqB,EAAc,CAAC,EACpDiD,EAAoBtE,EAAK,WAAWqB,EAAc,CAAC,EAEzD,GAAI,CACF,CAACwC,EAAkBC,CAAgB,EAAIS,GAAc1D,CAAO,EAG5D,QAASY,GAAI,EAAGA,GAAIL,EAAYK,KAC9BrC,GAAyBsE,EAAajC,EAAC,EAAGsC,EAAoBE,EAAmB9B,EAAWsB,EAAahC,EAAC,CAAC,EAI7G,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BrC,GACIwE,EAAcnC,EAAC,EAAGuC,EAAqBC,EAAmB9B,EAAWf,EAAauC,EAAclC,EAAC,CAAC,EAGxG,IAAI+C,EAAmBL,EAAoB,EACvCM,EAAkBL,EAAmB,EACrCM,GAAoBL,EAAqB,EACzCM,EAAmBL,EAAoB,EAC3C,QAAS7C,GAAI,EAAGA,GAAIL,EAAYK,KAC9BzB,EAAK,QAAQwE,GAAkB,EAAIT,EAAmBtC,EAAC,EACvDzB,EAAK,QAAQyE,GAAiB,EAAIxD,EAAsBwC,EAAahC,EAAC,CAAC,EAEzE,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BzB,EAAK,QAAQ0E,IAAmB,EAAIV,EAAoBvC,EAAC,EACzDzB,EAAK,QAAQ2E,GAAkB,EAAIzD,EAAuByC,EAAclC,EAAC,CAAC,EAG5E,GAAkCY,EAAgB,CAChD,GAAM,CAAC,OAAAuC,GAAQ,yBAAApD,GAA0B,gCAAAqD,CAA+B,EAAIxC,EAE5E,GAAIpB,EAAsB,SAAWG,EACnC,MAAM,IAAI,MAAM,2BACZA,CAAU,4DAA4DH,EAAsB,MAAM,IAAI,EAI5G,QAASQ,GAAI,EAAGA,GAAIL,EAAYK,KAAK,CACnC,IAAMe,GAAQiB,EAAahC,EAAC,EACV,MAAMzB,EAAK,cAAc4E,GAAQ3D,EAAsBuB,EAAK,EAAGuB,EAAmBtC,EAAC,CAAC,IACpF,GAChBrB,GAAe,oBAAoBqB,EAAC,iBAAiBU,CAAS,GAAG,CAErE,CAGA,QAASV,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMe,GAAQmB,EAAclC,EAAC,EACZmC,EAAcnC,EAAC,IAAI,CAAC,EAIjBzB,EAAK,eAAe4E,GAAQ1D,EAAuBsB,EAAK,EAAGwB,EAAoBvC,EAAC,EAAG,CAAC,IACpF,GAChBrB,GAAe,mCAAmCqB,EAAC,iBAAiBU,CAAS,GAAG,EAK9EnC,EAAK,eAAe4E,GAAQ1D,EAAuBsB,EAAK,EAAG,EAAGqC,EAAgCrC,EAAK,CAAC,IACtF,GAChBpC,GAAe,qBAAqBqB,EAAC,QAAQD,GAAyBC,EAAC,CAAC,gBAAgBU,CAAS,GAAG,CAG1G,CACF,CAEA,IAAI2C,EAE8BzC,EAChCyC,EAAY,MAAM9E,EAAK,mBACnBD,EAAesC,EAAe,OAAQhB,EAAagD,EAAoBR,CAAgB,EAE3FiB,EAAY,MAAM9E,EAAK,QACnBD,EAAeqE,EAAkBD,EAAmB/C,EAAYkD,EAAmBjD,EACnFgD,EAAoBR,CAAgB,EAGtCiB,IAAc,GAChB1E,GAAe,0BAA0B,EAG3C,IAAM2E,GAA2B,CAAC,EAElC,QAAStD,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMa,GAAStC,EAAK,QAAQqE,EAAqB,EAAI5C,EAAC,EACtD,GAAIa,KAAW0B,EAAoBvC,EAAC,EAAG,CAErCsD,GAAO,KAAKnB,EAAcnC,EAAC,CAAE,EAC7B,QACF,CAEA,IAAMuD,EAA2BhF,EAAK,UAAU,EAE1CiF,GAAmBjF,EAAK,WAAW,EAAI,CAAC,EAE1CkF,GAAmB,GACnBC,GAA6BhF,GAAa,EAC9C,GAAI,CACgBH,EAAK,kBACnBsC,GAAQ2C,GAAkBA,GAAmB,EAAGA,GAAmB,EAAGA,GAAmB,EAAE,IAC7E,GAChB7E,GAAe,4CAA4CqB,EAAC,GAAG,EAEjE,IAAI2D,GAAkBH,GAAmB,EACnCxC,GAAWzC,EAAK,QAAQoF,IAAiB,EAC/CjF,GAAaH,EAAK,QAAQoF,IAAiB,EAC3C,IAAM9B,EAAatD,EAAK,QAAQoF,IAAiB,EAC3CC,GAAarF,EAAK,QAAQoF,IAAiB,EAC3C1C,GAAO,CAAC,EACd,QAASjB,GAAI,EAAGA,GAAI4D,GAAY5D,KAC9BiB,GAAK,KAAK1C,EAAK,QAAQsD,EAAa,EAAI7B,EAAC,CAAC,EAE5CzB,EAAK,SAASsD,CAAU,EAExB,IAAMgC,GAAO5C,GAAK,OAAO,CAACO,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3CiC,GAAOI,GAA2B9C,EAAQ,EAE1C,IAAM+C,GAAoBnD,GAAgB,yBAAyBsB,EAAclC,EAAC,CAAC,EAEnF,GAAI0D,KAAS,SAAU,CACrB,GAAIK,KAAsB,aACxB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC1BrC,GAAYjD,GAAa,EAC7B,QAASsB,GAAI,EAAGA,GAAI6D,GAAM7D,KAAK,CAC7B,IAAMiE,GAAS1F,EAAK,QAAQoD,IAAW,EACjCuC,GAAiBlE,KAAM6D,GAAO,EAAI,OAAYtF,EAAK,QAAQoD,EAAS,EAAIsC,GAC9ED,GAAW,KAAKzF,EAAK,aAAa0F,GAAQC,EAAc,CAAC,CAC3D,CACAZ,GAAO,KAAK,CAACI,GAAMzC,GAAM+C,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBF,GAAO,EAAG,CAClD,IAAMzC,GAAY7C,EAAK,cAAcG,EAAU,EACzCyF,GAAc7C,GAAqBN,EAAQ,EACjD,GAAImD,KAAgB,QAAa,CAACC,GAAyBV,EAAI,EAC7D,MAAM,IAAI,MAAM,0BAA0BA,EAAI,EAAE,EAIlDD,GAAmB,GAEnBH,GAAO,KAAK,CACVI,GAAMzC,GAAM,CACV,UAAAG,GACA,SAAU7C,EAAK,qBAAqB6C,GAAWyC,GAAOM,GAAaT,EAAI,EACvE,QAAS,IAAM,CACbnF,EAAK,kBAAkBsC,EAAM,CAC/B,CACF,EACA,YACF,CAAC,CACH,KAAO,CACL,IAAMwD,GAAwBC,GAAkCZ,EAAI,EAC9DhC,GAAO,IAAI2C,GAAsBR,EAAI,EAC3C,IAAI,WAAWnC,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EACvD,IAAInD,EAAK,OAAO,SAASG,GAAYA,GAAagD,GAAK,UAAU,CAAC,EACvE4B,GAAO,KAAK,CAACI,GAAMzC,GAAMS,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACAnD,EAAK,aAAagF,CAAwB,EACtCG,KAAS,UAAYhF,IACvBH,EAAK,MAAMG,EAAU,EAElB+E,IACHlF,EAAK,kBAAkBsC,EAAM,CAEjC,CACF,CAEA,OAAID,GACFrC,EAAK,sBAAsBqC,EAAe,MAAM,EAG3C0C,EACT,QAAE,CACA/E,EAAK,aAAakE,CAAc,EAEhCH,EAAmB,QAAQiC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EACzDhC,EAAoB,QAAQgC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EAC1D/B,EAAkB,QAAQgC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,EAExCpC,IAAqB,GACvB7D,EAAK,sBAAsB6D,CAAgB,EAE7CC,EAAiB,QAAQmC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,CAC7C,CACF,EAKa3G,GAAgB6C,GAA4B,CACvD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMrC,EAAgBqC,EAAQ,CAAC,EAGzB8D,EAAkBlG,EAAK,iBAAiBD,CAAa,EACvDmG,IAAoB,GACtB9F,GAAe,iCAAkC,EAEnDJ,EAAK,SAASkG,CAAe,CAC/B,EAEa3G,GAA8B4G,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAW9D,KAAU6D,EAAS,CAC5B,IAAMhD,EAAOb,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQa,CAAI,GAAK,WAAYA,GACtCiD,EAAQ,KAAKjD,EAAK,MAAM,CAE5B,CACA,OAAOiD,CACT,IC7iBA,IAAAC,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,kkxPCAA,IASMC,GACFC,GACAC,GACAC,GACAC,GAKAC,GACAC,GACEC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GAEAC,GAMAC,GAwEAC,GAEOC,GA6CAC,GAaAC,GAaAC,GAcAC,GAkBAC,GAaAC,GAyBAC,GAaAC,GAtQbC,GAAAC,EAAA,kBAGAC,KAGAC,KACAC,KAEM9B,GAAU,IAAe,CAAC,CAAC+B,GAAI,KAAK,OAAS,OAAO,SAAa,IAEnE7B,GAAe,GACfC,GAAc,GACdC,GAAU,GAORG,GAAiF,CAAC,EAClFC,GAAuF,CAAC,EACxFC,GAA+E,CAAC,EAChFC,GAAyD,CAAC,EAC1DC,GAAsE,CAAC,EACvEC,GAAuD,CAAC,EACxDC,GAAiE,CAAC,EAElEC,GAAe,IAAY,CAC/B,GAAIZ,IAAgB,CAACC,IAAeC,IAAW,CAACH,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMc,GAAwBiB,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACH9B,GAAe,GACX8B,EAAG,KAAK,KACV5B,GAAU,GACVC,GAAkB,CAAC,EAAE2B,EAAG,KAAK,GAAG,IAEhC7B,GAAc,GACdE,GAAkB,CAAC,EAAE,GAEvB,MACF,IAAK,WACC2B,EAAG,KAAK,IACV1B,GAAiB,CAAC,EAAE0B,EAAG,KAAK,GAAG,EAE/B1B,GAAiB,CAAC,EAAE,EAEtB,MACF,IAAK,kBACC0B,EAAG,KAAK,IACVzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAG,EAEtDzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,kBACCA,EAAG,KAAK,IACVxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAG,EAEtDxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,SACCA,EAAG,KAAK,IACVvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAG,EAE9CvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAI,EAEjD,MACF,IAAK,UACCA,EAAG,KAAK,IACVtB,GAAwB,MAAM,EAAG,CAAC,EAAEsB,EAAG,KAAK,GAAG,EAE/CtB,GAAwB,MAAM,EAAG,CAAC,EAAE,EAEtC,MACF,IAAK,MACCsB,EAAG,KAAK,IACVrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAG,EAEpCrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAI,EAEvC,MACF,IAAK,gBACCA,EAAG,KAAK,IACVpB,GAAsB,MAAM,EAAG,CAAC,EAAEoB,EAAG,KAAK,GAAG,EAE7CpB,GAAsB,MAAM,EAAG,CAAC,EAAE,EAEpC,MACF,IAAK,yBACCoB,EAAG,KAAK,IACVnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAG,EAEpDnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAI,EAEvD,MACF,QACF,CACF,EAEMhB,GAAY,OAAO,SAAa,IAAe,UAAU,eAAqC,IAAM,OAE7FC,GAAgC,SAA0B,CACrE,GAAsCjB,GAAQ,EAAG,CAC/C,GAAIG,GACF,OAEF,GAAID,GACF,MAAM,IAAI,MAAM,0CAA4C,EAE9D,GAAIE,GACF,MAAM,IAAI,MAAM,uCAAyC,EAG3D,OAAAF,GAAe,GAGX6B,GAAI,KAAK,YAAc,QACrBf,IAAaA,GAAU,QAAQ,OAAO,IAAM,IAC9Ce,GAAI,KAAK,UAAYf,GAAU,OAAO,EAAG,CAAEA,GAAW,YAAY,GAAG,EAAI,CAAC,GAIvE,IAAI,QAAc,CAACiB,EAASC,IAAW,CAC5CjC,IAAa,UAAU,EAEvB,IAAMkC,EAAY,IAAI,gBAAgB,IAAI,KACtC,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAC9BlC,GAAc,IAAI,OAAOkC,EAAW,CAAC,KAAM,uBAAuB,CAAC,EACnElC,GAAY,QAAW+B,GAAmBE,EAAOF,CAAE,EACnD/B,GAAY,UAAYc,GACxB,IAAI,gBAAgBoB,CAAS,EAC7B9B,GAAoB,CAAC4B,EAASC,CAAM,EACpC,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAKL,GAAI,IAAI,EACjE9B,GAAY,YAAYmC,CAAO,CACjC,CAAC,CAEH,KACE,QAAOC,GAAsBN,GAAI,IAAI,CAEzC,EAEab,GAAoB,MAAMa,GAA4B,CACjE,GAAsC/B,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5C5B,GAAmB,CAAC2B,EAASC,CAAM,EACnC,IAAME,EAA0B,CAAC,KAAM,WAAY,GAAKL,CAAG,EAC3D9B,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAED,MAAWE,GAAYP,CAAG,CAE9B,EAEaZ,GAAwB,MAAMoB,GACHvC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAA+B,CAACmB,EAASC,IAAW,CAC7D3B,GAA+B,KAAK,CAAC0B,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,MAAAG,CAAK,CAAC,EACtEtC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,GAEWpB,GAAsBoB,CAAK,EAI9BnB,GAAwB,MAAMoB,EAAkCC,IAEjCzC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnE1B,GAA+B,KAAK,CAACyB,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,UAAAI,EAAW,QAAAC,CAAO,CAAC,EACnFxC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWhB,GAAsBoB,EAAWC,CAAO,EAI/CpB,GACT,MAAMkB,EAAmBE,IAAoF,CAC/G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAIyC,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAA3B,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnEzB,GAAuB,KAAK,CAACwB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,SAAU,GAAK,CAAC,MAAAG,EAAO,QAAAE,CAAO,CAAC,EACtExC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,CACH,KACE,QAAYlB,GAAckB,EAAOE,CAAO,CAE5C,EAEanB,GAAiB,MAAMoB,GAAqC,CACvE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CxB,GAAwB,KAAK,CAACuB,EAASC,CAAM,CAAC,EAC9C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAKM,CAAS,EAChEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEId,GAAeoB,CAAS,CAEjC,EAEanB,GAAM,MACfmB,EAAmBC,EAAwBC,EAA0BC,EACrEC,EAAqCL,IAAoE,CAC3G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAI4C,EAAO,KAAKG,GAAKA,EAAE,CAAC,IAAM,KAAK,EACjC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAID,EAAQ,KAAKC,GAAKA,CAAC,EACrB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAjC,GAAa,EACN,IAAI,QAAsC,CAACmB,EAASC,IAAW,CACpEvB,GAAa,KAAK,CAACsB,EAASC,CAAM,CAAC,EACnC,IAAMc,EAAqBJ,EACrBR,EACF,CAAC,KAAM,MAAO,GAAK,CAAC,UAAAM,EAAW,aAAAC,EAAc,OAAQK,EAAoB,cAAAH,EAAe,QAAAJ,CAAO,CAAC,EACpGxC,GAAa,YAAYmC,EAAca,GAA2BD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYzB,GAAImB,EAAWC,EAAcC,EAAQC,EAAeC,EAASL,CAAO,CAEpF,EAEajB,GAAe,MAAMkB,GAAqC,CACrE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CtB,GAAsB,KAAK,CAACqB,EAASC,CAAM,CAAC,EAC5C,IAAME,EAA0B,CAAC,KAAM,gBAAiB,GAAKM,CAAS,EACtEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEIZ,GAAakB,CAAS,CAE/B,EAEajB,GAAsB,SACKzB,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAiB,CAACmB,EAASC,IAAW,CAC/CrB,GAA6B,KAAK,CAACoB,EAASC,CAAM,CAAC,EACnD,IAAME,EAA0B,CAAC,KAAM,wBAAwB,EAC/DnC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWX,GAAoB,IC/QpC,IAUIyB,GAESC,GAWAC,GAiBAC,GAxCbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAIaP,GAAuB,CAACQ,EAAgBC,IAA0C,CAC7F,OAAQD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAC,UAAWA,EAAO,SAAS,EAAG,YAAY,EAC/E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQC,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaR,GAAwBO,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIE,GAAOF,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMG,EAAWH,EAAO,CAAC,EACzB,GAAI,CAACI,GAAyBD,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAC,UAAAE,EAAW,SAAAC,EAAU,QAAAC,CAAO,EAAIP,EAAO,CAAC,EAC/C,OAAOE,GAAO,cAAcG,EAAW,CAAC,SAAAF,EAAU,KAAMH,EAAO,CAAC,EAAG,SAAAM,EAAU,QAAAC,CAAO,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BP,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaN,GAAN,KAA8E,CAMnF,MAAM,sBAAsBc,EAA8C,CAGxE,IAAMC,EAAW,MAAM,MAAMD,CAAI,EACjC,GAAIC,EAAS,SAAW,IACtB,MAAM,IAAI,MAAM,yBAAyBD,CAAI,EAAE,EAEjD,IAAME,EAAc,MAAMD,EAAS,YAAY,EAC/C,OAAOE,GAAsB,IAAI,WAAWD,CAAW,CAAC,CAC1D,CAEA,MAAM,UAAUE,EAAiCC,EAA0D,CASzG,GARM,MAAMC,GAAoB,IACzBvB,KACHA,GAA+BwB,GAAkBC,EAAG,GAEtD,MAAMzB,GACNA,GAA+B,QAG7B,OAAOqB,GAAiB,SAC1B,GAAI,OAAO,QAAY,KAAe,QAAQ,UAAY,QAAQ,SAAS,KAAM,CAE/E,IAAMK,EAAQ,KAAM,SAASL,CAAY,EACzC,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMM,GAAcD,EAAOJ,CAAO,CAC1F,KAAO,CAGL,IAAMM,EAAmC,MAAM,KAAK,sBAAsBP,CAAY,EAEtF,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMQ,GAAsBD,EAAWN,CAAO,CACtG,KAEA,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMK,GAAcN,EAAcC,CAAO,CAEnG,CAEA,MAAM,SAAyB,CAC7B,OAAOQ,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IAAIC,EAAiCC,EAAqCV,EACzC,CACrC,IAAMW,EAAuB,CAAC,EACxBC,EAAyB,CAAC,EAChC,OAAO,QAAQH,CAAK,EAAE,QAAQI,GAAO,CACnC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,WAAW,QAAQD,CAAI,EAC1C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBD,CAAI,GAAG,EAE3CH,EAAW,KAAKxB,CAAM,EACtByB,EAAa,KAAKG,CAAK,CACzB,CAAC,EAED,IAAMC,EAAkC,CAAC,EACnCC,EAA0B,CAAC,EACjC,OAAO,QAAQP,CAAO,EAAE,QAAQG,GAAO,CACrC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,YAAY,QAAQD,CAAI,EAC3C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBD,CAAI,GAAG,EAE5CE,EAAY,KAAK7B,CAAM,EACvB8B,EAAc,KAAKF,CAAK,CAC1B,CAAC,EAED,IAAMG,EACFP,EAAW,IAAI,CAACQ,EAAGC,IAAMzC,GAAqBwC,EAAG,IAAM,UAAU,KAAK,WAAWP,EAAaQ,CAAC,CAAC,CAAC,GAAG,CAAC,EACnGC,EAAUL,EAAY,IACxB,CAACG,EAAGC,IAAMD,EAAIxC,GAAqBwC,EAAG,IAAM,WAAW,KAAK,YAAYF,EAAcG,CAAC,CAAC,CAAC,GAAG,EAAI,IAAI,EAElGE,EAAU,MAAMC,GAAI,KAAK,UAAWX,EAAcM,EAAQD,EAAeI,EAASrB,CAAO,EAEzFwB,EAAuC,CAAC,EAC9C,QAASJ,EAAI,EAAGA,EAAIE,EAAQ,OAAQF,IAClCI,EAAU,KAAK,YAAYP,EAAcG,CAAC,CAAC,CAAC,EAAIJ,EAAYI,CAAC,GAAKxC,GAAqB0C,EAAQF,CAAC,CAAC,EAEnG,OAAOI,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdC,GAAa,KAAK,SAAS,CAClC,CACF,ICxIA,IAeaC,GAmBAC,GAlCbC,GAAAC,EAAA,kBAIAC,KAEAC,KACAC,KAQaN,GAAkB,IAAY,CAazC,IAZI,OAAOO,GAAI,KAAK,aAAgB,UAAYA,GAAI,KAAK,YAAc,KACrEA,GAAI,KAAK,YAAc,GAGrB,OAAOA,GAAI,KAAK,MAAS,YAC3BA,GAAI,KAAK,KAAO,IAGd,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,GAAI,KAAK,UAAU,GAAKA,GAAI,KAAK,YAAc,EAAG,CACjH,IAAMC,EAAqB,OAAO,UAAc,IAAc,SAAK,EAAE,OAAS,UAAU,oBACxFD,GAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAMC,GAAsB,GAAK,CAAC,CAAC,CAC5E,CACF,EAEaP,GAAN,KAAuD,CAC5D,MAAM,MAAsB,CAE1BD,GAAgB,EAGhB,MAAMS,GAA8B,CACtC,CAKA,MAAM,8BAA8BC,EAAiCC,EAChC,CACnC,IAAMC,EAAU,IAAIC,GACpB,aAAMD,EAAQ,UAAUF,EAAcC,CAAO,EACtC,QAAQ,QAAQC,CAAO,CAChC,CACF,ICpDA,IAAAE,GAAA,GAAAC,GAAAD,GAAA,iBAAAE,KAAA,IAIaA,GAJbC,GAAAC,EAAA,kBAGAC,KACaH,GAAc,IAAII,KCI/BC,KACAA,KAGAA,KCNO,IAAMC,GAAU,iCDIvB,IAAOC,GAAQC,GAUe,CAC5B,IAAMC,EAA4C,cAAoC,YAEpD,OAAO,UAAc,KAAe,UAAU,KAC9EC,GAAgB,SAAUD,EAAa,CAAC,EAE1CC,GAAgB,MAAOD,EAAa,EAAE,EACtCC,GAAgB,OAAQD,EAAa,EAAE,EAErCC,GAAgB,UAAWD,EAAa,CAAC,EACzCC,GAAgB,QAASD,EAAa,CAAC,CAE3C,CAEA,OAAO,eAAeE,GAAI,SAAU,MAAO,CAAC,MAAOC,GAAS,WAAY,EAAI,CAAC",
  "names": ["backends", "backendsSortedByPriority", "registerBackend", "resolveBackend", "init_backend_impl", "__esmMin", "name", "backend", "priority", "currentBackend", "i", "backendHints", "backendNames", "errors", "backendName", "backendInfo", "isInitializing", "e", "init_backend", "__esmMin", "init_backend_impl", "version", "init_version", "__esmMin", "logLevelValue", "env", "init_env_impl", "__esmMin", "init_version", "version", "value", "env", "init_env", "__esmMin", "init_env_impl", "tensorToDataURL", "tensorToImageData", "init_tensor_conversion_impl", "__esmMin", "tensor", "options", "canvas", "pixels2DContext", "width", "height", "inputformat", "norm", "normMean", "normBias", "stride", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "j", "R", "G", "A", "image", "channels", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "bufferToTensor", "tensorFromImage", "tensorFromTexture", "tensorFromGpuBuffer", "tensorFromPinnedBuffer", "init_tensor_factory_impl", "__esmMin", "init_tensor_impl", "buffer", "options", "height", "width", "norm", "normMean", "normBias", "inputformat", "outputformat", "stride", "float32Data", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "Tensor", "image", "isHTMLImageEle", "isImageDataEle", "isImageBitmap", "isString", "data", "bufferToTensorOptions", "canvas", "pixels2DContext", "tempCanvas", "resolve", "reject", "context", "newImage", "img", "texture", "download", "dispose", "dims", "gpuBuffer", "dataType", "type", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "isBigIntChecked", "checkBigInt", "init_tensor_impl_type_mapping", "__esmMin", "isBigInt64ArrayAvailable", "isBigUint64ArrayAvailable", "calculateSize", "tensorReshape", "init_tensor_utils_impl", "__esmMin", "init_tensor_impl", "dims", "size", "i", "dim", "tensor", "Tensor", "Tensor", "init_tensor_impl", "__esmMin", "init_tensor_conversion_impl", "init_tensor_factory_impl", "init_tensor_impl_type_mapping", "init_tensor_utils_impl", "arg0", "arg1", "arg2", "checkBigInt", "type", "dims", "expectedTypedArrayConstructor", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "data", "maybeDims", "typedArrayConstructor", "firstElementType", "mappedType", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "size", "calculateSize", "image", "options", "tensorFromImage", "texture", "tensorFromTexture", "gpuBuffer", "tensorFromGpuBuffer", "buffer", "tensorFromPinnedBuffer", "tensorToDataURL", "tensorToImageData", "releaseData", "tensorReshape", "Tensor", "init_tensor", "__esmMin", "init_tensor_impl", "InferenceSession", "init_inference_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_InferenceSession", "handler", "feeds", "arg1", "arg2", "fetches", "options", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "arg0", "arg3", "filePathOrUint8Array", "buffer", "byteOffset", "byteLength", "backendHints", "i", "resolveBackend", "InferenceSession", "init_inference_session", "__esmMin", "init_inference_session_impl", "init_onnx_value", "__esmMin", "noBackendErrMsg", "TrainingSession", "init_training_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_TrainingSession", "handler", "trainingOptions", "sessionOptions", "evalModel", "optimizerModel", "options", "backendHints", "i", "backend", "resolveBackend", "feeds", "arg1", "arg2", "fetches", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "_array", "_trainableOnly", "TrainingSession", "init_training_session", "__esmMin", "init_training_session_impl", "esm_exports", "__export", "InferenceSession", "Tensor", "TrainingSession", "env", "registerBackend", "init_esm", "__esmMin", "init_backend", "init_env", "init_inference_session", "init_tensor", "init_onnx_value", "init_training_session", "fs_exports", "__export", "readFile", "init_fs", "__esmMin", "path_exports", "__export", "join", "init_path", "__esmMin", "require_ort_wasm_simd_jsep", "__commonJSMin", "exports", "module", "ortWasm", "_scriptDir", "moduleArg", "d", "aa", "h", "a", "b", "c", "e", "g", "k", "l", "t", "m", "p", "n", "u", "w", "r", "f", "q", "ba", "ca", "x", "y", "da", "z", "ea", "A", "B", "C", "D", "fs", "fa", "ha", "E", "F", "noExitRuntime", "H", "I", "J", "K", "L", "M", "N", "O", "P", "ia", "ja", "ka", "la", "ma", "na", "oa", "Q", "pa", "R", "qa", "S", "ra", "sa", "ta", "ua", "va", "T", "wa", "U", "v", "xa", "ya", "za", "Aa", "Ba", "Ca", "Da", "Ea", "Fa", "V", "Ga", "Ha", "Ja", "Ia", "Ka", "La", "Na", "Pa", "Oa", "Qa", "Ra", "Sa", "Ta", "Ua", "Ma", "G", "W", "Va", "X", "Y", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "kb", "jb", "lb", "mb", "nb", "ob", "Z", "pb", "qb", "require_worker_threads", "__commonJSMin", "require_perf_hooks", "__commonJSMin", "os_exports", "__export", "cpus", "init_os", "__esmMin", "require_ort_wasm_simd_threaded_jsep", "__commonJSMin", "exports", "module", "ortWasmThreaded", "_scriptDir", "moduleArg", "d", "l", "n", "u", "v", "aa", "z", "ba", "A", "ca", "da", "ea", "fa", "ha", "B", "ia", "C", "a", "b", "c", "e", "f", "h", "k", "r", "p", "m", "q", "w", "y", "D", "g", "t", "ja", "ka", "la", "E", "ma", "F", "G", "H", "I", "na", "oa", "J", "pa", "fs", "qa", "ra", "sa", "ta", "K", "L", "noExitRuntime", "M", "N", "ua", "P", "Q", "va", "wa", "xa", "ya", "za", "Aa", "R", "Ba", "S", "Ca", "Da", "Ea", "T", "Fa", "Ga", "Ha", "Ia", "U", "Ja", "V", "x", "Ka", "La", "Ma", "W", "Na", "Oa", "Pa", "Qa", "X", "Sa", "Ra", "Ta", "Ua", "Va", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "lb", "mb", "nb", "ob", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "wb", "xb", "Y", "yb", "zb", "Ab", "Bb", "Db", "Cb", "Eb", "Fb", "Hb", "Gb", "Ib", "Jb", "Kb", "Lb", "Nb", "Mb", "Ob", "Pb", "Qb", "Rb", "Sb", "Tb", "Vb", "Wb", "Xb", "Yb", "Zb", "$b", "Ub", "O", "ac", "bc", "cc", "Z", "dc", "ec", "fc", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "rc", "sc", "vc", "tc", "uc", "wc", "xc", "yc", "zc", "require_ort_wasm_threaded_worker", "__commonJSMin", "exports", "module", "ortWasmFactory", "ortWasmFactoryThreaded", "wasm", "initialized", "initializing", "aborted", "isMultiThreadSupported", "isSimdSupported", "getWasmFileName", "initializeWebAssembly", "getInstance", "init_wasm_factory", "__esmMin", "useSimd", "useThreads", "flags", "timeout", "numThreads", "simd", "wasmPaths", "wasmPrefixOverride", "wasmFileName", "wasmPathOverride", "isTimeout", "tasks", "resolve", "reject", "factory", "config", "fileName", "scriptDirectory", "prefix", "scriptSourceCode", "module", "what", "allocWasmString", "iterateExtraOptions", "checkLastError", "init_wasm_utils", "__esmMin", "init_wasm_factory", "data", "allocs", "wasm", "getInstance", "dataLength", "dataOffset", "options", "prefix", "seen", "handler", "key", "value", "name", "message", "stack", "paramsOffset", "errorCode", "errorMessagePointer", "errorMessage", "setRunOptions", "init_run_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "options", "wasm", "getInstance", "runOptionsHandle", "allocs", "runOptions", "tagDataOffset", "allocWasmString", "checkLastError", "iterateExtraOptions", "key", "value", "keyDataOffset", "valueDataOffset", "e", "alloc", "getGraphOptimzationLevel", "getExecutionMode", "appendDefaultOptions", "setExecutionProviders", "setSessionOptions", "init_session_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "graphOptimizationLevel", "executionMode", "options", "session", "ep", "sessionOptionsHandle", "executionProviders", "allocs", "epName", "webnnOptions", "keyDataOffset", "allocWasmString", "valueDataOffset", "getInstance", "checkLastError", "webgpuOptions", "epNameDataOffset", "wasm", "sessionOptions", "logIdDataOffset", "logSeverityLevel", "logVerbosityLevel", "optimizedModelFilePathOffset", "name", "value", "nameOffset", "iterateExtraOptions", "key", "e", "alloc", "tensorDataTypeStringToEnum", "tensorDataTypeEnumToString", "getTensorElementSize", "tensorTypeToTypedArrayConstructor", "logLevelStringToEnum", "isGpuBufferSupportedType", "dataLocationStringToEnum", "init_wasm_common", "__esmMin", "type", "typeProto", "dateType", "logLevel", "location", "logLevelPrefix", "doLog", "configLogLevel", "debug", "configureLogger", "LOG", "LOG_DEBUG", "init_log", "__esmMin", "init_wasm_common", "level", "message", "$configLogLevel", "$debug", "logLevel", "msg", "messageLevel", "logLevelStringToEnum", "configLevel", "args", "createView", "init_tensor_view", "__esmMin", "init_wasm_common", "dataBuffer", "type", "tensorTypeToTypedArrayConstructor", "init_types", "__esmMin", "calcNormalizedBufferSize", "guid", "createNewGpuDataId", "downloadGpuData", "GpuDataManagerImpl", "createGpuDataManager", "init_gpu_data_manager", "__esmMin", "init_log", "init_types", "size", "backend", "gpuBuffer", "originalSize", "getTargetBuffer", "bufferSize", "gpuReadBuffer", "commandEncoder", "arrayBuffer", "targetBuffer", "id", "data", "srcArrayBuffer", "srcOffset", "srcLength", "gpuDataCache", "gpuBufferForUploading", "LOG_DEBUG", "sourceId", "destinationId", "sourceGpuDataCache", "destinationGpuDataCache", "buffer", "previousBuffer", "usage", "isStorage", "isUniform", "freeBuffers", "buffers", "gpuData", "cachedData", "storage", "args", "AttributeWithCacheKeyImpl", "createAttributeWithCacheKey", "init_attribute_with_cache_key", "__esmMin", "attribute", "name", "MatMulUtil", "BroadcastUtil", "ShapeUtil", "PoolConvUtil", "GemmUtil", "MIN_CLIP", "MAX_CLIP", "init_util", "__esmMin", "a", "b", "adims", "bdims", "isMatMul", "arank", "brank", "crank", "cdims", "cShapeMatMul", "i", "aLen", "bLen", "shape", "finalShape", "inputRank", "finalRank", "_ShapeUtil", "dims", "axis", "start", "end", "size", "rank", "strides", "tensorRank", "axes", "x", "perm", "v", "pad", "shape1", "shape2", "_PoolConvUtil", "isGlobalOperator", "inputDims", "kernelShape", "dilations", "pads", "dim", "isChannelLast", "autoPad", "outputDims", "filterDims", "inSize", "stride", "dilation", "kernel", "padHeadIndex", "padTailIndex", "dkernel", "padNeeded", "leftShape", "transLeft", "rightShape", "transRight", "biasShape", "M", "K", "N", "kDim", "WORKGROUP_SIZE", "getWgslMappedType", "tensorTypeToWsglStorageType", "createTensorShapeVariables", "getMaxComponents", "fillVector", "castToF32", "sumVector", "createIndicesHelper", "inputVariable", "outputVariable", "ShaderHelperImpl", "createShaderHelper", "getBroadcastDims", "enableShapesUniforms", "init_common", "__esmMin", "init_wasm_common", "init_util", "type", "components", "mappedType", "dims", "ShapeUtil", "size", "dataType", "value", "name", "tensorType", "shapeOrRank", "isInput", "useUniform", "rank", "rankIdentity", "indicesType", "valueType", "storageType", "normalizeDim", "dim", "implementationUsed", "uniformPrefix", "shape", "strides", "o2iSnippet", "i", "offsetToIndicesImplementation", "offsetToIndices", "varOffset", "offsets", "indicesToOffsetImplementation", "indicesToOffset", "varIndices", "indices", "init", "indicesGet", "idx", "indicesSet", "broadcastedIndicesToOffsetImplementation", "broadcastedIndicesToOffset", "output", "implKey", "setByOffset", "offset", "getByOffset", "getByIndicesImplementation", "getImplementation", "functionParams", "dimsParams", "get", "normalizedIndices", "getByIndices", "setByIndicesImplementation", "setImplementation", "impls", "impl", "indicesAndValue", "normalizedDispatchGroup", "workgroupSize", "workgroupSizeX", "workgroupSizeY", "workgroupSizeZ", "is1DimensionDispatch", "paramList", "globalIdxDefinition", "variable", "bindingIndex", "access", "variables", "v", "uniformSnippets", "dispatchGroup", "inShape", "outShape", "inRank", "a", "validateInputs", "getAdjustedPerm", "getOutputShape", "permFunctionBody", "createTransposeProgramInfo", "transpose", "parseTransposeAttributes", "init_transpose", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputRank", "perm", "inputShape", "ShapeUtil", "rank", "input", "output", "reverseFunc", "i", "inputTensor", "permAttr", "inputDataType", "useShapesUniforms", "enableShapesUniforms", "outputShape", "outShapeOrRank", "inShapeOrRank", "outputVariable", "inputVariable", "getShaderSource", "shaderHelper", "outputSize", "createTensorShapeVariables", "context", "attributes", "createAttributeWithCacheKey", "reduceOps", "reduceSharedOps", "reduceInitValues", "reduceOutputValues", "getInnerMostAxes", "computeOutAndReduceShapes", "expandShapeToKeepDim", "areAxesInnerMostDims", "getAxesPermutation", "createReduceSharedProgramInfo", "reduceCommon", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "init_reduce_shared", "__esmMin", "init_util", "init_common", "init_reduce", "init_transpose", "numInnerAxes", "rank", "res", "i", "shape", "axes", "outputShape", "dim", "reduceShape", "expandShape", "shapeIdx", "axis", "name", "shaderCache", "inputs", "reduceType", "outputDataType", "inputShape", "outputSize", "ShapeUtil", "reduceSize", "input", "inputVariable", "output", "outputVariable", "workgroupSize", "sharedMemorySnippet", "shaderHelper", "context", "attributes", "updatedAttributes", "createReduceAttributesFromInputs", "updatedAxes", "s", "normalizeAxes", "permutedAxes", "createTransposeProgramInfo", "finalOutputShape", "validateInputs", "noOp", "createReduceProgramInfo", "createReduceAttributesFromInputs", "runReduceProgram", "reduceLogSumNaive", "reduceL1Naive", "reduceL2Naive", "reduceLogSumExpNaive", "reduceMaxNaive", "reduceMeanNaive", "reduceMinNaive", "reduceProdNaive", "reduceSumNaive", "reduceSumSquareNaive", "useNaiveReduceMethod", "reduceMean", "reduceL1", "reduceL2", "reduceLogSumExp", "reduceMax", "reduceMin", "reduceProd", "reduceSum", "reduceSumSquare", "reduceLogSum", "parseReduceAttributes", "init_reduce", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "init_reduce_shared", "inputs", "input", "name", "shaderCache", "reduceOp", "axesInput", "outputDataType", "keepDims", "noopWithEmptyAxes", "outputShape", "inputShape", "axes", "ShapeUtil", "reduceOnAllAxes", "d", "i", "idxCopy", "inputVariable", "output", "outputVariable", "ops", "inputOffsetAssignment", "initinputOffsetLet", "initinputOffsetVar", "initinputOffset", "reduceOps", "k", "l", "outputSize", "shaderHelper", "attributes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "_output", "idxZero", "size", "shape", "reduceSize", "dim", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "validateInputs", "createArgMinMaxAttributesFromInputs", "argMin", "argMax", "parseArgMinMaxAttributes", "init_argminmax", "__esmMin", "init_wasm_common", "init_attribute_with_cache_key", "init_reduce", "inputs", "attributes", "createAttributeWithCacheKey", "context", "argMinMaxOp", "input", "output", "axes", "idxZero", "k", "updatedAttributes", "createReduceProgramInfo", "validateInputs", "createBiasAddProgramInfo", "biasAdd", "init_bias_add", "__esmMin", "init_util", "init_common", "inputs", "outputShape", "channels", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "bias", "residual", "output", "outputVariable", "shaderHelper", "context", "createElementwiseProgramShader", "createElementwiseProgramInfo", "abs", "acos", "acosh", "asin", "asinh", "atan", "atanh", "parseCastAttributes", "cast", "clipV10", "generateClipAttributesFromInputs", "clip", "ceil", "cos", "cosh", "parseAlphaAttributes", "elu", "erfImpl", "erf", "exp", "floor", "gelu", "leakyRelu", "not", "neg", "reciprocal", "relu", "sigmoid", "sin", "sinh", "sqrt", "tan", "tanh", "thresholdedRelu", "log", "init_unary_op", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "shaderHelper", "datasize", "inputDataType", "outputDataType", "funcCall", "additionalImplementation", "vecSize", "expression", "input", "inputVariable", "output", "outputVariable", "name", "cacheKey", "ShapeUtil", "inputTensors", "context", "attributes", "createAttributeWithCacheKey", "func", "dataType", "tensorTypeToWsglStorageType", "inputs", "min", "MIN_CLIP", "max", "MAX_CLIP", "a", "varType", "validateInputs", "createBiasSplitGeluProgramInfo", "biasSplitGelu", "init_bias_split_gelu", "__esmMin", "init_util", "init_common", "init_unary_op", "inputs", "outputShape", "input", "inputVariable", "bias", "output", "outputVariable", "outputSize", "ShapeUtil", "shaderHelper", "erfImpl", "context", "createBinaryOpProgramShader", "createBinaryOpProgramInfo", "runBinaryOp", "add", "div", "equal", "mul", "pow", "sub", "greater", "less", "greaterOrEqual", "lessOrEqual", "init_binary_op", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "dimsA", "dimsB", "dimsOutput", "vectorize", "doBroadcast", "funcCall", "typeA", "typeB", "typeOutput", "additionalImplementation", "outputSize", "ShapeUtil", "vecSize", "expressionScalar", "expressionVector", "a", "b", "broadcastImpl", "output", "outputVariable", "inputVariable", "calcOffsetImpl", "dims", "strides", "offsets", "i", "idx", "assignment", "isAOneElement", "isBOneElement", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "name", "cacheKey", "outputDataType", "isBroadcast", "outputShape", "calculatedShape", "BroadcastUtil", "sharedDimension", "dimA", "dimB", "context", "type", "validateInputs", "calculateInputIndexImpl", "assignOutputData", "createConcatProgramInfo", "concat", "parseConcatAttributes", "init_concat", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputType", "inputDimensionality", "input", "numberOfTensors", "output", "codeLines", "i", "returnSnippet", "axis", "inputShape", "adjustedAxis", "outputShape", "dataNShape", "axisIndex", "outputSize", "ShapeUtil", "sizeInConcatAxis", "inputVars", "dataType", "previousSum", "inputVariable", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "typeSnippet", "activationFnSnippet", "biasActivationSnippet", "init_activation_util", "__esmMin", "component", "dataType", "activation", "_hasPreluActivationWeights", "_packed", "_coordsLength", "hasBias", "utilFunctions", "init_conv_util", "__esmMin", "getActivationSnippet", "parseInternalActivationAttributes", "init_fuse_utils", "__esmMin", "init_util", "attributes", "isVec4", "activation", "clipMin", "clipMax", "MIN_CLIP", "MAX_CLIP", "writeDataToSubAVec4Snippet", "calculateResultSnippet", "makeMatMulPackedVec4Source", "writeDataToSubASnippet", "readDataFromSubASnippet", "makeMatMulPackedSource", "matMulReadWriteFnSource", "createMatmulProgramInfo", "init_matmul_packed_webgpu", "__esmMin", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "transpose", "batchDims", "transposeA", "innerElementSize", "workPerThread", "workgroupSize", "type", "tileInner", "splitK", "splitedDimInner", "tileAOuter", "tileBOuter", "tileAWidth", "tileAHight", "rowPerThreadB", "sequentialAccessByThreads", "rowPerThreadA", "colPerThreadA", "matmulSnippet", "component", "hasBias", "applyActivation", "variables", "batchShapes", "isChannelsLast", "batchAShape", "batchBShape", "batchShape", "batchVariable", "aVariable", "bVariable", "outputVariable", "broadCastADims", "getBroadcastDims", "broadCastBDims", "dataType", "tensorTypeToWsglStorageType", "getAIndices", "aRank", "batchRank", "resStr", "i", "j", "getBIndices", "bRank", "typeSnippet", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "aShape", "bShape", "outerDimsA", "outerDimsB", "outerDims", "inputVariable", "batchSize", "ShapeUtil", "dimAOuter", "dimInner", "dimBOuter", "isVec4", "activationFunction", "getActivationSnippet", "elementsPerThread", "dispatch", "components", "A", "B", "output", "inputVariables", "declareFunctions", "biasComponents", "getShaderSource", "shaderHelper", "conv2dCommonSnippet", "createConv2DMatMulProgramInfo", "init_conv2d_mm_webgpu", "__esmMin", "init_log", "init_util", "init_common", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "fitAOuter", "fitBOuter", "fitInner", "addBias", "activation", "hasPreluActivationWeights", "innerElementSizeX", "innerElementSizeW", "innerElementSize", "dataType", "getXSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readXSnippet", "typeSnippet", "sampleX", "sampleW", "resType", "aType", "bType", "activationFnSnippet", "biasActivationSnippet", "inputs", "attributes", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileAOuter", "tileBOuter", "tileInner", "elementsSize", "t", "tensorTypeToWsglStorageType", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createGroupedConvProgramInfo", "init_conv_grouped", "__esmMin", "init_util", "init_common", "init_conv", "init_fuse_utils", "inputs", "attributes", "squeezeOutputShapeFunction", "hasBias", "processBias", "xShape", "wShape", "outputChannelsPerGroup", "activationFunction", "applyActivation", "getActivationSnippet", "isChannelLast", "outputShape", "calculateOutputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "x", "inputVariable", "w", "inputVars", "getShaderSource", "shaderHelper", "calculateOutputShape", "weightTransposeAttribute", "validateInputs", "getAdjustedConvAttributes", "parseConvAttributes", "conv2d", "conv1d", "conv", "init_conv", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_conv2d_mm_webgpu", "init_matmul_packed_webgpu", "init_conv_grouped", "init_fuse_utils", "init_transpose", "inputShape", "kernelShape", "dilations", "adjustPads", "strides", "isChannelLast", "batchSize", "inputSpatialShape", "spatialRank", "outChannels", "dilatedKernelShape", "v", "i", "outputShape", "inputs", "attributes", "dataChannel", "filterInChannel", "pads", "PoolConvUtil", "newAttributes", "activationAttributes", "parseInternalActivationAttributes", "format", "autoPad", "group", "wIsConst", "createAttributeWithCacheKey", "context", "adjustedAttributes", "createGroupedConvProgramInfo", "isChannelsLast", "hasBias", "inputHeight", "inputWidth", "inputChannels", "weightHeight", "weightWidth", "outHeight", "outWidth", "sameSize", "batch", "xReshaped", "wReshaped", "matmulOutputShape", "matmulInputs", "transposedWeight", "createTransposeProgramInfo", "sharedDim", "createMatmulProgramInfo", "sequentialAccessByThreads", "convInputs", "dimAOuter", "dimBOuter", "dimInner", "createConv2DMatMulProgramInfo", "conv2dTransposeCommonSnippet", "createConv2DTransposeMatMulProgramInfo", "init_conv_backprop_mm_webgpu", "__esmMin", "init_log", "init_util", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "addBias", "activation", "hasPreluActivationWeights", "innerElementSize", "type", "typeSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readASnippet", "sampleA", "sampleW", "activationFnSnippet", "biasActivationSnippet", "inputs", "attributes", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileInner", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createConvTranspose2DOpProgramShaderSource", "createConvTranspose2DProgramInfo", "init_conv_backprop_webgpu", "__esmMin", "init_log", "init_util", "init_common", "shaderHelper", "inputs", "attributes", "outputShape", "hasBias", "is1DimensionDispatch", "isVec4", "dataType", "isChannelsLast", "rowDim", "colDim", "channelDim", "outputSize", "ShapeUtil", "workPerThread", "group", "wShape", "inputChannelsPerGroup", "outputChannelsPerGroup", "declareFunctions", "components", "w", "inputVariable", "dy", "inputVariables", "output", "outputVariable", "codeSnippet4", "codeSnippet", "squeezeOutputShapeFunction", "dispatch", "LOG_DEBUG", "tensorTypeToWsglStorageType", "computeTotalPad", "distributePadding", "calculateOutputShapeAndPads", "getAdjustedConvTransposeAttributes", "parseConvTransposeAttributes", "validateInputs", "weightTransposePerm", "convTranspose2d", "convTranspose1d", "convTranspose", "init_conv_transpose", "__esmMin", "init_attribute_with_cache_key", "init_conv_backprop_mm_webgpu", "init_conv_backprop_webgpu", "init_fuse_utils", "init_transpose", "inDim", "stride", "adj", "kernel", "dilation", "outSize", "totalPad", "autoPad", "pads", "head", "tail", "smallPad", "inputShape", "kernelShape", "dilations", "group", "strides", "isChannelLast", "outputPadding", "outputShape", "spatialRank", "updateOutputShape", "i", "batchSize", "outChannels", "j", "inSize", "attributes", "inputs", "a", "b", "isChannelsLast", "newAttributes", "cacheKey", "activationAttributes", "parseInternalActivationAttributes", "format", "wIsConst", "createAttributeWithCacheKey", "dataChannel", "filterInChannel", "featureMaps", "context", "adjustedAttributes", "hasBias", "createConvTranspose2DProgramInfo", "outHeight", "outWidth", "weightHeight", "weightWidth", "inputChannels", "dimAOuter", "dimBOuter", "dimInner", "sequentialAccessByThreads", "transposedWeight", "createTransposeProgramInfo", "convTransposeInputs", "createConv2DTransposeMatMulProgramInfo", "symbolPattern", "termPattern", "termPatternOnly", "lhsPattern", "lhsPatternOnly", "EinsumTerm", "EinsumEquation", "createEinsumProgramInfo", "einsum", "parseEinsumAttributes", "init_einsum", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputIndex", "symbol", "index", "value", "inputs", "equation", "lhs", "rhs", "inputTerm", "dims", "einsumTerm", "sym", "info", "dimValue", "term", "isInput", "rank", "ellipsis", "ellipsisDims", "nextDim", "indexSymbols", "i", "ellipsisDimLength", "j", "einsumEquation", "dataType", "inputVars", "inputVariable", "outputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "idxCopy", "rhsSymbols", "initProd", "initSum", "updateSum", "reduceOpsSetIndices", "reduceOpsLoopHeaders", "reduceOpsLoopFooters", "reduceOpCompute", "isReduceOpsWithoutLoop", "outputIndex", "indices", "reduceOps", "inputVar", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "validateInputs", "getAdjustedShape", "calculateOutputShape", "createExpandProgramInfo", "expand", "init_expand", "__esmMin", "init_util", "init_common", "inputs", "inputShape", "shape", "shapeIndex", "inputShapeIndex", "shape1", "shape2", "diff", "i", "outputShape", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "validateInputs", "createGatherProgramInfo", "parseGatherAttributes", "gather", "init_gather", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "indicesShape", "inputRank", "axis", "ShapeUtil", "outputShape", "axisDimLimit", "outputSize", "data", "inputVariable", "indices", "output", "outputVariable", "calcDataIndices", "indicesRank", "calcStr", "i", "j", "getShaderSource", "shaderHelper", "createAttributeWithCacheKey", "context", "validateInputs", "createGatherElementsProgramInfo", "parseGatherElementsAttributes", "gatherElements", "init_gather_elements", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "inputOutputDataType", "inputRank", "inputStrides", "ShapeUtil", "inputSize", "indicesShape", "indicesDataType", "indicesSize", "axis", "axisDimLimit", "outputShape", "outputSize", "input", "inputVariable", "indices", "output", "outputVariable", "getShaderSource", "shaderHelper", "i", "createAttributeWithCacheKey", "context", "validateInputs", "offsetC", "createGemmProgramInfo", "gemm", "parseGemmAttributes", "init_gemm", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "m", "n", "dims", "broadcastM", "broadcastN", "offset", "attributes", "aShape", "bShape", "M", "N", "K", "GemmUtil", "outputShape", "outputSize", "ShapeUtil", "line", "dataType", "tensorTypeToWsglStorageType", "calculateAlpha", "calculateC", "inputStorageBuffersDeclarations", "getShaderSource", "shaderHelper", "context", "createAttributeWithCacheKey", "metadata", "createInstanceNormProgramInfo", "computeMean", "createInstanceNormNHWCProgramInfo", "parseInstanceNormAttributes", "instanceNorm", "init_instance_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "xShape", "outputShape", "axis", "normCount", "ShapeUtil", "normSize", "C", "x", "inputVariable", "scale", "bias", "output", "outputVariable", "variables", "dataType", "workgroupSize", "getShaderSource", "shaderHelper", "context", "input", "h", "c", "epsilon", "components", "getMaxComponents", "inputHelper", "scaleHelper", "biasHelper", "WG", "outputType", "sumCastType", "setOutputValue", "var1", "var2", "unitsOfWork", "wgSize", "getMeanShaderSource", "fillVector", "meanValues", "N", "H", "outputSize", "outputHelper", "tensorTypeToWsglStorageType", "scaleType", "scaleCastType", "channelScaleShift", "createAttributeWithCacheKey", "validateInputs", "createLayerNormProgramInfo", "parseLayerNormAttributes", "layerNorm", "init_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "outputCount", "xShape", "scale", "bias", "outputShape", "axis", "ShapeUtil", "normCount", "normSize", "scaleSize", "biasSize", "meanInvStdDevDim", "i", "components", "getMaxComponents", "dataType", "tensorTypeToWsglStorageType", "variables", "inputVariable", "outputVariable", "hasMeanDataOutput", "hasInvStdOutput", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "createAttributeWithCacheKey", "context", "validateInputs", "matMul", "init_matmul", "__esmMin", "init_util", "init_matmul_packed_webgpu", "inputs", "context", "outputShape", "BroadcastUtil", "createMatmulProgramInfo", "validateInputs", "getPadConstant", "getPadReflect", "getPadEdge", "getPadWrap", "getPadSnippet", "generatePadCode", "createPadProgramInfo", "createPadAttributesFromInputs", "pad", "parsePadAttributes", "init_pad", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "validPads", "output", "outputDims", "inputDims", "inputStrides", "pads", "dataType", "constantValue", "inputRank", "block", "i", "attributes", "shaderHelper", "ShapeUtil", "outputSize", "outputVariable", "input", "inputVariable", "padSnippet", "outputShape", "bigInt64Pads", "value", "updatePads", "axes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "mode", "validateInputs", "getAdjustedPoolAttributesAndOutputShape", "generatePoolingCode", "parsePoolCommonAttributes", "createAveragePoolProgramInfo", "parseAveragePoolAttributes", "averagePool", "globalPoolAttributes", "parseGlobalAveragePoolAttributes", "globalAveragePool", "createMaxPoolProgramInfo", "maxPool", "parseMaxPoolAttributes", "parseGlobalMaxPoolAttributes", "globalMaxPool", "init_pool", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "isGlobalOperator", "isChannelsLast", "inputShapeAsChannelFirst", "hasDilations", "kernelShape", "strides", "dilations", "pads", "PoolConvUtil", "outputShapeAsChannelFirst", "newAttributes", "outputShapeAsChannelLast", "shaderHelper", "x", "xShape", "outputShape", "op1", "op2", "start", "inputDims", "dataType", "rank", "outputSize", "ShapeUtil", "output", "outputVariable", "kw", "sw", "pwStart", "pwEnd", "dimIdxW", "codeW", "codeH", "codeHEnd", "kh", "sh", "phStart", "phEnd", "dimIdxH", "dimH", "kernelSize", "kernelStrides", "stridesRank", "padsRank", "hasPads", "sum", "cur", "padCode", "i", "name", "adjustedAttributes", "inputVariable", "countIncludePad", "attr", "createAttributeWithCacheKey", "context", "format", "storageOrder", "validateInputsContent", "createRangeProgramInfo", "range", "init_range", "__esmMin", "init_esm", "init_wasm_common", "init_common", "start", "limit", "delta", "sameStartLimit", "increasingRangeNegativeStep", "decreasingRangePositiveStep", "dataType", "numElements", "outputShape", "outputSize", "output", "outputVariable", "wgslType", "getShaderSource", "shaderHelper", "x", "context", "env", "validateScales", "updateScales", "validateInputs", "getOriginalCoordinateFromResizedCoordinate", "getNearestPixelFromOriginal", "updateRoI", "initOutputShape", "adjustOutputShape", "calculateOriginalIndicesFromOutputIndices", "calculateInputIndicesFromOutputIndices", "checkInputIndices", "bilinearInterpolation", "bicubicInterpolation", "createResizeProgramInfo", "getOpsetVersionFromCustomDataBuffer", "resize", "parseResizeAttributes", "init_resize", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "scales", "attributes", "value", "axes", "rank", "newScales", "index", "inputs", "opsetVersion", "sizes", "roi", "roiInputIndex", "scalesInputIndex", "sizesInputIndex", "coordinateTransferMode", "nearestMode", "roiTmp", "roiLocal", "v", "i", "inputShape", "outputShape", "scaleInPolicy", "adjustedOutputShape", "output", "input", "useExtrapolation", "extrapolationValue", "batchIdx", "heightIdx", "widthIdx", "channelIdx", "cubicCoeffA", "excludeOutside", "createCubicInterpolationFunction", "idx", "direction", "inputTensor", "scalesInput", "roiInput", "outputVariable", "inputVariable", "outputSize", "ShapeUtil", "noScale", "d", "getShaderSource", "shaderHelper", "context", "customDataBuffer", "antialias", "coordinateTransformMode", "keepAspectRatioPolicy", "mode", "createAttributeWithCacheKey", "validateInputs", "createSkipLayerNormProgramInfo", "skipLayerNorm", "parseSkipLayerNormAttributes", "init_skip_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "skip", "gamma", "hiddenSize", "sequenceLength", "beta", "bias", "attributes", "outputCount", "isTraining", "inputShape", "inputSize", "ShapeUtil", "outputShape", "outputSize", "meanInvStdDevDim", "hasBetaInput", "hasBiasInput", "hasMeanOutput", "hasInvStdDevOutput", "hasInputSkipBiasSumOutput", "components", "getMaxComponents", "variables", "inputVariable", "outputVariable", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "context", "epsilon", "createAttributeWithCacheKey", "validateInputs", "readInput", "createSliceAttributesFromInputs", "fixStartEndValues", "calculateInputIndicesImpl", "createSliceProgramInfo", "slice", "parseSliceAttributes", "init_slice", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "_", "idx", "input", "v", "starts", "ends", "axes", "createAttributeWithCacheKey", "value", "index", "inputShape", "steps", "newValue", "output", "outputShape", "inputSize", "ShapeUtil", "step", "start", "i", "end", "signs", "array", "numSteps", "newEnd", "newStart", "axis", "outputTensorInfo", "outputVariable", "inputVariable", "outputSize", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "validateInputs", "createSoftmaxProgramInfo", "softmax", "parseSoftmaxAttributes", "init_softmax", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "dataType", "tensorTypeToWsglStorageType", "shape", "outputSize", "ShapeUtil", "WG", "axis", "cols", "rows", "components", "getMaxComponents", "packedCols", "valueType", "maxVector", "name", "threadMaxDecl", "_shaderHelper", "sumVector", "context", "createAttributeWithCacheKey", "validateInputs", "createSplitAttributesFromInputs", "calculateOutputIndexImpl", "writeBufferDataImpl", "createSplitProgramInfo", "split", "parseSplitAttributes", "init_split", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "splitSizes", "numOutputs", "v", "createAttributeWithCacheKey", "numberOfTensors", "outputs", "codeLines", "i", "returnSnippet", "inputShape", "inputSize", "ShapeUtil", "dataType", "rank", "axis", "adjustedAxis", "input", "inputVariable", "sizeInConcatAxis", "outputsTensorInfo", "outputShapes", "previousSum", "outputShape", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "getRepeats", "validateInputs", "getOutputShape", "createTileProgramInfo", "tile", "init_tile", "__esmMin", "init_wasm_common", "init_util", "init_common", "repeatsTensorView", "inputs", "inputShape", "repeats", "outputShape", "i", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "createWhereOpProgramShader", "createWhereOpProgramInfo", "where", "init_where", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "inputs", "dimsOutput", "isBroadcast", "typeOutput", "outputSize", "ShapeUtil", "vecSize", "output", "outputVariable", "a", "inputVariable", "b", "c", "assignment", "expression", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "expressionC", "dimsA", "dimsB", "dimsC", "outputDataType", "outputShape", "calculatedShape", "BroadcastUtil", "context", "WEBGPU_OP_RESOLVE_RULES", "init_op_resolve_rules", "__esmMin", "init_argminmax", "init_bias_add", "init_bias_split_gelu", "init_binary_op", "init_concat", "init_conv", "init_conv_transpose", "init_einsum", "init_expand", "init_gather", "init_gather_elements", "init_gemm", "init_instance_norm", "init_layer_norm", "init_matmul", "init_pad", "init_pool", "init_range", "init_reduce", "init_resize", "init_skip_layer_norm", "init_slice", "init_softmax", "init_split", "init_tile", "init_transpose", "init_unary_op", "init_where", "abs", "acos", "acosh", "add", "argMax", "parseArgMinMaxAttributes", "argMin", "asin", "asinh", "atan", "atanh", "averagePool", "parseAveragePoolAttributes", "biasAdd", "biasSplitGelu", "cast", "parseCastAttributes", "ceil", "clipV10", "clip", "concat", "parseConcatAttributes", "conv", "parseConvAttributes", "convTranspose", "parseConvTransposeAttributes", "cos", "cosh", "div", "einsum", "parseEinsumAttributes", "elu", "parseAlphaAttributes", "equal", "erf", "exp", "expand", "floor", "gather", "parseGatherAttributes", "gatherElements", "parseGatherElementsAttributes", "gelu", "gemm", "parseGemmAttributes", "globalAveragePool", "parseGlobalAveragePoolAttributes", "globalMaxPool", "parseGlobalMaxPoolAttributes", "greater", "greaterOrEqual", "instanceNorm", "parseInstanceNormAttributes", "layerNorm", "parseLayerNormAttributes", "leakyRelu", "less", "lessOrEqual", "log", "matMul", "maxPool", "parseMaxPoolAttributes", "mul", "neg", "not", "pad", "parsePadAttributes", "pow", "range", "reciprocal", "reduceMin", "parseReduceAttributes", "reduceMean", "reduceMax", "reduceSum", "reduceProd", "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceSumSquare", "relu", "resize", "parseResizeAttributes", "sigmoid", "sin", "sinh", "slice", "parseSliceAttributes", "skipLayerNorm", "parseSkipLayerNormAttributes", "split", "parseSplitAttributes", "sqrt", "softmax", "parseSoftmaxAttributes", "sub", "tan", "tanh", "thresholdedRelu", "tile", "transpose", "parseTransposeAttributes", "where", "ProgramManager", "init_program_manager", "__esmMin", "init_wasm_common", "init_log", "init_common", "backend", "key", "artifact", "buildArtifact", "inputTensorViews", "outputTensorViews", "inputs", "outputs", "dispatchGroup", "uniformBufferBinding", "device", "computePassEncoder", "entries", "input", "output", "bindGroup", "syncData", "kernelId", "kernelInfo", "kernelName", "mappedData", "startTimeU64", "endTimeU64", "startTime", "endTime", "inputShapes", "value", "i", "tensorDataTypeEnumToString", "outputShapes", "programInfo", "normalizedDispatchGroupSize", "extensions", "shaderHelper", "createShaderHelper", "userCode", "code", "shaderModule", "LOG_DEBUG", "computePipeline", "x", "y", "z", "limitPerDimension", "size", "dispatchAverage", "getProgramInputTensorInfoDependencyKey", "getProgramInfoUniqueKey", "WebGpuBackend", "init_backend_webgpu", "__esmMin", "init_log", "init_tensor_view", "init_gpu_data_manager", "init_op_resolve_rules", "init_program_manager", "inputTensors", "inputDependencies", "inputInfos", "i", "type", "rank", "dims", "programInfo", "key", "data", "env", "adapter", "requiredFeatures", "deviceDescriptor", "createGpuDataManager", "ProgramManager", "configureLogger", "ev", "computePassDescriptor", "program", "inputTensorViews", "outputIndices", "createKernelOutput", "createIntermediateOutput", "inputDatas", "gpuData", "artifact", "outputs", "dispatchGroup", "programUniforms", "validatedOutputIndices", "_", "outputTensorViews", "outputDatas", "isTemporary", "isPersistent", "tensorView", "persistentData", "uniformBufferBinding", "currentOffset", "preLength", "offsets", "maxAlignmentOfField", "v", "baseAlignment", "arrayBuffer", "offset", "uniformBufferData", "normalizedDispatchGroup", "LOG_DEBUG", "gpuDataId", "src", "dst", "getTargetBuffer", "size", "ptr", "opType", "kernelId", "attribute", "nodeName", "op", "WEBGPU_OP_RESOLVE_RULES", "context", "errors", "kernel", "kernelEntry", "attributes", "useErrorScope", "e", "err", "sessionId", "index", "buffer", "sessionInputOutputMapping", "previousBuffer", "id", "bufferInfo", "gpuBuffer", "downloadGpuData", "createView", "init_exports", "__export", "init", "TensorViewImpl", "ComputeContextImpl", "init_init", "__esmMin", "init_wasm_common", "init_backend_webgpu", "init_log", "init_util", "_TensorViewImpl", "module", "dataType", "data", "dims", "elementCount", "ShapeUtil", "newDims", "backend", "contextDataOffset", "heapU32", "dataIndex", "inputCount", "inputs", "i", "dim", "d", "program", "inputsOutputsMapping", "mappedInputs", "outputIndices", "createKernelOutput", "index", "createTemporaryOutput", "elementSize", "getTensorElementSize", "bufferSize", "stack", "offset", "e", "env", "WebGpuBackend", "size", "ptr", "src", "dst", "isSourceGpu", "LOG_DEBUG", "gpuDataId", "dataOffset", "name", "kernel", "attribute", "sessionHandle", "errors", "context", "ortEnvInitialized", "getSessionInputOutputCount", "initOrt", "initRuntime", "activeSessions", "isOrtEnvInitialized", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "prepareInputOutputTensor", "run", "endProfiling", "extractTransferableBuffers", "init_wasm_core_impl", "__esmMin", "init_run_options", "init_session_options", "init_wasm_common", "init_wasm_factory", "init_wasm_utils", "sessionHandle", "wasm", "getInstance", "stack", "dataOffset", "checkLastError", "numThreads", "loggingLevel", "env", "logLevelStringToEnum", "initJsep", "model", "modelDataOffset", "modelData", "options", "sessionOptionsHandle", "ioBindingHandle", "allocs", "inputNamesUTF8Encoded", "outputNamesUTF8Encoded", "setSessionOptions", "inputCount", "outputCount", "inputNames", "outputNames", "outputPreferredLocations", "i", "name", "nameString", "location", "bindingState", "l", "dataLocationStringToEnum", "e", "buf", "alloc", "sessionId", "session", "ioBindingState", "tensor", "tensorHandles", "index", "dataType", "dims", "rawData", "dataByteLength", "gpuBuffer", "elementSizeInBytes", "getTensorElementSize", "tensorDataTypeStringToEnum", "a", "b", "data", "dataIndex", "allocWasmString", "dimsOffset", "dimIndex", "d", "inputIndices", "inputTensors", "outputIndices", "outputTensors", "runOptionsHandle", "runOptionsAllocs", "inputTensorHandles", "outputTensorHandles", "inputOutputAllocs", "beforeRunStack", "inputValuesOffset", "inputNamesOffset", "outputValuesOffset", "outputNamesOffset", "setRunOptions", "inputValuesIndex", "inputNamesIndex", "outputValuesIndex", "outputNamesIndex", "handle", "outputPreferredLocationsEncoded", "errorCode", "output", "beforeGetTensorDataStack", "tensorDataOffset", "keepOutputTensor", "type", "tensorDataIndex", "dimsLength", "size", "tensorDataTypeEnumToString", "preferredLocation", "stringData", "offset", "maxBytesToRead", "elementSize", "isGpuBufferSupportedType", "typedArrayConstructor", "tensorTypeToTypedArrayConstructor", "v", "p", "profileFileName", "tensors", "buffers", "require_main", "__commonJSMin", "exports", "module", "isProxy", "proxyWorker", "initializing", "initialized", "aborted", "initWasmCallbacks", "initOrtCallbacks", "createSessionAllocateCallbacks", "createSessionFinalizeCallbacks", "createSessionCallbacks", "releaseSessionCallbacks", "runCallbacks", "endProfilingCallbacks", "isOrtEnvInitializedCallbacks", "ensureWorker", "onProxyWorkerMessage", "scriptSrc", "initializeWebAssemblyInstance", "initializeRuntime", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "run", "endProfiling", "isOrtEnvInitialized", "init_proxy_wrapper", "__esmMin", "init_esm", "init_wasm_core_impl", "init_wasm_factory", "env", "ev", "resolve", "reject", "workerUrl", "message", "initializeWebAssembly", "initRuntime", "model", "modeldata", "options", "sessionId", "inputIndices", "inputs", "outputIndices", "outputs", "t", "serializableInputs", "extractTransferableBuffers", "runtimeInitializationPromise", "encodeTensorMetadata", "decodeTensorMetadata", "OnnxruntimeWebAssemblySessionHandler", "init_session_handler_inference", "__esmMin", "init_esm", "init_proxy_wrapper", "init_wasm_common", "tensor", "getName", "Tensor", "dataType", "isGpuBufferSupportedType", "gpuBuffer", "download", "dispose", "path", "response", "arrayBuffer", "createSessionAllocate", "pathOrBuffer", "options", "isOrtEnvInitialized", "initializeRuntime", "env", "model", "createSession", "modelData", "createSessionFinalize", "releaseSession", "feeds", "fetches", "inputArray", "inputIndices", "kvp", "name", "index", "outputArray", "outputIndices", "inputs", "t", "i", "outputs", "results", "run", "resultMap", "endProfiling", "initializeFlags", "OnnxruntimeWebAssemblyBackend", "init_backend_wasm", "__esmMin", "init_esm", "init_proxy_wrapper", "init_session_handler_inference", "env", "numCpuLogicalCores", "initializeWebAssemblyInstance", "pathOrBuffer", "options", "handler", "OnnxruntimeWebAssemblySessionHandler", "backend_wasm_inference_exports", "__export", "wasmBackend", "init_backend_wasm_inference", "__esmMin", "init_backend_wasm", "OnnxruntimeWebAssemblyBackend", "init_esm", "version", "lib_default", "esm_exports", "wasmBackend", "registerBackend", "env", "version"]
}
